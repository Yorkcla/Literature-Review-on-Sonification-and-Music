"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"5E593WU2","conferencePaper","2011","Stewart, Rebecca; Sandler, Mark","The amblr: A mobile spatial audio music browser","2011 IEEE International Conference on Multimedia and Expo","","","10.1109/ICME.2011.6012203","","Music collections are often visualized in a two-dimensional space to show relationships between songs. Some user inter faces interacting with these two-dimensional maps of songs use spatial auditory display to allow easier access to the au dio content. A common auditory display is to have multiple songs playing simultaneously from differing spatial locations around the user. However, when using this style of interface the sonification of the collection needs to be limited to a lo cal subset of the collection, usually three to six songs. This paper presents the amblr, a spatial audio music browser that allows a user to auralize the collection. It combines effective design from previous work with new approaches to create a novel interface. This allows for a more intuitive navigation of a virtual space populated by a large collection songs without relying on textual metadata.","2011-07","2023-07-06 01:56:57","2023-07-06 01:56:57","","1-6","","","","","","The amblr","","","","","","","","","","","","IEEE Xplore","","ISSN: 1945-788X","","/Users/minsik/Zotero/storage/JFRYIKXY/searchresult.html","","","Visualization; Auditory displays; auditory display; binaural; Graphical user interfaces; Mobile handsets; music information retrieval; Presses; Pressing; Servers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2011 IEEE International Conference on Multimedia and Expo","","","","","","","","","","","","","","",""
"T74LB7A3","conferencePaper","2000","Ballora, M.; Pennycook, B.; Ivanov, P.Ch.; Goldberger, A.; Glass, L.","Detection of obstructive sleep apnea through auditory display of heart rate variability","Computers in Cardiology 2000. Vol.27 (Cat. 00CH37163)","","","10.1109/CIC.2000.898630","","A data set of interbeat interval times is read into a music software synthesis program to become the basis of a ""soundtrack"" or auditory display. Here the authors present examples of the sonifications, and discuss potential advantages in listening to, as opposed to viewing, heart rate variability data. This method treats the diagnosis of obstructive sleep apnea as a problem of orchestration and melody.","2000-09","2023-07-06 01:56:57","2023-07-06 01:56:57","","739-740","","","","","","","","","","","","","","","","","","IEEE Xplore","","ISSN: 0276-6547","","/Users/minsik/Zotero/storage/MJMWHEAA/searchresult.html","","","Physics; Computer languages; Auditory displays; Auditory system; Graphical user interfaces; Cardiology; Heart rate detection; Heart rate variability; Polymers; Sleep apnea","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Computers in Cardiology 2000. Vol.27 (Cat. 00CH37163)","","","","","","","","","","","","","","",""
"U5FAZQYY","conferencePaper","2017","Yanan, Tian; Hongwei, Lei; Jinghong, Li","A blind guidance system based on GCADSF image enhancement and music display","2017 29th Chinese Control And Decision Conference (CCDC)","","","10.1109/CCDC.2017.7979356","","There are some problems in the conventional blind guidance systems, such as massive mapping data, low mapping efficiency and simple sound coding. And they are easily affected by noise. These make the blind difficult to use the system. To solve these problems, a system is presented based on GCADSF image enhancement and music display. GCADSF model uses an exponential function which monotonically decreases with the gradient module to control the diffusion in the vertical direction of the image gradient. So it protects the image details as the edges are enhanced and the noise is filtered. The enhanced image is mapped into electronic music. Experimental results showed that the system has higher recognition rates for the blind's recognizing the image contents.","2017-05","2023-07-06 01:56:57","2023-07-06 01:56:57","","4864-4867","","","","","","","","","","","","","","","","","","IEEE Xplore","","ISSN: 1948-9447","","/Users/minsik/Zotero/storage/85ZRQGFQ/searchresult.html","","","Music; Auditory displays; Mathematical model; Auditory Display; Blind Guidance System; Electric shock; Image edge detection; Image enhancement; Shock Filter; Vision Substitution","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2017 29th Chinese Control And Decision Conference (CCDC)","","","","","","","","","","","","","","",""
"IVT2HHUE","journalArticle","2002","Vickers, Paul; Alty, James L","Using music to communicate computing information","Interacting with Computers","","1873-7951","10.1016/S0953-5438(02)00003-6","","The audio channel remains little used in most computing applications, often its use being relegated to providing trivial sound effects whose novelty value soon wears off. Nevertheless, in principle sound offers much to the process of human–computer interaction as for most people the notion of auditory imagery is easily accepted.In this paper we explore how sound, specifically musical sound, can be used to communicate computing information. The findings of two studies are presented. The first investigated how pitch intervals and musical phrases of complex (non-sinusoidal) tones can be recognised. The second study aimed to demonstrate that musical structures could communicate information about high-level programming language structures and program run-time behaviour. Both studies showed that music could successfully be used as a communication medium and that listeners did not need to be musically trained to benefit from the audio signals. Finally, recommendations for further work are made.","2002-10","2023-07-06 01:56:57","2023-07-06 01:56:57","","435-456","","5","14","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: Interacting with Computers","","/Users/minsik/Zotero/storage/ID3LJ9NL/searchresult.html","","","Music; Auditory display; Communication; Visualisation; Program auralisation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4PLXEZ8L","conferencePaper","2008","Jung, Ralf","Take your smart music with you and be up to date","2008 IET 4th International Conference on Intelligent Environments","","","10.1049/cp:20081171","","We present a user adaptive ambient audio notification service for multi-user environments connected to a user modeling service. The location adaptive system works unobtrusively by embedding non-speech audio cues, in the form of natural instruments, in aesthetical self composed music. First we introduce the ambient notification system for intelligent environments followed by the identification of extension properties for the implemented user model ontology to get the personalized ambient audio notification service.","2008-07","2023-07-06 01:56:57","2023-07-06 01:56:57","","1-4","","","","","","","","","","","","","","","","","","IEEE Xplore","","ISSN: 0537-9989","","/Users/minsik/Zotero/storage/YE3ABPNA/searchresult.html","","","Auditory Display; Ambient Notification; Non-Speech Audio Cues; Ubiquitous User Modeling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2008 IET 4th International Conference on Intelligent Environments","","","","","","","","","","","","","","",""
"P4J5J7QW","conferencePaper","2017","Yanan, Tian","A blind guidance system based on ICA edge detection and MIDI music display","2017 29th Chinese Control And Decision Conference (CCDC)","","","10.1109/CCDC.2017.7979415","","The conventional blind guidance systems have some problems such as massive mapping data, low mapping efficiency and simple sound coding. These make the blind difficult to use the system. To solve these problems, a system is presented based on ICA edge detection and MIDI music display. In this system image edges that accord with visual characteristics are mapped into MIDI music by ICA edge basis functions' reconstruction. Experimental results showed that the system has higher recognition rates for the blind's recognizing the image contents.","2017-05","2023-07-06 01:56:57","2023-07-06 01:56:57","","5180-5183","","","","","","","","","","","","","","","","","","IEEE Xplore","","ISSN: 1948-9447","","/Users/minsik/Zotero/storage/KRNXAYHH/searchresult.html","","","Music; Training; Independent Component Analysis; Visualization; Auditory displays; Auditory Display; Blind Guidance System; Image edge detection; Vision Substitution; Image reconstruction; Neurons","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2017 29th Chinese Control And Decision Conference (CCDC)","","","","","","","","","","","","","","",""
"PZA9FJY6","journalArticle","2002","Vickers, Paul; Alty, James L","When bugs sing","Interacting with Computers","","1873-7951","10.1016/S0953-5438(02)00026-7","","In The Songs of Insects, Pierce (1949) described the striped ground cricket, Nemobius fasciatus-fasciatus, which chirps at a rate proportional to ambient air temperature. Twenty chirps-per-second tell us it is 31.4 °C; 16 chirps and it is 27 °C. This is a natural example of an auditory display, a mechanism for communicating data with sound. By applying auditory display techniques to computer programming we have attempted to give the bugs that live in software programs their own songs. We have developed the CAITLIN musical program auralisation system Vickers and Alty, 2002b) to allow structured musical mappings to be made of the constructs in Pascal programs. Initial experimental evaluation [Interacting with Computers (2002a,b)] showed that subjects could interpret the musical motifs used to represent the various Pascal language constructs.In this paper we describe how the CAITLIN system was used to study the effects of musical program auralisation on debugging tasks performed by novice Pascal programmers. The results of the experiment indicate that a formal musical framework can act as a medium for communicating information about program behaviour, and that the information communicated could be used to assist with the task of locating bugs in faulty programs.","2002-12","2023-07-06 01:56:57","2023-07-06 01:56:57","","793-819","","6","14","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: Interacting with Computers","","/Users/minsik/Zotero/storage/4DCBXQT6/searchresult.html","","","Music; Auditory display; Debugging; Auralisation; HCI; Pascal","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VV8D87PR","journalArticle","2002","Vickers, Paul; Alty, James L","Musical program auralisation: a structured approach to motif design","Interacting with Computers","","1873-7951","10.1016/S0953-5438(02)00004-8","","In an earlier paper, Vickers and Alty (2002) showed that musically untrained users could make use of musical cues to understand computing information. Using a technique known as musical program auralisation, they showed that music could communicate run-time and structural information about Pascal programs.This paper describes how a set of hierarchically related auralisation motifs was designed and constructed within a formal musical framework. These auralisations were then evaluated in an experiment to determine how well they could be interpreted by computer science students. The results showed that the musical motifs were generally understood by the subjects and that any prior musical training of the subjects did not affect their ability to interpret the musical signals.Based on the results of the experiment and study of some cognitive aspects of music perception, a set of organising principles for musical program auralisation is proposed. Finally, recommendations for further study are made with particular regard to assessing the usefulness of the auralisations in program debugging situations.","2002-10","2023-07-06 01:56:57","2023-07-06 01:56:57","","457-485","","5","14","","","Musical program auralisation","","","","","","","","","","","","IEEE Xplore","","Conference Name: Interacting with Computers","","/Users/minsik/Zotero/storage/HA7SIRUW/searchresult.html","","","Music; Auditory display; Communication; Visualisation; Program auralisation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M4PIXB4L","conferencePaper","2018","Broderick, James; Duggan, Jim; Redfern, Sam","The Importance of Spatial Audio in Modern Games and Virtual Environments","2018 IEEE Games, Entertainment, Media Conference (GEM)","","","10.1109/GEM.2018.8516445","","In Virtual Reality (VR), virtual environments, and gaming, audio greatly impacts the user, yet it is an area that has been under researched quite recently. While music and environmental sounds have been used to great effect throughout gaming history to craft a more immersive experience, spatial audio doesn't see as much focus. Not only does well made spatial audio allow a user to become more immersed in their virtual experience, it is an important channel for information about their environment. With the advent of VR, games are putting more work into spatial audio and audio design, and now the results are becoming available for both research and game development. This paper will look at not only why spatial audio can greatly improve virtual experiences, but also some of the new technologies that have become available in recent times which make the implementation of spatial audio far easier and of a higher quality than ever before. It will also look at some planned research to examine the advantages of spatial audio in sonified virtual environments using Unity 3D.","2018-08","2023-07-06 01:56:57","2023-07-06 01:56:57","","1-9","","","","","","","","","","","","","","","","","","IEEE Xplore","","","","/Users/minsik/Zotero/storage/NJAL4F3B/searchresult.html","","","sonification; Three-dimensional displays; auditory display; Games; Task analysis; Engines; game engine; Headphones; virtual environments; Virtual environments; virtual reality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2018 IEEE Games, Entertainment, Media Conference (GEM)","","","","","","","","","","","","","","",""
"2KKUWKID","conferencePaper","2008","O'Neill, Charles; Ng, Kia","Hearing Images: Interactive Sonification Interface for Images","2008 International Conference on Automated Solutions for Cross Media Content and Multi-Channel Distribution","","","10.1109/AXMEDIS.2008.42","","This paper describes research into methods for interactive sonification of 2D image data. The method utilizes an existing device (from computer game), Nintendopsilas wiimote controller to provide a means of interaction with 2D images for the exploration and triggering of sonic response. This paper details a selection of sonification algorithms which have been designed to provide auditory display of image structure through sonification of parameters which signify the users exploration within a segmented image environment.","2008-11","2023-07-06 01:56:57","2023-07-06 01:56:57","","25-31","","","","","","Hearing Images","","","","","","","","","","","","IEEE Xplore","","","","/Users/minsik/Zotero/storage/CFUYJ7P8/searchresult.html","","","sonification; Data analysis; Algorithm design and analysis; artistic; Auditory displays; Auditory system; Computer interfaces; Distributed computing; Feedback; Haptic interfaces; Image segmentation; interactive; Jitter; sensory; visual; wii","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2008 International Conference on Automated Solutions for Cross Media Content and Multi-Channel Distribution","","","","","","","","","","","","","","",""
"KKZBA8KA","journalArticle","2016","Barrett, Natasha","Interactive Spatial Sonification of Multidimensional Data for Composition and Auditory Display","Computer Music Journal","","0148-9267","10.1162/COMJ_a_00358","","This article presents a new approach to interactive spatial sonification of multidimensional data as a tool for spatial sound synthesis, for composing temporal–spatial musical materials, and as an auditory display for scientists to analyze multidimensional data sets in time and space. The approach applies parameter-mapping sonification and is currently implemented in an application called Cheddar, which was programmed in Max/MSP. Cheddar sonifies data in real time, where the user can modify a wide variety of temporal, spatial, and sonic parameters during the listening process, and thus more easily uncover patterns and processes in the data than when applying non-real-time, noninteractive techniques. The design draws on existing literature concerning perception and acoustics, and it applies the author's practical experience in acousmatic composition, spectromorphology, and sound semantics, while addressing accuracy, flexibility, and ease of use. Although previous sonification applications have addressed some degree of real-time control and spatialization, this approach integrates space and sound in an interactive framework. Spatial information is sonified in high-order 3-D ambisonics, where the user can interactively move the virtual listening position to reveal details easily missed from fixed or noninteractive spatial views. Sounds used as input to the sonification take advantage of the rich spectra and extramusical attributes of acoustic sources, which, although previously theorized, are investigated here in a practical context thoroughly tested alongside acoustic and psychoacoustic considerations. Furthermore, when using Cheddar, no specialized knowledge of programming, acoustics, or psychoacoustics is required. These approaches position Cheddar at the junction between science and art. With one application serving both disciplines, the patterns and processes of science are more fluently appropriated into music or sound art, and vice versa for scientific research, science public outreach, and education.","2016-06","2023-07-06 01:56:57","2023-07-06 01:56:57","","47-69","","2","40","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: Computer Music Journal","","/Users/minsik/Zotero/storage/A9CHE7LN/searchresult.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6K4RUVHY","conferencePaper","2019","Grond, Florian; Cascio, M. Ariel; Motta-Ochoa, Rossio; Tembeck, Tamar; Veen, Dan Ten; Blain-Moraes, Stefanie","Participatory design of biomusic with users on the autism spectrum","2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII)","","","10.1109/ACII.2019.8925484","","Assistive technologies that incorporate affective computing methods may be useful for increasing inclusion across the autism spectrum. The involvement of this target population during development and design is key to ensuring that the technology is beneficial and has the potential to be adopted. This article reports on a participatory design process used for the development of an affective technology intended for users on the autism spectrum. We first briefly recapitulate concepts and theories about emotions to illuminate emotion-specific challenges faced in the design process. We then introduce biomusic, an affective technology that communicates emotional states by translating physiological signals into auditory output. The necessity of stakeholder involvement during the development of biomusic is discussed, with a focus specifically on including individuals with autism spectrum condition (ASC). Finally, we present a concrete example of a participatory sound design workshop focusing on the development of biomusic's auditory display in collaboration with adolescents with ASC. From this experience, challenges of using participatory design for the development of affective technologies with people with ASC are presented and discussed.","2019-09","2023-07-06 01:56:57","2023-07-06 01:56:57","","1-7","","","","","","","","","","","","","","","","","","IEEE Xplore","","ISSN: 2156-8111","","/Users/minsik/Zotero/storage/5HMEI58Q/searchresult.html","","","Medical treatment; Auditory displays; auditory display; Production; Real-time systems; Physiology; Conferences; affective technologies; Autism; biomusic; inclusion; participatory design; physiological signal sonification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII)","","","","","","","","","","","","","","",""
"B4977SB8","conferencePaper","2009","Stockholm, Jack; Pasquier, Philippe","Reinforcement Learning of Listener Response for Mood Classification of Audio","2009 International Conference on Computational Science and Engineering","","","10.1109/CSE.2009.184","","This paper describes a method of applying a reinforcement learning artificial intelligence to categorize audio files by mood based on listener response during a performance. The system discussed is implemented in a performance art environment designed to present the moods of multiple participants simultaneously in a room via a diffusion o frepresentative audio samples.","2009-08","2023-07-06 01:56:57","2023-07-06 01:56:57","","849-853","","","4","","","","","","","","","","","","","","","IEEE Xplore","","","","/Users/minsik/Zotero/storage/7KUB72G4/searchresult.html","","","Art; Auditory Display; Artificial intelligence; Artificial Intelligence; Computer Music; Dictionaries; Investments; Learning; Lifting equipment; Mood; Net Art; Portable computers; Reinforcement Learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2009 International Conference on Computational Science and Engineering","","","","","","","","","","","","","","",""
"EIBCP85K","journalArticle","1993","Mayer-Kress, G.; Choi, I.; Weber, N.; Barger, R.; Hubler, A.","Musical signals from Chua's circuit","IEEE Transactions on Circuits and Systems II: Analog and Digital Signal Processing","","1558-125X","10.1109/82.246172","","Chua's circuit can produce a very rich variety of signals that are both periodic and chaotic. The authors explore some classes of these attractors with respect to their auditory display and musical properties. They discuss the fast control of the circuit through a specially developed computer-controlled electronic resistor and how chaotic control methods might be applied to optimally switch between different attractors. The Chua circuit has parameter regions where noisy frequency and amplitude modulated sounds are generated, each of which is related to a certain transition to chaos. The authors discovered a period-adding sequence of bassoon-like sounds that produces interesting almost harmonic pitch changes. Finally, they emphasize the importance of transient dynamics especially in the context of percussion-like sounds.<>","1993-10","2023-07-06 01:56:57","2023-07-06 01:56:57","","688-695","","10","40","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Circuits and Systems II: Analog and Digital Signal Processing","","/Users/minsik/Zotero/storage/RI8ECC6H/searchresult.html","","","Auditory displays; Acoustic noise; Chaos; Circuit noise; Noise generators; Noise level; Optimal control; Resistors; Switches; Switching circuits","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BUQ4I9MU","conferencePaper","2006","Kim, Hyunho; Seo, Changhoon; Lee, Junhun; Ryu, Jeha; Yu, Si-bok; Lee, Sooyoung","Vibrotactile Display for Driving Safety Information","2006 IEEE Intelligent Transportation Systems Conference","","","10.1109/ITSC.2006.1706802","","Vehicle driving support systems such as navigation systems and dead-angle warning systems make us safer and more comfortable. These kinds of systems provide only visual and auditory information. However, visual driving support systems are restricted in driver's field-of-view and auditory warning signals can lose in radio music, engine noise, or conversation noise. Tactile displays using vibration motors can provide useful information in spite of restricted field-of-view and noisy environment. It may quickly draw the attention of the driver when important events occur: for instance, collision warning and directional cues. These intuitive and quick cues may be combined together with the visual and auditory display to give multimodal feedback to the driver. In this paper, we present a vibrotactile display device for providing safety information to drivers. User studies with the vibrotactile device on the top of the foot show 86.7% recognition rate for alphabet characters after some training and 83.9% for providing driving safety information","2006-09","2023-07-06 01:56:57","2023-07-06 01:56:57","","573-577","","","","","","","","","","","","","","","","","","IEEE Xplore","","ISSN: 2153-0017","","/Users/minsik/Zotero/storage/3FUKQFI8/searchresult.html","","","Multiple signal classification; Auditory displays; Feedback; Engines; Vehicle driving; Alarm systems; Foot; Radio navigation; Safety devices; Working environment noise","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","2006 IEEE Intelligent Transportation Systems Conference","","","","","","","","","","","","","","",""