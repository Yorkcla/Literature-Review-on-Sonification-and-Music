"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"UXQFVVYL","journalArticle","2006","Weinberg, Gil; Thatcher, Travis","Interactive Sonification: Aesthetics, Functionality and Performance","Leonardo Music Journal","","0961-1215","","https://www.jstor.org/stable/4540587","The authors present a sonification installation that allows a group of players to interact with an auditory display of neural activity. The system is designed to represent electrical spike propagation in a neuron culture through sound propagation in space. Participants can simulate neural spikes by using a set of specially designed controllers, experimenting and sonically investigating the electrical activity of the brain. The article discusses some aesthetic and functional aspects of sonification and describes the authors' approach for group interaction with auditory displays. It concludes with the description of a performance piece for the system and ideas for improvements and future work.","2006","2023-07-10 07:04:19","2023-07-10 07:04:19","2023-07-10 07:04:17","9-12","","","16","","","Interactive Sonification","","","","","","","","","","","","JSTOR","","Publisher: The MIT Press","","/Users/minsik/Zotero/storage/7WC3NJBY/Weinberg and Thatcher - 2006 - Interactive Sonification Aesthetics, Functionalit.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FKDUWR85","journalArticle","2006","Barrass, Stephen; Whitelaw, Mitchell; Bailes, Freya","Listening to the Mind Listening: An Analysis of Sonification Reviews, Designs and Correspondences","Leonardo Music Journal","","0961-1215","","https://www.jstor.org/stable/4540588","Listening to the Mind Listening (LML) explored whether sonifications can be more than just ""noise"" in terms of perceived information and musical experience. The project generated an unprecedented body of 27 multichannel sonifications of the same dataset by 38 composers. The design of each sonification was explicitly documented, and there are 88 analytical reviews of the works. The public concert presenting 10 of these sonifications at the Sydney Opera House Studio drew a capacity audience. This paper presents an analysis of the reviews, the designs and the correspondences between timelines of these works.","2006","2023-07-10 07:04:19","2023-07-10 07:04:19","2023-07-10 07:04:18","13-19","","","16","","","Listening to the Mind Listening","","","","","","","","","","","","JSTOR","","Publisher: The MIT Press","","/Users/minsik/Zotero/storage/7ACGRLV2/Barrass et al. - 2006 - Listening to the Mind Listening An Analysis of So.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IP48NHEK","journalArticle","2013","Grond, Florian; Olmos, Adriana; Cooperstock, Jeremy R.","Making Sculptures Audible through Participatory Sound Design","Leonardo Music Journal","","0961-1215","","https://www.jstor.org/stable/43832491","A research group explores rendering sculptural forms as sound using echolocation and the participation of members of the visually impaired community.","2013","2023-07-10 07:04:19","2023-07-10 07:04:19","2023-07-10 07:04:19","12-13","","","23","","","","","","","","","","","","","","","JSTOR","","Publisher: The MIT Press","","/Users/minsik/Zotero/storage/GC27IPYR/Grond et al. - 2013 - Making Sculptures Audible through Participatory So.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2WE9Q6CS","journalArticle","2007","Shi, X. J.; Cai, Y. Y.; Chan, C. W.","Electronic Music for Bio-Molecules Using Short Music Phrases","Leonardo","","0024-094X","","https://www.jstor.org/stable/20206375","The authors explore protein sonification issues using Morse code theory. Short musical phrases based on protein amino acids are used to compose protein music. Rhythms and tunes familiar to teenagers are also investigated, with the aim of producing different genres of protein music. A special musical instrument, the Chinese guzheng, can be employed to play the protein music. Experiment is carried out with different proteins, including the HIV main protease. It is hoped that this study can help unveil the mysteries of nature and motivate students to learn biology.","2007","2023-07-10 07:07:55","2023-07-10 07:07:55","2023-07-10 07:07:52","137-141","","2","40","","","","","","","","","","","","","","","JSTOR","","Publisher: The MIT Press","","/Users/minsik/Zotero/storage/WRV7NYAR/Shi et al. - 2007 - Electronic Music for Bio-Molecules Using Short Mus.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MC7B8PVP","journalArticle","2005","Sturm, Bob L.","Pulse of an Ocean: Sonification of Ocean Buoy Data","Leonardo","","0024-094X","","https://www.jstor.org/stable/1577794","The author presents his work in sonifying ocean buoy data for scientific, pedagogical and compositional purposes. Mapping the spectral buoy data to audible frequencies creates interesting and illuminating sonifications of ocean wave dynamics. Several phenomena can be heard, including both those visible and those invisible in graphical representations of the data. The author has worked extensively with this data to compose music and to produce ""Music from the Ocean,"" a multimedia CD-ROM demonstrating the data, the phenomena and the sonification. After a brief introduction to physical oceanography, many examples are presented and a composition and installation created from the sonifications are discussed.","2005","2023-07-10 07:07:55","2023-07-10 07:07:55","2023-07-10 07:07:52","143-149","","2","38","","","Pulse of an Ocean","","","","","","","","","","","","JSTOR","","Publisher: The MIT Press","","/Users/minsik/Zotero/storage/Y9GLKEXD/Sturm - 2005 - Pulse of an Ocean Sonification of Ocean Buoy Data.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JIA5NDIS","journalArticle","2005","Miranda, Eduardo Reck; Brouse, Andrew","Interfacing the Brain Directly with Musical Systems: On Developing Systems for Making Music with Brain Signals","Leonardo","","0024-094X","","https://www.jstor.org/stable/20206079","The authors discuss their work on developing technology to interface the brain directly with music systems, a field of research generally known as Brain-Computer Interfacing (BCI). The paper gives a brief background of BCI in general and surveys various attempts at musical BCI, or Brain-Computer Music Interface (BCMI)--systems designed to make music from brain signals, or brainwaves. The authors present a technical introduction to the electroencephalogram (EEG), which measures brainwaves detected by electrodes placed directly on the scalp. They introduce approaches to the design of BCI and BCMI systems and present two case study systems of their own design: the BCMI-Piano and the Inter-Harmonium.","2005","2023-07-10 07:07:55","2023-07-10 07:07:55","2023-07-10 07:07:53","331-336","","4","38","","","Interfacing the Brain Directly with Musical Systems","","","","","","","","","","","","JSTOR","","Publisher: [Leonardo, The MIT Press]","","/Users/minsik/Zotero/storage/443A55BS/Miranda and Brouse - 2005 - Interfacing the Brain Directly with Musical System.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XAUJMII9","journalArticle","2016","Eloul, Shaltiel; Zissu, Gil; Amo, Yehiel H.; Jacoby, Nori","Motion Tracking of a Fish as a Novel Way to Control Music Performance","Leonardo","","0024-094X","","https://www.jstor.org/stable/43834350","The authors have mapped the three-dimensional motion of a fish onto various electronic music performance gestures, including loops, melodies, arpeggio and DJ-like interventions. They combine an element of visualization, using an LED screen installed on the back of an aquarium, to create a link between the fish's motion and the sonified music. This visual addition provides extra information about the fish's role in the music, enabling the perception of versatile and developing auditory structures during the performance that extend beyond the sonification of the momentary motion of objects.","2016","2023-07-10 07:07:55","2023-07-10 07:07:55","2023-07-10 07:07:53","203-210","","3","49","","","","","","","","","","","","","","","JSTOR","","Publisher: [Leonardo, The MIT Press]","","/Users/minsik/Zotero/storage/UZ8ME2QE/Eloul et al. - 2016 - Motion Tracking of a Fish as a Novel Way to Contro.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VK2KXJTT","journalArticle","2004","Ben-Tal, Oded; Berger, Jonathan","Creative Aspects of Sonification","Leonardo","","0024-094X","","https://www.jstor.org/stable/1577727","A goal of sonification research is the intuitive audio representation of complex, multidimensional data. The authors present two facets of this research that may provide insight into the creative process. First, they discuss aspects of categorical perception in nonverbal auditory scene analysis and propose that these characteristics are simplified models of creative engagement with sound. Second, they describe the use of sonified data in musical compositions by each of the authors and observe aspects of the creative process in the purely aesthetic use of sonified statistical data.","2004","2023-07-10 07:07:55","2023-07-10 07:07:55","2023-07-10 07:07:54","229-232","","3","37","","","","","","","","","","","","","","","JSTOR","","Publisher: [Leonardo, The MIT Press]","","/Users/minsik/Zotero/storage/P5JZ9M68/Ben-Tal and Berger - 2004 - Creative Aspects of Sonification.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZZJFWYHU","journalArticle","2004","Ballora, Mark; Pennycook, Bruce; Ivanov, Plamen C.; Glass, Leon; Goldberger, Ary L.","Heart Rate Sonification: A New Approach to Medical Diagnosis","Leonardo","","0024-094X","","https://www.jstor.org/stable/1577570","Ever since 1819, when Theophile Laënnec first put a block of wood to a patient's chest in order to listen to her heartbeat, physicians have used auscultation to help diagnose cardiopulmonary disorders. Here the authors describe a novel diagnostic method based in music technology. Digital musicsynthesis software is used to transform the sequence of time intervals between consecutive heartbeats into an electroacoustic soundtrack. The results show promise as a diagnostic tool and also provide the basis of an interesting musical soundscape.","2004","2023-07-10 07:07:55","2023-07-10 07:07:55","2023-07-10 07:07:54","41-46","","1","37","","","Heart Rate Sonification","","","","","","","","","","","","JSTOR","","Publisher: The MIT Press","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8U6XCV85","journalArticle","2013","Jensenius, Alexander Refsum","Some Video Abstraction Techniques for Displaying Body Movement in Analysis and Performance","Leonardo","","0024-094X","","https://www.jstor.org/stable/23468117","This paper presents an overview of techniques for creating visual displays of human body movement based on video recordings. First a review of early movement and video visualization techniques is given. Then follows an overview of techniques that the author has developed and used in the study of music-related body movements: motion history images, motion average images, motion history keyframe images and motiongrams. Finally, examples are given of how such visualization techniques have been used in empirical music research, in medical research and for creative applications.","2013","2023-07-10 07:07:55","2023-07-10 07:07:55","2023-07-10 07:07:54","53-43","","1","46","","","","","","","","","","","","","","","JSTOR","","Publisher: The MIT Press","","/Users/minsik/Zotero/storage/QCZDFP4Z/Jensenius - 2013 - Some Video Abstraction Techniques for Displaying B.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3WMMYIK9","journalArticle","2012","Burraston, Dave","Rainwire: Environmental Sonification of Rainfall","Leonardo","","0024-094X","","https://www.jstor.org/stable/41550653","The Rainwire project forms part of an art/science initiative to investigate environmental sonifícation of land-based natural rainfall using large-scale long wire instruments.","2012","2023-07-10 07:07:55","2023-07-10 07:07:55","2023-07-10 07:07:54","288-289","","3","45","","","Rainwire","","","","","","","","","","","","JSTOR","","Publisher: The MIT Press","","/Users/minsik/Zotero/storage/HYSUURZ9/Burraston - 2012 - Rainwire Environmental Sonification of Rainfall.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XVJBWQWC","journalArticle","2012","Taylor, Sean; Fernström, Mikael","Marbh Chrios","Leonardo","","0024-094X","","https://www.jstor.org/stable/41550776","Marbh Crhios (Dead Zone) is a multimedia artwork, part of the Lovely Weather Donegal Residencies Project, that reflects upon climate change in the context of a local community in Killybegs in County Donegal, Ireland. The work was based on scientific data about contested marine 'dead zones' that the authors represented with algorithmically generated music, sonifications and visualizations in a live performance in Mooney's Boatyard in Killybegs, involving three local ensembles.","2012","2023-07-10 07:07:55","2023-07-10 07:07:55","2023-07-10 07:07:55","192-193","","2","45","","","","","","","","","","","","","","","JSTOR","","Publisher: The MIT Press","","/Users/minsik/Zotero/storage/TGKZHNVX/Taylor and Fernström - 2012 - Marbh Chrios.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V67DG6M6","journalArticle","2005","Polli, Andrea","""Atmospherics/Weather Works"": A Spatialized Meteorological Data Sonification Project","Leonardo","","0024-094X","","https://www.jstor.org/stable/1577642","""Atmospherics/Weather Works"" is a performance, installation and distributed software project for the sonification of storms and other meteorological events, generated directly from data produced by a highly detailed and physically accurate simulation of the weather.","2005","2023-07-10 07:07:55","2023-07-10 07:07:55","2023-07-10 07:07:55","31-36","","1","38","","","""Atmospherics/Weather Works""","","","","","","","","","","","","JSTOR","","Publisher: [Leonardo, The MIT Press]","","/Users/minsik/Zotero/storage/XNCT83UA/Polli - 2005 - AtmosphericsWeather Works A Spatialized Meteor.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I7HBIQU9","journalArticle","2013","Peters, Nils; Lossius, Trond; Schacher, Jan C.","The Spatial Sound Description Interchange Format: Principles, Specification, and Examples","Computer Music Journal","","0148-9267","","https://www.jstor.org/stable/24265581","SpatDIF, the Spatial Sound Description Interchange Format, is an ongoing collaborative effort offering a semantic and syntactic specification for storing and transmitting spatial audio scene descriptions. The SpatDIF core is a lightweight minimal solution providing the most essential set of descriptors for spatial sound scenes. Additional descriptors are introduced as extensions, expanding the namespace and scope with respect to authoring, scene description, rendering, and reproduction of spatial sound. A general overview presents the principles informing the specification, as well as the structure and the terminology of the SpatDIF syntax. Two use cases exemplify SpatDIF's potential for pre-composed pieces as well as interactive installations, and several prototype implementations that have been developed show its real-life utility.","2013","2023-07-10 07:14:41","2023-07-10 07:14:41","2023-07-10 07:14:36","11-22","","1","37","","","The Spatial Sound Description Interchange Format","","","","","","","","","","","","JSTOR","","Publisher: The MIT Press","","/Users/minsik/Zotero/storage/RJYCZHE9/Peters et al. - 2013 - The Spatial Sound Description Interchange Format .pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7LW3RGME","journalArticle","2014","Caramiaux, Baptiste; Françoise, Jules; Schnell, Norbert; Bevilacqua, Frédéric","Mapping Through Listening","Computer Music Journal","","0148-9267","","https://www.jstor.org/stable/24265481","Gesture-to-sound mapping is generally defined as the association between gestural and sound parameters. This article describes an approach that brings forward the perception–action loop as a fundamental design principle for gesture–sound mapping in digital music instrument. Our approach considers the processes of listening as the foundation—and the first step—in the design of action–sound relationships. In this design process, the relationship between action and sound is derived from actions that can be perceived in the sound. Building on previous work on listening modes and gestural descriptions, we propose to distinguish between three mapping strategies: instantaneous, temporal, and metaphorical. Our approach makes use of machine-learning techniques for building prototypes, from digital music instruments to interactive installations. Four different examples of scenarios and prototypes are described and discussed.","2014","2023-07-10 07:14:41","2023-07-10 07:14:41","2023-07-10 07:14:36","34-48","","3","38","","","","","","","","","","","","","","","JSTOR","","Publisher: The MIT Press","","/Users/minsik/Zotero/storage/IUI4A67T/Caramiaux et al. - 2014 - Mapping Through Listening.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BSG2IW78","journalArticle","2016","Barrett, Natasha","Interactive Spatial Sonification of Multidimensional Data for Composition and Auditory Display","Computer Music Journal","","0148-9267","","https://www.jstor.org/stable/43829321","This article presents a new approach to interactive spatial sonification of multidimensional data as a tool for spatial sound synthesis, for composing temporal-spatial musical materials, and as an auditory display for scientists to analyze multidimensional data sets in time and space. The approach applies parameter-mapping sonification and is currently implemented in an application called Cheddar, which was programmed in Max/MSP. Cheddar sonifies data in real time, where the user can modify a wide variety of temporal, spatial, and sonic parameters during the listening process, and thus more easily uncover patterns and processes in the data than when applying non-real-time, noninteractive techniques. The design draws on existing literature concerning perception and acoustics, and it applies the author's practical experience in acousmatic composition, spectromorphology, and sound semantics, while addressing accuracy, flexibility, and ease of use. Although previous sonification applications have addressed some degree of real-time control and spatialization, this approach integrates space and sound in an interactive framework. Spatial information is sonified in high-order 3-D ambisonics, where the user can interactively move the virtual listening position to reveal details easily missed from fixed or noninteractive spatial views. Sounds used as input to the sonification take advantage of the rich spectra and extramusical attributes of acoustic sources, which, although previously theorized, are investigated here in a practical context thoroughly tested alongside acoustic and psychoacoustic considerations. Furthermore, when using Cheddar, no specialized knowledge of programming, acoustics, or psychoacoustics is required. These approaches position Cheddar at the junction between science and art. With one application serving both disciplines, the patterns and processes of science are more fluently appropriated into music or sound art, and vice versa for scientific research, science public outreach, and education.","2016","2023-07-10 07:14:41","2023-07-10 07:14:41","2023-07-10 07:14:41","47-69","","2","40","","","","","","","","","","","","","","","JSTOR","","Publisher: The MIT Press","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J5B36V95","journalArticle","2013","Dansereau, Donald G.; Brock, Nathan; Cooperstock, Jeremy R.","Predicting an Orchestral Conductor's Baton Movements Using Machine Learning","Computer Music Journal","","0148-9267","","https://www.jstor.org/stable/24265465","Telematic musical performance, in which performers at two or more sites collaborate via networked audio and video, suffers significantly from latency. In the extreme case, performers at all sites slow to match their delayed counterparts, resulting in a steadily decreasing temp. Introducing video of a conductor does not immediately solve the problem, as conductor video is also subjected to network latencies. This article lays the groundwork for an alternative approach to mitigating the effects of latency in distributed orchestral performances, based on generation of a predicted version of the conductor's baton trajectory. The prediction step is the most fundamental problem in this scheme, for which we propose the use of conventional machine learning techniques. Specifically, we demonstrate a particle filter and an extended Kalman filter that each track the location of the baton's tip and predict it multiple beats into the future; we compare these with a conventional feature-based method. We also describe a generic two-part framework that prescribes the incorporation of rehearsal data into a probabilistic model, which is then adapted during live performance. Finally, we suggest a framework and experimental methodology for establishing perceptually based metrics for predicted baton paths. Note that the perceptual efficacy of the presented methods requires experimental confirmation beyond the scope of this article.","2013","2023-07-10 07:15:15","2023-07-10 07:15:15","2023-07-10 07:15:11","28-45","","2","37","","","","","","","","","","","","","","","JSTOR","","Publisher: The MIT Press","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FJUEAB34","journalArticle","2016","Cabrera, Andrés; Kuchera-Morin, JoAnn; Roads, Curtis","The Evolution of Spatial Audio in the AlloSphere","Computer Music Journal","","0148-9267","","https://www.jstor.org/stable/26777022","Spatial audio has been at the core of the multimodal experience at the AlloSphere, a unique instrument for data discovery and exploration through interactive immersive display, since its conception. The AlloSphere multichannel spatial audio design has direct roots in the history of electroacoustic spatial audio and is the result of previous activities in spatial audio at the University of California at Santa Barbara. A concise technical description of the AlloSphere, its architectural and acoustic features, its unique 3-D visual projection system, and the current 54.1 Meyer Sound audio infrastructure is presented, with details of the audio software architecture and the immersive sound capabilities it supports. As part of the process of realizing scientific and artistic projects for the AlloSphere, spatial audio research has been conducted, including the use of decorrelation of audio signals to supplement spatialization and tackling the thorny problem of interactive up-mixing through the Sound Element Spatializer and the Zirkonium Chords project. The latter uses the metaphor of geometric spatial chords as a high-level means of spatial up-mixing in performance. Other developments relating to spatial audio are presented, such as Ryan McGee’s Spatial Modulation Synthesis, which simultaneously explores the synthesis of space and timbre.","2016","2023-07-10 07:15:15","2023-07-10 07:15:15","2023-07-10 07:15:12","47-61","","4","40","","","","","","","","","","","","","","","JSTOR","","Publisher: The MIT Press","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YBR5IRW3","journalArticle","2014","Cádiz, Rodrigo F.; Ramos, Javier","Sound Synthesis of a Gaussian Quantum Particle in an Infinite Square Well","Computer Music Journal","","0148-9267","","https://www.jstor.org/stable/24265449","This article describes a synthesis technique based on the sonification of the dynamic behavior of a quantum particle enclosed in an infinite square well. More specifically, we sonify the momentum distribution of a one-dimensional Gaussian bouncing wave packet model. We have chosen this particular case because of its relative simplicity and interesting dynamic behavior, which makes it suitable for a novel sonification mapping that can be applied to standard synthesis techniques, resulting in the generation of appealing sounds. In addition, this sonification might provide useful insight into the behavior of the quantum particle. In particular, this model exhibits quantum revivals, minimizes uncertainty, and exhibits similarities to the case of a classical bouncing ball. The proposed model has been implemented in real time in both the Max/MSP and the Pure Data environments. The algorithm is based on concepts of additive synthesis where each oscillator describes the eigenfunctions that characterize the state evolution of the wave packet. We also provide an analysis of the sounds produced by the model from both a physical and a perceptual point of view.","2014","2023-07-10 07:15:15","2023-07-10 07:15:15","2023-07-10 07:15:13","53-67","","4","38","","","","","","","","","","","","","","","JSTOR","","Publisher: The MIT Press","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IN6N2ZY3","journalArticle","2017","Zotter, Franz; Zaunschirm, Markus; Frank, Matthias; Kronlachner, Matthias","A Beamformer to Play with Wall Reflections: The Icosahedral Loudspeaker","Computer Music Journal","","0148-9267","","https://www.jstor.org/stable/26777075","The quote from Pierre Boulez, given as an epigraph to this article, inspired French researchers to start developing technology for spherical loudspeaker arrays in the 1990s. The hope was to retain the naturalness of sound sources. Now, a few decades later, one might be able to show that even more can be done: In electroacoustic music, using the icosahedral loudspeaker array called IKO seems to enable spatial gestures that enrich alien sounds with a tangible acoustic naturalness. After a brief discussion of directivity-based composition in computer music, the first part of the article describes the technical background of the IKO, its usage in a digital audio workstation, and psychoacoustic evidence regarding the auditory objects the IKO produces. The second part deals with acoustic equations of spherical beamforming, how the IKO’s loudspeakers are controlled correspondingly, how we deal with excursion limits, and the resulting beam patterns generated by the IKO.","2017","2023-07-10 07:15:15","2023-07-10 07:15:15","2023-07-10 07:15:14","50-68","","3","41","","","A Beamformer to Play with Wall Reflections","","","","","","","","","","","","JSTOR","","Publisher: The MIT Press","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V4K3VCD7","journalArticle","2015","Kirke, Alexis; Freeman, Samuel; Miranda, Eduardo Reck","Wireless Interactive Sonification of Large Water Waves to Demonstrate the Facilities of a Large-Scale Research Wave Tank","Computer Music Journal","","0148-9267","","https://www.jstor.org/stable/43829278","Interactive sonification can provide a platform for demonstration and education as well as for monitoring and investigation. We present a system designed to demonstrate the facilities of the UK's most advanced large-scale research wave tank. The interactive sonification of water waves in the ""ocean basin"" wave tank at Plymouth University consisted of a number of elements: generation of ocean waves, acquisition and sonification of ocean-wave measurement data, and gesture-controlled pitch and amplitude of sonifications. The generated water waves were linked in real time to sonic features via depth monitors and motion tracking of a floating buoy. Types of water-wave patterns, varying in shape and size, were selected and triggered using wireless motion detectors attached to the demonstrator's arms. The system was implemented on a network of five computers utilizing Max/MSP alongside specialist marine research software, and was demonstrated live in a public performance for the formal opening of the Marine Institute building.","2015","2023-07-10 07:15:15","2023-07-10 07:15:15","2023-07-10 07:15:14","59-70","","3","39","","","","","","","","","","","","","","","JSTOR","","Publisher: The MIT Press","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NV6BEXHL","journalArticle","2017","Hagan, Kerry L.","Textural Composition: Aesthetics, Techniques, and Spatialization for High-Density Loudspeaker Arrays","Computer Music Journal","","0148-9267","","https://www.jstor.org/stable/26777036","This article documents a personal journey of compositional practice that led to the necessity for working with high-density loudspeaker arrays (HDLAs). I work with textural composition, an approach to composing real-time computer music arising from acousmatic and stochastic principles in the form of a sound metaobject. Textural composition depends upon highly mobile sounds without the need for trajectory-based spatialization procedures. In this regard, textural composition is an intermediary aesthetic—between “tape music” and real-time computer music, between sound objects and soundscape, and between point-source and trajectory-based, mimetic spatialization.I begin with the aesthetics of textural composition, including the musical and sonic spaces it needs to inhabit. I then detail the techniques I use to create textures for this purpose. I follow with the spatialization technique I devised that supports the aesthetic requirements. Finally, I finish with an example of an exception to my techniques, one where computational requirements and the HDLA required me to create a textural composition without my real-time strategies.","2017","2023-07-10 07:15:15","2023-07-10 07:15:15","2023-07-10 07:15:14","34-45","","1","41","","","Textural Composition","","","","","","","","","","","","JSTOR","","Publisher: The MIT Press","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PHCSEKIG","journalArticle","2014","Conan, Simon; Thoret, Etienne; Aramaki, Mitsuko; Derrien, Olivier; Gondre, Charles; Ystad, Sølvi; Kronland-Martinet, Richard","An Intuitive Synthesizer of Continuous-Interaction Sounds: Rubbing, Scratching, and Rolling","Computer Music Journal","","0148-9267","","https://www.jstor.org/stable/24265447","In this article, we propose a control strategy for synthesized continuous-interaction sounds. The framework of our research is based on the action—object paradigm that describes the sound as the result of an action on an object and that presumes the existence of sound invariants (i.e., perceptually relevant signal morphologies that carry information about the action's or the object's attributes). Auditory cues are investigated here for the evocations of rubbing, scratching, and rolling interactions. A generic sound-synthesis model that simulates these interactions is detailed. We then suggest an intuitive control strategy that enables users to navigate continuously from one interaction to another in an ""action space,"" thereby offering the possibility to simulate morphed interactions—for instance, ones that morph between rubbing and rolling.","2014","2023-07-10 07:16:03","2023-07-10 07:16:03","2023-07-10 07:16:00","24-37","","4","38","","","An Intuitive Synthesizer of Continuous-Interaction Sounds","","","","","","","","","","","","JSTOR","","Publisher: The MIT Press","","/Users/minsik/Zotero/storage/459732X2/Conan et al. - 2014 - An Intuitive Synthesizer of Continuous-Interaction.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9QW5B9EQ","journalArticle","2014","Van Nort, Doug; Wanderley, Marcelo M.; Depalle, Philippe","Mapping Control Structures for Sound Synthesis: Functional and Topological Perspectives","Computer Music Journal","","0148-9267","","https://www.jstor.org/stable/24265479","This article contributes a holistic conceptual framework for the notion of ""mapping"" that extends the classical view of mapping as parameter association. In presenting this holistic approach to mapping techniques, we apply the framework to existing works from the literature as well as to new implementations that consider this approach in their construction. As any mapping control structure for a given digital instrument is determined by the musical context in which it is used, we present musical examples that relate the relatively abstract realm of mapping design to the physically and perceptually grounded notions of control and sonic gesture. Making this connection allows mapping to be more clearly seen as a linkage between a physical action and a sonic result. In this sense, the purpose of this work is to translate the discussion on mapping so that it links an abstract and formalized approach—intended for representation and conceptualization—with a viewpoint that considers mapping in its role as a perceived correspondence between physical materials (i.e., those that act on controllers and transducers) and sonic events. This correspondence is, at its heart, driven by our cognitive and embodied understanding of the acoustic world.","2014","2023-07-10 07:16:03","2023-07-10 07:16:03","2023-07-10 07:16:02","6-22","","3","38","","","Mapping Control Structures for Sound Synthesis","","","","","","","","","","","","JSTOR","","Publisher: The MIT Press","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3BMH5JB9","journalArticle","2016","Lyon, Eric; Caulkins, Terence; Blount, Denis; Bukvic, Ivica Ico; Nichols, Charles; Roan, Michael; Upthegrove, Tanner","Genesis of the Cube: The Design and Deployment of an HDLA-Based Performance and Research Facility","Computer Music Journal","","0148-9267","","https://www.jstor.org/stable/26777023","The Cube is a recently built facility that features a high-density loudspeaker array. The Cube is designed to support spatial computer music research and performance, art installations, immersive environments, scientific research, and all manner of experimental formats and projects. We recount here the design process, implementation, and initial projects undertaken in the Cube during the years 2013–2015.","2016","2023-07-10 07:16:03","2023-07-10 07:16:03","2023-07-10 07:16:02","62-78","","4","40","","","Genesis of the Cube","","","","","","","","","","","","JSTOR","","Publisher: The MIT Press","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HBKK6EQG","journalArticle","2017","Lynch, Hugh; Sazdov, Robert","A Perceptual Investigation into Spatialization Techniques Used in Multichannel Electroacoustic Music for Envelopment and Engulfment","Computer Music Journal","","0148-9267","","https://www.jstor.org/stable/26777035","Composers of electroacoustic music have developed and creatively implemented various spatialization techniques for multichannel loudspeaker setups. What is not known is which of these spatialization techniques is most effective for exploiting the extended creative possibilities available in multidimensional sound. This article discusses an experiment investigating the perception of the spatial attributes of “envelopment” and “engulfment” within a high-density loudspeaker array. The spatialization techniques used in the experiment were timbre spatialization, spectral splitting, amplitude point-source panning, and dynamic spectral subband decorrelation. Three loudspeaker setups, or spatial dimensions, were investigated: horizontal-only; elevated-only; and three-dimensional, which consisted of both horizontal and elevated loudspeaker setups. Results suggest that dynamic spectral subband decorrelation was perceived as both the most enveloping and the most engulfing technique when compared to other techniques in these experimental loudspeaker configurations. We propose that the experimental results can be successfully implemented when composing electroacoustic music to exploit the creative possibilities in a high-density loudspeaker array or in other multichannel loudspeaker configurations.","2017","2023-07-10 07:16:03","2023-07-10 07:16:03","2023-07-10 07:16:02","13-33","","1","41","","","","","","","","","","","","","","","JSTOR","","Publisher: The MIT Press","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TGWL3K7B","journalArticle","2016","Garavaglia, Javier Alejandro","Creating Multiple Spatial Settings with “Granular Spatialisation” in the High-Density Loudspeaker Array of the Cube Concert Hall","Computer Music Journal","","0148-9267","","https://www.jstor.org/stable/26777024","This article offers an alternative for spatializing electroacoustic music using high-density loudspeaker arrays (HDLAs). It describes and contextualizes experimentation with the large array of speakers of the Cube concert hall made during the Spatial Audio Workshop residency at the Moss Arts Center, Virginia Polytechnic Institute and State University in August 2015. The experiments were performed using the implementation of “Granular Spatialisation” (GS), a technique developed by the author for sound diffusion in HDLAs. This is based on the projection of sound using spatial grains of “microdurations,” with ideally one grain individually addressing each speaker of the array. The article focuses on particular aspects of, challenges from, and strategies for using GS for the projection of sound with the Cube’s array of 138 loudspeakers, including four independent subwoofers, while composing a new acousmatic piece that was diffused in the Cube at the end of the residency.","2016","2023-07-10 07:16:03","2023-07-10 07:16:03","2023-07-10 07:16:02","79-90","","4","40","","","","","","","","","","","","","","","JSTOR","","Publisher: The MIT Press","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2HR7SN32","journalArticle","2016","Barrett, Natasha","A Musical Journey towards Permanent High-Density Loudspeaker Arrays","Computer Music Journal","","0148-9267","","https://www.jstor.org/stable/26777021","Historically, most acousmatic works were composed in stereo and performed, or “diffused”, over loudspeaker orchestras. These systems furnished performers and composers with a wealth of opportunities to enhance the spatial contrast, motion, and musical articulations latent in the music. Although loudspeaker orchestras, stereo diffusion, and—more recently—hybrid performance techniques remain alive, especially in Europe, there is a trend towards fixed installation, high-density loudspeaker arrays (HDLAs), which I will call permanent HDLAs to differentiate them from loudspeaker-orchestra HDLAs. Permanent HDLAs (P-HDLAs) stimulate alternative approaches to musical space and pose challenges in both spatial composition and performance, encompassing both technology and aesthetics. This article consolidates many of the technical and aesthetic approaches that I have found specific to P-HDLAs with an emphasis on the application of higher-order Ambisonics (HOA) at fourth-order 3-D and above—what I will call V-HOA (“very high-order” Ambisonics) as distinguished from lower orders, or L-HOA (lower than fourth-order HOA). These approaches are guided by spatial-audio research, and then developed in a musical context. The study is divided into three sections: a description of musical and technical approaches that I have found to function over different P-HDLA installations; reflections on the compromises of lower-order monitoring during the compositional process; and presentation of the “Virtualmonium”: an instrument for the performance of stereo works that benefits from the growing popularity of P-HDLA installations.","2016","2023-07-10 07:16:03","2023-07-10 07:16:03","2023-07-10 07:16:03","35-46","","4","40","","","","","","","","","","","","","","","JSTOR","","Publisher: The MIT Press","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""