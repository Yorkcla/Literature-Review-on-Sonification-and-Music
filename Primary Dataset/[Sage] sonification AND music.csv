"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"EII9DQZX","journalArticle","2018","Nees, Michael A.","Auditory Graphs Are Not the “Killer App” of Sonification, But They Work","Ergonomics in Design","","1064-8046","10.1177/1064804618773563","https://doi.org/10.1177/1064804618773563","The search for the elusive “killer app” of sonification has been a recurring theme in sonification research. In this comment, I argue that the killer-app criterion of success stems from interdisciplinary tensions about how to evaluate sonifications. Using auditory graphs as an example, I argue that the auditory display community has produced successful examples of sonic information design that accomplish the human factors goal of improving human interactions with systems. Still, barriers to using sonifications in interfaces remain, and reducing those barriers could result in more widespread use of audio in systems.","2018-10-01","2023-07-06 06:14:02","2023-07-06 06:14:02","2023-07-06 06:13:45","25-28","","4","26","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/5MAL9TZ7/Nees - 2018 - Auditory Graphs Are Not the “Killer App” of Sonifi.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PXZ7A296","journalArticle","2022","Yang, Jiajun; Hunt, Andy","Assisting Dumbbell Curls via Interactive Sonification of Arm Movement and Muscular Signals","Ergonomics in Design","","1064-8046","10.1177/1064804619829664","https://doi.org/10.1177/1064804619829664","We developed an interactive sonification system that lets users listen to their own hand/arm movement and bicep muscle signals as sonic feedback during biceps curls exercise. The system aims to improve the exercise quality and user motivation. Based on two studies, we found that the sonification was more effective in providing temporal cues to slow down the repetition but not as effective as hoped in extending the vertical movement range and increasing repetition amount. The studies provide some design guidelines for multivariate sonification and also reflect a wider potential for applications that include general fitness, physiotherapy, and sports training.","2022-07-01","2023-07-06 06:14:02","2023-07-06 06:14:02","2023-07-06 06:13:47","11-15","","3","30","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/FHUD3C63/Yang and Hunt - 2022 - Assisting Dumbbell Curls via Interactive Sonificat.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KHXQZNKU","journalArticle","2016","Hinckfuss, Kelly; Sanderson, Penelope; Loeb, Robert G.; Liley, Helen G.; Liu, David","Novel Pulse Oximetry Sonifications for Neonatal Oxygen Saturation Monitoring: A Laboratory Study","Human Factors","","0018-7208","10.1177/0018720815617406","https://doi.org/10.1177/0018720815617406","ObjectiveWe aimed to test whether the use of novel pulse oximetry sounds (sonifications) better informs listeners when a neonate’s oxygen saturation (SpO2) deviates from the recommended range.BackgroundVariable-pitch pulse oximeters do not accurately inform clinicians via sound alone when SpO2 is outside the target range of 90% to 95% for neonates on supplemental oxygen. Risk of blindness, organ damage, and death increase if SpO2 remains outside the target range. A more informative sonification may improve clinicians’ ability to maintain the target range.MethodIn two desktop experiments, nonclinicians’ ability to detect SpO2 range and direction of change was tested with novel versus conventional sonifications of simulated patient data. In Experiment 1, a “shoulder” sonification used larger pitch differences between adjacent saturation percentages for SpO2 values outside the target range. In Experiment 2, a “beacon” sonification used equal-appearing pitch differences, but when SpO2 was outside the target range, a fixed-pitch reference tone from the center of the target SpO2 range preceded every fourth pulse tone.ResultsThe beacon sonification improved range identification accuracy over the control display (85% vs. 60%; p < .001), but the shoulder sonification did not (55% vs. 52%).ConclusionThe beacon provided a distinct auditory alert and reference that significantly improved nonclinical participants’ ability to identify SpO2 range.ApplicationAdding a beacon to the variable-pitch pulse oximeter sound may help clinicians identify when, and by how much, a neonate’s SpO2 deviates from the target range, particularly during patient transport situations when auditory information becomes essential.","2016-03-01","2023-07-06 06:14:02","2023-07-06 06:14:02","2023-07-06 06:13:49","344-359","","2","58","","Hum Factors","Novel Pulse Oximetry Sonifications for Neonatal Oxygen Saturation Monitoring","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/2UZBV9Q5/Hinckfuss et al. - 2016 - Novel Pulse Oximetry Sonifications for Neonatal Ox.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AYI32QS8","journalArticle","2004","Smith, Daniel R.; Walker, Bruce N.","Effects of Training and Auditory Context on Performance of a Point Estimation Sonification Task","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/154193120404801608","https://doi.org/10.1177/154193120404801608","Research on auditory graphs has investigated mappings, scalings, and polarities (Walker, 2002), as well as the addition of some contextual design features (Bonebright, Nees, Connerley, & McCain, 2001; Flowers, Buhman, & Turnage, 1997), in order to improve performance. However, little has been done to quantify the performance effects of such features, or to investigate effects of training in specific sonification tasks such as point estimation. Smith and Walker (2002) took a step towards quantifying and comparing the effects of adding several contextual design features. Presented here are selected results from a comprehensive follow-on study comparing effects of adding auditory context, either with or without training. The overall results indicate that some kinds of auditory context improved performance, while others did not. Training improved performance, and an interaction was discovered between type of auditory context and type of training (Smith, 2003). Implications are discussed.","2004-09-01","2023-07-06 06:14:02","2023-07-06 06:14:02","2023-07-06 06:13:51","1828-1831","","16","48","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/XC38U5EI/Smith and Walker - 2004 - Effects of Training and Auditory Context on Perfor.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EDG3SAS7","journalArticle","2004","Anderson, Janet; Sanderson, Penelope","Designing Sonification for Effective Attentional Control in Complex Work Domains","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/154193120404801606","https://doi.org/10.1177/154193120404801606","Complex safety-critical work domains such as anesthesia require human operators to direct their attention appropriately. A sonification is a possible method for directing attention to relevant changes while still allowing monitoring under divided attention conditions. However, there is currently little information to guide the design of sonification. Two experiments investigated the effect of the number of auditory streams on ability to detect changes (Experiment 1), and the effect of the number of auditory streams under different attention conditions (Experiment 2). When monitoring with selective attention, participants noted changes more accurately with three streams than with one or two streams, but when there were also distracter changes participants noted changes more accurately in multiple streams. Overall, accuracy was lower when attention was divided than when it was selective, but accuracy was especially low in the three-stream configuration. Distracter changes increased divided attention accuracy. The results suggest that the number of streams should be minimized if operators' attention will be divided between monitoring and other tasks.","2004-09-01","2023-07-06 06:14:02","2023-07-06 06:14:02","2023-07-06 06:13:53","1818-1822","","16","48","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/EQK5CY9A/Anderson and Sanderson - 2004 - Designing Sonification for Effective Attentional C.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5WXYZ4R2","journalArticle","2004","Watson, Marcus; Sanderson, Penelope","Sonification Supports Eyes-Free Respiratory Monitoring and Task Time-Sharing","Human Factors","","0018-7208","10.1518/hfes.46.3.497.50401","https://doi.org/10.1518/hfes.46.3.497.50401","Three experiments explored the effectiveness of continuous auditory displays, or sonifications, for conveying information about a simulated anesthetized patient's respiration. Experiment 1 established an effective respiratory sonification. Experiment 2 showed an effect of expertise in the use of respiratory sonification and revealed that some apparent differences in sonification effectiveness could be accounted for by response bias. Experiment 3 showed that sonification helps anesthesiologists to maintain high levels of awareness of the simulated patient's state while performing other tasks more effectively than when relying upon visual monitoring of the simulated patient state. Overall, sonification of patient physiology beyond traditional pulse oximetry appears to be a viable and useful adjunct to visual monitors. Actual and potential applications of this research include monitoring in a wide variety of busy critical care contexts.","2004-09-01","2023-07-06 06:14:02","2023-07-06 06:14:02","2023-07-06 06:13:54","497-517","","3","46","","Hum Factors","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/EYDTIKUV/Watson and Sanderson - 2004 - Sonification Supports Eyes-Free Respiratory Monito.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EDZ9A22W","journalArticle","2013","Viraldo, Jacob; Caldwell, Barrett","Sonification as Sensemaking in Control Room Applications","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/1541931213571318","https://doi.org/10.1177/1541931213571318","Traditional analog alarms are nearly always exclusively binary, resulting in a single audio signal display sounding in order to inform users of a particular system parameter which has varied from within its predefined limits. During emergency situations, users can be faced with multiple simultaneous alarms, each relaying information concerning different, but usually related, system parameters. Using advanced sonification principles, achieved real-time with digital sound manipulation according to established human factors principles, new multi-parameter alarms can be created to better inform users of suboptimal conditions. These high-tech alarms also serve to help users maintain high levels of situational awareness, while aiding in sensemaking and decreasing stress caused by alarm flooding and cognitive overload.","2013-09-01","2023-07-06 06:14:02","2023-07-06 06:14:02","2023-07-06 06:13:56","1423-1426","","1","57","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/P6P54ZJR/Viraldo and Caldwell - 2013 - Sonification as Sensemaking in Control Room Applic.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EMRR9SQT","journalArticle","2021","Nadri, Chihab; Ko, Sangjin; Diggs, Colin; Winters, Michael; Sreehari, V. K.; Jeon, Myounghoon","Novel Auditory Displays in Highly Automated Vehicles: Sonification Improves Driver Situation Awareness, Perceived Workload, and Overall Experience","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/1071181321651071","https://doi.org/10.1177/1071181321651071","Highly automated driving systems are expected to require the design of new user-vehicle interactions. Sonification can be used to provide contextualized alarms and cues that can increase situation awareness and user experience. In this study, we examined user perceptions of potential use cases for level 4 automated vehicles in online focus group interviews (N=12). Also, in a driving simulator study, we evaluated (1) visual-only display; (2) non-speech with visual display; and (3) speech with visual display with 20 young drivers. Results indicated participants’ interest in the use cases and insight on desired functions in highly automated vehicles. Both audiovisual display conditions resulted in higher situation awareness for drivers than the visual-only condition. Some differences were found between the non-speech and speech conditions suggesting benefits of sonification for both driving and non-driving related auditory use cases. This study will provide guidance on sonification design for highly automated vehicles.","2021-09-01","2023-07-06 06:14:02","2023-07-06 06:14:02","2023-07-06 06:13:58","586-590","","1","65","","","Novel Auditory Displays in Highly Automated Vehicles","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/T2U83TRA/Nadri et al. - 2021 - Novel Auditory Displays in Highly Automated Vehicl.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KJD2PQIZ","journalArticle","2014","Nees, Michael A.; Walker, Bruce N.","Performance of a Sonification Task in the Presence of Verbal, Visuospatial, and Auditory Interference Tasks","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/1541931214581249","https://doi.org/10.1177/1541931214581249","An experiment examined performance with sonifications—a general term for nonspeech auditory displays—as a function of working memory encoding and the demands of three different types of interference tasks. Participants encoded the sonifications as verbal representations, visuospatial images, or auditory images. After encoding, participants engaged in brief verbal, visuospatial, or auditory interference tasks before responding to point estimation queries about the sonifications. Results were expected to show selective impact on sonification task performance when the interference task demands matched the working memory encoding strategy, but instead a pattern of general working memory interference emerged in addition to auditory modal interference. In practical applications, results suggested that performance with auditory displays will be impacted by any interference task, though auditory tasks likely will cause more interference than verbal or visuospatial tasks.","2014-09-01","2023-07-06 06:14:02","2023-07-06 06:14:02","2023-07-06 06:14:00","1194-1198","","1","58","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/DEQVRDUG/Nees and Walker - 2014 - Performance of a Sonification Task in the Presence.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"533TWJF3","journalArticle","2016","Paterson, Estrella; Sanderson, Penelope; Paterson, Neil; Liu, David; Loeb, Robert","The effect of a secondary task on identification accuracy of oxygen saturation ranges using an enhanced pulse oximetry sonification: A laboratory study","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/1541931213601143","https://doi.org/10.1177/1541931213601143","In the operating theatre, anesthesiologists monitor an anesthetized patient’s oxygen saturation (SpO2) with a visual display but also with an auditory tone, or sonification. However, if the anesthesiologist must divide their attention across tasks, they may be less effective at recognising their patient’s SpO2 level. Previous research indicates that a sonification enhanced with additional sound dimensions of tremolo and brightness more effectively supports participants’ identification of SpO2 ranges than a conventional sonification does. This laboratory study explored the effect of a secondary task on participants’ ability to identify SpO2 range when using a conventional sonification (LogLinear sonification) versus an enhanced sonification (Stepped Effects sonification). Nineteen non-clinician participants who used the Stepped Effects sonification were significantly more effective at identifying SpO2 range (Md = 100%) than were 18 participants using the LogLinear sonification (Md = 80%). Range identification performance of participants using the Stepped Effects sonification tended to be less disrupted by a concurrent arithmetic task (drop from Md = 100% to 95%) than it was for participants using the LogLinear sonification (drop from Md = 80% to 73%). However, the disruption effect in each case was small, and the difference in disruption across sonifications was not statistically significant. Future research will test the sonifications under more intense cognitive load and in the presence of ambient noise.","2016-09-01","2023-07-06 06:14:02","2023-07-06 06:14:02","2023-07-06 06:14:02","628-632","","1","60","","","The effect of a secondary task on identification accuracy of oxygen saturation ranges using an enhanced pulse oximetry sonification","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/Q4ZT82K3/Paterson et al. - 2016 - The effect of a secondary task on identification a.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G78PJ2IC","journalArticle","2013","Janata, Petr; Edwards, William H.","A Novel Sonification Strategy for Auditory Display of Heart Rate and Oxygen Saturation Changes in Clinical Settings","Human Factors","","0018-7208","10.1177/0018720812455433","https://doi.org/10.1177/0018720812455433","Objective:The aim of this study was development of a sonification scheme to convey deviations in heart rate and oxygen saturation from a desired target level.Background:Maintaining physiologic parameters, such as oxygen saturation, within desired ranges, is challenging in many clinical situations. High rates of false positive alarms in clinical settings limit the utility of the alarms that trigger when thresholds are exceeded. Auditory displays that consider the semantic connotations of sounds and the processing limitations of human perception and cognition may improve monitoring.Method:Across two experiments, clinical practi-tioners were tested on their ability to (a) discriminate pairs of sounds (two-note discrimination task), (b) infer and discern the intended physiological connotation of each acoustic attribute (name-the-variable task), and (c) categorize the amount of change in an implied physiological variable into three levels of change: none, small, and large (change-magnitude task).Results:Considerable variation in performance was observed across the set of practitioners, ranging from near-perfect performance on all tasks, even with no prior exposure to the stimuli, to failure to reach a target accuracy criterion of 87.5% after ~80 min of training. On average, performance was well above chance on the name-the-variable and change-magnitude tasks during initial exposure and reached criterion within ~20 min of training on each task.Conclusion:The described sonification strategy may effectively communicate information about current heart rate and oxygen saturation status relative to desired target levels.Application:The results can be applied to clinical monitoring settings in which a stream of discrete auditory informational items is indicated.","2013-04-01","2023-07-06 06:15:01","2023-07-06 06:15:01","2023-07-06 06:14:41","356-372","","2","55","","Hum Factors","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/WK8KNB2S/Janata and Edwards - 2013 - A Novel Sonification Strategy for Auditory Display.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8E6G336H","journalArticle","2020","Collett, Renae; Salisbury, Isaac; Loeb, Robert G.; Sanderson, Penelope M.","Smooth or Stepped? Laboratory Comparison of Enhanced Sonifications for Monitoring Patient Oxygen Saturation","Human Factors","","0018-7208","10.1177/0018720819845742","https://doi.org/10.1177/0018720819845742","Background:The pulse oximeter (PO) provides anesthesiologists with continuous visual and auditory information about a patient’s oxygen saturation (SpO2). However, anesthesiologists’ attention is often diverted from visual displays, and clinicians may inaccurately judge SpO2 values when relying on conventional PO auditory tones. We tested whether participants could identify SpO2 value (e.g., “97%”) better with acoustic enhancements that identified three discrete clinical ranges by either changing abruptly at two threshold values (stepped-effects) or changing incrementally with each percentage value of SpO2 (smooth-effects).Method:In all, 79 nonclinicians participated in a between-subjects experiment that compared performance of participants using the stepped-effects display with those who used the smooth-effects display. In both conditions, participants heard sequences of 72 tones whose pitch directly correlated to SpO2 value, and whose value could change incrementally. Primary outcome was percentage of responses that correctly identified the absolute SpO2 percentage, ±1, of the last pulse tone in each sequence.Results:Participants using the stepped-effects auditory tones identified absolute SpO2 percentage more accurately (M = 53.7%) than participants using the smooth-effects tones (M = 47.9%, p = .038). Identification of range and detection of transitions between ranges showed even stronger advantages for the stepped-effects display (p < .005).Conclusion:The stepped-effects display has more pronounced auditory cues at SpO2 range transitions, from which participants can better infer absolute SpO2 values. Further development of a smooth-effects display for this purpose is not necessary.","2020-02-01","2023-07-06 06:15:01","2023-07-06 06:15:01","2023-07-06 06:14:43","124-137","","1","62","","Hum Factors","Smooth or Stepped?","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/HXURIUAP/Collett et al. - 2020 - Smooth or Stepped Laboratory Comparison of Enhanc.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SVKIG5IA","journalArticle","2012","Viraldo, Jacob; Caldwell, Barrett","Developing a Unique Research Opportunity in Control Room Alarm Sonification","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/1071181312561129","https://doi.org/10.1177/1071181312561129","Alarm flooding occurs because of systemic overreliance on alarms and recurrent manpower shortage in control environments due to the relative unpredictability and scarcity of emergency states. As alarm technology has become cheaper, digitized, and more effective, its pervasiveness has increased. Organizations trying to reduce costs, human error, and manpower have taken to using more automated systems, more alarms and fewer operators. Such approaches are logical using a strict cost basis, but can lead to significant problems in cognitive loading and sensemaking when emergency states are triggered and alarm flooding occurs in any quintessential safety-critical system. The result of these trends has been a tendency towards more frequent alarm flooding. In this context, the primary author has a unique opportunity to develop a dissertation research project to address a once-in-a-generation challenge: addressing system design and implementation criteria for improved alarm designs for emerging technologies, including nuclear power plant control environments. This paper addresses technical and student development issues in developing a novel, unprecedented doctoral dissertation with significant application potential.","2012-09-01","2023-07-06 06:15:01","2023-07-06 06:15:01","2023-07-06 06:14:45","620-623","","1","56","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/3WQJKR5C/Viraldo and Caldwell - 2012 - Developing a Unique Research Opportunity in Contro.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8BVRNZXY","journalArticle","2019","Winters, R. Michael; Joshi, Neel; Cutrell, Edward; Morris, Meredith Ringel","Strategies for Auditory Display of Social Media","Ergonomics in Design","","1064-8046","10.1177/1064804618788098","https://doi.org/10.1177/1064804618788098","Social media is an overwhelmingly visual medium, and we ask the simple question: How can the data and images of social media posts be transformed into something as meaningful and vivid in the auditory sense? Such a design would be useful for eyes-free browsing and could enhance the existing visual media. Our strategy first uses artificial intelligence systems to transform low-level input data into high-level sociocultural features. These features are then conveyed using a multifactored temporal design that uses speech, sonification, auditory scenes, and music.","2019-01-01","2023-07-06 06:15:01","2023-07-06 06:15:01","2023-07-06 06:14:47","11-15","","1","27","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/TIH6TQLQ/Winters et al. - 2019 - Strategies for Auditory Display of Social Media.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5JJK4GUV","journalArticle","2019","Zestic, Jelena; Brecknell, Birgit; Liley, Helen; Sanderson, Penelope","A Novel Auditory Display for Neonatal Resuscitation: Laboratory Studies Simulating Pulse Oximetry in the First 10 Minutes After Birth","Human Factors","","0018-7208","10.1177/0018720818793769","https://doi.org/10.1177/0018720818793769","Objective:We tested whether enhanced sonifications would improve participants’ ability to judge the oxygen saturation levels (SpO2) of simulated neonates in the first 10 min after birth.Background:During the resuscitation of a newborn infant, clinicians must keep the neonate’s SpO2 levels within the target range, however the boundaries for the target range change each minute during the first 10 min after birth. Resuscitation places significant demand on the clinician’s visual attention, and the pulse oximeter’s sonification could provide eyes-free monitoring. However, clinicians have difficulty judging SpO2 levels using the current sonification.Method:In two experiments, nonclinicians’ ability to detect SpO2 range and direction—while performing continuous arithmetic problems—was tested with enhanced versus conventional sonifications. In Experiment 1, tremolo signaled when SpO2 had deviated below or above the target range. In Experiment 2, tremolo plus brightness signaled when SpO2 was above target range, and tremolo alone when SpO2 was below target range.Results:The tremolo sonification improved range identification accuracy over the conventional display (81% vs. 63%, p < .001). The tremolo plus brightness sonification further improved range identification accuracy over the conventional display (92% vs. 62%, p <.001). In both experiments, there was no difference across conditions in arithmetic task accuracy (p >.05).Conclusion:Using the enhanced sonifications, participants identified SpO2 range more accurately despite a continuous distractor task.Application:An enhanced pulse oximetry sonification could help clinicians multitask more effectively during neonatal resuscitations.","2019-02-01","2023-07-06 06:15:01","2023-07-06 06:15:01","2023-07-06 06:14:49","119-138","","1","61","","Hum Factors","A Novel Auditory Display for Neonatal Resuscitation","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/CD46EQ59/Zestic et al. - 2019 - A Novel Auditory Display for Neonatal Resuscitatio.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MYEQ5BF4","journalArticle","2014","Towers, John; Burgess-Limerick, Robin; Riek, Stephan","Concurrent 3-D Sonifications Enable the Head-Up Monitoring of Two Interrelated Aircraft Navigation Instruments","Human Factors","","0018-7208","10.1177/0018720814536443","https://doi.org/10.1177/0018720814536443","Objective:The aim of this study was to enable the head-up monitoring of two interrelated aircraft navigation instruments by developing a 3-D auditory display that encodes this navigation information within two spatially discrete sonifications.Background:Head-up monitoring of aircraft navigation information utilizing 3-D audio displays, particularly involving concurrently presented sonifications, requires additional research.Method:A flight simulator’s head-down waypoint bearing and course deviation instrument readouts were conveyed to participants via a 3-D auditory display. Both readouts were separately represented by a colocated pair of continuous sounds, one fixed and the other varying in pitch, which together encoded the instrument value’s deviation from the norm. Each sound pair’s position in the listening space indicated the left/right parameter of its instrument’s readout. Participants’ accuracy in navigating a predetermined flight plan was evaluated while performing a head-up task involving the detection of visual flares in the out-of-cockpit scene.Results:The auditory display significantly improved aircraft heading and course deviation accuracy, head-up time, and flare detections. Head tracking did not improve performance by providing participants with the ability to orient potentially conflicting sounds, suggesting that the use of integrated localizing cues was successful.Conclusion:A supplementary 3-D auditory display enabled effective head-up monitoring of interrelated navigation information normally attended to through a head-down display.Application:Pilots operating aircraft, such as helicopters and unmanned aerial vehicles, may benefit from a supplementary auditory display because they navigate in two dimensions while performing head-up, out-of-aircraft, visual tasks.","2014-12-01","2023-07-06 06:15:01","2023-07-06 06:15:01","2023-07-06 06:14:51","1414-1427","","8","56","","Hum Factors","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/X44E7GN7/Towers et al. - 2014 - Concurrent 3-D Sonifications Enable the Head-Up Mo.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GDB7EZWV","journalArticle","2013","Ho, Anson; Burns, Catherine","Music as an Auditory Display: Interaction Effects of Mode and Tempo on Perceived Urgency","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/1541931213571256","https://doi.org/10.1177/1541931213571256","Currently, there are very few guidelines on parameters needed to create an effective auditory display. Auditory displays can be intrusive and may not be used effectively if they are poorly designed. However, music is often in our environments as ambient noise and, instead of being intrusive, can be perceived as making the environment calmer and more productive. We present the initial steps of exploring the option of using music as a medium to develop an auditory display capable of conveying normal state information and warning information. An important feature that may impact the effectiveness of auditory warnings is perceived urgency: the impression of urgency that a sound evokes on a listener. To explore whether music could convey urgency as needed for auditory warnings, we evaluated four different musical phrases that varied in time and key signature as a method of measuring the effects of mode and tempo on perceived urgency. The effectiveness of the study was tested with twenty subjects split into a two by two factorial design: gender (male vs. female) and musical experience (experienced vs. non-experienced). The applications of this research can help develop concrete guidelines when designing effective auditory displays in order to improve users’ performance when dealing with complex interfaces.","2013-09-01","2023-07-06 06:15:01","2023-07-06 06:15:01","2023-07-06 06:14:53","1149-1153","","1","57","","","Music as an Auditory Display","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/NTXE2XZU/Ho and Burns - 2013 - Music as an Auditory Display Interaction Effects .pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MRE88DBM","journalArticle","2022","Clarke, Hugh; Leav, Samnang; Zestic, Jelena; Mohamed, Ismail; Salisbury, Isaac; Sanderson, Penelope","Enhanced Neonatal Pulse Oximetry Sounds for the First Minutes of Life: A Laboratory Trial","Human Factors","","0018-7208","10.1177/00187208221118472","https://doi.org/10.1177/00187208221118472","ObjectiveAuditory enhancements to the pulse oximetry tone may help clinicians detect deviations from target ranges for oxygen saturation (SpO2) and heart rate (HR).BackgroundClinical guidelines recommend target ranges for SpO2 and HR during neonatal resuscitation in the first 10 minutes after birth. The pulse oximeter currently maps HR to tone rate, and SpO2 to tone pitch. However, deviations from target ranges for SpO2 and HR are not easy to detect.MethodForty-one participants were presented with 30-second simulated scenarios of an infant’s SpO2 and HR levels in the first minutes after birth. Tremolo marked distinct HR ranges and formants marked distinct SpO2 ranges. Participants were randomly allocated to conditions: (a) No Enhancement control, (b) Enhanced HR Only, (c) Enhanced SpO2 Only, and (d) Enhanced Both.ResultsParticipants in the Enhanced HR Only and Enhanced SpO2 Only conditions identified HR and SpO2 ranges, respectively, more accurately than participants in the No Enhancement condition, ps < 0.001. In the Enhanced Both condition, the tremolo enhancement of HR did not affect participants’ ability to identify SpO2 range, but the formants enhancement of SpO2 may have attenuated participants’ ability to identify tremolo-enhanced HR range.ConclusionTremolo and formant enhancements improve range identification for HR and SpO2, respectively, and could improve clinicians’ ability to identify SpO2 and HR ranges in the first minutes after birth.ApplicationEnhancements to the pulse oximeter tone to indicate clinically important ranges could improve the management of oxygen delivery to the neonate during resuscitation in the first 10 minutes after birth.","2022-08-21","2023-07-06 06:15:01","2023-07-06 06:15:01","2023-07-06 06:14:57","00187208221118472","","","","","Hum Factors","Enhanced Neonatal Pulse Oximetry Sounds for the First Minutes of Life","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/GFK4F3LN/Clarke et al. - 2022 - Enhanced Neonatal Pulse Oximetry Sounds for the Fi.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K73AHRVK","journalArticle","2017","Hickling, Anna; Brecknell, Birgit; Loeb, Robert G.; Sanderson, Penelope","Using a Sequence of Earcons to Monitor Multiple Simulated Patients","Human Factors","","0018-7208","10.1177/0018720816670986","https://doi.org/10.1177/0018720816670986","Objective:The aim of this study was to determine whether a sequence of earcons can effectively convey the status of multiple processes, such as the status of multiple patients in a clinical setting.Background:Clinicians often monitor multiple patients. An auditory display that intermittently conveys the status of multiple patients may help.Method:Nonclinician participants listened to sequences of 500-ms earcons that each represented the heart rate (HR) and oxygen saturation (SpO2) levels of a different simulated patient. In each sequence, one, two, or three patients had an abnormal level of HR and/or SpO2. In Experiment 1, participants reported which of nine patients in a sequence were abnormal. In Experiment 2, participants identified the vital signs of one, two, or three abnormal patients in sequences of one, five, or nine patients, where the interstimulus interval (ISI) between earcons was 150 ms. Experiment 3 used the five-sequence condition of Experiment 2, but the ISI was either 150 ms or 800 ms.Results:Participants reported which patient(s) were abnormal with median 95% accuracy. Identification accuracy for vital signs decreased as the number of abnormal patients increased from one to three, p < .001, but accuracy was unaffected by number of patients in a sequence. Overall, identification accuracy was significantly higher with an ISI of 800 ms (89%) compared with an ISI of 150 ms (83%), p < .001.Conclusion:A multiple-patient display can be created by cycling through earcons that represent individual patients.Application:The principles underlying the multiple-patient display can be extended to other vital signs, designs, and domains.","2017-03-01","2023-07-06 06:15:01","2023-07-06 06:15:01","2023-07-06 06:14:59","268-288","","2","59","","Hum Factors","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/2EXAKH5P/Hickling et al. - 2017 - Using a Sequence of Earcons to Monitor Multiple Si.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E3QECN5N","journalArticle","2019","Winters, R. Michael; Tomlinson, Brianna J.; Walker, Bruce N.; Moore, Emily B.","Sonic Interaction Design for Science Education","Ergonomics in Design","","1064-8046","10.1177/1064804618797399","https://doi.org/10.1177/1064804618797399","The PhET project is a collection of over 130 interactive simulations (or “sims”) designed to teach physics concepts to students from elementary to university levels. The sims rely heavily on visual representation, making them inaccessible to students with disabilities, including those with visual impairments. We present the theory, methods, and process behind our audio design and provide example mapping strategies from two of the simulations. We compare physical, abstract, and musical mapping strategies, noting the strengths of each. We conclude with design recommendations that have arisen in our work, and for which we think would benefit the field at large.","2019-01-01","2023-07-06 06:15:01","2023-07-06 06:15:01","2023-07-06 06:15:01","5-10","","1","27","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/KZQF5EF2/Winters et al. - 2019 - Sonic Interaction Design for Science Education.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WPGL3RLX","journalArticle","2016","Haygood, Montana; Walker, Bruce N.","Temporary and Permanent Hearing Loss Among College-Aged Drumline Members","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/1541931213601234","https://doi.org/10.1177/1541931213601234","Many musicians experience dangerous levels of sound exposure throughout their musical careers. In particular, members of marching percussion ensembles (“drumlines”) are exposed to prolonged periods of potentially damaging levels of sound. As a result, they are at risk of developing hearing loss. This study determines whether any significant hearing loss or threshold shifts occurs with drumline members in an indoor drumline and college marching band. Two groups of participants were analyzed: one group consisted of both college drumline and community-based competitive drumline members, while the other (control) group consisted of non-drummers who were matched for age and gender to the drummers. The non-drummers were given an audiogram to determine the lowest levels of sound they could detect. The drummers were given an audiogram immediately before and after a drumline rehearsal. First, the drummer group showed significant hearing loss at the start of their rehearsal, compared to the non-drummer group. This is indication of permanent hearing loss for the drummers. Second, the drummers’ hearing thresholds after rehearsal were compared to their levels immediately before rehearsal. A significant shift in the drummer group’s hearing threshold was found, indicating (additional) temporary hearing loss occurring over the course of the rehearsal. Earplug usage of the drummers during their rehearsals was also analyzed. Drummers who did not wear earplugs exhibited a significantly greater threshold shift (i.e., hearing loss) than drummers who did wear earplugs. Evidence of both temporary and permanent hearing loss amongst the drummer group makes it clear that drumline members should be required to wear hearing protection during rehearsals, and presumably also during performances.","2016-09-01","2023-07-06 06:16:07","2023-07-06 06:16:07","2023-07-06 06:15:48","1009-1013","","1","60","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/ZY4FFGCR/Haygood and Walker - 2016 - Temporary and Permanent Hearing Loss Among College.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8XYTALR7","journalArticle","2008","Palladino, Dianne K.; Walker, Bruce N.","Navigation Efficiency of Two Dimensional Auditory Menus Using Spearcon Enhancements","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/154193120805201823","https://doi.org/10.1177/154193120805201823","A total of 28 undergraduates navigated to specific items in a two dimensional menu that was displayed using only sound. The auditory menu consisted of either text-to-speech (TTS) only, or TTS enhanced with spearcons. Spearcons are brief sound cues created by compressing the original TTS sound file. Speed of navigation to target items in the auditory menu was found to be significantly faster in the spearcon condition than in the condition using only TTS. There was also a smaller per-item cost in terms of speed for the spearcon-enhanced menu, leading to increasingly better performance as menu length increased. These results provide further evidence that spearcon enhancements can lead to faster navigational performance in auditory menus, when compared to text-to-speech alone.","2008-09-01","2023-07-06 06:16:07","2023-07-06 06:16:07","2023-07-06 06:15:50","1262-1266","","18","52","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/KY5MMNGD/Palladino and Walker - 2008 - Navigation Efficiency of Two Dimensional Auditory .pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5V7BUU85","journalArticle","2011","Jeon, Myounghoon; Walker, Bruce N.","What to detect?: Analyzing Factor Structures of Affect in Driving Contexts for an Emotion Detection and Regulation System","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/1071181311551393","https://journals.sagepub.com/doi/abs/10.1177/1071181311551393","This research is a part of the IVAT (In-Vehicle Assistive Technology) project, an in-dash interface design project to help drivers who have various disabilities, including deficits in emotion regulation. While there have been several studies on emotion detection for drivers, few studies have seriously addressed what to detect and why. Those are crucial issues to consider when implementing an effective affect management system. Phase 1 of our study gathered a total of 33 different driving situations that can induce emotions and 56 plausible affective keywords to describe such emotions. Phase 2 analyzed factor structures of affect for driving contexts through user ratings and Factor Analysis, and obtained nine factors: fearful, happy, angry, depressed, curious, embarrassed, urgent, bored, and relieved. These factors accounted for 65.1% of the total variance. Results are discussed in terms of designing the IVAT emotion detection and regulation system for driving contexts.","2011-09-01","2023-07-06 06:16:07","2023-07-06 06:16:07","2023-07-06 06:15:52","1889-1893","","1","55","","","What to detect?","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/ILTV7XGS/Jeon and Walker - 2011 - What to detect Analyzing Factor Structures of Af.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3TSDSPRU","journalArticle","2009","Jeon, Myounghoon; Walker, Bruce N.","“Spindex”: Accelerated Initial Speech Sounds Improve Navigation Performance in Auditory Menus","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/154193120905301708","https://doi.org/10.1177/154193120905301708","Users interact with mobile devices through menus, which can include many items. Auditory menus can supplement or even replace visual menus. Unfortunately, little research has been devoted to enhancing the usability of large auditory menus. We evaluated a novel auditory menu enhancement called a “spindex” (i.e., speech index), in which brief audio cues inform the user where she is in a long menu. In the current implementation, each item in a menu is preceded by a sound based on the item's initial letter. 25 undergraduates navigated through an alphabetized contact list of 50 or 150 names. The menu was presented with text-to-speech (TTS) alone, or TTS plus spindex, and with the visual menu displayed or not. Search time was faster with the spindex-enhanced menu, especially for long lists. Subjective ratings also favored the spindex. Results are discussed in terms of theory and practical applications.","2009-10-01","2023-07-06 06:16:07","2023-07-06 06:16:07","2023-07-06 06:15:55","1081-1085","","17","53","","","“Spindex”","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/WAEAUD65/Jeon and Walker - 2009 - “Spindex” Accelerated Initial Speech Sounds Impro.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FCZR7596","journalArticle","2002","Flowers, John H.; Grafel, Douglas C.","Perception of Sonified Daily Weather Records","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/154193120204601711","https://doi.org/10.1177/154193120204601711","Human participants performed a perceptual task in which they sorted auditory (musical) displays of one-month long daily weather summaries (temperature, rainfall, and snowfall) based on perceived similarity of weather patterns. Displays for fifteen winter months and fifteen summer months were sorted by separate groups of participants. Each group sorted two sets of displays that varied in presentation speed. Multidimensional scaling analyses indicated that these displays were effective in conveying weather features important for climate comparisons for both winter and summer months, and that the faster (7.1 sec) displays were more effective than the slower (14.2 sec) displays. These results show that sonification can be an effective tool for exploring multivariate time series data, but that optimization of such displays may require consideration of the temporal constraints of auditory sensory memory and working memory.","2002-09-01","2023-07-06 06:16:07","2023-07-06 06:16:07","2023-07-06 06:15:57","1579-1583","","17","46","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/JI5IN99S/Flowers and Grafel - 2002 - Perception of Sonified Daily Weather Records.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YW3D5DBT","journalArticle","2012","Suh, Hyewon; Jeon, Myounghoon; Walker, Bruce N.","Spearcons Improve Navigation Performance and Perceived Speediness in Korean Auditory Menus","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/1071181312561390","https://doi.org/10.1177/1071181312561390","For decades, auditory menus using both speech (usually text-to-speech, TTS) and non-speech sounds have been extensively studied. Researchers have developed situation-optimized auditory menus involving such cues as auditory icons, earcons, spearcons, and spindex. Spearcons have generally outperformed other cues in terms of providing both contextual information and item-specific information. However, little research has been devoted to exploration of spearcons in languages other than English, or the use of spearcon-only auditory menus. In this study, we evaluated the use of spearcons in Korean menus, as well as the use of spearcons alone. Twenty-five native Korean speakers navigated through a two-dimensional auditory menu presented via TTS, with or without spearcon enhancements. Korean spearcons were successful. Participants also rated the spearcon-enhanced menu as seeming speedier and more fun than the TTS-only menu. After a short learning period, mean time-to-target in the auditory menu was even faster with spearcons alone, compared to traditional TTS-only menus.","2012-09-01","2023-07-06 06:16:07","2023-07-06 06:16:07","2023-07-06 06:15:59","1361-1365","","1","56","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/67JXM32K/Suh et al. - 2012 - Spearcons Improve Navigation Performance and Perce.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K5QVQWD7","journalArticle","2000","Xiao, Yan; Seagull, F. Jacob","Auditory Warning Signals: New Concepts and Approaches","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/154193120004400156","https://doi.org/10.1177/154193120004400156","The importance of auditory warning signals has long been recognized by designers, yet the design of current auditory warnings are often cited as fundamentally flawed by numerous shortcomings. This symposium, using the medical domain as the context, begins by introducing the status quo and trends in auditory warning design, and discusses the current problems within this setting. We continue with a presentation of the efforts of the International Organization for Standards (ISO) to improve auditory warnings for current and future medical devices. Informative auditory signals are discussed in the final two presentations, focusing first on techniques using “earcons,” “sonification,” in general, and then examining how these continuous and intermittent auditory warnings and informative displays could support the users' tasks.","2000-07-01","2023-07-06 06:16:07","2023-07-06 06:16:07","2023-07-06 06:16:02","210-210","","1","44","","","Auditory Warning Signals","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/PYWC6YA6/Xiao and Seagull - 2000 - Auditory Warning Signals New Concepts and Approac.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5RYS4LP2","journalArticle","2019","Jeon, Myounghoon","Exploring Design Constructs In Sound Design With A Focus On Perceived Affordance","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/1071181319631340","https://doi.org/10.1177/1071181319631340","While design theories in visual displays have been well developed and further refined, relatively little research has been conducted on design theories and models in auditory displays. The existing discussions mainly account for functional mappings between sounds and referents, but these do not fully address design aspects of auditory displays. To bridge the gap, the present proposal focuses on design affordances in sound design among many design constructs. To this end, the definition and components of design affordances are briefly explored, followed by the auditory display examples of those components to gauge whether sound can deliver perceived affordances in interactive products. Finally, other design constructs, such as feedback and signifier, are discussed together with future work. This exploratory proposal is expected to contribute to elaborating sound design theory and practice.","2019-11-01","2023-07-06 06:16:07","2023-07-06 06:16:07","2023-07-06 06:16:03","1199-1203","","1","63","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/8GE2KDDI/Jeon - 2019 - Exploring Design Constructs In Sound Design With A.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8KXK7HWG","journalArticle","2022","Choi, Jinwoo; Lodinger, Natalie; Jones, Keith S.; Siami Namin, Akbar; Armstrong, Miriam; Sears, David","Are Users Better Able to Correctly Interpret Single or Concatenated Auditory Icons that Convey a Complex Message?","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/1071181322661416","https://doi.org/10.1177/1071181322661416","Auditory icons are naturally occurring sounds that systems play to convey information. Systems must convey complex messages. To do so, systems can play: 1) a single sound that represents the entire message, or 2) a single sound that represents the first part of the message, followed by another sound that represents the next part of that message, etc. The latter are known as concatenated auditory icons. To evaluate those approaches, participants interpreted single and concatenated auditory icons designed to convey their message well and poorly. Single auditory icons designed to convey their message well were correctly interpreted more often than those designed to convey their message poorly; that was not true for concatenated auditory icons. Concatenated auditory icons should not be comprised of a series of sounds that each represents its piece of a message well. The whole of a concatenated auditory icon is not the sum of its parts.","2022-09-01","2023-07-06 06:16:07","2023-07-06 06:16:07","2023-07-06 06:16:05","1100-1104","","1","66","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/MAYXTZEX/Choi et al. - 2022 - Are Users Better Able to Correctly Interpret Singl.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EINQ3YY8","journalArticle","2016","Jeon, Myounghoon","How Is Nonverbal Auditory Information Processed? Revisiting Existing Models and Proposing a Preliminary Model","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/1541931213601351","https://doi.org/10.1177/1541931213601351","Use of multimodal displays is getting more prevalent in Human Factors and Human-Computer Interaction. Existing information processing models and theories predict the benefits of multimodality in user interfaces. While the models have been refined regarding vision, more granularity is still required regarding audition. The existing models mainly account for verbal processing in terms of representation, encoding, and retrieving, but these models do not provide sufficient explanations for nonverbal processing. In the present paper, I point out research gaps in nonverbal information processing of the representative models at the working memory and attention level. Then, I propose a preliminary conceptual model supported by neural and behavioral level evidence, and provide evaluations of the model and future works.","2016-09-01","2023-07-06 06:16:07","2023-07-06 06:16:07","2023-07-06 06:16:07","1529-1533","","1","60","","","How Is Nonverbal Auditory Information Processed?","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/6G88XHVA/Jeon - 2016 - How Is Nonverbal Auditory Information Processed R.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UI2MQNVD","journalArticle","2011","Horiguchi, Yukio; Yasuda, Keisuke; Nakanishi, Hiroaki; Sawaragi, Tetsuo","Data-To-Sound Mapping To Sonify Ongoing System Status In Continuous Manual Control Task","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/1071181311551257","https://journals.sagepub.com/doi/abs/10.1177/1071181311551257","This study empirically examines parameter-mapping sonifications to represent the difference or error between the desired state and the current state of the system being controlled using the non-speech audio. Eight different types of data-to-sound mappings were prepared by which the error was mapped onto either or both of two acoustic parameters of intensity and frequency. The mappings were tested through an experiment using a one-dimensional tracking task. The experimental results shows the following points: 1) as for the tracking task, the mappings are preferable in which the sound intensity falls as the error decreases, 2) no audible sound when no error remains is effective because listeners can easily identify the achievement to the goal from the sound itself, and 3) it seems more effective to map the error to the intensity and frequency redundantly than only to either of them, if perceptual interaction between changes in loudness and pitch is considered enough.","2011-09-01","2023-07-06 06:16:42","2023-07-06 06:16:42","2023-07-06 06:16:23","1235-1239","","1","55","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/H7QD3N9T/Horiguchi et al. - 2011 - Data-To-Sound Mapping To Sonify Ongoing System Sta.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PKV8BIQY","journalArticle","2021","Šabić, Edin; Chen, Jing; MacDonald, Justin A.","Toward a Better Understanding of In-Vehicle Auditory Warnings and Background Noise","Human Factors","","0018-7208","10.1177/0018720819879311","https://doi.org/10.1177/0018720819879311","ObjectiveThe effectiveness of three types of in-vehicle warnings was assessed in a driving simulator across different noise conditions.BackgroundAlthough there has been much research comparing different types of warnings in auditory displays and interfaces, many of these investigations have been conducted in quiet laboratory environments with little to no consideration of background noise. Furthermore, the suitability of some auditory warning types, such as spearcons, as car warnings has not been investigated.MethodTwo experiments were conducted to assess the effectiveness of three auditory warnings (spearcons, text-to-speech, auditory icons) with different types of background noise while participants performed a simulated driving task.ResultsOur results showed that both the nature of the background noise and the type of auditory warning influenced warning recognition accuracy and reaction time. Spearcons outperformed text-to-speech warnings in relatively quiet environments, such as in the baseline noise condition where no music or talk-radio was played. However, spearcons were not better than text-to-speech warnings with other background noises. Similarly, the effectiveness of auditory icons as warnings fluctuated across background noise, but, overall, auditory icons were the least efficient of the three warning types.ConclusionOur results supported that background noise can have an idiosyncratic effect on a warning’s effectiveness and illuminated the need for future research into ameliorating the effects of background noise.ApplicationThis research can be applied to better present warnings based on the anticipated auditory environment in which they will be communicated.","2021-03-01","2023-07-06 06:16:42","2023-07-06 06:16:42","2023-07-06 06:16:25","312-335","","2","63","","Hum Factors","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/GPPNZKUD/Šabić et al. - 2021 - Toward a Better Understanding of In-Vehicle Audito.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3J7HJP28","journalArticle","2019","Cave, James; Eyes, Ben","Combining Composition and Sonic Information Design in a New Electroacoustic Work","Ergonomics in Design","","1064-8046","10.1177/1064804618792647","https://doi.org/10.1177/1064804618792647","It might be suggested that composition and sonic information design are fundamentally different. However, some academic commentators and composers have explored the intersection between these disciplines. The authors presented one such work, Eonsounds: Fiamignano Gorge, at International Community of Auditory Display 2017. We argue that analysis of the aesthetic and informational choices in such hybrid works is essential to the development of sonic information design, with implications for the emergence of sonic information design as a subtype of human factors design. By acknowledging the relationship between aesthetics and information presentation, sound designers may develop designs that are safer and more user-friendly.","2019-01-01","2023-07-06 06:16:42","2023-07-06 06:16:42","2023-07-06 06:16:27","20-22","","1","27","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/FN49Q4NE/Cave and Eyes - 2019 - Combining Composition and Sonic Information Design.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FUXSVRVM","journalArticle","2015","Xu, Jie; Montague, Enid; Gratch, Jonathan; Hancock, Peter; Jeon, Myounghoon; Pfaff, Mark S.; Xu, Jie","Advances of Research in Affective Processes in Communication and Collaboration","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/1541931215591061","https://doi.org/10.1177/1541931215591061","Affective processes have been an important research area for human factors and ergonomics. Although there is an obvious connection between affect and communication and collaboration, little research has been conducted in the human factors community until recently. In this panel, the panelists will discuss recent advances in affective research in communication and collaboration systems. Theoretical perspectives in human computer interaction, human agent interaction, and teamwork that take affective process into account will be discussed. Methodological issues will also be addressed, such as the measurements of affect, research design, and data analysis methods. Finally the applications of the theories and methods in different systems, such as human robot interaction, healthcare, and multi-tasking teams, will be discussed.","2015-09-01","2023-07-06 06:16:42","2023-07-06 06:16:42","2023-07-06 06:16:29","299-302","","1","59","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/3QHUUN6W/Xu et al. - 2015 - Advances of Research in Affective Processes in Com.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K2BDIK5K","journalArticle","2016","Lacherez, Philippe; Donaldson, Liam; Burt, Jennifer S.","Do Learned Alarm Sounds Interfere With Working Memory?","Human Factors","","0018-7208","10.1177/0018720816662733","https://doi.org/10.1177/0018720816662733","Objective:To assess whether identifying (or ignoring) learned alarm sounds interferes with performance on a task involving working memory.Background:A number of researchers have suggested that auditory alarms could interfere with working memory in complex task environments, and this could serve as a caution against their use. Changing auditory information has been shown to interfere with serial recall, even when the auditory information is to be ignored. However, previous researchers have not examined well-learned patterns, such as familiar alarms.Method:One group of participants learned a set of alarms (either a melody, a rhythmic pulse, or a spoken nonword phrase) and subsequently undertook a digits-forward task in three conditions (no alarms, identify the alarm, or ignore the alarm). A comparison group undertook the baseline and ignore conditions but had no prior exposure to the alarms.Results:All alarms interfered with serial recall when participants were asked to identify them; however, only the nonword phrase interfered with recall when ignored. Moreover, there was no difference between trained and untrained participants in terms of recall performance when ignoring the alarms, suggesting that previous training does not make alarms less ignorable.Conclusion:Identifying any alarm sound may interfere with immediate working memory; however, spoken alarms may interfere even when ignored.Application:It is worth considering the importance of alarms in environments requiring high working memory performance and in particular avoiding spoken alarms in such environments.","2016-11-01","2023-07-06 06:16:42","2023-07-06 06:16:42","2023-07-06 06:16:31","1044-1051","","7","58","","Hum Factors","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/T9FLKZJ9/Lacherez et al. - 2016 - Do Learned Alarm Sounds Interfere With Working Mem.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B96PG3KV","journalArticle","2007","Watson, Marcus O.; Sanderson, Penelope M.","Designing for Attention With Sound: Challenges and Extensions to Ecological Interface Design","Human Factors","","0018-7208","10.1518/001872007X312531","https://doi.org/10.1518/001872007X312531","Objective: We explore whether ecological interface design (EID) principles can be applied to the design of an auditory display for anesthesia monitoring. Background: EID examples focus almost exclusively on visual displays. In the anesthesia work environment, however, auditory displays may provide better individual and team awareness of patient state. Method: Using a work domain analysis of physiological monitoring in anesthesia, we identify information to display. Using the skills, rules, and knowledge distinction we identify cognitive control needed. Using semantic mapping we map physiological variables and constraints to auditory dimensions. Results: EID principles do not address when information should be displayed and to whom. An attentional mapping stage helps to specify answers to these questions so that a workable auditory display for anesthesia monitoring is achieved. Conclusion: EID principles of representing work domain functional structure and minimizing resource-demanding cognitive control are necessary but insufficient to specify requirements for an effective auditory display. Also needed are analyses of control tasks, strategies, and the social organization of work. Such analyses are an integral part of the broader cognitive work analysis framework from which EID emerged.  Application: Actual or potential uses of this research include the design of displays that support continuous peripheral awareness in collaborative multimodal work environments.","2007-04-01","2023-07-06 06:16:42","2023-07-06 06:16:42","2023-07-06 06:16:34","331-346","","2","49","","Hum Factors","Designing for Attention With Sound","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/EDA29ZB5/Watson and Sanderson - 2007 - Designing for Attention With Sound Challenges and.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LP8CZBIJ","journalArticle","2015","Gable, Thomas M.; Walker, Bruce N.; Baldwin, Carryl L.; Gable, Thomas M.; Jeon, Myounghoon; Kun, Andrew L.; Mehler, Bruce","Collection and Analysis of Physiological Measures in Driving Research","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/1541931215591344","https://doi.org/10.1177/1541931215591344","Driving research has recently seen a surge in the collection and use of physiological measurements. This use of physiological data is often part of an attempt to either measure cognitive load or detect affective states. While these methods are becoming more popular it seems that many driving researchers are still unsure of the best methods of data collection and analysis. This discussion panel will center around a question and answer session between the audience and experts in techniques for the collection and analysis of physiological measures in the driving research fields to help researchers increase their productivity in this space and provide a forum for frank discussion on methods in the area.","2015-09-01","2023-07-06 06:16:42","2023-07-06 06:16:42","2023-07-06 06:16:35","1593-1595","","1","59","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/CCMWVBV3/Gable et al. - 2015 - Collection and Analysis of Physiological Measures .pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7AGYVZ6J","journalArticle","2013","Kelling, Nicholas; Bedwell, Wendy; Corso, Gregory M.; Cuevas, Haydee M.; Keebler, Joseph R.; Peres, S. Camille; Walker, Bruce N.","Life, the Universe, and Academia: An Interactive Discussion on Balance and Early Success for Potential Academics","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/1541931213571095","https://doi.org/10.1177/1541931213571095","The human factors discipline has always benefited from a strong connection between industry and academia. However, the increasing need of an educated industry workforce has created a potential concern of maintaining a viable academic workforce. Students, in particular, have previously voiced apprehensions regarding academic careers when compared to industry options. The balance between industry and academia should be preserved. Therefore, to aid in this equilibrium, an open discussion centered on student inquiries about early academia is needed to maintain an understanding of the current academic environment. Specifically, the most beneficial interaction may be through discussions between those interested in academia and those currently entrenched in multiple facets of success in early academic careers.","2013-09-01","2023-07-06 06:16:42","2023-07-06 06:16:42","2023-07-06 06:16:37","438-442","","1","57","","","Life, the Universe, and Academia","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/3NX4D5AT/Kelling et al. - 2013 - Life, the Universe, and Academia An Interactive D.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H445IQSC","journalArticle","1997","Flowers, John H.; Buhman, Dion C.; Turnage, Kimberly D.","Cross-Modal Equivalence of Visual and Auditory Scatterplots for Exploring Bivariate Data Samples","Human Factors","","0018-7208","10.1518/001872097778827151","https://doi.org/10.1518/001872097778827151","The equivalence of visual and auditory scatterplots was examined in two experiments. Experiment 1 examined the relationship between actual Pearson's r and visual and auditory judgments of direction and magnitude of correlation for 24 bivariate data samples. Experiment 2 directly evaluated visual and auditory perceptual sensitivity to outliers by examining changes in perceived magnitude and direction of correlation estimates for scatterplots from Experiment 1 that were altered by the addition of outlier points. Results suggest that the information conveyed by visual and auditory scatterplots is used very similarly by the two modalities. Both visual and auditory scatterplots are quite efficient in conveying sign and magnitude of correlation, and the effect of outliers on judged magnitude of correlation is similar for the two types of data display.","1997-09-01","2023-07-06 06:16:42","2023-07-06 06:16:42","2023-07-06 06:16:40","341-351","","3","39","","Hum Factors","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"43LMHCEX","journalArticle","2018","Greer, Jasmine M.; Burdick, Kendall J.; Chowdhury, Arman R.; Schlesinger, Joseph J.","Dynamic Alarm Systems for Hospitals (D.A.S.H.)","Ergonomics in Design","","1064-8046","10.1177/1064804618769186","https://doi.org/10.1177/1064804618769186","Hospital alarms today indicate urgent clinical need, but they are seldom “true.” False alarms are contributing to the ever-increasing issue of alarm fatigue, or desensitization, among doctors and nurses. Alarm fatigue is a high-priority health care concern because of its potential to compromise health care quality and inflict harm on patients. To address this concern, we have engineered Dynamic Alarm Systems for Hospitals (D.A.S.H.), a dynamic alarm system that self-regulates alarm loudness based on the environmental noise level and incorporates differentiable and learnable alarms. D.A.S.H., with its ability to adapt to environmental noise and encode nuanced physiological information, may improve patient safety and attenuate clinician alarm fatigue.","2018-10-01","2023-07-06 06:16:42","2023-07-06 06:16:42","2023-07-06 06:16:42","14-19","","4","26","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/G8NRHT59/Greer et al. - 2018 - Dynamic Alarm Systems for Hospitals (D.A.S.H.).pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N5RH2GS5","journalArticle","2008","Thompson, Matthew B.; Sanderson, Penelope M.","Multisensory Integration with a Head-Mounted Display and Auditory Display","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/154193120805201829","https://doi.org/10.1177/154193120805201829","Human operators who use head-mounted displays (HMDs) in their work may benefit from auditory support. It is unclear whether auditory support is better delivered in free-field or via earpiece, and what the effect of walking is. To examine this problem, a novel multisensory integration task was created in which participants identified mismatches between sounds and visual information on an HMD. Participants listened to the sounds either via earpiece or free-field while they either sat or walked about the test room. When using an earpiece, participants performed the mismatch task equally well whether walking or sitting, but when using free-field sound, participants performed the task significantly worse when walking than when sitting. The worse performance for participants using free-field sound while walking may relate to spatial and motion inconsistencies between the sound and vision or because of misperceptions of the time at which the sounds occurred. The results underscore the need for representative design of experiments exploring multisensory integration and they suggest auditory conditions that might influence effective multisensory integration with HMDs.","2008-09-01","2023-07-06 06:17:05","2023-07-06 06:17:05","2023-07-06 06:16:56","1292-1296","","18","52","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/SDVGHTXE/Thompson and Sanderson - 2008 - Multisensory Integration with a Head-Mounted Displ.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3F4SJM9A","journalArticle","2015","Werner, Steffen; Hauck, Christopher; Roome, Nicholas; Hoover, Connor; Choates, Daniel","Can VoiceScapes Assist in Menu Navigation?","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/1541931215591157","https://doi.org/10.1177/1541931215591157","Providing better information access to blind users is an important goal in the context of accessible interface design. Similarly, designers of user interfaces benefit from alternative interface techniques for usage scenarios in which visual (graphical) interfaces are either not possible or suboptimal. In our study we compared a traditional serial aural presentation of menu items to a new simultaneous aural presentation of up to seven menu items. These continuously present VoiceScapes allow the user to actively scan the auditory display to find the most appropriate command. While VoiceScapes are more difficult and attentionally more demanding than other formats of presentation, extended use might allow experienced users to more efficiently navigate complex menu hierarchies. A first pilot experiment with 13 sighted participants presented here tested the basic viability of this approach.","2015-09-01","2023-07-06 06:17:05","2023-07-06 06:17:05","2023-07-06 06:16:57","1095-1099","","1","59","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/6KUHVDZ5/Werner et al. - 2015 - Can VoiceScapes Assist in Menu Navigation.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4GSBZ7WE","journalArticle","2008","Thompson, Matthew B.; Sanderson, Penelope M.","Multisensory Integration with a Head-Mounted Display: Sound Delivery and Self-Motion","Human Factors","","0018-7208","10.1518/001872008X312323","https://journals.sagepub.com/doi/abs/10.1518/001872008X312323","Objective: We tested whether the method of sound delivery affects people's ability to integrate information from multiple modalities when they are walking and using a head-mounted display (HMD). Background: HMDs increasingly support mobile work. Human operators may benefit from auditory support when using an HMD. However, it is unclear whether sound is better delivered publicly in free field or privately via earpiece and what the effect of walking is. Method: Participants identified mismatches between sounds and visual information on an HMD. Participants heard the sounds via either earpiece or free field while they either sat or walked about the test room. Results: When using an earpiece, participants performed the mismatch task equally well whether sitting or walking, but when using free-field sound, participants performed the task significantly worse when walking than when sitting (p = .006).  Conclusion: The worse performance for participants using free-field sound while walking may relate to spatial and motion inconsistencies between visual events on the head-referenced HMD and auditory events from world-referenced speakers. Researchers should more frequently examine the effect of self-motion on people's ability to perform various multisensory tasks. Application: When multisensory integration tasks are performed with an HMD and free-field delivery of sound, as may happen in medicine, transportation, or industry, performance may suffer when the relative location of sound changes as the user moves.","2008-10-01","2023-07-06 06:17:05","2023-07-06 06:17:05","2023-07-06 06:16:59","789-800","","5","50","","Hum Factors","Multisensory Integration with a Head-Mounted Display","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/GH8NWMSY/Thompson and Sanderson - 2008 - Multisensory Integration with a Head-Mounted Displ.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F2PRV6F9","journalArticle","2019","Li, Simon Y. W.; Tse, Man-Kei; Brecknell, Birgit; Sanderson, Penelope M.","Spearcon Sequences for Monitoring Multiple Patients: Laboratory Investigation Comparing Two Auditory Display Designs","Human Factors","","0018-7208","10.1177/0018720818797502","https://doi.org/10.1177/0018720818797502","Objective:The aim was to compare the effectiveness of two auditory displays, implemented with spearcons (time-compressed speech), for monitoring multiple patients.Background:Sequences of sounds can convey information about patients’ vital signs, such as oxygen saturation (SpO2) and heart rate (HR). We tested whether participants could monitor five patients using spearcon-based sound sequences.Method:A 2 × 3 within-subjects design was used. The first factor was interface, with two levels: the ALL interface used spearcons to convey vital signs for all five patients, whereas the ABN (abnormal) interface represented patients who had normal vital signs with a low-pitched single-tone sound and patients who had at least one abnormal vital sign with spearcons. The second factor was the number of patients who had at least one abnormal vital sign: there were one, two, or three such patients in each monitoring sequence. Participants were 40 nonclinicians.Results:Participants identified abnormal patients’ SpO2 and HR levels and located abnormal patients in the sound sequence more accurately with the ABN interface than the ALL interface. Accuracy declined as the number of abnormal patients increased. Participants associated ABN with easier identification of vital signs, resulting in higher ratings of confidence and pleasantness compared with ALL.Conclusion:Sequences of spearcons may support effective eyes-free monitoring of multiple patients.Application:Sequences of spearcons may be useful in monitoring multiple patients and the underlying design principles may extend to monitoring in other domains such as industrial process control or control of multiple autonomous vehicles.","2019-03-01","2023-07-06 06:17:05","2023-07-06 06:17:05","2023-07-06 06:17:01","288-304","","2","61","","Hum Factors","Spearcon Sequences for Monitoring Multiple Patients","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/U85XN3ZE/Li et al. - 2019 - Spearcon Sequences for Monitoring Multiple Patient.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D8HHEML4","journalArticle","2004","Lee, John D.; See, Katrina A.","Trust in Automation: Designing for Appropriate Reliance","Human Factors","","0018-7208","10.1518/hfes.46.1.50_30392","https://journals.sagepub.com/doi/abs/10.1518/hfes.46.1.50_30392","Automation is often problematic because people fail to rely upon it appropriately. Because people respond to technology socially, trust influences reliance on automation. In particular, trust guides reliance when complexity and unanticipated situations make a complete understanding of the automation impractical. This review considers trust from the organizational, sociological, interpersonal, psychological, and neurological perspectives. It considers how the context, automation characteristics, and cognitive processes affect the appropriateness of trust. The context in which the automation is used influences automation performance and provides a goal-oriented perspective to assess automation characteristics along a dimension of attributional abstraction. These characteristics can influence trust through analytic, analogical, and affective processes. The challenges of extrapolating the concept of trust in people to trust in automation are discussed. A conceptual model integrates research regarding trust in automation and describes the dynamics of trust, the role of context, and the influence of display characteristics. Actual or potential applications of this research include improved designs of systems that require people to manage imperfect automation.","2004-03-01","2023-07-06 06:17:05","2023-07-06 06:17:05","2023-07-06 06:17:03","50-80","","1","46","","Hum Factors","Trust in Automation","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/6SJ3DMYY/Lee and See - 2004 - Trust in Automation Designing for Appropriate Rel.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YULVQQL4","journalArticle","2014","Yang, Shiyan; Tippey, Kathryn; Ferris, Thomas K.","Exploring the Emergent Perception of Haptic Beats from Paired Vibrotactile Presentation","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/1541931214581358","https://doi.org/10.1177/1541931214581358","Haptic beats, an analogous presentation to auditory beats, can be generated when a vibrotactile actuator is driven by a signal that contains two different activation frequencies. In contrast to a combined signal stimulating one location, this study explored to what extent haptic beats can be perceived as an emergent property when separate body locations are stimulated at two different frequencies. Consistent with previous findings, haptic beats were reliably perceived with paired presentations on the same fingertip; previously-unexplored locations on the palm, wrist, and elbow also supported the perception of beats. However, haptic beats were not perceived when stimuli were presented to distant locations, such as on different hands, suggesting that haptic beats most likely involve a localized mechanical integration rather than neural integration. These results have implications for the design of complex haptic displays for various domains, such as driving, navigation, medicine, and immersive virtual reality.","2014-09-01","2023-07-06 06:17:05","2023-07-06 06:17:05","2023-07-06 06:17:05","1716-1720","","1","58","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/AB6AN8RZ/Yang et al. - 2014 - Exploring the Emergent Perception of Haptic Beats .pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LZACH5SD","journalArticle","2008","Nees, Michael A.; Walker, Bruce N.","Encoding of Information in Auditory Displays: Initial Research on Flexibility and Processing Codes in Dual-task Scenarios","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/154193120805202208","https://doi.org/10.1177/154193120805202208","Interest in the use of sound as a means of information display in human-machine systems has surged in recent years. While researchers have begun to address issues surrounding good auditory display design as well as potential domains of application, little is known about the cognitive processes involved in interpreting auditory displays. In multi-tasking scenarios, dividing concurrent information display across modalities (e.g., vision and audition) may allow the human operator to receive (i.e., to sense and perceive) more information, yet higher-level conflicts in the encoding and representation of information may persist. Surprisingly few studies to date have examined auditory information display in dual-task scenarios. This study examined the flexibility of encoding of information and processing code conflicts in a dual-task paradigm with auditory graphs—a specific class of auditory displays that represent quantitative information with sound. Results showed that 1) patterns of dual-task interference were task dependent, and 2) a verbal interference task was relatively more disruptive to auditory graph performance than a visuospatial interference task, particularly for point estimation.","2008-09-01","2023-07-06 06:19:25","2023-07-06 06:19:25","2023-07-06 06:19:23","1820-1824","","22","52","","","Encoding of Information in Auditory Displays","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/CNZACKZN/Nees and Walker - 2008 - Encoding of Information in Auditory Displays Init.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FAXBFCPP","journalArticle","2007","Sanderson, P.M.; Watson, M.O.; Jenkins, S.; Liu, D.; Russell, W.J.; Green, N.; Cole, P.","Summative evaluation with a full-scale patient simulator: Challenges and adaptations","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/154193120705101135","https://doi.org/10.1177/154193120705101135","In this paper we outline considerations that went into designing and executing a full-scale simulator-based summative evaluation of four different display configurations for presenting information about anesthetized patients to an anesthesiologist. Although patient simulators appear to provide a “natural laboratory” for evaluating medical device innovations and equipment interface concepts, the software underlying patient simulators can be unequal to the challenges posed by the need for good representation of patient physiology and good experimental control. Moreover, the opportunities that full-scale patient simulators can offer for completely interactive, event-driven scenarios can present problems for experimental control and can promote participant hypervigilance. We describe the design of our experimental scenarios, the challenges our scenarios posed for simulator software and how we overcame those challenges, the design of a distractor task, and the methodology used to ensure we collected behavioral data sensitive to the manipulations of interest. Our adaptations in the face of challenges posed by the full-scale simulator context let us design an experiment that was highly informative about the advantages and disadvantages of the display configurations of interest.","2007-10-01","2023-07-06 06:19:25","2023-07-06 06:19:25","2023-07-06 06:19:25","770-774","","11","51","","","Summative evaluation with a full-scale patient simulator","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/KJK8FAIW/Sanderson et al. - 2007 - Summative evaluation with a full-scale patient sim.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""