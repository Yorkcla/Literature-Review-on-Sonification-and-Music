"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"IJEGIIBF","journalArticle","2022","Destexhe, Alain; Foubert, Luc","A method to convert neural signals into sound sequences","The Journal of the Acoustical Society of America","","0001-4966","10.1121/10.0011549","https://doi.org/10.1121/10.0011549","We present a method to convert neural signals into sound sequences, with the constraint that the sound sequences precisely reflect the sequences of events in the neural signal. The method consists in quantifying the wave motifs in the signal and using these parameters to generate sound envelopes. We illustrate the procedure for sleep delta waves in the human electro-encephalogram (EEG), which are converted into sound sequences that encode the time structure of the original EEG waves. This procedure can be applied to synthesize personalized sound sequences specific to the EEG of a given subject.","2022-06-02","2023-07-10 06:09:18","2023-07-10 06:09:18","2023-07-10 06:09:18","3685-3689","","6","151","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CYUZP3JX","journalArticle","2022","Foley, Liam; Schlesinger, Joseph; Schutz, Michael","More detectable, less annoying: Temporal variation in amplitude envelope and spectral content improves auditory interface efficacy","The Journal of the Acoustical Society of America","","0001-4966","10.1121/10.0010447","https://doi.org/10.1121/10.0010447","Auditory interfaces, such as auditory alarms, are useful tools for human computer interaction. Unfortunately, poor detectability and annoyance inhibit the efficacy of many interface sounds. Here, it is shown in two ways how moving beyond the traditional simplistic temporal structures of normative interface sounds can significantly improve auditory interface efficacy. First, participants rated tones with percussive amplitude envelopes as significantly less annoying than tones with flat amplitude envelopes. Crucially, this annoyance reduction did not come with a detection cost as percussive tones were detected more often than flat tones—particularly, at relatively low listening levels. Second, it was found that reductions in the duration of a tone's harmonics significantly lowered its annoyance without a commensurate reduction in detection. Together, these findings help inform our theoretical understanding of detection and annoyance of sound. In addition, they offer promising original design considerations for auditory interfaces.","2022-05-12","2023-07-10 06:09:30","2023-07-10 06:09:30","2023-07-10 06:09:30","3189-3196","","5","151","","The Journal of the Acoustical Society of America","More detectable, less annoying","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/R4DFNGQJ/Foley et al. - 2022 - More detectable, less annoying Temporal variation.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y89UI66V","journalArticle","2021","Engel, Isaac; Henry, Craig; Amengual Garí, Sebastià V.; Robinson, Philip W.; Picinali, Lorenzo","Perceptual implications of different Ambisonics-based methods for binaural reverberation","The Journal of the Acoustical Society of America","","0001-4966","10.1121/10.0003437","https://doi.org/10.1121/10.0003437","Reverberation is essential for the realistic auralisation of enclosed spaces. However, it can be computationally expensive to render with high fidelity and, in practice, simplified models are typically used to lower costs while preserving perceived quality. Ambisonics-based methods may be employed to this purpose as they allow us to render a reverberant sound field more efficiently by limiting its spatial resolution. The present study explores the perceptual impact of two simplifications of Ambisonics-based binaural reverberation that aim to improve efficiency. First, a “hybrid Ambisonics” approach is proposed in which the direct sound path is generated by convolution with a spatially dense head related impulse response set, separately from reverberation. Second, the reverberant virtual loudspeaker method (RVL) is presented as a computationally efficient approach to dynamically render binaural reverberation for multiple sources with the potential limitation of inaccurately simulating listener's head rotations. Numerical and perceptual evaluations suggest that the perceived quality of hybrid Ambisonics auralisations of two measured rooms ceased to improve beyond the third order, which is a lower threshold than what was found by previous studies in which the direct sound path was not processed separately. Additionally, RVL is shown to produce auralisations with comparable perceived quality to Ambisonics renderings.","2021-02-04","2023-07-10 06:09:44","2023-07-10 06:09:44","2023-07-10 06:09:44","895-910","","2","149","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/4EDDAJZL/Engel et al. - 2021 - Perceptual implications of different Ambisonics-ba.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SDVFJDNI","journalArticle","2019","Fishbein, Adam R.; Lawson, Shelby L.; Dooling, Robert J.; Ball, Gregory F.","How canaries listen to their song: Species-specific shape of auditory perception","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.5087692","https://doi.org/10.1121/1.5087692","The melodic, rolling songs of canaries have entertained humans for centuries and have been studied for decades by researchers interested in vocal learning, but relatively little is known about how the birds listen to their songs. Here, it is investigated how discriminable the general acoustic features of conspecific songs are to canaries, and their discrimination abilities are compared with a small parrot species, the budgerigar. Past experiments have shown that female canaries are more sexually responsive to a particular song element—the “special” syllables—and consistent with those observations, it was found that special syllables are perceptually distinctive for canaries. It is also shown that canaries discriminate the subtle differences among syllables and phrases using spectral, envelope, and temporal fine structure cues. Yet, while canaries can hear these fine details of the acoustic structure of their song, the evidence overall suggests that they listen at a more global, phrase by phrase level, rather than an analytic, syllable by syllable level, except when attending to some features of special syllables. These results depict the species-specific shape of auditory perception in canaries and lay the groundwork for future studies examining how song perception changes seasonally and according to hormonal state.","2019-01-31","2023-07-10 06:10:34","2023-07-10 06:10:34","2023-07-10 06:10:34","562-574","","1","145","","The Journal of the Acoustical Society of America","How canaries listen to their song","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/Y9DV54JA/Fishbein et al. - 2019 - How canaries listen to their song Species-specifi.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UMWV5DSP","journalArticle","2018","Lembke, Sven-Amin","Hearing triangles: Perceptual clarity, opacity, and symmetry of spectrotemporal sound shapes","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.5048130","https://doi.org/10.1121/1.5048130","In electroacoustic music, the spectromorphological approach commonly employs analogies to non-sonic phenomena like shapes, gestures, or textures. In acoustical terms, sound shapes can concern simple geometries on the spectrotemporal plane, for instance, a triangle that widens in frequency over time. To test the auditory relevance of such triangular sound shapes, two psychoacoustic experiments assessed if and how these shapes are perceived. Triangular sound-shape stimuli, created through granular synthesis, varied across the factors grain density, frequency and amplitude scales, and widening vs narrowing orientations. The perceptual investigation focused on three auditory qualities, derived in analogy to the visual description of a triangle: the clarity of the triangular outline, the opacity of the area enclosed by the outline, and the symmetry along the vertical dimension. These morphological qualities seemed to capture distinct perceptual aspects, each linked to different acoustical factors. Clarity of shape was conveyed even for sparse grain densities, while also exhibiting a perceptual bias for widening orientations. Opacity varied as a function of grain texture, whereas symmetry strongly depended on frequency and amplitude scales. The perception of sound shapes could relate to common perceptual cross-modal correspondences and share the same principles of perceptual grouping with vision.","2018-08-06","2023-07-10 06:10:46","2023-07-10 06:10:46","2023-07-10 06:10:46","608-619","","2","144","","The Journal of the Acoustical Society of America","Hearing triangles","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/AIHAPMU2/Lembke - 2018 - Hearing triangles Perceptual clarity, opacity, an.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T3K8F6WK","journalArticle","2017","Lee, Doheon; van Dorp Schuitman, Jasper; Cabrera, Densil; Qiu, Xiaojun; Burnett, Ian","Comparison of psychoacoustic-based reverberance parameters","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.5005508","https://doi.org/10.1121/1.5005508","This study compared psychoacoustic reverberance parameters to each other, as well as to reverberation time (RT) and early decay time (EDT) under various acoustic conditions. The psychoacoustic parameters were loudness-based RT (TN), loudness-based EDT [EDTN; Lee, Cabrera, and Martens, J. Acoust. Soc. Am. 131, 1194–1205 (2012a)], and parameter for reverberance [PREV; van Dorp Schuitman, de Vries, and Lindau., J. Acoust. Soc. Am. 133, 1572–1585 (2013)]. For the comparisons, a wide range of sound pressure levels (SPLs) from 20 dB to 100 dB and RTs from 0.5 s to 5.0 s were evaluated, and two sets of subjective data from the previous studies were used for the cross-validation and comparison. Results of the comparisons show that the psychoacoustic reverberance parameters provided better matches to reverberance than RT and EDT; however, the performance of these psychoacoustic reverberance parameters varied with the SPL range, the type of audio sample, and the reverberation conditions. This study reveals that PREV is the most relevant for estimating a relative change in reverberance between samples when the SPL range is small, while EDTN is useful in estimating the absolute reverberance. This study also suggests the use of PREV and EDTN for speech and music samples, respectively.","2017-10-05","2023-07-10 06:10:56","2023-07-10 06:10:56","2023-07-10 06:10:56","1832-1840","","4","142","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/5FUQJJ45/Lee et al. - 2017 - Comparison of psychoacoustic-based reverberance pa.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8ARJI7QW","journalArticle","2017","Farbood, Morwaread M.; Price, Khen C.","The contribution of timbre attributes to musical tensiona)","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.4973568","https://doi.org/10.1121/1.4973568","Timbre is an auditory feature that has received relatively little attention in empirical work examining musical tension. In order to address this gap, an experiment was conducted to explore the contribution of several specific timbre attributes—inharmonicity, roughness, spectral centroid, spectral deviation, and spectral flatness—to the perception of tension. Listeners compared pairs of sounds representing low and high degrees of each attribute and indicated which sound was more tense. Although the response profiles showed that the high states corresponded with increased tension for all attributes, further analysis revealed that some attributes were strongly correlated with others. When qualitative factors, attribute correlations, and listener responses were all taken into account, there was fairly strong evidence that higher degrees of roughness, inharmonicity, and spectral flatness elicited higher tension. On the other hand, evidence that higher spectral centroid and spectral deviation corresponded to increases in tension was ambiguous.","2017-01-20","2023-07-10 06:11:10","2023-07-10 06:11:10","2023-07-10 06:11:10","419-427","","1","141","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/MZT2WAQ2/Farbood and Price - 2017 - The contribution of timbre attributes to musical t.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZWTKBWIR","journalArticle","2017","Paté, Arthur; Boschi, Lapo; Dubois, Danièle; Le Carrou, Jean-Loïc; Holtzman, Benjamin","Auditory display of seismic data: On the use of experts' categorizations and verbal descriptions as heuristics for geoscience","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.4978441","https://doi.org/10.1121/1.4978441","Auditory display can complement visual representations in order to better interpret scientific data. A previous article showed that the free categorization of “audified seismic signals” operated by listeners can be explained by various geophysical parameters. The present article confirms this result and shows that cognitive representations of listeners can be used as heuristics for the characterization of seismic signals. Free sorting tests are conducted with audified seismic signals, with the earthquake/seismometer relative location, playback audification speed, and earthquake magnitude as controlled variables. The analysis is built on partitions (categories) and verbal comments (categorization criteria). Participants from different backgrounds (acousticians or geoscientists) are contrasted in order to investigate the role of the participants' expertise. Sounds resulting from different earthquake/station distances or azimuths, crustal structure and topography along the path of the seismic wave, earthquake magnitude, are found to (a) be sorted into different categories, (b) elicit different verbal descriptions mainly focused on the perceived number of events, frequency content, and background noise level. Building on these perceptual results, acoustic descriptors are computed and geophysical interpretations are proposed in order to match the verbal descriptions. Another result is the robustness of the categories with respect to the audification speed factor.","2017-03-27","2023-07-10 06:11:23","2023-07-10 06:11:23","2023-07-10 06:11:23","2143-2162","","3","141","","The Journal of the Acoustical Society of America","Auditory display of seismic data","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/HZ2N492N/Paté et al. - 2017 - Auditory display of seismic data On the use of ex.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7FTHP8HB","journalArticle","2007","Cavaco, Sofia; Lewicki, Michael S.","Statistical modeling of intrinsic structures in impacts sounds","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.2729368","https://doi.org/10.1121/1.2729368","This paper presents a statistical data-driven method for learning intrinsic structures of impact sounds. The method applies principal and independent component analysis to learn low-dimensional representations that model the distribution of both the time-varying spectral and amplitude structure. As a result, the method is able to decompose sounds into a small number of underlying features that characterize acoustic properties such as ringing, resonance, sustain, decay, and onsets. The method is highly flexible and makes no a priori assumptions about the physics, acoustics, or dynamics of the objects. In addition, by modeling the underlying distribution, the method can capture the natural variability of ensembles of related impact sounds.","2007-06-01","2023-07-10 06:11:41","2023-07-10 06:11:41","2023-07-10 06:11:41","3558-3568","","6","121","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/Z2CJGRX3/Cavaco and Lewicki - 2007 - Statistical modeling of intrinsic structures in im.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GSQG9DH5","journalArticle","2006","Semal, Catherine; Demany, Laurent","Individual differences in the sensitivity to pitch direction","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.2357708","https://doi.org/10.1121/1.2357708","It is commonly assumed that one can always assign a direction—upward or downward—to a percept of pitch change. The present study shows that this is true for some, but not all, listeners. Frequency difference limens (FDLs, in cents) for pure tones roved in frequency were measured in two conditions. In one condition, the task was to detect frequency changes; in the other condition, the task was to identify the direction of frequency changes. For three listeners, the identification FDL was about 1.5 times smaller than the detection FDL, as predicted (counterintuitively) by signal detection theory under the assumption that performance in the two conditions was limited by one and the same internal noise. For three other listeners, however, the identification FDL was much larger than the detection FDL. The latter listeners had relatively high detection FDLs. They had no difficulty in identifying the direction of just-detectable changes in intensity, or in the frequency of amplitude modulation. Their difficulty in perceiving the direction of small frequency/pitch changes showed up not only when the task required absolute judgments of direction, but also when the directions of two successive frequency changes had to be judged as identical or different.","2006-12-01","2023-07-10 06:11:55","2023-07-10 06:11:55","2023-07-10 06:11:55","3907-3915","","6","120","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/JHGQLG9E/Semal and Demany - 2006 - Individual differences in the sensitivity to pitch.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M288S9L7","journalArticle","2001","Krishnan, Sridhar; Rangayyan, Rangaraj M.; Bell, G. Douglas; Frank, Cyril B.","Auditory display of knee-joint vibration signals","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.1413995","https://doi.org/10.1121/1.1413995","Sounds generated due to rubbing of knee-joint surfaces may lead to a potential tool for noninvasive assessment of articular cartilage degeneration. In the work reported in the present paper, an attempt is made to perform computer-assisted auscultation of knee joints by auditory display (AD) of vibration signals (also known as vibroarthrographic or VAG signals) emitted during active movement of the leg. Two types of AD methods are considered: audification and sonification. In audification, the VAG signals are scaled in time and frequency using a time-frequency distribution to facilitate aural analysis. In sonification, the instantaneous mean frequency and envelope of the VAG signals are derived and used to synthesize sounds that are expected to facilitate more accurate diagnosis than the original signals by improving their aural quality. Auditory classification experiments were performed by two orthopedic surgeons with 37 VAG signals including 19 normal and 18 abnormal cases. Sensitivity values (correct detection of abnormality) of 31%, 44%, and 83%, and overall classification accuracies of 53%, 40%, and 57% were obtained with the direct playback, audification, and sonification methods, respectively. The corresponding d′ scores were estimated to be 1.10, −0.36, and 0.55. The high sensitivity of the sonification method indicates that the technique could lead to improved detection of knee-joint abnormalities; however, additional work is required to improve its specificity and achieve better overall performance.","2001-12-01","2023-07-10 06:12:07","2023-07-10 06:12:07","2023-07-10 06:12:07","3292-3304","","6","110","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/I2I9GI2U/Auditory-display-of-knee-joint-vibration-signals.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2NNDT6TM","journalArticle","2000","Jin, Craig; Schenkel, Markus; Carlile, Simon","Neural system identification model of human sound localization","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.1288411","https://doi.org/10.1121/1.1288411","This paper examines the role of biological constraints in the human auditory localization process. A psychophysical and neural system modeling approach was undertaken in which performance comparisons between competing models and a human subject explore the relevant biologically plausible “realism constraints.” The directional acoustical cues, upon which sound localization is based, were derived from the human subject’s head-related transfer functions (HRTFs). Sound stimuli were generated by convolving bandpass noise with the HRTFs and were presented to both the subject and the model. The input stimuli to the model were processed using the Auditory Image Model of cochlear processing. The cochlear data were then analyzed by a time-delay neural network which integrated temporal and spectral information to determine the spatial location of the sound source. The combined cochlear model and neural network provided a system model of the sound localization process. Aspects of humanlike localization performance were qualitatively achieved for broadband and bandpass stimuli when the model architecture incorporated frequency division (i.e., the progressive integration of information across the different frequency channels) and was trained using variable bandwidth and center-frequency sounds. Results indicate that both issues are relevant to human sound localization performance.","2000-09-01","2023-07-10 06:13:12","2023-07-10 06:13:12","2023-07-10 06:13:12","1215-1235","","3","108","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/LT5YKCG4/Jin et al. - 2000 - Neural system identification model of human sound .pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WE2NL5QX","journalArticle","2023","Bevilacqua, Antonella; Iannace, Gino","From discoveries of 1990s measurements to acoustic simulations of three sceneries carried out inside the San Carlo Theatre of Naplesa)","The Journal of the Acoustical Society of America","","0001-4966","10.1121/10.0019800","https://doi.org/10.1121/10.0019800","Many acoustic studies have been conducted in the San Carlo Theatre of Naples over the centuries. The discovery of valuable acoustic measurements from 1998 led the authors to photograph the architectural and acoustic conditions of the Theatre prior to restoration works in 2008. As the first opera house built in Europe, the San Carlo Theatre has always offered a rich artistic programme, making this historic building synonymous with classical music in Naples. From the great variety of operas, three specific sceneries have been selected to analyse the acoustic response based on different geometries and materials located on stage. Acoustic simulations have been performed based on site measurements, starting from a digital model that reproduces the geometry and absorbing coefficients of the materials existing in the Theatre. Using the recorded impulse response, the monoaural and binaural acoustic parameters have been obtained from the acoustic simulations and thereafter compared among the Elektra, Traviata, and La clemenza di Tito sceneries. The results in terms of reverberation highlight that La clemenza di Tito absorbs the high frequencies better than the other two sceneries. Under a clarity perspective, all the sceneries have values above the optimal range limit set for opera houses, although it is typical of other opera theatres built in the same period. A detailed historical background on the architectural changes of the San Carlo Theatre over the centuries is also given to understand the digital reconstruction that modelled the acoustic behaviour of this prominent cultural heritage building.","2023-07-06","2023-07-10 07:32:38","2023-07-10 07:32:38","2023-07-10 07:32:38","66-80","","1","154","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AT373WVR","journalArticle","2022","McMullen, Kyla; Wan, Yunhao","A machine learning tutorial for spatial auditory display using head-related transfer functions","The Journal of the Acoustical Society of America","","0001-4966","10.1121/10.0007486","https://doi.org/10.1121/10.0007486","This review presents a high-level overview of the uses of machine learning (ML) to address several challenges in spatial auditory display research, primarily using head-related transfer functions. This survey also reviews and compares several categories of ML techniques and their application to virtual auditory reality research. This work addresses the use of ML techniques such as dimensionality reduction, unsupervised learning, supervised learning, reinforcement learning, and deep learning algorithms. The paper concludes with a discussion of the usage of ML algorithms to address specific spatial auditory display research challenges.","2022-02-23","2023-07-10 07:32:48","2023-07-10 07:32:48","2023-07-10 07:32:48","1277-1293","","2","151","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/2XGQLK6M/McMullen and Wan - 2022 - A machine learning tutorial for spatial auditory d.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YXZ3QR9R","journalArticle","2023","Tronchin, Lamberto; Bevilacqua, Antonella","The Royal Tajo Opera Theatre of Lisbon: From architecture to acousticsa)","The Journal of the Acoustical Society of America","","0001-4966","10.1121/10.0016861","https://doi.org/10.1121/10.0016861","Throughout history, many buildings of significant cultural value have been lost due to natural disasters (e.g., earthquakes, volcanic eruptions, subsidence, etc.) as well as other human causes (e.g., fire, war destruction, etc.). The Tajo Opera theatre was hit by an earthquake that led to the collapse of the entire structure eight months after it was built. This paper deals with the revival of the acoustic characteristics of one of the masterpieces of the architect Giovanni Carlo Sicinio Galli Bibiena. The realization of a three-dimensional (3D) model that faithfully reproduces the architectural features of the Royal Tajo Opera theatre of Lisbon allows the authors to perform acoustic simulations that reveal the sound field representing the environment perceived by the audience during artistic performances in Lisbon in 1755. In addition, the simulated results have been compared with the values of the Teatro Comunale of Bologna, which has a similar bell-shaped plan layout and has already been studied by the authors. For the comparison of the two opera theatres, both the stalls and the balconies have been considered.","2023-01-19","2023-07-10 07:32:59","2023-07-10 07:32:59","2023-07-10 07:32:59","400-414","","1","153","","The Journal of the Acoustical Society of America","The Royal Tajo Opera Theatre of Lisbon","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/9PZPDXTG/Tronchin and Bevilacqua - 2023 - The Royal Tajo Opera Theatre of Lisbon From archi.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YVVJBL4R","journalArticle","2023","Lelo de Larrea-Mancera, E. Sebastian; Solís-Vivanco, Rodolfo; Sánchez-Jimenez, Yolanda; Coco, Laura; Gallun, Frederick J.; Seitz, Aaron R.","Development and validation of a Spanish-language spatial release from masking task in a Mexican population","The Journal of the Acoustical Society of America","","0001-4966","10.1121/10.0016850","https://doi.org/10.1121/10.0016850","This study validates a new Spanish-language version of the Coordinate Response Measure (CRM) corpus using a well-established measure of spatial release from masking (SRM). Participants were 96 Spanish-speaking young adults without hearing complaints in Mexico City. To present the Spanish-language SRM test, we created new recordings of the CRM with Spanish-language Translations and updated the freely available app (PART; https://ucrbraingamecenter.github.io/PART_Utilities/) to present materials in Spanish. In addition to SRM, we collected baseline data on a battery of non-speech auditory assessments, including detection of frequency modulations, temporal gaps, and modulated broadband noise in the temporal, spectral, and spectrotemporal domains. Data demonstrate that the newly developed speech and non-speech tasks show similar reliability to an earlier report in English-speaking populations. This study demonstrates an approach by which auditory assessment for clinical and basic research can be extended to Spanish-speaking populations for whom testing platforms are not currently available.","2023-01-18","2023-07-10 07:33:10","2023-07-10 07:33:10","2023-07-10 07:33:10","316-327","","1","153","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/9BN5DNJ2/Lelo de Larrea-Mancera et al. - 2023 - Development and validation of a Spanish-language s.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z9HI3ZTY","journalArticle","2022","Meyer-Kahlen, Nils; Schlecht, Sebastian J.; Lokki, Tapio","Clearly audible room acoustical differences may not reveal where you are in a rooma)","The Journal of the Acoustical Society of America","","0001-4966","10.1121/10.0013364","https://doi.org/10.1121/10.0013364","A common aim in virtual reality room acoustics simulation is accurate listener position dependent rendering. However, it is unclear whether a mismatch between the acoustics and visual representation of a room influences the experience or is even noticeable. Here, we ask if listeners without any special experience in echolocation are able to identify their position in a room based on the acoustics alone. In a first test, direct comparison between acoustic recordings from the different positions in the room revealed clearly audible differences, which subjects described with various acoustic attributes. The design of the subsequent experiment allows participants to move around and explore the sound within different zones in this room while switching between visual renderings of the zones in a head-mounted display. The results show that identification was only possible in some special cases. In about 74% of all trials, listeners were not able to determine where they were in the room. The results imply that audible position dependent room acoustic rendering in virtual reality may not be noticeable under certain conditions, which highlights the importance of evaluation paradigm choice when assessing virtual acoustics.","2022-08-05","2023-07-10 07:33:32","2023-07-10 07:33:32","2023-07-10 07:33:32","877-887","","2","152","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/XUYWXD7U/Meyer-Kahlen et al. - 2022 - Clearly audible room acoustical differences may no.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SIBPKWDF","journalArticle","2022","Chabot, Samuel; Braasch, Jonas","Walkable auralizations for experiential learning in an immersive classrooma)","The Journal of the Acoustical Society of America","","0001-4966","10.1121/10.0012985","https://doi.org/10.1121/10.0012985","This paper proposes an experiential method for learning acoustics and consequences of room design through the rapid creation of audio-visual congruent walkable auralizations. An efficient method produces auralizations of acoustical landmarks using a two-dimensional ray-tracing algorithm and publicly available floor plans for a 128-channel wave-field synthesis system. Late reverberation parameters are calculated using additional volumetric data. Congruent visuals are produced using a web-based interface accessible via personal devices, which automatically formats for and transmits to the immersive display. Massive user-contributed online databases are harnessed through application programming interfaces, such as those offered by the Google Maps Platform, to provide near-instant access to innumerable locations. The approach allows the rapid sonic recreation of historical concert venues with adequate sound sources. Listeners can walk through these recreations over an extended user area (12 m × 10 m).","2022-08-10","2023-07-10 07:33:43","2023-07-10 07:33:43","2023-07-10 07:33:43","899-910","","2","152","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/T4GKU458/Chabot and Braasch - 2022 - Walkable auralizations for experiential learning i.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TNUJ329D","journalArticle","2022","Prodi, Nicola; Pellegatti, Matteo; Visentin, Chiara","Effects of type of early reflection, clarity of speech, reverberation and diffuse noise on the spatial perception of a speech source and its intelligibility","The Journal of the Acoustical Society of America","","0001-4966","10.1121/10.0011403","https://doi.org/10.1121/10.0011403","Changing the balance between the early and late reflections in the impulse response affects the clarity of speech, and also the spatial perception of the sound source is affected when the direction of the early reflections is manipulated. While the effect of noise on early reflections has long been investigated in speech intelligibility studies, it is unclear whether and how the spatial characteristics of the source are altered by noise, and whether this would influence speech intelligibility in any way. The aim of the present work was to analyze the spatial perception of a speech source in noise and its relationship, if any, with speech intelligibility. Impulse responses with specular or scattered early reflections and two different reverberant tails were used to create sound fields with controlled clarity and reverberation. It emerged that noise affects spatial cues compared to the reverberation-only (quiet) condition; ratings are consequently changed, and most percepts are distorted. Speech intelligibility is also sensitive to changes in acoustic variables and the type of reflection, but the direct association between spatial percepts and speech intelligibility is weak.","2022-05-27","2023-07-10 07:34:09","2023-07-10 07:34:09","2023-07-10 07:34:09","3522-3534","","5","151","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/QQQ5LJXK/Prodi et al. - 2022 - Effects of type of early reflection, clarity of sp.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NHXALUMX","journalArticle","2022","Otčenášek, Jan; Frič, Marek; Dvořáková, Eva; Otčenášek, Zdeněk; Ubik, Sven","The subjective relevance of perceived sound aspects in remote singing educationa)","The Journal of the Acoustical Society of America","","0001-4966","10.1121/10.0009143","https://doi.org/10.1121/10.0009143","One of the consequences of the pandemic is a transition to remote education and the use of network audiovisual communication tools for education in musical disciplines. The circumstances of such education can differ and might influence the perceived sound or the education. The research observes the ratings of perceived aspects in singing lessons taught in three settings (common, reference, and direct). A variance of several aspects that relate to the perceived sound (temporal qualities and qualities of the sound and room) is observed in the remote forms, suggesting that these can be impaired in some settings and significant in the experience. The findings are discussed in relation to the perceived conditions and present practice.","2022-01-25","2023-07-10 07:34:23","2023-07-10 07:34:23","2023-07-10 07:34:23","428-433","","1","151","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/SWV6QS7E/Otčenášek et al. - 2022 - The subjective relevance of perceived sound aspect.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SGLY8EWY","journalArticle","2022","del Solar Dorrego, Fernando; Vigeant, Michelle C.","A study of the just noticeable difference of early decay time for symphonic halls","The Journal of the Acoustical Society of America","","0001-4966","10.1121/10.0009167","https://doi.org/10.1121/10.0009167","The just noticeable differences (JNDs) of room acoustic parameters are important for the design of concert halls and, in general, research of room acoustics. Precise knowledge of JNDs helps the concert hall designer in assessing the impact that changes in the geometry or materials of the hall will have on its perceived acoustics. When designing a concert hall, creating an appropriate feeling of reverberance for the audience is of prime importance. The early decay time (EDT) parameter has proved to be a better predictor of the perception of reverberance than the classical reverberation time (T30), but no studies have been conducted to specifically determine the EDT JND. In the present study, the EDT JND was investigated for broadband conditions and assessed for individual frequency ranges. A subjective study was conducted with 26 subjects with musical training, in which 21 were considered reliable. The participants listened to orchestral music convolved with measured spatial room impulse responses from three concert halls. The stimuli were auralized in an anechoic chamber using third-order Ambisonic reproduction. The obtained values show that the JNDs for the broadband conditions are lower than those for the individual frequency ranges. The EDT JND for the broadband conditions was found to be approximately 18% of the EDT value.","2022-01-05","2023-07-10 07:34:32","2023-07-10 07:34:32","2023-07-10 07:34:32","80-94","","1","151","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/DL5FH5ML/del Solar Dorrego and Vigeant - 2022 - A study of the just noticeable difference of early.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"89NN482T","journalArticle","2021","Kothinti, Sandeep Reddy; Huang, Nicholas; Elhilali, Mounya","Auditory salience using natural scenes: An online study","The Journal of the Acoustical Society of America","","0001-4966","10.1121/10.0006750","https://doi.org/10.1121/10.0006750","Salience is the quality of a sensory signal that attracts involuntary attention in humans. While it primarily reflects conspicuous physical attributes of a scene, our understanding of processes underlying what makes a certain object or event salient remains limited. In the vision literature, experimental results, theoretical accounts, and large amounts of eye-tracking data using rich stimuli have shed light on some of the underpinnings of visual salience in the brain. In contrast, studies of auditory salience have lagged behind due to limitations in both experimental designs and stimulus datasets used to probe the question of salience in complex everyday soundscapes. In this work, we deploy an online platform to study salience using a dichotic listening paradigm with natural auditory stimuli. The study validates crowd-sourcing as a reliable platform to collect behavioral responses to auditory salience by comparing experimental outcomes to findings acquired in a controlled laboratory setting. A model-based analysis demonstrates the benefits of extending behavioral measures of salience to broader selection of auditory scenes and larger pools of subjects. Overall, this effort extends our current knowledge of auditory salience in everyday soundscapes and highlights the limitations of low-level acoustic attributes in capturing the richness of natural soundscapes.","2021-10-19","2023-07-10 07:34:45","2023-07-10 07:34:45","2023-07-10 07:34:45","2952-2966","","4","150","","The Journal of the Acoustical Society of America","Auditory salience using natural scenes","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/49GK3YZP/Kothinti et al. - 2021 - Auditory salience using natural scenes An online .pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CRWTJA7Z","journalArticle","2020","Kuusinen, Antti; Lokki, Tapio","Recognizing individual concert halls is difficult when listening to the acoustics with different musical passages","The Journal of the Acoustical Society of America","","0001-4966","10.1121/10.0001915","https://doi.org/10.1121/10.0001915","This article presents a listening experiment in which the listeners' task was to recognize the acoustics of a seat in a specific concert hall. Stimuli included two short passages extracted from a Beethoven symphony and samples of a solo violin auralized to four real concert halls. In each trial, listeners were presented with a reference and four alternatives with one correct match. In the “same” condition, the reference and the alternatives contained the same source sound. In the “different” condition, the source sounds were different musical passages but always of the same sound type, that is, symphonic music or solo violin. Results show that on average listeners could recognize the halls when the task was performed with the same source sound but had difficulty when listening to different sounds. The patterns of erroneous responses exhibited confusion between particular hall pairs and corresponded well to the values and just-noticeable-differences of the traditional objective room acoustic parameters. While the type of music is previously well known to influence the perception of concert hall acoustics, the present results indicate that even minor changes in the source sound content may have a strong impact on the ability to recognize the acoustics of individual halls.","2020-09-10","2023-07-10 07:34:56","2023-07-10 07:34:56","2023-07-10 07:34:56","1380-1390","","3","148","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/ZU7B693I/Kuusinen and Lokki - 2020 - Recognizing individual concert halls is difficult .pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LMI6DL3S","journalArticle","2021","Thery, David; Katz, Brian F. G.","Auditory perception stability evaluation comparing binaural and loudspeaker Ambisonic presentations of dynamic virtual concert auralizations","The Journal of the Acoustical Society of America","","0001-4966","10.1121/10.0002942","https://doi.org/10.1121/10.0002942","Auralizations can be computed in a variety of ways as well as be rendered over different sound reproduction systems. They are used as a design tool in architectural projects and for fundamental studies on spatial perception and cognition, hence requiring reliability and confidence in the obtained results. This study assessed this reliability through auditory perception stability by comparing the perceived differences between two rendering systems for a given set of second-order Ambisonic auralizations: virtual loudspeaker binaural rendering over head-tracked headphones versus 32-loudspeaker rendering. Anechoic extracts of jazz pieces have been recorded and presented in various acoustic conditions over these two systems, evaluated on the following criteria: Readability, distance, listener envelopment (LEV), apparent source width (ASW), reverberance, and loudness. Results show that consistent significant differences between scene conditions are comparably perceived across the two systems. However, significant effects of the sound reproduction system were observed for ASW, LEV, and reverberance in some configurations.","2021-01-11","2023-07-10 07:35:25","2023-07-10 07:35:25","2023-07-10 07:35:25","246-258","","1","149","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/4DMZ6UX6/Thery and Katz - 2021 - Auditory perception stability evaluation comparing.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZPW3RUDK","journalArticle","2020","Bordonné, Thomas; Kronland-Martinet, Richard; Ystad, Sølvi; Derrien, Olivier; Aramaki, Mitsuko","Exploring sound perception through vocal imitations","The Journal of the Acoustical Society of America","","0001-4966","10.1121/10.0001224","https://doi.org/10.1121/10.0001224","Understanding how sounds are perceived and interpreted is an important challenge for researchers dealing with auditory perception. The ecological approach to perception suggests that the salient perceptual information that enables an auditor to recognize events through sounds is contained in specific structures called invariants. Identifying such invariants is of interest from a fundamental point of view to better understand auditory perception and it is also useful to include perceptual considerations to model and control sounds. Among the different approaches used to identify perceptually relevant sound structures, vocal imitations are believed to bring a fresh perspective to the field. The main goal of this paper is to better understand how invariants are transmitted through vocal imitations. A sound corpus containing different types of known invariants obtained from an existing synthesizer was established. Participants took part in a test where they were asked to imitate the sound corpus. A continuous and sparse model adapted to the specificities of the vocal imitations was then developed and used to analyze the imitations. Results show that participants were able to highlight salient elements of the sounds that partially correspond to the invariants used in the sound corpus. This study also confirms that vocal imitations reveal how these invariants are transmitted through perception and offers promising perspectives on auditory investigations.","2020-05-11","2023-07-10 07:35:35","2023-07-10 07:35:35","2023-07-10 07:35:35","3306-3321","","5","147","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/87HICQ94/Bordonné et al. - 2020 - Exploring sound perception through vocal imitation.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ITZCRH2H","journalArticle","2020","Xiang, Ning","Model-based Bayesian analysis in acoustics—A tutoriala)","The Journal of the Acoustical Society of America","","0001-4966","10.1121/10.0001731","https://doi.org/10.1121/10.0001731","Bayesian analysis has been increasingly applied in many acoustical applications. In these applications, prediction models are often involved to better understand the process under investigation by purposely learning from the experimental observations. When involving the model-based data analysis within a Bayesian framework, issues related to incorporating the experimental data and assigning probabilities into the inferential learning procedure need fundamental consideration. This paper introduces Bayesian probability theory on a tutorial level, including fundamental rules for manipulating the probabilities, and the principle of maximum entropy for assignment of necessary probabilities prior to the data analysis. This paper also employs a number of examples recently published in this journal to explain detailed steps on how to apply the model-based Bayesian inference to solving acoustical problems.","2020-08-28","2023-07-10 07:35:44","2023-07-10 07:35:44","2023-07-10 07:35:44","1101-1120","","2","148","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/6EU6LQQ5/Xiang - 2020 - Model-based Bayesian analysis in acoustics—A tutor.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2APSV8A7","journalArticle","2020","Prepelit, ă, Sebastian T.; Gómez Bolaños, Javier; Geronazzo, Michele; Mehra, Ravish; Savioja, Lauri","Pinna-related transfer functions and lossless wave equation using finite-difference methods: Validation with measurements","The Journal of the Acoustical Society of America","","0001-4966","10.1121/10.0001230","https://doi.org/10.1121/10.0001230","Nowadays, wave-based simulations of head-related transfer functions (HRTFs) lack strong justifications to replace HRTF measurements. The main cause is the complex interactions between uncertainties and biases in both simulated and measured HRTFs. This paper deals with the validation of pinna-related high-frequency information in the ipsilateral directions-of-arrival, computed by lossless wave-based simulations with finite-difference models. A simpler yet related problem is given by the pinna-related transfer function (PRTF), which encodes the acoustical effects of only the external ear. Results stress that PRTF measurements are generally highly repeatable but not necessarily easily reproducible, leading to critical issues in terms of reliability for any ground truth condition. On the other hand, PRTF simulations exhibit an increasing uncertainty with frequency and grid-dependent frequency changes, which are here quantified analyzing the benefits in the use of a unique asymptotic solution. In this validation study, the employed finite-difference model accurately and reliably predict the PRTF magnitude mostly within ±1 dB up to ≈8 kHz and a space- and frequency-averaged spectral distortion within about 2 dB up to ≈ 18 kHz.","2020-05-26","2023-07-10 07:36:03","2023-07-10 07:36:03","2023-07-10 07:36:03","3631-3645","","5","147","","The Journal of the Acoustical Society of America","Pinna-related transfer functions and lossless wave equation using finite-difference methods","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/F53FBFYI/Prepelit et al. - 2020 - Pinna-related transfer functions and lossless wave.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UMYL96IY","journalArticle","2020","Zagala, Franck; Noisternig, Markus; Katz, Brian F. G.","Comparison of direct and indirect perceptual head-related transfer function selection methods","The Journal of the Acoustical Society of America","","0001-4966","10.1121/10.0001183","https://doi.org/10.1121/10.0001183","When a personalized set of head-related transfer functions (HRTFs) is not available, a common solution is identifying a perceptually appropriate substitute from a database. There are various approaches to this selection process whether based on localization cues, subjective evaluations, or anthropomorphic similarities. This study investigates whether HRTF rankings that stem from different selection methods yield comparable results. A perceptual study was carried out using a basic source localization method and a subjective quality judgment method for a common set of eight HRTFs. HRTF rankings were determined according to different metrics from each method for each subject and the respective results were compared. Results indicate a significant and positive mean correlation between certain metrics. The best HRTFs selected according to one method had significant above-average rating scores according to metrics in the second method.","2020-05-11","2023-07-10 07:36:13","2023-07-10 07:36:13","2023-07-10 07:36:13","3376-3389","","5","147","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/2VM9VRU5/Zagala et al. - 2020 - Comparison of direct and indirect perceptual head-.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TI249HJI","journalArticle","2019","Kaplanis, Neofytos; Bech, Søren; Lokki, Tapio; van Waterschoot, Toon; Holdt Jensen, Søren","Perception and preference of reverberation in small listening rooms for multi-loudspeaker reproduction","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.5135582","https://doi.org/10.1121/1.5135582","An experiment was conducted to identify the perceptual effects of acoustical properties of domestic listening environments, in a stereophonic reproduction scenario. Nine sound fields, originating from four rooms, were captured and spatially reproduced over a three-dimensional loudspeaker array. A panel of ten expert assessors identified and quantified the perceived differences of those sound fields using their own perceptual attributes. A multivariate analysis revealed two principal dimensions that could summarize the sound fields of this investigation. Four perceptual constructs seem to characterize the sensory properties of these dimensions, relating to Reverberance, Width &amp; Envelopment, Proximity, and Bass. Overall, the results signify the importance of reverberation in residential listening environments on the perceived sensory experience, and as a consequence, the assessors' preferences towards certain decay times.","2019-11-27","2023-07-10 07:36:27","2023-07-10 07:36:27","2023-07-10 07:36:27","3562-3576","","5","146","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/YKU9I82V/Kaplanis et al. - 2019 - Perception and preference of reverberation in smal.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BPWGNHS5","journalArticle","2019","Ganguli, Kaustuv Kanti; Rao, Preeti","On the perception of raga motifs by trained musicians","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.5097588","https://doi.org/10.1121/1.5097588","A prominent aspect of the notion of musical similarity across the music of various cultures is related to the local matching of melodic motifs. This holds for Indian art music, a highly structured form with raga playing a critical role in the melodic organization. Apart from the tonal material, a raga is characterized by a set of melodic phrases that serve as important points of reference in a music performance. Musicians acquire in their training a knowledge of the melodic phrase shapes or motifs particular to a raga and the proficiency to render these correctly in performance. This phenomenon of learned schema might be expected to influence the musicians' perception of variations of the melodic motif in terms of pitch contour shape. Motivated by the parallels between the musical structure and prosodic structure in speech, identification and discrimination experiments are presented, which explore the differences between trained musicians' (TMs) and non-musicians' perception of ecologically valid synthesized variants of a raga-characteristic motif, presented both in and out of context. It is found that trained musicians are relatively insensitive to acoustic differences associated with note duration in the vicinity of a prototypical phrase shape while also clearly demonstrating the heightened sensitivity associated with categorical perception in the context of the boundary between ragas.","2019-04-29","2023-07-10 07:36:57","2023-07-10 07:36:57","2023-07-10 07:36:57","2418-2434","","4","145","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/BJ2DKXQP/Ganguli and Rao - 2019 - On the perception of raga motifs by trained musici.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W29WMDIW","journalArticle","2017","Postma, Barteld N. J.; Katz, Brian F. G.","The influence of visual distance on the room-acoustic experience of auralizations","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.5009554","https://doi.org/10.1121/1.5009554","Auralizations have become more prevalent in architectural acoustics and virtual reality. Studies have shown that by employing a methodical calibration procedure, ecologically/perceptually valid auralizations can be obtained. Another study demonstrated a manner to include dynamic voice directivity with results indicating these auralizations were judged significantly more plausible than auralizations with static source orientations. With the increased plausibility of auralizations, it is possible to study room-acoustic experience employing virtual reality, having confidence that the results also apply to real-life situations. Limited studies have examined the influence of visuals on room-acoustic experience. Using a virtual reality framework, this study investigated the influence of visuals on the room-acoustic experience of auralizations. Evaluations compared dynamic voice auralizations coherently matched with visualization positions to incoherently matched audio-visual pairs. Based on the results, the test population could be divided into three subgroups: (1) those who judged auralizations more acoustically distant with increased visual distance, (2) those who judged auralizations louder with increased visual distance, and (3) those whose audio judgment was uninfluenced by the visual stimulus.","2017-11-16","2023-07-10 07:37:20","2023-07-10 07:37:20","2023-07-10 07:37:20","3035-3046","","5","142","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/ZDQBRD2T/Postma and Katz - 2017 - The influence of visual distance on the room-acous.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7GVSCMNJ","journalArticle","2017","Brinkmann, Fabian; Lindau, Alexander; Weinzierl, Stefan","On the authenticity of individual dynamic binaural synthesis","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.5005606","https://doi.org/10.1121/1.5005606","A simulation that is perceptually indistinguishable from the corresponding real sound field could be termed authentic. Using binaural technology, such a simulation would theoretically be achieved by reconstructing the sound pressure at a listener's ears. However, inevitable errors in the measurement, rendering, and reproduction introduce audible degradations, as it has been demonstrated in previous studies for anechoic environments and static binaural simulations (fixed head orientation). The current study investigated the authenticity of individual dynamic binaural simulations for three different acoustic environments (anechoic, dry, wet) using a highly sensitive listening test design. The results show that about half of the participants failed to reliably detect any differences for a speech stimulus, whereas all participants were able to do so for pulsed pink noise. Higher detection rates were observed in the anechoic condition, compared to the reverberant spaces, while the source position had no significant effect. It is concluded that the authenticity mainly depends on how comprehensive the spectral cues are provided by the audio content, and the amount of reverberation, whereas the source position plays a minor role. This is confirmed by a broad qualitative evaluation, suggesting that remaining differences mainly affect the tone color rather than the spatial, temporal or dynamical qualities.","2017-10-04","2023-07-10 07:37:41","2023-07-10 07:37:41","2023-07-10 07:37:41","1784-1795","","4","142","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/GNM7693G/Brinkmann et al. - 2017 - On the authenticity of individual dynamic binaural.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"685YMQ3I","journalArticle","2017","Nowak, Johannes; Klockgether, Stefan","Perception and prediction of apparent source width and listener envelopment in binaural spherical microphone array auralizations","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.5003917","https://doi.org/10.1121/1.5003917","This article deals with the assessment and prediction of the reproduction quality when binaurally auralizing spherical microphone array data for room simulation applications. The auralization is perceptually assessed in a listening experiment using the two attributes, apparent source width (ASW) and listener envelopment (LEV), for spatial quality description, whereas the technical analysis employs a psychoacoustically motivated model for room acoustical perception (RAP) which is specifically designed to estimate ASW and LEV. Both analyses focus on the array configuration in terms of varying modal resolutions and its influence on the spatial reproduction quality. The auralizations comprise three simulated environments, i.e., free-field sound fields as well as a dry and a reverberant room. Ten different audio signals are used as test material. Perceptual results show that the array configuration strongly influences the perception of ASW and LEV which also depends on the reflection properties of the simulated room. The ASW and LEV predictions by the RAP model correlate well with the results from the listening experiment.","2017-09-26","2023-07-10 07:38:06","2023-07-10 07:38:06","2023-07-10 07:38:06","1634-1645","","3","142","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/MBIZDNFR/Nowak and Klockgether - 2017 - Perception and prediction of apparent source width.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"39KVUX84","journalArticle","2017","Rozé, Jocelyn; Aramaki, Mitsuko; Kronland-Martinet, Richard; Ystad, Sølvi","Exploring the perceived harshness of cello sounds by morphing and synthesis techniques","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.4978522","https://doi.org/10.1121/1.4978522","Cello bowing requires a very fine control of the musicians' gestures to ensure the quality of the perceived sound. When the interaction between the bow hair and the string is optimal, the sound is perceived as broad and round. On the other hand, when the gestural control becomes more approximate, the sound quality deteriorates and often becomes harsh, shrill, and quavering. In this study, such a timbre degradation, often described by French cellists as harshness (décharnement), is investigated from both signal and perceptual perspectives. Harsh sounds were obtained from experienced cellists subjected to a postural constraint. A signal approach based on Gabor masks enabled us to capture the main dissimilarities between round and harsh sounds. Two complementary methods perceptually validated these signal features: First, a predictive regression model of the perceived harshness was built from sound continua obtained by a morphing technique. Next, the signal structures identified by the model were validated within a perceptual timbre space, obtained by multidimensional scaling analysis on pairs of synthesized stimuli controlled in harshness. The results revealed that the perceived harshness was due to a combination between a more chaotic harmonic behavior, a formantic emergence, and a weaker attack slope.","2017-03-24","2023-07-10 07:38:21","2023-07-10 07:38:21","2023-07-10 07:38:21","2121-2136","","3","141","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/A9P3UE5N/Rozé et al. - 2017 - Exploring the perceived harshness of cello sounds .pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CHS4QFRP","journalArticle","2016","Romblom, David; Guastavino, Catherine; Depalle, Philippe","Perceptual thresholds for non-ideal diffuse field reverberation","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.4967523","https://doi.org/10.1121/1.4967523","The objective of this study is to understand listeners' sensitivity to directional variations in non-ideal diffuse field reverberation. An ABX discrimination test was conducted using a semi-spherical 28-loudspeaker array; perceptual thresholds were estimated by systematically varying the level of a segment of loudspeakers for lateral, height, and frontal conditions. The overall energy was held constant using a gain compensation scheme. When compared to an ideal diffuse field, the perceptual threshold for detection is −2.5 dB for the lateral condition, −6.8 dB for the height condition, and −3.2 dB for the frontal condition. Measurements of the experimental stimuli were analyzed using a Head and Torso Simulator as well as with opposing cardioid microphones aligned on the three Cartesian axes. Additionally, opposing cardioid measurements made in an acoustic space demonstrate that level differences corresponding to the perceptual thresholds can be found in practice. These results suggest that non-ideal diffuse field reverberation may be a previously unrecognized component of spatial impression.","2016-11-22","2023-07-10 07:38:43","2023-07-10 07:38:43","2023-07-10 07:38:43","3908-3916","","5","140","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/SSCXT928/Romblom et al. - 2016 - Perceptual thresholds for non-ideal diffuse field .pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FKH3N6PD","journalArticle","2017","Huang, Nicholas; Elhilali, Mounya","Auditory salience using natural soundscapes","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.4979055","https://doi.org/10.1121/1.4979055","Salience describes the phenomenon by which an object stands out from a scene. While its underlying processes are extensively studied in vision, mechanisms of auditory salience remain largely unknown. Previous studies have used well-controlled auditory scenes to shed light on some of the acoustic attributes that drive the salience of sound events. Unfortunately, the use of constrained stimuli in addition to a lack of well-established benchmarks of salience judgments hampers the development of comprehensive theories of sensory-driven auditory attention. The present study explores auditory salience in a set of dynamic natural scenes. A behavioral measure of salience is collected by having human volunteers listen to two concurrent scenes and indicate continuously which one attracts their attention. By using natural scenes, the study takes a data-driven rather than experimenter-driven approach to exploring the parameters of auditory salience. The findings indicate that the space of auditory salience is multidimensional (spanning loudness, pitch, spectral shape, as well as other acoustic attributes), nonlinear and highly context-dependent. Importantly, the results indicate that contextual information about the entire scene over both short and long scales needs to be considered in order to properly account for perceptual judgments of salience.","2017-03-28","2023-07-10 07:38:58","2023-07-10 07:38:58","2023-07-10 07:38:58","2163-2176","","3","141","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/MU4NDBV3/Huang and Elhilali - 2017 - Auditory salience using natural soundscapes.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S9GRBIFL","journalArticle","2017","Hendrickx, Etienne; Stitt, Peter; Messonnier, Jean-Christophe; Lyzwa, Jean-Marc; Katz, Brian FG; de Boishéraud, Catherine","Influence of head tracking on the externalization of speech stimuli for non-individualized binaural synthesis","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.4978612","https://doi.org/10.1121/1.4978612","Binaural reproduction aims at recreating a realistic audio scene at the ears of the listener using headphones. In the real acoustic world, sound sources tend to be externalized (that is, perceived to be emanating from a source out in the world) rather than internalized (that is, perceived to be emanating from inside the head). Unfortunately, several studies report a collapse of externalization, especially with frontal and rear virtual sources, when listening to binaural content using non-individualized Head-Related Transfer Functions (HRTFs). The present study examines whether or not head movements coupled with a head tracking device can compensate for this collapse. For each presentation, a speech stimulus was presented over headphones at different azimuths, using several intermixed sets of non-individualized HRTFs for the binaural rendering. The head tracker could either be active or inactive, and the subjects could either be asked to rotate their heads or to keep them as stationary as possible. After each presentation, subjects reported to what extent the stimulus had been externalized. In contrast to several previous studies, results showed that head movements can substantially enhance externalization, especially for frontal and rear sources, and that externalization can persist once the subject has stopped moving his/her head.","2017-03-22","2023-07-10 07:39:21","2023-07-10 07:39:21","2023-07-10 07:39:21","2011-2023","","3","141","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/GJVKFAWD/Hendrickx et al. - 2017 - Influence of head tracking on the externalization .pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MC8VW3VU","journalArticle","2016","Simon, Laurent S. R.; Zacharov, Nick; Katz, Brian F. G.","Perceptual attributes for the comparison of head-related transfer functions","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.4966115","https://doi.org/10.1121/1.4966115","The benefit of using individual head-related transfer functions (HRTFs) in binaural audio is well documented with regards to improving localization precision. However, with the increased use of binaural audio in more complex scene renderings, cognitive studies, and virtual and augmented reality simulations, the perceptual impact of HRTF selection may go beyond simple localization. In this study, the authors develop a list of attributes which qualify the perceived differences between HRTFs, providing a qualitative understanding of the perceptual variance of non-individual binaural renderings. The list of attributes was designed using a Consensus Vocabulary Protocol elicitation method. Participants followed an Individual Vocabulary Protocol elicitation procedure, describing the perceived differences between binaural stimuli based on binauralized extracts of multichannel productions. This was followed by an automated lexical reduction and a series of consensus group meetings during which participants agreed on a list of relevant attributes. Finally, the proposed list of attributes was then evaluated through a listening test, leading to eight valid perceptual attributes for describing the perceptual dimensions affected by HRTF set variations.","2016-11-11","2023-07-10 07:39:42","2023-07-10 07:39:42","2023-07-10 07:39:42","3623-3632","","5","140","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/RS3NAZJK/Simon et al. - 2016 - Perceptual attributes for the comparison of head-r.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QPGJEZJN","journalArticle","2016","Postma, Barteld N. J.; Katz, Brian F. G.","Perceptive and objective evaluation of calibrated room acoustic simulation auralizations","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.4971422","https://doi.org/10.1121/1.4971422","Recently, auralizations have become more prevalent in architectural acoustics and virtual reality. However, there have been few studies examining the perceptual quality achievable by room acoustic simulations and auralizations. Such studies have highlighted potential problems in creating perceptually equivalent simulations when compared to measured auralizations in terms of parameter estimation. In order to accomplish realistic auralizations, calibration of the geometrical acoustics model can be considered a necessary step. In situations where the studied space exists, well-calibrated auralizations can be employed for multiple purposes, such as multi-modal virtual reality explorations, studies of the acoustical influence of renovations, and historic research. Using this case type as a base, a perceptual study evaluating state-of-the-art binaural auralizations has been carried out. Three test sites of different complexity and acoustics were selected: the abbey church Saint-Germain-des-Prés, the cathedral Notre-Dame de Paris, and the Théâtre de l'Athénée. Models were calibrated according to omni-directional source-receiver measurements for reverberation and clarity parameters. In the subjective listening test, measured and simulated binaural auralizations were compared according to eight acoustic perceptual attributes. Results showed that the methodical calibration procedure employed in combination with attention to control factors led to ecologically/perceptually valid auralizations.","2016-12-19","2023-07-10 07:40:03","2023-07-10 07:40:03","2023-07-10 07:40:03","4326-4337","","6","140","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/ELEZRVYR/Postma and Katz - 2016 - Perceptive and objective evaluation of calibrated .pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8UI87GNS","journalArticle","2016","Trapeau, Régis; Aubrais, Valérie; Schönwiesner, Marc","Fast and persistent adaptation to new spectral cues for sound localization suggests a many-to-one mapping mechanism","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.4960568","https://doi.org/10.1121/1.4960568","The adult human auditory system can adapt to changes in spectral cues for sound localization. This plasticity was demonstrated by changing the shape of the pinna with earmolds. Previous results indicate that participants regain localization accuracy after several weeks of adaptation and that the adapted state is retained for at least one week without earmolds. No aftereffect was observed after mold removal, but any aftereffect may be too short to be observed when responses are averaged over many trials. This work investigated the lack of aftereffect by analyzing single-trial responses and modifying visual, auditory, and tactile information during the localization task. Results showed that participants localized accurately immediately after mold removal, even at the first stimulus presentation. Knowledge of the stimulus spectrum, tactile information about the absence of the earmolds, and visual feedback were not necessary to localize accurately after adaptation. Part of the adaptation persisted for one month without molds. The results are consistent with the hypothesis of a many-to-one mapping of the spectral cues, in which several spectral profiles are simultaneously associated with one sound location. Additionally, participants with acoustically more informative spectral cues localized sounds more accurately, and larger acoustical disturbances by the molds reduced adaptation success.","2016-08-10","2023-07-10 07:40:14","2023-07-10 07:40:14","2023-07-10 07:40:14","879-890","","2","140","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/XYX7PFCU/Trapeau et al. - 2016 - Fast and persistent adaptation to new spectral cue.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WAVCYIVJ","journalArticle","2016","Pearce, Andy; Brookes, Tim; Dewhirst, Martin; Mason, Russell","Eliciting the most prominent perceived differences between microphones","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.4950820","https://doi.org/10.1121/1.4950820","The attributes contributing to the differences perceived between microphones (when auditioning recordings made with those microphones) are not clear from previous research. Consideration of technical specifications and expert opinions indicated that recording five programme items with eight studio and two microelectromechanical system microphones could allow determination of the attributes related to the most prominent inter-microphone differences. Pairwise listening comparisons between the resulting 50 recordings, followed by multi-dimensional scaling analysis, revealed up to 5 salient dimensions per programme item; 17 corresponding pairs of recordings were selected exemplifying the differences across those dimensions. Direct elicitation and panel discussions on the 17 pairs identified a hierarchy of 40 perceptual attributes. An attribute contribution experiment on the 31 lowest-level attributes in the hierarchy allowed them to be ordered by degree of contribution and showed brightness, harshness, and clarity to always contribute highly to perceived inter-microphone differences. This work enables the future development of objective models to predict these important attributes.","2016-05-25","2023-07-10 07:40:24","2023-07-10 07:40:24","2023-07-10 07:40:24","2970-2981","","5","139","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/RWHKIZGE/Pearce et al. - 2016 - Eliciting the most prominent perceived differences.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GE2XUUMF","journalArticle","2016","Prepeliță, Sebastian; Geronazzo, Michele; Avanzini, Federico; Savioja, Lauri","Influence of voxelization on finite difference time domain simulations of head-related transfer functions","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.4947546","https://doi.org/10.1121/1.4947546","The scattering around the human pinna that is captured by the Head-Related Transfer Functions (HRTFs) is a complex problem that creates uncertainties in both acoustical measurements and simulations. Within the simulation framework of Finite Difference Time Domain (FDTD) with axis-aligned staircase boundaries resulting from a voxelization process, the voxelization-based uncertainty propagating in the HRTF-captured sound field is quantified for one solid and two surface voxelization algorithms. Simulated results utilizing a laser-scanned mesh of Knowles Electronics Manikin for Acoustic Research (KEMAR) show that in the context of complex geometries with local topology comparable to grid spacing such as the human pinna, the voxelization-related uncertainties in simulations emerge at lower frequencies than the generally used accuracy bandwidths. Numerical simulations show that the voxelization process induces both random error and algorithm-dependent bias in the simulated HRTF spectral features. Frequencies fr below which the random error is bounded by various dB thresholds are estimated and predicted. Particular shortcomings of the used voxelization algorithms are identified and the influence of the surface impedance on the induced errors is studied. Simulations are also validated against measurements.","2016-05-09","2023-07-10 07:40:36","2023-07-10 07:40:36","2023-07-10 07:40:35","2489-2504","","5","139","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/NPIKZXKB/Prepeliță et al. - 2016 - Influence of voxelization on finite difference tim.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3FEGLINN","journalArticle","2015","Kuusinen, Antti; Lokki, Tapio","Investigation of auditory distance perception and preferences in concert halls by using virtual acoustics","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.4935388","https://doi.org/10.1121/1.4935388","Virtual acoustics with multichannel sound reproduction was used to study auditory distance perception in four concert halls with multiple sound sources on stage. Eight subjects reported apparent auditory distances in five seating positions from 10 to 26 m to the middle of the sources on stage. The distance estimates were collected by absolute distance estimation procedure as well as a free modulus estimation procedure including both within and between halls evaluations. In addition, pairwise preferences were collected for two positions within each hall and for one position between halls. Results reveal that the perception of distance is dependent on the hall acoustics and show how the strength factor G and direct-to-reverberant energy ratio covary in relation to perceptual distances in these halls. The results also indicate that in such large spaces the overestimation of short distances may continue up to and further than 10 m from the sound sources. Preference results show that closer seats were liked more than further ones and that the strength of this preference is associated with the difference in perceptual distances.","2015-11-19","2023-07-10 07:40:46","2023-07-10 07:40:46","2023-07-10 07:40:46","3148-3159","","5","138","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/Y7WVU6I2/Kuusinen and Lokki - 2015 - Investigation of auditory distance perception and .pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J97NFKWV","journalArticle","2015","Luizard, Paul; Katz, Brian F. G.; Guastavino, Catherine","Perceptual thresholds for realistic double-slope decay reverberation in large coupled spaces","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.4904515","https://doi.org/10.1121/1.4904515","Reverberation highly influences sound perception in enclosed spaces. The reverberation time (RT) metric, used to quantify reverberation in single volumes, is inappropriate for coupled spaces characterized by non-exponential double-slope energy decays. Previous research on reverberation perception of double-slope decays has been predominantly based on varying basic impulse response characteristics such as decay times corresponding to reverberation times of individual volumes presented as independent variables. Alternatively, several studies have employed geometrical room acoustic software simulations to generate collections of responses while varying architectural parameters such as coupling area and room volumes. To avoid issues related to geometrical acoustics simulations, such as position dependence and limitations of some software to properly simulate coupled volume behavior, this study examines perception of the variability of reverberation typical of a physical coupled volume system. Employing an established statistical model, the control parameter of coupling area aperture which acoustically connects the volumes serves as the independent variable. Two listening tests were conducted to determine perceptual thresholds using an ABX discrimination task. The range of tested values corresponded to physically realizable variations. Just noticeable differences (JNDs) were derived with an average JND of ≈ 10% variation of the coupling aperture. No significant differences were found between different musical excerpts.","2015-01-01","2023-07-10 07:41:11","2023-07-10 07:41:11","2023-07-10 07:41:11","75-84","","1","137","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/3UA7RNIE/Luizard et al. - 2015 - Perceptual thresholds for realistic double-slope d.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BS8GGES9","journalArticle","2015","Baumann, Claude; Rogers, Chris; Massen, Francis","Dynamic binaural sound localization based on variations of interaural time delays and system rotations","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.4923448","https://doi.org/10.1121/1.4923448","This work develops the mathematical model for a steerable binaural system that determines the instantaneous direction of a sound source in space. The model combines system angular speed and interaural time delays (ITDs) in a differential equation, which allows monitoring the change of source position in the binaural reference frame and therefore resolves the confusion about azimuth and elevation. The work includes the analysis of error propagation and presents results from a real-time application that was performed on a digital signal processing device. Theory and experiments demonstrate that the azimuthal angle to the sound source is accurately yielded in the case of horizontal rotations, whereas the elevation angle is estimated with large uncertainty. This paper also proves the equivalence of the ITD derivative and the Doppler shift appearing between the binaurally captured audio signals. The equation of this Doppler shift is applicable for any kind of motion. It shows that weak binaural pitch differences may represent an additional cue in localization of sound. Finally, the paper develops practical applications from this relationship, such as the synthesizing of binaural images of pure and complex tones emitted by a moving source, and the generation of multiple frequency images for binaural beat experiments.","2015-08-06","2023-07-10 07:41:21","2023-07-10 07:41:21","2023-07-10 07:41:21","635-650","","2","138","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/UDL58F39/Baumann et al. - 2015 - Dynamic binaural sound localization based on varia.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YXA265LN","journalArticle","2014","Francombe, Jon; Mason, Russell; Dewhirst, Martin; Bech, Søren","Elicitation of attributes for the evaluation of audio-on-audio interference","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.4898053","https://doi.org/10.1121/1.4898053","An experiment to determine the perceptual attributes of the experience of listening to a target audio program in the presence of an audio interferer was performed. The first stage was a free elicitation task in which a total of 572 phrases were produced. In the second stage, a consensus vocabulary procedure was used to reduce these phrases into a comprehensive set of attributes. Groups of experienced and inexperienced listeners determined nine and eight attributes, respectively. These attribute sets were combined by the listeners to produce a final set of 12 attributes: masking, calming, distraction, separation, confusion, annoyance, environment, chaotic, balance and blend, imagery, response to stimuli over time, and short-term response to stimuli. In the third stage, a simplified ranking procedure was used to select only the most useful and relevant attributes. Four attributes were selected: distraction, annoyance, balance and blend, and confusion. Ratings using these attributes were collected in the fourth stage, and a principal component analysis performed. This suggested two dimensions underlying the perception of an audio-on-audio interference situation: The first dimension was labeled “distraction” and accounted for 89% of the variance; the second dimension, accounting for 10% of the variance, was labeled “balance and blend.”","2014-11-01","2023-07-10 07:41:30","2023-07-10 07:41:30","2023-07-10 07:41:30","2630-2641","","5","136","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/GBCDBAAC/Francombe et al. - 2014 - Elicitation of attributes for the evaluation of au.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MRGHCD4D","journalArticle","2014","Bezat, Marie-Céline; Kronland-Martinet, Richard; Roussarie, Vincent; Ystad, Sølvi","From acoustic descriptors to evoked quality of car door sounds","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.4883364","https://doi.org/10.1121/1.4883364","This article describes the first part of a study aiming at adapting the mechanical car door construction to the drivers' expectancies in terms of perceived quality of cars deduced from car door sounds. A perceptual cartography of car door sounds is obtained from various listening tests aiming at revealing both ecological and analytical properties linked to evoked car quality. In the first test naive listeners performed absolute evaluations of five ecological properties (i.e., solidity, quality, weight, closure energy, and success of closure). Then experts in the area of automobile doors categorized the sounds according to organic constituents (lock, joints, door panel), in particular whether or not the lock mechanism could be perceived. Further, a sensory panel of naive listeners identified sensory descriptors such as classical descriptors or onomatopoeia that characterize the sounds, hereby providing an analytic description of the sounds. Finally, acoustic descriptors were calculated after decomposition of the signal into a lock and a closure component by the Empirical Mode Decomposition (EMD) method. A statistical relationship between the acoustic descriptors and the perceptual evaluations of the car door sounds could then be obtained through linear regression analysis.","2014-07-01","2023-07-10 07:41:49","2023-07-10 07:41:49","2023-07-10 07:41:49","226-241","","1","136","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/JFAZAAG8/Bezat et al. - 2014 - From acoustic descriptors to evoked quality of car.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DK9QYT26","journalArticle","2014","Iida, Kazuhiro; Ishii, Yohji; Nishioka, Shinsuke","Personalization of head-related transfer functions in the median plane based on the anthropometry of the listener's pinnaea)","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.4880856","https://doi.org/10.1121/1.4880856","A listener's own head-related transfer functions (HRTFs) are required for accurate three-dimensional sound image control. The HRTFs of other listeners often cause front-back confusion and errors in the perception of vertical angles. However, measuring the HRTFs of all listeners for all directions of a sound source is impractical because the measurement requires a special apparatus and a lot of time. The present study proposes a method for estimating the appropriate HRTFs for an individual listener. The proposed method estimates the frequencies of the two lowest spectral notches (N1 and N2), which play an important role in vertical localization, in the HRTF of an individual listener by anthropometry of the listener's pinnae. The best-matching HRTFs, of which N1 and N2 are the closest to the estimates, are then selected from an HRTF database. In order to examine the validity of the proposed method, localization tests in the upper median plane were performed using four subjects. The results revealed that the best-matching HRTFs provided approximately the same performance as the listener's own HRTFs for the target directions of the front and rear for all four subjects. For the upper target directions, however, the performance of the localization for some of the subjects decreased.","2014-07-01","2023-07-10 07:42:04","2023-07-10 07:42:04","2023-07-10 07:42:04","317-333","","1","136","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/JV6DCIJR/Iida et al. - 2014 - Personalization of head-related transfer functions.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"USSNB6VA","journalArticle","2014","Ziegelwanger, Harald; Majdak, Piotr","Modeling the direction-continuous time-of-arrival in head-related transfer functions","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.4863196","https://doi.org/10.1121/1.4863196","Head-related transfer functions (HRTFs) describe the filtering of the incoming sound by the torso, head, and pinna. As a consequence of the propagation path from the source to the ear, each HRTF contains a direction-dependent, broadband time-of-arrival (TOA). TOAs are usually estimated independently for each direction from HRTFs, a method prone to artifacts and limited by the spatial sampling. In this study, a continuous-direction TOA model combined with an outlier-removal algorithm is proposed. The model is based on a simplified geometric representation of the listener, and his/her arbitrary position within the HRTF measurement. The outlier-removal procedure uses the extreme studentized deviation test to remove implausible TOAs. The model was evaluated for numerically calculated HRTFs of sphere, torso, and pinna under various conditions. The accuracy of estimated parameters was within the resolution given by the sampling rate. Applied to acoustically measured HRTFs of 172 listeners, the estimated parameters were consistent with realistic listener geometry. The outlier removal further improved the goodness-of-fit, particularly for some problematic fits. The comparison with a simpler model that fixed the listener position to the center of the measurement geometry showed a clear advantage of listener position as an additional free model parameter.","2014-03-01","2023-07-10 07:42:27","2023-07-10 07:42:27","2023-07-10 07:42:27","1278-1293","","3","135","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/AZXLDHF8/Ziegelwanger and Majdak - 2014 - Modeling the direction-continuous time-of-arrival .pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RBVSDXUJ","journalArticle","2013","van Dorp Schuitman, Jasper; de Vries, Diemer; Lindau, Alexander","Deriving content-specific measures of room acoustic perception using a binaural, nonlinear auditory model","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.4789357","https://doi.org/10.1121/1.4789357","Acousticians generally assess the acoustic qualities of a concert hall or any other room using impulse response-based measures such as the reverberation time, clarity index, and others. These parameters are used to predict perceptual attributes related to the acoustic qualities of the room. Various studies show that these physical measures are not able to predict the related perceptual attributes sufficiently well under all circumstances. In particular, it has been shown that physical measures are dependent on the state of occupation, are prone to exaggerated spatial fluctuation, and suffer from lacking discrimination regarding the kind of acoustic stimulus being presented. Accordingly, this paper proposes a method for the derivation of signal-based measures aiming at predicting aspects of room acoustic perception from content specific signal representations produced by a binaural, nonlinear model of the human auditory system. Listening tests were performed to test the proposed auditory parameters for both speech and music. The results look promising; the parameters correlate with their corresponding perceptual attributes in most cases.","2013-03-06","2023-07-10 07:42:43","2023-07-10 07:42:43","2023-07-10 07:42:43","1572-1585","","3","133","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/H2XSCSEK/van Dorp Schuitman et al. - 2013 - Deriving content-specific measures of room acousti.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DND5AEQ3","journalArticle","2012","Jagla, Jan; Maillard, Julien; Martin, Nadine","Sample-based engine noise synthesis using an enhanced pitch-synchronous overlap-and-add method","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.4754663","https://doi.org/10.1121/1.4754663","An algorithm for the real time synthesis of internal combustion engine noise is presented. Through the analysis of a recorded engine noise signal of continuously varying engine speed, a dataset of sound samples is extracted allowing the real time synthesis of the noise induced by arbitrary evolutions of engine speed. The sound samples are extracted from a recording spanning the entire engine speed range. Each sample is delimitated such as to contain the sound emitted during one cycle of the engine plus the necessary overlap to ensure smooth transitions during the synthesis. The proposed approach, an extension of the PSOLA method introduced for speech processing, takes advantage of the specific periodicity of engine noise signals to locate the extraction instants of the sound samples. During the synthesis stage, the sound samples corresponding to the target engine speed evolution are concatenated with an overlap and add algorithm. It is shown that this method produces high quality audio restitution with a low computational load. It is therefore well suited for real time applications.","2012-11-08","2023-07-10 07:43:02","2023-07-10 07:43:02","2023-07-10 07:43:02","3098-3108","","5","132","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/6ISZ5BIH/Jagla et al. - 2012 - Sample-based engine noise synthesis using an enhan.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"89UV6QHB","journalArticle","2012","Van Nort, Doug; Braasch, Jonas; Oliveros, Pauline","Sound texture recognition through dynamical systems modeling of empirical mode decomposition","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.4751535","https://doi.org/10.1121/1.4751535","This paper describes a system for modeling, recognizing, and classifying sound textures. The described system translates contemporary approaches from video texture analysis, creating a unique approach in the realm of audio and music. The signal is first represented as a set of mode functions by way of the Empirical Mode Decomposition technique for time/frequency analysis, before expressing the dynamics of these modes as a linear dynamical system (LDS). Both linear and nonlinear techniques are utilized in order to learn the system dynamics, which leads to a successful distinction between unique classes of textures. Five classes of sounds comprised a data set, consisting of crackling fire, typewriter action, rainstorms, carbonated beverages, and crowd applause, drawing on a variety of source recordings. Based on this data set the system achieved a classification accuracy of 90%, which outperformed both a Mel-Frequency Cepstral Coefficient based LDS-modeling approach from the literature, as well as one based on a standard Gaussian Mixture Model classifier.","2012-10-03","2023-07-10 07:44:49","2023-07-10 07:44:49","2023-07-10 07:44:49","2734-2744","","4","132","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/T5AUMIV4/Van Nort et al. - 2012 - Sound texture recognition through dynamical system.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NFKLSABP","journalArticle","2012","Valente, Daniel L.; Braasch, Jonas; Myrbeck, Shane A.","Comparing perceived auditory width to the visual image of a performing ensemble in contrasting bi-modal environmentsa)","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.3662055","https://doi.org/10.1121/1.3662055","Despite many studies investigating auditory spatial impressions in rooms, few have addressed the impact of simultaneous visual cues on localization and the perception of spaciousness. The current research presents an immersive audiovisual environment in which participants were instructed to make auditory width judgments in dynamic bi-modal settings. The results of these psychophysical tests suggest the importance of congruent audio visual presentation to the ecological interpretation of an auditory scene. Supporting data were accumulated in five rooms of ascending volumes and varying reverberation times. Participants were given an audiovisual matching test in which they were instructed to pan the auditory width of a performing ensemble to a varying set of audio and visual cues in rooms. Results show that both auditory and visual factors affect the collected responses and that the two sensory modalities coincide in distinct interactions. The greatest differences between the panned audio stimuli given a fixed visual width were found in the physical space with the largest volume and the greatest source distance. These results suggest, in this specific instance, a predominance of auditory cues in the spatial analysis of the bi-modal scene.","2012-01-13","2023-07-10 07:45:04","2023-07-10 07:45:04","2023-07-10 07:45:04","205-217","","1","131","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/4JEEPD53/Valente et al. - 2012 - Comparing perceived auditory width to the visual i.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FLL2DMGQ","journalArticle","2012","Xie, Bo-Sun","Recovery of individual head-related transfer functions from a small set of measurementsa)","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.4728168","https://doi.org/10.1121/1.4728168","Head-related transfer functions (HRTFs) vary with individuals, and in practice, measuring HRTFs with high directional resolution for each individual is tiresome. Based on a basis functions representation of HRTFs, the present work proposes a method for recovering individual HRTFs from a small set of measurements. The HRTFs are represented by a combination of a small set of spatial basis functions (SBFs) with frequency- and individual-dependent weights. The SBFs are derived by applying spatial principal component analysis to a baseline HRTF dataset with high directional resolution. The individual weights for any subject outside the dataset are estimated from measurements at a few source directions, and then the HRTFs with high directional resolution are recovered by combining the SBFs and the individual weights. In an illustrative case, the SBFs derived from a baseline dataset that includes 20 subjects are used to recover the HRTF magnitudes for six subjects outside the baseline dataset. Results show that individual HRTF magnitudes can be recovered from measurements at 73 directions with a mean signal-to-distortion ratio of 19 dB. The proposed method is also applicable to recovering head-related impulse responses. The results of psychoacoustic experiments indicate that in most cases the recovered and measured HRTFs are indistinguishable.","2012-07-10","2023-07-10 07:45:17","2023-07-10 07:45:17","2023-07-10 07:45:17","282-294","","1","132","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/NTD5BZT3/Xie - 2012 - Recovery of individual head-related transfer funct.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WUVLUXZJ","journalArticle","2011","Song, Wookeun; Ellermeier, Wolfgang; Hald, Jørgen","Psychoacoustic evaluation of multichannel reproduced sounds using binaural synthesis and spherical beamforming","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.3628323","https://doi.org/10.1121/1.3628323","The binaural auralization of a 3D sound field using spherical-harmonics beamforming (SHB) techniques was investigated and compared with the traditional method using a head-and-torso simulator (HATS). The new procedure was verified by comparing simulated room impulse responses with measured ones binaurally. The objective comparisons show that there is good agreement in the frequency range between 0.1 and 6.4 kHz. A listening experiment was performed to validate the SHB method subjectively and to compare it to the HATS method. Two musical excerpts, pop and classical, were used. Subjective responses were collected in two head rotation conditions (fixed and rotating) and six spatial reproduction modes, including phantom mono, stereo, and surround sound. The results show that subjective scales of width, spaciousness, and preference based on the SHB method were similar to those obtained for the HATS method, although the width and spaciousness of the stimuli processed by the SHB method were judged slightly higher than the ones using the HATS method in general. Thus, binaural synthesis using SHB may be a useful tool to reproduce a 3D sound field binaurally, while saving considerably on measurement time because head rotation can be simulated based on a single recording.","2011-10-03","2023-07-10 07:45:30","2023-07-10 07:45:30","2023-07-10 07:45:30","2063-2075","","4","130","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/VVWACSCS/Song et al. - 2011 - Psychoacoustic evaluation of multichannel reproduc.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BCKTHKC7","journalArticle","2010","Féron, François-Xavier; Frissen, Ilja; Boissinot, Julien; Guastavino, Catherine","Upper limits of auditory rotational motion perception","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.3502456","https://doi.org/10.1121/1.3502456","Three experiments are reported, which investigated the auditory velocity thresholds beyond which listeners are no longer able to perceptually resolve a smooth circular trajectory. These thresholds were measured for band-limited noises, white noise, and harmonic sounds (HS), and in different acoustical environments. Experiments 1 and 2 were conducted in an acoustically dry laboratory. Observed thresholds varied as a function of stimulus type and spectral content. Thresholds for band-limited noises were unaffected by center frequency and equal to that of white noise. For HS, however, thresholds decreased as the fundamental frequency of the stimulus increased. The third experiment was a replication of the second in a reverberant concert hall, which produced qualitatively similar results except that thresholds were significantly higher than in the acoustically dry laboratory.","2010-12-01","2023-07-10 07:45:52","2023-07-10 07:45:52","2023-07-10 07:45:52","3703-3714","","6","128","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/MN2AKEJL/Féron et al. - 2010 - Upper limits of auditory rotational motion percept.pdf; /Users/minsik/Zotero/storage/986VTBYX/Upper-limits-of-auditory-rotational-motion.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SEM874FV","journalArticle","2011","Santala, Olli; Pulkki, Ville","Directional perception of distributed sound sources","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.3533727","https://doi.org/10.1121/1.3533727","The perception of spatially distributed sound sources was investigated by conducting two listening experiments in anechoic conditions with 13 loudspeakers evenly distributed in the frontal horizontal plane emitting incoherent noise signals. In the first experiment, widely distributed sound sources with gaps in their distribution emitted pink noise. The results indicated that the exact loudspeaker distribution could not be perceived accurately and that the width of the distribution was perceived to be narrower than it was in reality. Up to three spatially distributed loudspeakers that were simultaneously emitting sound could be individually perceived. In addition, the number of loudspeakers that were indicated as emitting sound was smaller than the actual number. In the second experiment, a reference with 13 loudspeakers and test cases with fewer loudspeakers were presented and their perceived spatial difference was rated. The effect of the noise bandwidth was of particular interest. Noise with different bandwidths centered around 500 and 4000 Hz was used. The results indicated that when the number of loudspeakers was increased from four to seven, the perceived auditory event was very similar to that perceived with 13 loudspeakers at all bandwidths. The perceived differences were larger in wideband noise than in narrow-band noise.","2011-03-09","2023-07-10 07:46:27","2023-07-10 07:46:27","2023-07-10 07:46:27","1522-1530","","3","129","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/MU6MM4SV/Santala and Pulkki - 2011 - Directional perception of distributed sound source.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2J2NSPZ9","journalArticle","2010","Valente, Daniel L.; Braasch, Jonas","Subjective scaling of spatial room acoustic parameters influenced by visual environmental cues","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.3478797","https://doi.org/10.1121/1.3478797","Although there have been numerous studies investigating subjective spatial impression in rooms, only a few of those studies have addressed the influence of visual cues on the judgment of auditory measures. In the psychophysical study presented here, video footage of five solo music/speech performers was shown for four different listening positions within a general-purpose space. The videos were presented in addition to the acoustic signals, which were auralized using binaural room impulse responses (BRIR) that were recorded in the same general-purpose space. The participants were asked to adjust the direct-to-reverberant energy ratio (D/R ratio) of the BRIR according to their expectation considering the visual cues. They were also directed to rate the apparent source width (ASW) and listener envelopment (LEV) for each condition. Visual cues generated by changing the sound-source position in the multi-purpose space, as well as the makeup of the sound stimuli affected the judgment of spatial impression. Participants also scaled the direct-to-reverberant energy ratio with greater direct sound energy than was measured in the acoustical environment.","2010-10-18","2023-07-10 07:46:41","2023-07-10 07:46:41","2023-07-10 07:46:41","1952-1964","","4","128","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/M3QFY5FP/Valente and Braasch - 2010 - Subjective scaling of spatial room acoustic parame.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E4H5GTX8","journalArticle","2005","Pollack, Irwin","The Information of Elementary Auditory Displays","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.1906969","https://doi.org/10.1121/1.1906969","In contrast to the extremely acute sensitivity of a human listener to discriminate small differences in the frequency or intensity between two sounds is his relative inability to identify (and name) sounds presented individually. When the frequency of a single tone is varied in equal‐logarithmic steps in the range between 100 cps and 8000 cps (and when the level of the tone is randomly adjusted to reduce loudness cues), the amount of information transferred is about 2.3 bits per stimulus presentation. This is equivalent to perfect identification among only 5 tones. The information transferred, under the conditions of measurement employed, is reasonably invariant under wide variations in stimulus conditions.","2005-06-29","2023-07-10 07:47:01","2023-07-10 07:47:01","2023-07-10 07:47:01","745-749","","6","24","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/ZFV3MW2H/The-Information-of-Elementary-Auditory-Displays.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KQCBTY6X","journalArticle","2005","Pollack, Irwin","The Information of Elementary Auditory Displays. II","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.1907173","https://doi.org/10.1121/1.1907173","Previous studies have shown that the amount of information transmitted with a simple one‐dimensional auditory display is relatively small. This paper considers three conditions designed to increase the information transmission with elementary auditory displays. The three conditions or variables were (1) the frequency range of tones investigated; (2) the utilization of objective reference tones presented with the unknown tone; and (3) the “dimensionality” of the display—the number of independently varying stimulus aspects of the display. Little additional gain in information transmission is associated with the first factor; a moderate gain is associated with the second; and a relatively substantial gain is associated with the third.","2005-06-29","2023-07-10 07:47:23","2023-07-10 07:47:23","2023-07-10 07:47:23","765-769","","4","25","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/2QDJP65K/The-Information-of-Elementary-Auditory-Displays-II.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VM2VPP5W","journalArticle","2009","Bergman, Penny; Sköld, Anders; Västfjäll, Daniel; Fransson, Niklas","Perceptual and emotional categorization of sound","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.3243297","https://doi.org/10.1121/1.3243297","This paper investigates how different types of data from psychoacoustical experiments may be combined to render further knowledge about the mechanisms underlying sound perception. Two studies were conducted with auditory alerts of short duration. First, an experiment where participants rated the dissimilarity among the auditory alerts was performed. This resulted in a two-dimensional multi-dimensional scaling solution. Second, an experiment where participants evaluated the stimuli with semantic descriptors and rated their emotional reactions to the sounds was performed. The output of this experiment was a reduced set of underlying perceptual and emotional dimensions. The results of the two experiments were then integrated by the use of multi-dimensional perceptual unfolding and a set mediation analyses. The integrative analyses showed that part of the cognitive categorization of the semantic descriptors was mediated by the emotional reactions to the sounds. The results are discussed in relation to theories of auditory perception and emotional response categorization.","2009-12-14","2023-07-10 07:47:38","2023-07-10 07:47:38","2023-07-10 07:47:38","3156-3167","","6","126","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/ZCSIYWP3/Bergman et al. - 2009 - Perceptual and emotional categorization of sound.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S7NBAXN7","journalArticle","2009","Zahorik, Pavel","Perceptually relevant parameters for virtual listening simulation of small room acoustics","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.3167842","https://doi.org/10.1121/1.3167842","Various physical aspects of room-acoustic simulation techniques have been extensively studied and refined, yet the perceptual attributes of the simulations have received relatively little attention. Here a method of evaluating the perceptual similarity between rooms is described and tested using 15 small-room simulations based on binaural room impulse responses (BRIRs) either measured from a real room or estimated using simple geometrical acoustic modeling techniques. Room size and surface absorption properties were varied, along with aspects of the virtual simulation including the use of individualized head-related transfer function (HRTF) measurements for spatial rendering. Although differences between BRIRs were evident in a variety of physical parameters, a multidimensional scaling analysis revealed that when at-the-ear signal levels were held constant, the rooms differed along just two perceptual dimensions: one related to reverberation time (T60) and one related to interaural coherence (IACC). Modeled rooms were found to differ from measured rooms in this perceptual space, but the differences were relatively small and should be easily correctable through adjustment of T60 and IACC in the model outputs. Results further suggest that spatial rendering using individualized HRTFs offers little benefit over nonindividualized HRTF rendering for room simulation applications where source direction is fixed.","2009-08-01","2023-07-10 07:47:57","2023-07-10 07:47:57","2023-07-10 07:47:57","776-791","","2","126","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/CRM6YZ5X/Zahorik - 2009 - Perceptually relevant parameters for virtual liste.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ECWCEKIN","journalArticle","2010","Lutfi, Robert A.; Stoelinga, Christophe N. J.","Sensory constraints on auditory identification of the material and geometric properties of struck bars","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.3263606","https://doi.org/10.1121/1.3263606","A computational formula is derived for estimating the constraints limited auditory sensitivity imposes on auditory identification of the material and geometric properties of struck bars. The formula combines a model of the transverse motion of the bar with empirical psychometric functions to map out “null” regions in the bar’s physical parameter space where changes in the frequency, amplitude, and decay of partials are likely below threshold for detection. Parameters of the physical space include bar density, Young’s modulus, fluid and viscoelastic damping factors, bar length, and bar cross-sectional area (as related to bar shape and hollowness). The formula is used to estimate the possible effect of limited sensitivity in past studies on the auditory identification of bar attributes. The results suggest that sensitivity may, indeed, have played a role in some studies, and that apparent discrepancies in results may be understood based on whether the predominant source of damping was internal or external to the bar. The formula identifies conditions representing an expected bound on identification performance and thereby may be used to aid in the design of future studies for which the struck bar is the sound source of choice.","2010-01-05","2023-07-10 07:48:19","2023-07-10 07:48:19","2023-07-10 07:48:19","350-360","","1","127","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/9E4IERV7/Lutfi and Stoelinga - 2010 - Sensory constraints on auditory identification of .pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EMHVRAR5","journalArticle","2008","Stalinski, Stephanie M.; Schellenberg, E. Glenn; Trehub, Sandra E.","Developmental changes in the perception of pitch contour: Distinguishing up from down","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.2956470","https://doi.org/10.1121/1.2956470","Musically untrained participants in five age groups (5-, 6-, 8-, and 11‐year-olds, and adults) heard sequences of three 1s piano tones in which the first and third tones were identical (A5, or 880Hz) but the middle tone was displaced upward or downward in pitch. Their task was to identify whether the middle tone was higher or lower than the other two tones. In experiment 1, 5‐year-olds successfully identified upward and downward shifts of 4, 2, 1, 0.5, and 0.3 semitones. In experiment 2, older children (6-, 8-, and 11‐year-olds) and adults successfully identified the same shifts as well as a smaller shift (0.1 semitone). For all age groups, performance accuracy decreased as the size of the shift decreased. Performance improved from 5to8years of age, reaching adult levels at 8years.","2008-09-01","2023-07-10 07:48:31","2023-07-10 07:48:31","2023-07-10 07:48:31","1759-1763","","3","124","","The Journal of the Acoustical Society of America","Developmental changes in the perception of pitch contour","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/9M7W8J38/Stalinski et al. - 2008 - Developmental changes in the perception of pitch c.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3TU3YPXZ","journalArticle","2008","Jones, Gary L.; Litovsky, Ruth Y.","Role of masker predictability in the cocktail party problema)","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.2996336","https://doi.org/10.1121/1.2996336","In studies of the cocktail party problem, the number and locations of maskers are typically fixed throughout a block of trials, which leaves out uncertainty that exists in real-world environments. The current experiments examined whether there is (1) improved speech intelligibility and (2) increased spatial release from masking (SRM), as predictability of the number/locations of speech maskers is increased. In the first experiment, subjects identified a target word presented at a fixed level in the presence of 0, 1, or 2 maskers as predictability of the masker configuration ranged from 10% to 80%. The second experiment examined speech reception thresholds and SRM as (a) predictability of the masker configuration is increased from 20% to 80% and/or (b) the complexity of the listening environment is decreased. In the third experiment, predictability of the masker configuration was increased from 20% up to 100% while minimizing the onset delay between maskers and the target. All experiments showed no effect of predictability of the masker configuration on speech intelligibility or SRM. These results suggest that knowing the number and location(s) of maskers may not necessarily contribute significantly to solving the cocktail party problem, at least not when the location of the target is known.","2008-12-01","2023-07-10 07:48:53","2023-07-10 07:48:53","2023-07-10 07:48:53","3818-3830","","6","124","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/58SES8WR/Jones and Litovsky - 2008 - Role of masker predictability in the cocktail part.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T7ZKNELS","journalArticle","2008","Jeon, Jin Yong; Kim, Yong Hee; Cabrera, Densil; Bassett, John","The effect of visual and auditory cues on seat preference in an opera theater","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.2912435","https://doi.org/10.1121/1.2912435","Opera performance conveys both visual and auditory information to an audience, and so opera theaters should be evaluated in both domains. This study investigates the effect of static visual and auditory cues on seat preference in an opera theater. Acoustical parameters were measured and visibility was analyzed for nine seats. Subjective assessments for visual-only, auditory-only, and auditory-visual preferences for these seat positions were made through paired-comparison tests. In the cases of visual-only and auditory-only subjective evaluations, preference judgment tests on a rating scale were also employed. Visual stimuli were based on still photographs, and auditory stimuli were based on binaural impulse responses convolved with a solo tenor recording. For the visual-only experiment, preference is predicted well by measurements taken related to the angle of seats from the theater midline at the center of the stage, the size of the photographed stage view, the visual obstruction, and the distance from the stage. Sound pressure level was the dominant predictor of auditory preference in the auditory-only experiment. In the cross-modal experiments, both auditory and visual preferences were shown to contribute to overall impression, but auditory cues were more influential than the static visual cues. The results show that both a positive visual-only or a positive auditory-only evaluations positively contribute to the assessments of seat quality.","2008-06-01","2023-07-10 07:49:02","2023-07-10 07:49:02","2023-07-10 07:49:02","4272-4282","","6","123","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/ZR2329F7/Jeon et al. - 2008 - The effect of visual and auditory cues on seat pre.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9TFZB4P3","journalArticle","2000","Langendijk, Erno H. A.; Bronkhorst, Adelbert W.","Fidelity of three-dimensional-sound reproduction using a virtual auditory display","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.428321","https://doi.org/10.1121/1.428321","The fidelity of reproducing free-field sounds using a virtual auditory display was investigated in two experiments. In the first experiment, listeners directly compared stimuli from an actual loudspeaker in the free field with those from small headphones placed in front of the ears. Headphone stimuli were filtered using head-related transfer functions (HRTFs), recorded while listeners were wearing the headphones, in order to reproduce the pressure signatures of the free-field sounds at the eardrum. Discriminability was investigated for six sound-source positions using broadband noise as a stimulus. The results show that the acoustic percepts of real and virtual sounds were identical. In the second experiment, discrimination between virtual sounds generated with measured and interpolated HRTFs was investigated. Interpolation was performed using HRTFs measured for loudspeaker positions with different spatial resolutions. Broadband noise bursts with flat and scrambled spectra were used as stimuli. The results indicate that, for a spatial resolution of about 6°, the interpolation does not introduce audible cues. For resolutions of 20° or more, the interpolation introduces audible cues related to timbre and position. For intermediate resolutions (10°–15°) the data suggest that only timbre cues were used.","2000-01-01","2023-07-10 07:49:16","2023-07-10 07:49:16","2023-07-10 07:49:16","528-537","","1","107","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/DSBSMWPL/Langendijk and Bronkhorst - 2000 - Fidelity of three-dimensional-sound reproduction u.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q4KYWCFU","journalArticle","2008","Larsen, Erik; Iyer, Nandini; Lansing, Charissa R.; Feng, Albert S.","On the minimum audible difference in direct-to-reverberant energy ratioa)","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.2936368","https://doi.org/10.1121/1.2936368","The goals of this study were to measure sensitivity to the direct-to-reverberant energy ratio (D/R) across a wide range of D/R values and to gain insight into which cues are used in the discrimination process. The main finding is that changes in D/R are discriminated primarily based on spectral cues. Temporal cues may be used but only when spectral cues are diminished or not available, while sensitivity to interaural cross-correlation is too low to be useful in any of the conditions tested. These findings are based on an acoustic analysis of these variables and the results of two psychophysical experiments. The first experiment employs wideband noise with two values for onset and offset times to determine the D/R just-noticeable difference at −10, 0, 10, and 20dB D/R. This yielded substantially higher sensitivity to D/R at 0 and 10dB D/R (2–3dB) than has been reported previously, while sensitivity is much lower at −10 and 20dB D/R. The second experiment consists of three parts where specific cues to D/R are reduced or removed, which enabled the specified rank ordering of the cues. The acoustic analysis and psychophysical experiments also provide an explanation for the “auditory horizon effect.”","2008-07-01","2023-07-10 07:49:30","2023-07-10 07:49:30","2023-07-10 07:49:30","450-461","","1","124","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/86Z86N8Z/Larsen et al. - 2008 - On the minimum audible difference in direct-to-rev.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NZB9U3Z7","journalArticle","2007","Cabrera, Densil; Morimoto, Masayuki","Influence of fundamental frequency and source elevation on the vertical localization of complex tones and complex tone pairs","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.2736782","https://doi.org/10.1121/1.2736782","This study investigates the vertical localization of single complex tones (monads) and simultaneous complex tone pairs (dyads), especially as it is affected by their fundamental frequency and source elevation. Two complex tone timbres are considered: one consisting of five low-order harmonics, and the other of all odd harmonics (a square wave). Sound sources were at −15, 0, 15, and 30deg from the horizontal plane at ear height. For eight subjects, this source array was in the median plane, and for a further nine subjects, it was directly to the subject’s left (lateral plane). The subjects localized the angle of the auditory image(s) of one or two complex tones around the vertical plane containing the sound sources. Mean responses for the five-harmonic complex tones show a systematic effect (referred to as Pratt’s effect) of fundamental frequency on vertical localization—whereby high-frequency complex tones are localized to positions higher than low-frequency complex tones for equivalent source positions. For the square wave, the sound-source position dominates localization, although some effect of fundamental frequency is evident for median plane sources.","2007-07-01","2023-07-10 07:49:44","2023-07-10 07:49:44","2023-07-10 07:49:43","478-488","","1","122","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/W55YE5RQ/Cabrera and Morimoto - 2007 - Influence of fundamental frequency and source elev.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PVN8FKJM","journalArticle","2008","Alexander, Joshua M.; Lutfi, Robert A.","Sample discrimination of frequency by hearing-impaired and normal-hearing listeners","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.2816415","https://doi.org/10.1121/1.2816415","In a multiple observation, sample discrimination experiment normal-hearing (NH) and hearing-impaired (HI) listeners heard two multitone complexes each consisting of six simultaneous tones with nominal frequencies spaced evenly on an ERBN logarithmic scale between 257 and 6930Hz. On every trial, the frequency of each tone was sampled from a normal distribution centered near its nominal frequency. In one interval of a 2IFC task, all tones were sampled from distributions lower in mean frequency and in the other interval from distributions higher in mean frequency. Listeners had to identify the latter interval. Decision weights were obtained from multiple regression analysis of the between- interval frequency differences for each tone and listeners’ responses. Frequency difference limens (an index of sensorineural resolution) and decision weights for each tone were used to predict the sensitivity of different decision-theoretic models. Results indicate that low-frequency tones were given much greater perceptual weight than high-frequency tones by both groups of listeners. This tendency increased as hearing loss increased and as sensorineural resolution decreased, resulting in significantly less efficient weighting strategies for the HI listeners. Overall, results indicate that HI listeners integrated frequency information less optimally than NH listeners, even after accounting for differences in sensorineural resolution.","2008-01-01","2023-07-10 07:50:06","2023-07-10 07:50:06","2023-07-10 07:50:06","241-253","","1","123","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/QWIIKIV9/Alexander and Lutfi - 2008 - Sample discrimination of frequency by hearing-impa.pdf; /Users/minsik/Zotero/storage/I5S7GCZR/Sample-discrimination-of-frequency-by-hearing.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7LQCCX85","journalArticle","2007","Choisel, Sylvain; Wickelmaier, Florian","Evaluation of multichannel reproduced sound: Scaling auditory attributes underlying listener preference","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.2385043","https://doi.org/10.1121/1.2385043","A study was conducted with the goal of quantifying auditory attributes that underlie listener preference for multichannel reproduced sound. Short musical excerpts were presented in mono, stereo, and several multichannel formats to a panel of 40 selected listeners. Scaling of auditory attributes, as well as overall preference, was based on consistency tests of binary paired-comparison judgments and on modeling the choice frequencies using probabilistic choice models. As a result, the preferences of nonexpert listeners could be measured reliably at a ratio scale level. Principal components derived from the quantified attributes predict overall preference well. The findings allow for some generalizations within musical program genres regarding the perception of and preference for certain spatial reproduction modes, but for limited generalizations across selections from different musical genres.","2007-01-01","2023-07-10 07:52:54","2023-07-10 07:52:54","2023-07-10 07:52:54","388-400","","1","121","","The Journal of the Acoustical Society of America","Evaluation of multichannel reproduced sound","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/G7SITH6M/Choisel and Wickelmaier - 2007 - Evaluation of multichannel reproduced sound Scali.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PSDH6FPX","journalArticle","2006","Zotkin, Dmitry N.; Duraiswami, Ramani; Grassi, Elena; Gumerov, Nail A.","Fast head-related transfer function measurement via reciprocity","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.2207578","https://doi.org/10.1121/1.2207578","An efficient method for head-related transfer function (HRTF) measurement is presented. By applying the acoustical principle of reciprocity, one can swap the speaker and the microphone positions in the traditional (direct) HRTF measurement setup, that is, insert a microspeaker into the subject’s ear and position several microphones around the subject, enabling simultaneous HRTF acquisition at all microphone positions. The setup used for reciprocal HRTF measurement is described, and the obtained HRTFs are compared with the analytical solution for a sound-hard sphere and with KEMAR manikin HRTF obtained by the direct method. The reciprocally measured sphere HRTF agrees well with the analytical solution. The reciprocally measured and the directly measured KEMAR HRTFs are not exactly identical but agree well in spectrum shape and feature positions. To evaluate if the observed differences are significant, an auditory localization model based on work by J. C. Middlebrooks [J. Acoust. Soc. Am. 92, 2607–2624 (1992)] was used to predict where a virtual sound source synthesized with the reciprocally measured HRTF would be localized if the directly measured HRTF were used for the localization. It was found that the predicted localization direction generally lies close to the measurement direction, indicating that the HRTFs obtained via the two methods are in good agreement.","2006-10-01","2023-07-10 07:53:07","2023-07-10 07:53:07","2023-07-10 07:53:07","2202-2215","","4","120","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/9YI7BV5N/Zotkin et al. - 2006 - Fast head-related transfer function measurement vi.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AKZX5B5N","journalArticle","2005","Webster, J. C.; Carpenter, A.; Woodhead, M. M.","Identifying Meaningless Tonal Complexes","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.1911128","https://doi.org/10.1121/1.1911128","A series of nine tonal complexes was constructed in which varying patterns of harmonics like 2, 4, 6…24; 3, 6, 9…24; 4, 8…24 were emphasized. Six listeners were asked to differentiate the sounds, which they did easily. They were then asked to identify the complexes by number, for example; 4, 8…24 was to be called No. 4; 5, 10…25 called 5. This they did with 33% accuracy. The most easily identified sounds were Nos. 6 (6, 12, 18, 24); 8 (8, 16, 24); 7 (8, 9); and 9 (1, 2, 3, 4…25). Numbers 6 and 8 were judged to be more complex and higher in pitch than the others. Sound 9 was judged to be the least complex and the lowest in pitch. All, in fact, had a fundamental frequency of 75 Hz.","2005-07-21","2023-07-10 07:54:47","2023-07-10 07:54:47","2023-07-10 07:54:47","606-609","","2","44","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HV7MGPFP","journalArticle","2005","Lutfi, Robert A.; Oh, Eunmi; Storm, Eileen; Alexander, Joshua M.","Classification and identification of recorded and synthesized impact sounds by practiced listeners, musicians, and nonmusicians","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.1931867","https://doi.org/10.1121/1.1931867","Three experiments were conducted to test the viability of a low-parameter modal model for synthesizing impact sounds to be used in commercial and psychoacoustic research. The model was constrained to have four physically based parameters dictating the amplitude, frequency, and decay of modes. The values of these parameters were selected by ear to roughly match the recordings of ten different resonant objects suspended by hand and struck with different mallets. In experiment 1, neither 35 professional musicians nor 187 college undergraduates could identify which of the two matched sounds was the real recording with better than chance accuracy, though significantly better than chance performance was obtained when modal parameters were selected without the previously imposed physical constraints. In experiment 2, the undergraduates identified the source corresponding to the recorded and synthesized sounds with the same level of accuracy and largely the same pattern of errors. Finally, experiment 3 showed highly practiced listeners to be largely insensitive to changes in the acoustic waveform resulting from an increase in the number of free parameters used in the modal model beyond 3. The results suggest that low-parameter, modal models might be exploited meaningfully in many commercial and research applications involving human perception of impact sounds.","2005-07-01","2023-07-10 07:54:57","2023-07-10 07:54:57","2023-07-10 07:54:57","393-404","","1","118","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/HZ8VN8MP/Lutfi et al. - 2005 - Classification and identification of recorded and .pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8HNTGBEA","journalArticle","2005","Shinn-Cunningham, Barbara G.; Kopco, Norbert; Martin, Tara J.","Localizing nearby sound sources in a classroom: Binaural room impulse responses","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.1872572","https://doi.org/10.1121/1.1872572","Binaural room impulse responses (BRIRs) were measured in a classroom for sources at different azimuths and distances (up to 1 m) relative to a manikin located in four positions in a classroom. When the listener is far from all walls, reverberant energy distorts signal magnitude and phase independently at each frequency, altering monaural spectral cues, interaural phase differences, and interaural level differences. For the tested conditions, systematic distortion (comb-filtering) from an early intense reflection is only evident when a listener is very close to a wall, and then only in the ear facing the wall. Especially for a nearby source, interaural cues grow less reliable with increasing source laterality and monaural spectral cues are less reliable in the ear farther from the sound source. Reverberation reduces the magnitude of interaural level differences at all frequencies; however, the direct-sound interaural time difference can still be recovered from the BRIRs measured in these experiments. Results suggest that bias and variability in sound localization behavior may vary systematically with listener location in a room as well as source location relative to the listener, even for nearby sources where there is relatively little reverberant energy.","2005-04-28","2023-07-10 07:55:10","2023-07-10 07:55:10","2023-07-10 07:55:10","3100-3115","","5","117","","The Journal of the Acoustical Society of America","Localizing nearby sound sources in a classroom","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/9Y7VFT4M/Shinn-Cunningham et al. - 2005 - Localizing nearby sound sources in a classroom Bi.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4U6IQAW6","journalArticle","2005","Rumsey, Francis; Zielinski, Slawomir; Kassier, Rafael; Bech, Søren","Relationships between experienced listener ratings of multichannel audio quality and naïve listener preferences","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.1904305","https://doi.org/10.1121/1.1904305","The preferences of a large number of naïve listeners were elicited in response to a selection of multichannel audio items that had been degraded in quality by using band-limiting and down-mixing algorithms. Relationships were sought between these preference ratings and the quality judgements of experienced listeners in an attempt to determine whether one could be predicted from the other. Results suggest that a simple regression model can be used to do this with adequate results, but that a better prediction can be successfully based on experienced listener ratings of timbral and spatial fidelity. There is a difference between naïve and experienced listeners in the weightings of the fidelities and their relationship to overall quality.","2005-05-31","2023-07-10 07:55:19","2023-07-10 07:55:19","2023-07-10 07:55:19","3832-3840","","6","117","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/KJZCNTQ6/Rumsey et al. - 2005 - Relationships between experienced listener ratings.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GKHWB6SL","journalArticle","2005","Kirk, Roger E.","Difference Limen for Tone Diminution","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.1909404","https://doi.org/10.1121/1.1909404","The difference limen for tone diminution was investigated with diminution rate, fundamental frequency, and tonal complexity as parameters. Electronic means provided two tones whose diminution rates were independently adjustable. The tones were alternately presented to subjects over PDR‐8 earphones. The method of constant stimuli was used in determining the difference limen.The relative difference limen for tone diminution is of the order of 412 to 512% over the range of diminution rates investigated. The difference limen is relatively independent of fundamental frequency and tonal complexity. The relationship between the difference limen and diminution rate is described by an equation of the form Y = 0.048X where Y and X are measured in db/sec.","2005-06-29","2023-07-10 07:55:34","2023-07-10 07:55:34","2023-07-10 07:55:34","915-918","","10","30","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XSW32XB7","journalArticle","2006","Matsumoto, Mitsuharu; Hashimoto, Shuji","A miniaturized adaptive microphone array under directional constraint utilizing aggregated microphones","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.2141232","https://doi.org/10.1121/1.2141232","This paper introduces a miniaturized microphone array using the Directionally Constrained Minimization of Power (DCMP) method, which utilizes the transfer functions of microphones located at the same place, namely aggregated microphones. The phased microphone array realizes a noise reduction and direction of arrival (DOA) estimation system according to differences in the arrival time, phase shift, and/or the level of the sound wave for each microphone. Hence it is difficult to miniaturize the microphone array. The objective of our research is to miniaturize the system size using aggregated microphones. In this paper, we first show that the phased microphone array system and the proposed aggregated microphone system can be described within the same framework. We then apply a microphone array under directional constraint to the aggregated microphones and compare the proposed method with the microphone array. We show the directional pattern of the aggregated microphones. We also show the experimental results regarding DOA estimation.","2006-01-01","2023-07-10 07:55:55","2023-07-10 07:55:55","2023-07-10 07:55:55","352-359","","1","119","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/HECE6L6B/Matsumoto and Hashimoto - 2006 - A miniaturized adaptive microphone array under dir.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RZY3FI6S","journalArticle","2005","Raykar, Vikas C.; Duraiswami, Ramani; Yegnanarayana, B.","Extracting the frequencies of the pinna spectral notches in measured head related impulse responses","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.1923368","https://doi.org/10.1121/1.1923368","The head related impulse response (HRIR) characterizes the auditory cues created by scattering of sound off a person’s anatomy. The experimentally measured HRIR depends on several factors such as reflections from body parts (torso, shoulder, and knees), head diffraction, and reflection/diffraction effects due to the pinna. Structural models (Algazi et al., 2002; Brown and Duda, 1998) seek to establish direct relationships between the features in the HRIR and the anatomy. While there is evidence that particular features in the HRIR can be explained by anthropometry, the creation of such models from experimental data is hampered by the fact that the extraction of the features in the HRIR is not automatic. One of the prominent features observed in the HRIR, and one that has been shown to be important for elevation perception, are the deep spectral notches attributed to the pinna. In this paper we propose a method to robustly extract the frequencies of the pinna spectral notches from the measured HRIR, distinguishing them from other confounding features. The method also extracts the resonances described by Shaw (1997). The techniques are applied to the publicly available CIPIC HRIR database (Algazi et al., 2001c). The extracted notch frequencies are related to the physical dimensions and shape of the pinna.","2005-07-01","2023-07-10 07:56:04","2023-07-10 07:56:04","2023-07-10 07:56:04","364-374","","1","118","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/6QWNBG2V/Raykar et al. - 2005 - Extracting the frequencies of the pinna spectral n.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PEXMY6F2","journalArticle","2004","Guastavino, Catherine; Katz, Brian F. G.","Perceptual evaluation of multi-dimensional spatial audio reproduction","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.1763973","https://doi.org/10.1121/1.1763973","Perceptual differences between sound reproduction systems with multiple spatial dimensions have been investigated. Two blind studies were performed using system configurations involving 1-D, 2-D, and 3-D loudspeaker arrays. Various types of source material were used, ranging from urban soundscapes to musical passages. Experiment I consisted in collecting subjects’ perceptions in a free-response format to identify relevant criteria for multi-dimensional spatial sound reproduction of complex auditory scenes by means of linguistic analysis. Experiment II utilized both free response and scale judgments for seven parameters derived form Experiment I. Results indicated a strong correlation between the source material (sound scene) and the subjective evaluation of the parameters, making the notion of an “optimal” reproduction method difficult for arbitrary source material.","2004-08-02","2023-07-10 07:56:16","2023-07-10 07:56:16","2023-07-10 07:56:16","1105-1115","","2","116","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/7BFHYUKJ/Guastavino and Katz - 2004 - Perceptual evaluation of multi-dimensional spatial.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P2PAZ8HX","journalArticle","2003","Best, Virginia; van Schaik, André; Carlile, Simon","Separation of concurrent broadband sound sources by human listeners","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.1632484","https://doi.org/10.1121/1.1632484","The effect of spatial separation on the ability of human listeners to resolve a pair of concurrent broadband sounds was examined. Stimuli were presented in a virtual auditory environment using individualized outer ear filter functions. Subjects were presented with two simultaneous noise bursts that were either spatially coincident or separated (horizontally or vertically), and responded as to whether they perceived one or two source locations. Testing was carried out at five reference locations on the audiovisual horizon (0°, 22.5°, 45°, 67.5°, and 90° azimuth). Results from experiment 1 showed that at more lateral locations, a larger horizontal separation was required for the perception of two sounds. The reverse was true for vertical separation. Furthermore, it was observed that subjects were unable to separate stimulus pairs if they delivered the same interaural differences in time (ITD) and level (ILD). These findings suggested that the auditory system exploited differences in one or both of the binaural cues to resolve the sources, and could not use monaural spectral cues effectively for the task. In experiments 2 and 3, separation of concurrent noise sources was examined upon removal of low-frequency content (and ITDs), onset/offset ITDs, both of these in conjunction, and all ITD information. While onset and offset ITDs did not appear to play a major role, differences in ongoing ITDs were robust cues for separation under these conditions, including those in the envelopes of high-frequency channels.","2003-12-31","2023-07-10 07:56:26","2023-07-10 07:56:26","2023-07-10 07:56:26","324-336","","1","115","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/BGWJTTRI/Best et al. - 2003 - Separation of concurrent broadband sound sources b.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GX3LUYMC","journalArticle","2004","Kulkarni, Abhijit; Colburn, H. Steven","Infinite-impulse-response models of the head-related transfer function","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.1650332","https://doi.org/10.1121/1.1650332","Head-related transfer functions (HRTFs) measured from human subjects were approximated using infinite-impulse-response (IIR) filter models. Models were restricted to rational transfer functions (plus simple delays) so that specific models are characterized by the locations of poles and zeros in the complex plane. The all-pole case (with no nontrivial zeros) is treated first using the theory of linear prediction. Then the general pole-zero model is derived using a weighted-least-squares (WLS) formulation of the modified least-squares problem proposed by Kalman (1958). Both estimation algorithms are based on solutions of sets of linear equations and result in efficient computational schemes to find low-order model HRTFs. The validity of each of these two low-order models was assessed in psychophysical experiments. Specifically, a four-interval, two-alternative, forced-choice paradigm was used to test the discriminability of virtual stimuli constructed from empirical and model HRTFs for corresponding locations. For these experiments, the stimuli were 80 ms, noise tokens generated from a wideband noise generator. Results show that sounds synthesized through model HRTFs were indistinguishable from sounds synthesized from original HRTF measurements for the majority of positions tested. The advantages of the techniques described here are the computational efficiencies achieved for low-order IIR models. Properties of the all-pole and pole-zero estimators are discussed in the context of low-order HRTF representations, and implications for basic and applied contexts are considered.","2004-03-24","2023-07-10 07:57:06","2023-07-10 07:57:06","2023-07-10 07:57:06","1714-1728","","4","115","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/FDGLQXJQ/Kulkarni and Colburn - 2004 - Infinite-impulse-response models of the head-relat.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FB3RH9CH","journalArticle","1999","Burns, Edward M.; Houtsma, Adrianus J. M.","The influence of musical training on the perception of sequentially presented mistuned harmonics","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.428151","https://doi.org/10.1121/1.428151","The question of whether musical scales have developed from a processing advantage for frequency ratios based on small integers, i.e., ratios derived from relationships among harmonically related tones, is widely debated in musicology and music perception. In the extreme position, this processing advantage for these so-called “natural intervals” is assumed to be inherent, and to apply to sequentially presented tones. If this is the case, evidence for this processing advantage should show up in psychoacoustic experiments using listeners from the general population. This paper reports on replications and extensions of two studies from the literature. One [Lee and Green, J. Acoust. Soc. Am. 96, 716–725 (1994)] suggests that listeners from the general population can in fact determine whether sequentially presented tones are harmonically related. The other study [Houtgast, J. Acoust. Soc. Am. 60, 405–409 (1976)] is interpreted in different terms, but could be confounded by such an ability. The results of the replications and extensions, using listeners of known relative pitch proficiency, are consistent with the idea that only trained musicians can reliably determine whether sequentially presented tones are harmonically related.","1999-12-01","2023-07-10 07:57:30","2023-07-10 07:57:30","2023-07-10 07:57:30","3564-3570","","6","106","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/YJ48RK6M/Burns and Houtsma - 1999 - The influence of musical training on the perceptio.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HXPH7ZIN","journalArticle","2002","Langendijk, Erno H. A.; Bronkhorst, Adelbert W.","Contribution of spectral cues to human sound localization","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.1501901","https://doi.org/10.1121/1.1501901","The contribution of spectral cues to human sound localization was investigated by removing cues in 12-, 1- or 2-octave bands in the frequency range above 4 kHz. Localization responses were given by placing an acoustic pointer at the same apparent position as a virtual target. The pointer was generated by filtering a 100-ms harmonic complex with equalized head-related transfer functions (HRTFs). Listeners controlled the pointer via a hand-held stick that rotated about a fixed point. In the baseline condition, the target, a 200-ms noise burst, was filtered with the same HRTFs as the pointer. In other conditions, the spectral information within a certain frequency band was removed by replacing the directional transfer function within this band with the average transfer of this band. Analysis of the data showed that removing cues in 12-octave bands did not affect localization, whereas for the 2-octave band correct localization was virtually impossible. The results obtained for the 1-octave bands indicate that up–down cues are located mainly in the 6–12-kHz band, and front–back cues in the 8–16-kHz band. The interindividual spread in response patterns suggests that different listeners use different localization cues. The response patterns in the median plane can be predicted using a model based on spectral comparison of directional transfer functions for target and response directions.","2002-09-27","2023-07-10 07:57:43","2023-07-10 07:57:43","2023-07-10 07:57:43","1583-1596","","4","112","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/7TYEXQIM/Langendijk and Bronkhorst - 2002 - Contribution of spectral cues to human sound local.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IX7EMW69","journalArticle","2002","Zahorik, Pavel","Assessing auditory distance perception using virtual acoustics","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.1458027","https://doi.org/10.1121/1.1458027","In most naturally occurring situations, multiple acoustic properties of the sound reaching a listener’s ears change as sound source distance changes. Because many of these acoustic properties, or cues, can be confounded with variation in the acoustic properties of the source and the environment, the perceptual processes subserving distance localization likely combine and weight multiple cues in order to produce stable estimates of sound source distance. Here, this cue-weighting process is examined psychophysically, using a method of virtual acoustics that allows precise measurement and control of the acoustic cues thought to be salient for distance perception in a representative large-room environment. Though listeners’ judgments of sound source distance are found to consistently and exponentially underestimate true distance, the perceptual weight assigned to two primary distance cues (intensity and direct-to-reverberant energy ratio) varies substantially as a function of both sound source type (noise and speech) and angular position (0° and 90° relative to the median plane). These results suggest that the cue-weighting process is flexible, and able to adapt to individual distance cues that vary as a result of source properties and environmental conditions.","2002-04-03","2023-07-10 07:57:56","2023-07-10 07:57:56","2023-07-10 07:57:56","1832-1846","","4","111","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/IUHNAVVW/Zahorik - 2002 - Assessing auditory distance perception using virtu.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8XW2TGHG","journalArticle","1999","Brungart, Douglas S.","Auditory localization of nearby sources. III. Stimulus effects","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.428212","https://doi.org/10.1121/1.428212","A series of experiments has examined the auditory localization of a nearby (&lt;1 m) sound source under four conditions: (1) a fixed-amplitude condition where loudness-based distance cues were available; (2) a monaural condition where the contralateral ear was occluded by an ear-plug and muff; (3) a high-pass condition where the stimulus bandwidth was 3 Hz to 15 kHz; and (4) a low-pass condition where the stimulus bandwidth was 200 Hz to 3 kHz. The results of these experiments were compared to those of a previous experiment that measured localization performance for a nearby broadband, random-amplitude source [Brungart et al., J. Acoust. Soc. Am. 106, 1956–1968 (1999)]. Directional localization performance in each condition was consistent with the results of previous far-field localization experiments. Distance localization accuracy improved slightly in the fixed-amplitude condition relative to the earlier broadband random-amplitude experiment, especially near the median plane, but was severely degraded in the monaural condition. Distance accuracy was also found to be highly dependent on the low-frequency energy of the stimulus: in the low-pass condition, distance accuracy was similar to that in the broadband condition, while in the high-pass condition, distance accuracy was significantly reduced. The results suggest that low-frequency interaural level differences are the dominant auditory distance cue in the proximal region.","1999-12-01","2023-07-10 07:58:12","2023-07-10 07:58:12","2023-07-10 07:58:12","3589-3602","","6","106","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/DG48Z67D/Brungart - 1999 - Auditory localization of nearby sources. III. Stim.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NQW5XTHZ","journalArticle","1999","Brungart, Douglas S.; Durlach, Nathaniel I.; Rabinowitz, William M.","Auditory localization of nearby sources. II. Localization of a broadband source","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.427943","https://doi.org/10.1121/1.427943","Although many researchers have examined auditory localization for relatively distant sound sources, little is known about the spatial perception of nearby sources. In the region within 1 m of a listener’s head, defined as the “proximal region,” the interaural level difference increases dramatically as the source approaches the head, while the interaural time delay is roughly independent of distance. An experiment has been performed to evaluate proximal-region localization performance. An auditory point source was moved to a random position within 1 m of the subject’s head, and the subject responded by pointing to the perceived location of the sound with an electromagnetic position sensor. The overall angular error (17°) was roughly comparable to previously measured results in distal-region experiments. Azimuth error increased slightly as the sound source approached the head, but elevation performance was essentially independent of source distance. Distance localization performance was generally better than has been reported in distal-region experiments and was strongly dependent on azimuth, with the stimulus–response correlation ranging from 0.85 to the side of the head to less than 0.4 in the median plane. The results suggest that the enlarged binaural difference cues found in the head-related transfer function (HRTF) for nearby sources are important to auditory distance perception in the proximal region.","1999-10-01","2023-07-10 07:58:25","2023-07-10 07:58:25","2023-07-10 07:58:25","1956-1968","","4","106","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/Y8DK6QRF/Brungart et al. - 1999 - Auditory localization of nearby sources. II. Local.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LPW25QKV","journalArticle","1999","Altman, Jacob A.; Variaguina, Olga V.; Nikitin, Nikolay I.; Radionova, Elena A.","Lateralization of a moving auditory image: Interrelation of interaural time and intensity differences","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.424603","https://doi.org/10.1121/1.424603","Lateralization of moving fused auditory images (FAIs) was studied under dichotic stimulation, with FAI movement from the right and left ears to midline. The movement was produced by the gradual change of interaural time delay (from ±630 to 0 μs) in a binaurally presented click train in which a constant interaural intensity difference (IID) between ±13 dB was also imposed. The task of the subjects was to show with her/his finger the point on the head surface where the FAI trajectory’s ending or starting points were perceived. With IID change within ±13 dB, the FAI movement trajectory shifted toward the ear receiving the more intense stimulus. The length of the movement trajectory shortened with IID increase. Functions relating the value of perceived lateral position (Y) of the movement trajectory’s ending and starting points to IID value (X) were nearly linear: Y=AX+B. These functions differed in their characteristics whether the movement was to the right versus to the left of midline. They also differed from analogous functions for stationary FAI. At IID=0 the FAI movement trajectory’s endpoint was shifted from midline in the direction of movement. Equivalence ratio for IID and ITD were estimated to be 51 and 29 μs/dB respectively for the trajectory’s starting and ending points. The IID factor could be several times as effective in moving FAI lateralization as the ITD factor.","1999-01-01","2023-07-10 07:58:43","2023-07-10 07:58:43","2023-07-10 07:58:43","366-376","","1","105","","The Journal of the Acoustical Society of America","Lateralization of a moving auditory image","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/I98INPS4/Altman et al. - 1999 - Lateralization of a moving auditory image Interre.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NZGZNIDR","journalArticle","1998","Shinn-Cunningham, Barbara G.; Durlach, Nathaniel I.; Held, Richard M.","Adapting to supernormal auditory localization cues. I. Bias and resolution","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.423088","https://doi.org/10.1121/1.423088","Head-related transfer functions (HRTFs) were used to create spatialized stimuli for presentation through earphones. Subjects performed forced-choice, identification tests during which allowed response directions were indicated visually. In each experimental session, subjects were first presented with auditory stimuli in which the stimulus HRTFs corresponded to the allowed response directions. The correspondence between the HRTFs used to generate the stimuli and the directions was then changed so that response directions no longer corresponded to the HRTFs in the natural way. Feedback was used to train subjects as to which spatial cues corresponded to which of the allowed responses. Finally, the normal correspondence between direction and HRTFs was reinstated. This basic experimental paradigm was used to explore the effects of the type of feedback provided, the complexity of the simulated acoustic scene, the number of allowed response positions, and the magnitude of the HRTF transformation subjects had to learn. Data showed that (1) although subjects may not adapt completely to a new relationship between physical stimuli and direction, response bias decreases substantially with training, and (2) the ability to resolve different HRTFs depends both on the stimuli presented and on the state of adaptation of the subject.","1998-06-01","2023-07-10 07:58:53","2023-07-10 07:58:53","2023-07-10 07:58:53","3656-3666","","6","103","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E2ELCD2E","journalArticle","1999","Kulkarni, Abhijit; Isabelle, S. K.; Colburn, H. S.","Sensitivity of human subjects to head-related transfer-function phase spectra","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.426898","https://doi.org/10.1121/1.426898","Head-related transfer functions (HRTFs) for human subjects in anechoic space were modeled with modified phase spectra, including minimum-phase-plus-delay, linear-phase, and reversed-phase-plus-delay functions. The overall (wide-band) interaural time delay (ITD) for the modeled HRTFs was made consistent with that of the empirical HRTFs by setting the position-dependent, frequency-independent delay in the HRTF for the lagging ear. Signal analysis of the minimum-phase-plus-delay reconstructions indicated that model HRTFs deviate from empirical HRTF measurements maximally for contralateral azimuths and low elevations. Subjects assessed the perceptual validity of the model HRTFs in a four-interval, two-alternative, forced-choice discrimination paradigm. Results indicate that monaural discrimination performance of subjects was at chance for all three types of HRTF models. Binaural discrimination performance was at chance for the linear-phase HRTFs, was above chance for some locations for the minimum-phase-plus-delay HRTFs, and was above chance for all tested locations for the reversed-phase-plus-delay HRTFs. An analysis of low-frequency timing information showed that all of these results are consistent with efficient use of interaural time differences in the low-frequency components of the stimulus waveforms. It is concluded that listeners are insensitive to HRTF phase spectra as long as the overall ITD of the low-frequency components does not provide a reliable cue. In particular, the minimum-phase-plus-delay approximation to the HRTF phase spectrum is an adequate approximation as long as the low-frequency ITD is appropriate. These results and conclusions are all limited to the anechoic case when the HRTFs correspond to brief impulse responses limited to a few milliseconds.","1999-05-01","2023-07-10 07:59:04","2023-07-10 07:59:04","2023-07-10 07:59:04","2821-2840","","5","105","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/LRSQ2RQ2/Kulkarni et al. - 1999 - Sensitivity of human subjects to head-related tran.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MCGR7IR8","journalArticle","1997","Noble, William; Byrne, Denis; Ter-Horst, Kim","Auditory localization, detection of spatial separateness, and speech hearing in noise by hearing impaired listeners","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.419618","https://doi.org/10.1121/1.419618","In two groups, one with sensorineural and the other with conductive-mixed hearing loss, measures were made of single-source localization and speech intelligibility in both spatially separate and nonseparate noise. There was also a test for detecting when two sounds came from the same location or from separate ones. Localization test results confirmed earlier findings, namely, disruption of vertical plane ability generally, and a further, particular disturbance to horizontal plane localization in the conductive-mixed group. Compared with a normal control group, there were only slight signs of benefit from separation of speech and noise in the region lateral to the listener, and virtually none in the frontal region. The new test, spatial separateness, had elements in common with both of the other tests, and links were observed from localization to separateness detection, and from separateness to benefit from separation of speech and noise. Localization was also related to speech hearing in nonspatially separated noise.","1997-10-01","2023-07-10 07:59:19","2023-07-10 07:59:19","2023-07-10 07:59:18","2343-2352","","4","102","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PJ8SN98G","journalArticle","1995","Bronkhorst, Adelbert W.","Localization of real and virtual sound sources","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.413219","https://doi.org/10.1121/1.413219","Localization of real and virtual sound sources was studied using two tasks. In the first task, subjects had to turn their head while the sound was continuously on and press a button when they thought they faced the source. In the second task, the source only produced a short sound and the subjects had to indicate, by pressing one of eight buttons, in which quadrant the source was located, and whether it was located above or below the horizontal plane. Virtual sound sources were created using head‐related transfer functions (HRTFs), measured with probe microphones placed in the ear canals of the subjects. Sound stimuli were harmonic signals with a fundamental frequency of 250 Hz and an upper frequency ranging from 4 to 15 kHz. Results, obtained from eight subjects, show that localization performance for real and virtual sources was similar in both tasks, provided that the stimuli did not contain frequencies above 7 kHz. When frequencies up to 15 kHz were included, performance for virtual sources was, in general, poorer than for real sources. Differences between results for real and virtual sources were relatively small in the first task, provided that individualized HRTFs were used to create the virtual sources, but quite large (a factor of 2) in the second task. The differences were probably caused by a distortion of high‐frequency spectral cues in the HRTFs, introduced by the probe microphone measurement in the ear canal.","1995-11-01","2023-07-10 07:59:28","2023-07-10 07:59:28","2023-07-10 07:59:28","2542-2553","","5","98","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SAH7NCMA","journalArticle","1978","Burns, Edward M.; Ward, W. Dixon","Categorical perception—phenomenon or epiphenomenon: Evidence from experiments in the perception of melodic musical intervals","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.381737","https://doi.org/10.1121/1.381737","Categorical perception was investigated in a series of experiments on the perception of melodic musical intervals (sequential frequency ratios). When procedures equivalent to those typically used in speech‐perception experiments were employed, (i.e., determination of identification and discrimination functions for stimuli separated by equal physical increments), musical intervals were perceived categorically by trained musicians. When a variable‐step‐size (adaptive) discrimination procedure was used, evidence of categorical perception (in the form of smaller interval‐width DL’s for ratios at identification category boundaries than for ratios within categories), although present initially, largely disappeared after subjects had reached asymptotic performance. However, equal‐step‐size discrimination functions obtained after observers had reached asymptotic performance in the adaptive paradigm were not substantially different from those initially obtained. The results of other experiments imply that this dependence of categorical perception on procedure may be related to differences in stimulus uncertainty between the procedures. An experiment on the perception of melodic intervals by musically untrained observers showed no evidence for the existence of ’’natural’’ categories for musical intervals.","1978-02-01","2023-07-10 07:59:36","2023-07-10 07:59:36","2023-07-10 07:59:36","456-468","","2","63","","The Journal of the Acoustical Society of America","Categorical perception—phenomenon or epiphenomenon","","","","","","","","","","","","Silverchair","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""