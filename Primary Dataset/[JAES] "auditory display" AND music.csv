"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"G4JTHMAL","journalArticle","2019","Brinkmann, Fabian; Dinakaran, Manoj; Pelzer, Robert; Grosche, Peter; Voss, Daniel; Weinzierl, Stefan","A Cross-Evaluated Database of Measured and Simulated HRTFs Including 3D Head Meshes, Anthropometric Features, and Headphone Impulse Responses","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=20546","The individualization of head related transfer functions (HRTFs) can make an important contribution to improving the quality of binaural technology applications. One approach to individualization is to exploit the relationship between the shape of HRTFs and the anthropometric features of the ears, head, and torso of the corresponding listeners. To identify statistically significant relationships between the two sets of variables, a relatively large database is required. For this purpose full-spherical HRTFs of 96 subjects were acoustically measured and numerically simulated. A detailed cross-evaluation showed a good agreement to previous data between repeated measurements and between measured and simulated data. In addition to 96 HRTFs, the database includes high-resolution head-meshes, a list of 25 anthropometric features per subject, and headphone transfer functions for two headphone models.","2019","2023-07-12 06:41:35","2023-07-19 03:45:08","","705–718","","9","67","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RJXKVADJ","journalArticle","2012","Stewart, Rebecca; Sandler, Mark","Spatial Auditory Display in Music Search and Browsing Applications","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=16637","","2012","2023-07-12 07:04:55","2023-07-12 07:04:55","","936–946","","11","60","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"96XL5BG6","journalArticle","2012","Peres, S. Camille","A Comparison of Sound Dimensions for Auditory Graphs: Pitch Is Not So Perfect","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=16367","Visually-impaired individuals and sighted individuals who are conducting tasks in divided-attention situations, both benefit from using sound to display information typically communicated visually. Auditory displays of statistical graphs are one such tool and can be effective in these situations. However, it is not obvious how these graphs should be designed. In a series of experiments in which information was conveyed by sound, subjects were divided into two groups: those hearing graphs using integral (pitch and loudness) and separable (pitch and timing) dimensions of sound. The results showed that pitch alone produced the worst performance and timing the best. However, designs using pitch and loudness redundantly provided good results as well.","2012","2023-07-12 07:04:59","2023-07-19 04:37:44","","561–567","","7/8","60","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VUR44Y8A","journalArticle","2012","Grond, Florian; Kramer, Oliver; Hermann, Thomas","Balancing Salience and Unobtrusiveness in Auditory Monitoring of Evolutionary Optimization","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=16364","Sonification, which is the conversion of physical data (temperature, network traffic, or an electrocardiogram) into sound, is very suitable for augmenting task monitoring. The challenge to the sound designer is to create a monitoring display that maximizes the conveyed information while at the same time remaining unobtrusive. In this article an auditory augmentation approach was developed for monitoring evolutionary optimization algorithms. In order to augment short interaction sounds effectively with the information about the high-dimensional search space, a sonification method known as data sonograms was applied. Various mappings of data to sound features have been investigated, where the delay of the signal has been shown to be an interesting parameter that plays a role in both unobtrusiveness and information conveyed.","2012","2023-07-12 07:05:02","2023-07-19 04:02:51","","531–539","","7/8","60","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L7Q6MY8L","journalArticle","2012","Roginska, Agnieszka","Effect of Spatial Location and Presentation Rate on the Reaction to Auditory Displays","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=16361","The way in which auditory displays are presented can significantly influence the experience of listeners. Spatio-temporal factors influence and redirect the attention toward such displays. These factors include presentation speed, stimulus externalization, and location in the three dimensional space. Results show that stimuli perceived inside the head resulted in a more accurate and faster response than those that were externalized. For externalized auditory displays, those presented in the frontal hemisphere were attended to faster. Response times did not change linearly with presentation speed; there was an optimal presentation rate at which the response time is fastest without compromising accuracy.","2012","2023-07-12 07:05:05","2023-07-19 04:41:19","","497–504","","7/8","60","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HSDXTGIC","journalArticle","2012","Altinsoy, M. Ercan","The Quality of Auditory-Tactile Virtual Environments","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=16164","","2012","2023-07-12 07:05:08","2023-07-12 07:05:08","","38–46","","1/2","60","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9REG4A3X","journalArticle","1995","Crispien, Kai; Ehrenberg, Tasso","Evaluation of the -Cocktail-Party Effect- for Multiple Speech Stimuli within a Spatial Auditory Display","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=7922","In order to provide access to graphics-based user interfaces for blind computer users, a spatial auditory computer display is under development which conveys the visual information embedded in the user interface in an auditory form. A spatial representation of the auditory display, based on a binaural real-time processing syst;em, is used to provide orientational information and to permit the use of multiple simultaneous verbal and nonverbal audio information. A psychoacoustic experiment was carried out with 31 participating subjects in order to investigate the ability to discriminate multiple simultaneous speech stimuli within a spatial auditory display. Localization performance and speech reception were investigated.","1995","2023-07-12 07:05:11","2023-07-19 03:50:37","","932–941","","11","43","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E2T2NBML","journalArticle","2012","Jeon, Myounghoon; Gupta, Siddharth; Davison, Benjamin K.; Walker, Bruce N.","Auditory Menus Are Not Just Spoken Visual Menus: A Case Study of “Unavailable” Menu Items","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=16362","When a visual menu, such as in a computer, needs to be presented with sound, there is a question about how to best communicate an item that is unavailable. This question was explored in three studies that showed that using a whispered voice for unavailable items was favored over an attenuated voice, saying “unavailable,” or skipping such items. In general, participants preferred a female voice over a male voice. Results are discussed in terms of acoustic theory, cognitive menu selection theory, and user interface accessibility. The authors asserted that designers should go beyond a naïve translation from text into speech when creating auditory systems, thereby creating subjective satisfaction.","2012","2023-07-12 07:05:14","2023-07-19 04:08:40","","505–518","","7/8","60","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"48EGYBNH","journalArticle","2012","Parseihian, Gaëtan; Katz, Brian F. G.","Morphocons: A New Sonification Concept Based on Morphological Earcons","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=16355","","2012","2023-07-12 07:05:17","2023-07-12 07:05:17","","409–418","","6","60","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QNCRYSEQ","journalArticle","1998","Begault, Durand R.","Virtual Acoustics, Aeronautics, and Communications","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=12140","","1998","2023-07-12 07:05:20","2023-07-12 07:05:20","","520–530","","6","46","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TXR3HFCY","journalArticle","2012","Asutay, Erkin; Västfjäll, Daniel; Tajadura-Jiménez, Ana; Genell, Anders; Bergman, Penny; Kleiner, Mendel","Emoacoustics: A Study of the Psychoacoustical and Psychological Dimensions of Emotional Sound Design","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=16162","Even though traditional psychoacoustics has provided indispensable knowledge about auditory perception, it has, in its narrow focus on signal characteristics, neglected listener and contextual characteristics. To demonstrate the influence of the meaning the listener attaches to a sound in the resulting sensations we used a Fourier-time-transform processing to reduce the identifiability of 18 environmental sounds. In a listening experiment, 20 subjects listened to and rated their sensations in response to, first, all the processed stimuli and then, all original stimuli, without being aware of the relationship between the two groups. Another 20 subjects rated only the processed stimuli, which were primed by their original counterparts. This manipulation was used in order to see the difference in resulting sensation when the subject could tell what the sound source is. In both tests subjects rated their emotional experience for each stimulus on the orthogonal dimensions of valence and arousal, as well as perceived annoyance and perceived loudness for each stimulus. They were also asked to identify the sound source. It was found that processing caused correct identification to reduce substantially, while priming recovered most of the identification. While original stimuli induced a wide range of emotional experience, reactions to processed stimuli were emotionally neutral. Priming manipulation reversed the effects of processing to some extent. Moreover, even though the 5th percentile Zwickers-loudness (N5) value of most of the stimuli was reduced after processing, neither perceived loudness nor auditory-induced emotion changed accordingly. Thus indicating the importance of considering other factors apart from the physical sound characteristics in sound design.","2012","2023-07-12 07:05:23","2023-07-19 03:37:20","","21–28","","1/2","60","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A3BEQY2C","journalArticle","2014","Begault, Durand R.; Bittner, Rachel M.; Anderson, Mark R.","Multimodal Information Management: Evaluation of Auditory and Haptic Cues for NextGen Communication Displays","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=17333","","2014","2023-07-12 07:05:26","2023-07-12 07:05:26","","375–385","","6","62","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"USHA5FTU","journalArticle","2018","Yang, Jiajun; Hermann, Thomas","Interactive Mode Explorer Sonification Enhances Exploratory Cluster Analysis","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=19712","","2018","2023-07-12 07:05:29","2023-07-12 07:05:29","","703–711","","9","66","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NW442W7Q","journalArticle","2016","Lafay, Grégoire; Misdariis, Nicolas; Lagrange, Mathieu; Rossignol, Mathias","Semantic Browsing of Sound Databases without Keywords","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=18371","","2016","2023-07-12 07:05:32","2023-07-12 07:05:32","","628–635","","9","64","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9P4AMXV2","journalArticle","2012","Grosshauser, T.; Bläsing, B.; Spieth, C.; Hermann, T.","Wearable Sensor-Based Real-Time Sonification of Motion and Foot Pressure in Dance Teaching and Training","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=16369","","2012","2023-07-12 07:05:36","2023-07-12 07:05:36","","580–589","","7/8","60","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JIXTJ5Y8","journalArticle","2014","Sanz, Pablo Revuelta; Mezcua, Belén Ruiz; Pena, José M. Sánchez; Walker, Bruce N.","Scenes and Images into Sounds: A Taxonomy of Image Sonification Methods for Mobility Applications","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=17130","Sonification is the systematic representation of data using sounds, such as text-to-speech, color readers, Geiger counters, acoustic radars, and MIDI synthesizers. This paper surveys existing sonification systems and suggests taxonomy of algorithms and devices. The sonification process requires an artificial mapping between two sensory modalities using a model based on either psychoacoustics or artificial heuristics. In the former, the paradigm exploits the natural discrimination of the source spatial parameters (distance, azimuth, and elevation, for instance). In the latter, the paradigm creates an artificial match between graphical and auditory cues. Artificial sonification uses nonspatial characteristics of the sound, such as frequency, brightness or timbre, formants, saturation, and time intervals, which are not related to the physical characteristics or parameters of objects or surroundings.","2014","2023-07-12 07:05:39","2023-07-19 04:46:32","","161–171","","3","62","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZRUWMWTG","journalArticle","2012","Bujacz, Michal; Skulimowski, Piotr; Strumillo, Pawel","Naviton—A Prototype Mobility Aid for Auditory Presentation of Three-Dimensional Scenes to the Visually Impaired","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=16374","","2012","2023-07-12 07:05:42","2023-07-12 07:05:42","","696–708","","9","60","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z6D3VPBT","journalArticle","2006","Väljamäe, Aleksander; Larsson, Pontus; Västfjäll, Daniel; Kleiner, Mendel","Vibrotactile Enhancement of Auditory-Induced Self-Motion and Spatial Presence","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=13883","","2006","2023-07-12 07:05:47","2023-07-12 07:05:47","","954–963","","10","54","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6M2GCAN4","journalArticle","2012","Wersényi, György","Virtual Localization by Blind Persons","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=16368","","2012","2023-07-12 07:05:50","2023-07-12 07:05:50","","568–579","","7/8","60","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7GYAPSE7","journalArticle","2009","Väljamäe, Aleksander; Larsson, Pontus; Västfjäll, Daniel; Kleiner, Mendel","Auditory Landmarks Enhance Circular Vection in Multimodal Virtual Reality","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=14809","The means by which an individual distinguishes between (a) self-movement relative to a fixed external object and (b) a fixed sense of self relative to a moving object involves both sensory input and cognitive processes. The current study examines the cognitive influences of an auditory presentation on the illusion of motion. The illusion of self-motion was strongest when simulating multiple auditory objects of the type that are expected to be immobile: acoustic landmarks. The effect is strongest without visual cues, which can dominate if present. The addition of vibrotactile stimulation of the whole body was only selectively contributing to the experience of being in motion depending on the simulated auditory objects.","2009","2023-07-12 07:05:54","2023-07-19 04:54:55","","111–120","","3","57","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DKBXWL8R","journalArticle","2020","Salmon, François; Hendrickx, Étienne; Épain, Nicolas; Paquier, Mathieu","The Influence of Vision on Perceived Differences Between Sound Spaces","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=20888","","2020","2023-07-12 07:05:57","2023-07-12 07:05:57","","522–531","","7/8","68","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4P6HSCRW","journalArticle","1994","Begault, Durand R.; Erbe, Tom","Multichannel Spatial Auditory Display for Speech Communications","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=6924","","1994","2023-07-12 07:06:01","2023-07-12 07:06:01","","819–826","","10","42","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V8X6TWTC","journalArticle","2005","Ferguson, Sam; Cabrera, Densil","Vertical Localization of Sound from Multiway Loudspeakers","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=13406","Practical wide-range loudspeakers are usually implemented with multiple drivers, but the systematic effect of the signal frequency upon the vertical localization of sound is scarcely used for loudspeaker enclosure design. Tendencies in vertical localization for the frequency bands characteristic of woofers and tweeters in loudspeakers are shown. Using vertical arrays of individually controlled loudspeakers, synchronous and asynchronous bands of noise were presented to subjects. The frequency of the source affected the vertical position of the lowand high-frequency auditory image pairs significantly and systematically, in a manner broadly consistent with previous studies concerned with single auditory images. Lower frequency sources are localized below their physical positions whereas high-frequency sources are localized at their true positions. This effect is also shown to occur for musical signals. It is demonstrated that low-frequency sources are not localized well when presented in exact synchrony with high-frequency sources, or when they only include energy below 500 Hz.","2005","2023-07-12 07:06:05","2023-07-19 03:57:29","","163–173","","3","53","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U4N5RWVA","journalArticle","2016","Bulla, Wesley","Detection of High-Frequency Harmonics in a Brief Complex Tone","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=18100","Prior investigations have generally failed to confirm or deny the perceptual influence of high-frequency harmonics contained in musical sounds. Because harmonics that are beyond the frequency range of auditory detection influence the resulting waveform, they may alter the perception of a sound’s tonal character. This study found no evidence that capable listeners noticed an effect of high-frequency harmonics within a brief complex tone. With regard to the influence of high-frequency harmonic content on timbre perception, subjects were capable of performing the assigned task, the presentation technology was adequate for delivering reliable stimuli, the stimuli were appropriate for the interests of the study, and yet, there were no indications that the presence of high-frequency harmonics influenced listeners’ perception of the timbre of a complex waveform.","2016","2023-07-12 07:06:09","2023-07-19 03:45:44","","4–12","","1/2","64","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"42NJRG9W","journalArticle","2015","Kim, Sungyoung; Okumura, Hiraku; Otani, Makoto","Near-Field Sound Control Using a Planar Loudspeaker","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=17566","Even with the more advanced sound rendering methods, creating a convincing near-field image has remained a challenge, especially when sound is integrated with high resolution video. In order to render a near-field sound image in a relatively simple yet effective way, the authors proposed a new method using an overhead planar loudspeaker. Subjective evaluation showed that planar waves radiating from overhead position generated a sound image very near to the listener when coupled with an additional filter that removes spectral cues associated with an overhead sound source. The results also showed that the proposed method could continuously control the distance of sound image between the screen and the listener position. The planar loudspeaker generated smaller variance of group delay at the listener's ears than conventional loudspeakers.","2015","2023-07-12 07:06:12","2023-07-19 04:12:01","","54–62","","1/2","63","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LBGCU7WJ","journalArticle","2012","Vogt, Katharina; Höldrich, Robert","Translating Sonifications","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=16636","","2012","2023-07-12 07:06:15","2023-07-12 07:06:15","","926–935","","11","60","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K29GQU82","journalArticle","2014","Evreinova, Tatiana V.; Evreinov, Grigori; Raisamo, Roope","An Exploration of Volumetric Data in Auditory Space","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=17131","Sonification of 3-dimensional shapes is challenging because there are fundamental differences between the human auditory and visual systems. Subjects were asked to explore the audio representations of top-projected shapes having different levels of visual complexity using several different strategies. After a 50-minute experience with each sonification technique, all subjects agreed that auditory patterns derived from cross-sectional profiles of virtual objects were robust and extremely easy for mental manipulation, enabling them to mentally rebuild virtual shapes. At the beginning of the test, subjects could not imagine that it would be possible to get a sense of a virtual shape by relying exclusively on ordinary MIDI sounds. Two other techniques were not successful.","2014","2023-07-12 07:06:20","2023-07-19 03:55:11","","172–187","","3","62","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DIIRWSZD","journalArticle","2012","Metatla, Oussama; Bryan-Kinns, Nick; Stockman, Tony","The Effects of Using Headphones and Speakers on Collaboration in an Audio-Only Workspace","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=16365","","2012","2023-07-12 07:06:23","2023-07-12 07:06:23","","540–550","","7/8","60","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MBV92KBC","journalArticle","2001","Begault, Durand R.; Wenzel, Elizabeth M.; Anderson, Mark R.","Direct Comparison of the Impact of Head Tracking, Reverberation, and Individualized Head-Related Transfer Functions on the Spatial Perception of a Virtual Speech Source","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=10175","A study of sound localization performance was conducted using headphone-delivered virtual speech stimuli, rendered via HRTF-based acoustic auralization software and hardware, and blocked-meatus HRTF measurements. The independent variables were chosen to evaluate commonly held assumptions in the literature regarding improved localization: inclusion of head tracking, individualized HRTFs, and early and diffuse reflections. Significant effects were found for azimuth and elevation error, reversal rates, and externalization.","2001","2023-07-12 07:06:27","2023-07-19 03:41:13","","904–916","","10","49","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z79DRCGJ","journalArticle","2022","Yang, Jing; Barde, Amit; Billinghurst, Mark","Audio Augmented Reality: A Systematic Review of Technologies, Applications, and Future Research Directions","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=22008","Audio Augmented Reality (AAR) aims to augment people's auditory perception of the real world by synthesizing virtual spatialized sounds. AAR has begun to attract more research interest in recent years, especially because Augmented Reality (AR) applications are becoming more commonly available on mobile and wearable devices. However, because audio augmentation is relatively under-studied in the wider AR community, AAR needs to be further investigated in order to be widely used in different applications. This paper systematically reports on the technologies used in past studies to realize AAR and provide an overview of AAR applications. A total of 563 publications indexed on Scopus and Google Scholar were reviewed, and from these, 117 of the most impactful papers were identified and summarized in more detail. As one of the first systematic reviews of AAR, this paper presents an overall landscape of AAR, discusses the development trends in techniques and applications, and indicates challenges and opportunities for future research. For researchers and practitioners in related fields, this review aims to provide inspirations and guidance for conducting AAR research in the future.","2022","2023-07-12 07:06:30","2023-07-19 10:58:33","","788–809","","10","70","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WXCDKCR5","journalArticle","2013","Xie, Bosun; Zhong, Xiaoli; Yu, Guangzheng; Guan, Shanquin; Rao, Dan; Liang, Zhiqiang; Zhang, Chengyun","Report on Research Projects on Head-Related Transfer Functions and Virtual Auditory Displays in China","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=16826","","2013","2023-07-12 07:06:34","2023-07-12 07:06:34","","314–326","","5","61","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6QDY3QGN","journalArticle","2012","Schaffert, Nina; Gehret, Reiner; Mattes, Klaus","Modeling the Rowing Stroke Cycle Acoustically","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=16366","","2012","2023-07-12 07:06:37","2023-07-12 07:06:37","","551–560","","7/8","60","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7FQ3C2QM","journalArticle","2004","Tan, Chin-Tuan; Moore, Brian C. J.; Zacharov, Nick; Mattila, Ville-Veikko","Predicting the Perceived Quality of Nonlinearly Distorted Music and Speech Signals","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=13013","In a previous study perceptual experiments were reported in which subjects had to rate the perceived quality of speech and music that had been subjected to various forms of nonlinear distortion. The subjective ratings were compared to a physical measure of distortion, DS, based on the output spectrum of each nonlinear system in response to a 10-component multitone test signal with logarithmically spaced components. The values of DS were highly negatively correlated with the subjective ratings for stimuli that had been subjected to ""artificial"" distortions such as peak clipping and zero clipping. However, for stimuli that had been subjected to nonlinear distortion produced by real transducers, the correlation between the DS values and the subjective ratings was only moderately negative. A new method predicts the perceived quality of nonlinearly distorted signals based on the outputs of an array of gammatone filters in response to the original signal and the distorted signal. For each filter, the cross correlation is calculated between the outputs in response to the original and the distorted signals for a series of brief samples (frames). The maximum value of the cross correlation for each filter for each frame is determined, and the maximum values are summed across filters, with a weighting that depends on the magnitude of the output of each filter in response to the distorted signal. The resultant weighted cross correlation gives a perceptually relevant measure of distortion called Rnonlin, which can be used to predict subjective ratings. There were high correlations between the predicted ratings and the subjective ratings obtained previously. The correlations were greater than obtained using the DS measure. A new perceptual experiment, using a mixture of artificial and real distortions, confirmed the validity of the new measure.","2004","2023-07-12 07:06:43","2023-07-19 04:51:24","","699–711","","7/8","52","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"68LHCK8N","journalArticle","1994","Stuart, J. Robert","Noise: Methods for Estimating Detectability and Threshold","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=6959","","1994","2023-07-12 07:06:46","2023-07-12 07:06:46","","124–140","","3","42","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JBZI5K8C","journalArticle","2003","Chen, Fang","Localization of 3-D Sound Presented through Headphone - Duration of Sound Presentation and Localization Accuracy","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=12188","","2003","2023-07-12 07:06:49","2023-07-12 07:06:49","","1163–1171","","12","51","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ANDJ5X66","journalArticle","2021","Tamer, Yahya Burak","Spectral and Dynamic Analyses of Popular Music Playlists: The Concept of Presence Optimization for Digital Music Streaming Playback","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=21036","Digital streaming has become the most popular way to experience music today. Loudness normalization applied by streaming services allows for the restoration of dynamic contrast, yet the hypercompressed production trends sustain. This paper studies current dynamic and spectral tendencies through integrated loudness and long-term average spectrum (LTAS) analyses of popular music playlists offered by digital streaming services. Deviations from the large-scale spectral characterizations provided by earlier studies on popular music LTAS were investigated and an increase in the slope of the presence band was observed. The paper concludes with recommendations for the optimization of the presence band using digital filtering via metadata during streaming playback.","2021","2023-07-12 07:06:53","2023-07-19 04:51:05","","309–322","","5","69","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X6YU2FTL","journalArticle","2001","Blesser, Barry A.","An Interdisciplinary Synthesis of Reverberation Viewpoints","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=10176","Artificial reverberator algorithms, which are implemented using digital signal processing, can be best understood by considering their relationships to several disciplines: the perceptual metrics of the auditory system, the statistical properties of the acoustic spaces, the artistic needs of the music culture, and the mixing techniques in the recording studio. Both the early reverberations, containing the unique spatial personality, and the late part, containing the statistically random process, play different roles in each of the related disciplines. When the temporal and spectral statistics match the perceptual criteria, the process is transparent. Some of the apparent paradoxes are resolved by considering psychoacoustic and statistical models. Moreover, there is sufficient knowledge to predict the performance of an algorithm without extensive ad hoc listening tests. The unifying theme is the question of how the human auditory system builds a sense of space.","2001","2023-07-12 07:06:56","2023-07-19 03:43:06","","867–903","","10","49","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WDZXIV8X","journalArticle","2001","Mason, Russell; Ford, Natanya; Rumsey, Francis; De Bruyn, Bart","Verbal and Nonverbal Elicitation Techniques in the Subjective Assessment of Spatial Sound Reproduction","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=10190","Current research into spatial audio has shown an increasing interest in the way subjective attributes of reproduced sound are elicited from listeners. The emphasis at present is on verbal semantics, however, studies suggest that nonverbal methods of elicitation could be beneficial. Research into the relative merits of these methods has found that nonverbal responses may result in different elicited attributes compared to verbal techniques. Nonverbal responses may be closer to the perception of the stimuli than the verbal interpretation of this perception. There is evidence that drawing is not as accurate as other nonverbal methods of elicitation when it comes to reporting the localization of auditory images. However, the advantage of drawing is its ability to describe the whole auditory space rather than a single dimension.","2001","2023-07-12 07:07:00","2023-07-19 04:29:02","","366–384","","5","49","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BPC4CDDG","journalArticle","2013","Kunka, Bartosz; Kostek, Bozena","New Aspects of Virtual Sound Source Localization Research–Impact of Visual Angle and 3-D Video Content on Sound Perception","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=16824","Human beings create an internal picture of the external work by combining the information in all their sense. For example, an image can influence the localization of a virtual sound source, called the “image proximity effect.” And, similarly, the visual presentation of someone talking can strongly influence the perception of phonemes, called the “ventriloquism effect.” This paper focuses on two other aspects related to the multimodal effect: the influence of the screen size on the observed shift of the virtual sound source, and the relationship between the observed image proximity effect and the stereoscopic depth of a 3-D object. Experimental results showed that the visual angle of the presented object determines the image proximity effect regardless of the screen size.","2013","2023-07-12 07:07:06","2023-07-19 04:16:34","","280–289","","5","61","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GNSVMPW6","journalArticle","2015","Manor, Ella; Martens, William; Marui, Atsushi; Cabrera, Densil","Nearfield Crosstalk Increases Listener Preferences for Headphone-Reproduced Stereophonic Imagery","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=17638","","2015","2023-07-12 07:07:09","2023-07-12 07:07:09","","324–335","","5","63","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FX6HJ9LE","journalArticle","1986","Wrightson, Jack","Psychoacoustic Considerations in the Design of Studio Control Rooms","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=5243","A great deal of discussion has been held concerning opotimal control room shapes and finishes, and their effect upon monitoring accuracy, localization, and illusory ambience. Design considerations based upon experimental data are described which are concerned with the perception of temporal and directional characteristics of reflected sounds. Application of these data to minitoring situations argues against the discrete, high-amplitude, laterally opposed reflections currently in vogue.","1986","2023-07-12 07:07:13","2023-07-19 10:57:05","","789–795","","10","34","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J6N4Y8AS","journalArticle","1991","Begault, Durand R.","Challenges to the Successful Implementation of 3-D Sound","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=10281","The major challenges for the successful implementation of 3-D audio systems involve minimizing reversals, intracranially heard sound, and localization error for listeners. Designers of 3-D audio systems are faced with additional challenges in data reduction and low-frequency response characteristics. The relationship of the head-related transfer function (HRTF) to these challenges is shown, along with some preliminary psychoacoustic results gathered at NASA-Ames.","1991","2023-07-12 07:07:17","2023-07-19 03:40:25","","864–870","","11","39","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ACH99GC6","journalArticle","2016","Woodcock, James; Davies, William J.; Cox, Trevor J.; Melchior, Frank","Categorization of Broadcast Audio Objects in Complex Auditory Scenes","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=18297","Because object-based audio is becoming an important framework for the representation of complex sound scenes, this research describes a series of experiments to determine a categorization framework for broadcast audio objects. Categorization is a fundamental human strategy for reducing cognitive load, and knowledge of these categories should be beneficial for the development of perceptually based representations and rendering strategies for object-based audio. In this study, 21 expert and non-expert listeners took part in a free card sorting task using audio objects from a variety of different types of program material. Hierarchical agglomerative clustering suggests that there are 7 general categories, which relate to sounds indicating actions and movement, continuous background sound, transient background sound, clear speech, non-diegetic music and effects, sounds indicating the presence of people, and prominent attention-grabbing transient sounds. A three-dimensional perceptual space calculated via multidimensional scaling suggests that these categories vary along the dimensions of semantic content, continuous-transient, and presence-absence of people. The position of an audio object along the dimensions of the perceptual space relates to its perceived importance.","2016","2023-07-12 07:07:20","2023-07-19 10:56:38","","380–394","","6","64","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PUED7ARM","journalArticle","2004","Moore, Brian C. J.; Tan, Chin-Tuan; Zacharov, Nick; Mattila, Ville-Veikko","Measuring and Predicting the Perceived Quality of Music and Speech Subjected to Combined Linear and Nonlinear Distortion","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=13034","The results of experiments in which subjects rated the perceived quality of speech and music that had been subjected to various forms of both linear and nonlinear distortion are reported. Experiment 1 made use of artificial distortions (such as ripples in frequency response combined with peak clipping). Experiment 2 included both artificial distortions and real distortions introduced by transducers. The results were compared with the predictions of a new model based on a weighted sum of predictions for linear distortion alone and for nonlinear distortion alone. There was a very good correspondence between the obtained and predicted ratings. Correlations were greater than 0.85 for speech stimuli and 0.90 for music stimuli. It is concluded that the new model can predict accurately the perceived quality of speech and music subjected to combined linear and nonlinear distortion.","2004","2023-07-12 07:07:36","2023-07-19 04:33:46","","1228–1244","","12","52","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AR6ILMSJ","journalArticle","2006","Choisel, Sylvain; Wickelmaier, Florian","Extraction of Auditory Features and Elicitation of Attributes for the Assessment of Multichannel Reproduced Sound","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=13903","The identification of relevant auditory attributes is pivotal in sound quality evaluation. Two fundamentally different psychometric methods were employed to uncover perceptually relevant auditory features of multichannel reproduced sound. In the first method, called repertory grid technique (RGT), subjects were asked to assign verbal labels directly to the features when encountering them, and to subsequently rate the sounds on the scales thus obtained. The second method, perceptual structure analysis (PSA), required the subjects to consistently use the perceptually relevant features in triadic comparisons, without having to assign them a verbal label; given sufficient consistency, a lattice representation—as frequently used in formal concept analysis (FCA)—can be derived to depict the structure of auditory features.","2006","2023-07-12 07:07:39","2023-07-19 03:48:18","","815–826","","9","54","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FFC8DI7T","journalArticle","2022","Lladó, Pedro; Mckenzie, Thomas; Meyer-Kahlen, Nils; Schlecht, Sebastian J.","Predicting Perceptual Transparency of Head-Worn Devices","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=21825","","2022","2023-07-12 07:07:43","2023-07-12 07:07:43","","585–600","","7/8","70","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UVISRXNP","journalArticle","1985","Benade, Arthur H.","From Instrument to Ear in a Room: Direct or via Recording","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=4457","The fluctuation statistics of the path between source and detector in room acoustics is reviewed along with some of the perceptual mechanisms used by the musical listener at a concert. Auditory parallel processing is important in both time and frequency domains. It is shown that the listener exploits the room statistics as a means for gaining information unavailable in a reflection-free environment. Properties of a good concert hall are examined as preparation for a discussion of the acoustical requirements of a recording studio. The record/playback process is examined, where two successive room-transmission paths and two types of sources must be dealt with by the listener. Finally, microphone placement is considered, as influenced by musical-instrument radiation patterns.","1985","2023-07-12 07:07:47","2023-07-19 03:41:31","","218–233","","4","33","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"956XITGV","journalArticle","2019","Woodcock, James; Davies, William J.; Cox, Trevor J.","Influence of Visual Stimuli on Perceptual Attributes of Spatial Audio","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=20494","","2019","2023-07-12 07:07:51","2023-07-12 07:07:51","","557–567","","7/8","67","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UUHNZLYW","journalArticle","2021","Kim, Sungyoung; Howie, Will","Influence of the Listening Environment on Recognition of Immersive Reproduction of Orchestral Music Sound Scenes","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=21533","This study investigates how a listening environment (the combination of a room's acoustics and reproduction loudspeaker) influences a listener's perception of reproduced sound fields. Three distinct listening environmentswith different reverberation times and clarity indices were compared for their perceptual characteristics. Binaural recordings were made of orchestral music, mixed for 22.2 and 2-channel audio reproduction, within each of the three listening rooms. In a subjective listening test, 48 listeners evaluate these binaural recordings in terms of overall preference and five auditory attributes: perceived width, perceived depth, spatial clarity, impression of being enveloped, and spectral fidelity. Factor analyses of these five attribute ratings show that listener perception of the reproduced sound fields focused on two salient factors, spatial and spectral fidelity, yet the attributes' weightings in those two factors differs depending on a listener's previous experience with audio production and 3D immersive audio listening. For the experienced group, the impression of being enveloped was the most salient attribute, with spectral fidelity being the most important for the non-experienced group.","2021","2023-07-12 07:07:53","2023-07-19 04:11:44","","834–848","","11","69","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TCPLDPTJ","journalArticle","2004","Härmä, Aki; Jakka, Julia; Tikander, Miikka; Karjalainen, Matti; Lokki, Tapio; Hiipakka, Jarmo; Lorho, Gaëtan","Augmented Reality Audio for Mobile and Wearable Appliances","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=13010","The concept of augmented reality audio characterizes techniques where a real sound environment is extended with virtual auditory environments and communications scenarios. A framework is introduced for mobile augmented reality audio (MARA) based on a specific headset configuration where binaural microphone elements are integrated into stereo earphones. When microphone signals are routed directly to the earphones, a user is exposed to a pseudoacoustic representation of the real environment. Virtual sound events are then mixed with microphone signals to produce a hybrid, an augmented reality audio representation, for the user. An overview of related technology, literature, and application scenarios is provided. Listening test results with a prototype system show that the proposed system has interesting properties. For example, in some cases listeners found it very difficult to determine which sound sources in an augmented reality audio representation are real and which are virtual.","2004","2023-07-12 07:07:56","2023-07-19 04:03:47","","618–639","","6","52","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q764BVEW","journalArticle","2012","Terasawa, Hiroko; Berger, Jonathan; Makino, Shoji","In Search of a Perceptual Metric for Timbre: Dissimilarity Judgments among Synthetic Sounds with MFCC-Derived Spectral Envelopes","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=16372","","2012","2023-07-12 07:08:00","2023-07-12 07:08:00","","674–685","","9","60","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SAG32NAM","journalArticle","2014","Merchel, Sebastian; Altinsoy, M. Ercan","The Influence of Vibrations on Musical Experience","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=17134","","2014","2023-07-12 07:08:03","2023-07-12 07:08:03","","220–234","","4","62","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"URX8AR4Y","journalArticle","2001","Wun, Cheuk-Wai; Horner, Andrew","Perceptual Wavetable Matching for Synthesis of Musical Instrument Tones","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=10195","Recent parameter matching methods for multiple wavetable synthesis have used a simple relative spectral error formula to measure how accurately the synthetic spectrum matches an original spectrum. It is supposed that the smaller the spectral error, the better the match, but this is not always true. A modified error formula is described, which takes into account the masking characteristics of our auditory system, as an improved measure of the perceived quality of the matched spectrum. Selected instrument tones have been matched using both error formulas and resynthesized. Listening test results show that wavetable matching using the perceptual error formula slightly outperforms ordinary matching, especially for instrument tones that have several masked partials.","2001","2023-07-12 07:08:07","2023-07-19 10:57:41","","250–262","","4","49","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UR9K342V","journalArticle","1964","Clark, Melville, Jr.; Milner, Paul","Dependence of Timbre on the Tonal Loudness Produced by Musical Instruments","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=764","To determine if the timbre of nonpercussive musical instruments are dependent upon the intensities with which they are played, musically competent subjects were asked to identify the various original dynamic markings with which the instruments were played from tones equalized in loudness by adjustment of the gain upon reproduction. Confusion matrices display the results. The timbre of nonpercussive musical instruments is, at most, a weak function of the intensity with which they are played, with a few exceptions.","1964","2023-07-12 07:08:10","2023-07-19 03:48:45","","28–31","","1","12","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4Z888DJ4","journalArticle","2012","Barrass, Stephen","Digital Fabrication of Acoustic Sonifications","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=16375","Because the human brain is often optimal for detecting subtle patterns, this paper explores a novel transformation that maps numerical data into sound. In this research, a set of data taken from head-related transfer functions was used to create physical objects (bells made from stainless steel) whose acoustics were then presented to listeners. The technique is called acoustic sonification. Listeners were able to hear differences in pitch and timbre of bells that were constructed from different datasets, while bells constructed from similar datasets sounded similar. Modulating the shape of a bell with a dataset can influence the acoustic spectrum in a way that results in audible differences |even though there was no apparent visual difference. Acoustic sonification can take advantage of auditory pattern recognition.","2012","2023-07-12 07:08:13","2023-07-19 03:38:58","","709–715","","9","60","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DKY79PHV","journalArticle","2004","Rao, Preeti; Shandilya, Saurabh","On the Detection of Melodic Pitch in a Percussive Background","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=12999","The extraction of pitch (or fundamental frequency) information from polyphonic audio signals remains a challenging problem. The specific case of detecting the pitch of a melodic instrument playing in a percussive background is presented. Time-domain pitch detection algorithms based on a temporal autocorrelation model, including the Meddis-Hewitt algorithm, are considered. The temporal and spectral characteristics of percussive interference degrade the performance of the pitch detection algorithms to various extents. From an experimental study of the pitch estimation errors obtained on a set of synthetic musical signals, the effectiveness of the auditory-perception-based modules of the Meddis-Hewitt pitch detection algorithm in improving the robustness of fundamental frequency tracking in the presence of percussive interference is discussed.","2004","2023-07-12 07:08:18","2023-07-19 04:40:10","","378–390","","4","52","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MRUMB8RI","journalArticle","2019","Geronazzo, Michele; Peruch, Enrico; Prandoni, Fabio; Avanzini, Federico","Applying a Single-Notch Metric to Image-Guided Head-Related Transfer Function Selection for Improved Vertical Localization","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=20483","This paper describes an image-guided HRTF selection procedure that exploits the relation between features of the pinna shape and HRTF notches. Using a 2D image of a user’s pinna, the procedure selects from a database the HRTF set that best fits the anthropometry of that user. The proposed procedure is designed to be quickly applied and easy to use for a user without previous knowledge of binaural audio technologies. The entire process is evaluated by means of an auditory model for sound localization in the mid-sagittal plane available from previous literature and a short localization test in virtual reality. Using both virtual and real subjects from a HRTF database, predictions and the experimental evaluation aimed to assess the vertical localization performance with HRTF sets are selected by the proposed procedure. The results report a statistically significant improvement in predictions of the auditory model for localization performance with selected HRTFs compared to KEMAR HRTFs.","2019","2023-07-12 07:08:25","2023-07-19 04:02:23","","414–428","","6","67","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TYPMVK72","journalArticle","2012","Schönstein, David; Katz, Brian F.G.","Variability in Perceptual Evaluation of HRTFs","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=16552","","2012","2023-07-12 07:08:34","2023-07-12 07:08:34","","783–793","","10","60","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4HWPJG7S","journalArticle","2001","Papaodysseus, Constantin; Roussopoulos, George; Fragoulis, Dimitrios; Panagopoulos, Athanasios; Alexiou, Constantin","A New Approach to the Automatic Recognition of Musical Recordings","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=10203","A new methodology for the automatic recognition of musical recordings is presented. A system has been developed that performs recognition among a set of specific musical recordings. The system claims a high rate of success (greater than 86%), even when the unknown compositions have suffered from up to a medium degree of distortion. It comprises a database of musical characteristics that correspond to a set of model musical recordings. These characteristics are derived by applying novel feature extraction algorithms to every model musical recording selected. In order to determine whether an unknown musical recording corresponds to a piece represented in the database, the same feature extraction algorithm is applied to it, and the characteristics thus derived are compared to the database contents by means of a set of criteria. The system can operate in parallel, essentially in real time, even for a considerable number of model musical recordings, as long as the hardware necessary is available.","2001","2023-07-12 07:09:25","2023-07-19 04:36:51","","23–35","","1/2","49","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6J38C3H7","journalArticle","2015","McGregor, Iain Peter; Cunningham, Stuart","Comparative Evaluation of Radio and Audio Logo Sound Designs","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=18048","This study aims to explore the suitability of capturing designers’ and listeners’ experiences of sound design for a radio drama and audio logos using the repertory grid technique, which is a proven method of information elicitation based on Personal Construct Theory. Sound designs that incorporate sound effects, music, or dialogue can be broken down into discrete sound events that can then be rated using attributes that are meaningful to both designers and listeners. A method for evaluating sound without training casual listeners and without depending on expert listeners is presented. A number of the constructs show strong matches between the sound’s designers and listeners, indicating that these constructs have value as a common vocabulary and can be used to mediate and articulate audio features between the two.","2015","2023-07-12 07:09:28","2023-07-19 04:29:53","","876–888","","11","63","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M549R4UK","journalArticle","2015","Karandreas, Alex; Christensen, Flemming","Influence of Visual Appearance on Loudspeaker Sound Quality Evaluation","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=17872","","2015","2023-07-12 07:09:31","2023-07-12 07:09:31","","684–697","","9","63","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J8BI7U9W","journalArticle","2018","Stolfi, Ariane; Sokolovskis, Janis; Goródscy, Fábio; Iazzetta, Fernando; Barthet, Mathieu","Audio Semantics: Online Chat Communication in Open Band Participatory Music Performances","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=19868","Technology-mediated audience participation is an emergent topic in creative music technology with a blurred distinction between audience and performers. This paper analyzes communication patterns occurring in the online chat of the Open Band system for participatory live music performance. In addition to acting as a multi-user messaging tool, the chat system also serves as a control interface for the sonification of textual messages from the audience. Open Band performances have been presented at various festivals and conferences since 2016. Its web-based platform enables collective “sound dialogues” that are opened to everyone regardless of musical skills. Drawing on interactive participatory art and networked music performance, the system aims to provide engaging social experiences in colocated music-making situations. The authors collected data from four public performances including over 3,000 anonymous messages sent by audiences. After presenting the design of the system, the authors analyzed the semantic content of messages using thematic and statistical methods. Findings show how different sonification mechanisms alter the nature of the communication between participants who articulate both linguistic and musical self-expression. One of the design goals was to provide a platform for free audience expression as a web “agora.” The various themes that emerged from the analyses endorse this idea, as participants felt free to discuss subjects ranging from love to political opinions.","2018","2023-07-12 07:09:35","2023-07-19 04:49:44","","910–921","","11","66","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TKBB6E6I","journalArticle","2023","Dupré, Théophile; Denjean, Sébastien; Aramaki, Mitsuko; Kronland-Martinet, Richard","Spatial Integration of Dynamic Auditory Feedback in Electric Vehicle Interior","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=22142","","2023","2023-07-12 07:09:39","2023-07-12 07:09:39","","349–362","","6","71","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CX22LM96","journalArticle","2020","Kritsis, Kosmas; Garoufis, Christos; Zlatintsi, Athanasia; Bouillon, Manuel; Acosta, Carlos; Martín-Albo, Daniel; Piechaud, Robert; Maragos, Petros; Katsouros, Vassilis","iMuSciCA Workbench: Web-based Music Activities For Science Education","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=20990","This paper presents the iMuSciCA Workbench, developed to address secondary school students with the aim to support mastery of core academic content on Science, Technology, Engineering, Arts, and Mathematics (STEAM) subjects, along with the development of creativity and deeper learning skills through the students' participation in music activities. Herein, we focus on the technical implementation of the innovative music-related web environments hosted by the iMuSciCA Workbench.","2020","2023-07-12 07:09:43","2023-07-19 04:16:17","","738–746","","10","68","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RS3ZP9MY","journalArticle","2023","Cairns, Patrick; Hunt, Anthony; Johnston, Daniel; Cooper, Jacob; Lee, Ben; Daffern, Helena; Kearney, Gavin","Evaluation of Metaverse Music Performance With BBC Maida Vale Recording Studios","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=22139","This paper details a case study evaluation of a recording experience in a networked XR simulation of the renowned BBC Maida Vale Recording Studios. The system allows multiple remote musicians to connect over a network, providing a shared virtual acoustic space, with interactive immersive audio, XR display, and low-latency throughput. A four-piece rock band used this system in a live recording session, performing under different latency and audio conditions. Technical setup and case study protocol is detailed. Evaluation is provided in the form of Quality of Experience rating, tempo analysis, and a semi-structured exit interview.","2023","2023-07-12 07:09:46","2023-07-19 03:46:55","","313–325","","6","71","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3BVYC2QU","journalArticle","2022","Allan, Jon; Leijonhufvud, Susanna","Listener Preferences in Streamed Music","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=21557","","2022","2023-07-12 07:09:49","2023-07-12 07:09:49","","156–176","","3","70","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BPKURE35","journalArticle","2021","Cairns, Patrick; Daffern, Helena; Kearney, Gavin","Parametric Evaluation of Ensemble Vocal Performance Using an Immersive Network Music Performance Audio System","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=21541","","2021","2023-07-12 07:09:52","2023-07-12 07:09:52","","924–933","","12","69","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K59SGNAG","journalArticle","2016","Rummukainen, Olli; Romblom, David; Guastavino, Catherine","Diffuse Field Modeling Using Physically-Inspired Decorrelation Filters and B-Format Microphones: Part II Evaluation","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=18128","","2016","2023-07-12 07:09:56","2023-07-12 07:09:56","","194–207","","4","64","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EAUY3GBA","journalArticle","2017","Yu, Shiwei; Zhang, Hongjuan; Duan, Zhiyao","Singing Voice Separation by Low-Rank and Sparse Spectrogram Decomposition with Prelearned Dictionaries","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=18731","Although the human auditory system can easily distinguish the singing voice from the background music in a music recording, it is extremely difficult for computer systems to replicate this ability, especially when the music mixture is a single channel. The challenge arises from the variety of simultaneous sound sources as well from the rich pitch and timbre variations of a singing voice. Unsupervised spectrogram decomposition involves separating the mixture spectrogram into a sparse spectrogram for the singing voice and a low-rank spectrogram for the background music. This approach has two limitations: the unsupervised nature prevents the prelearning of voice and background in music dictionaries; some components of the singing voice and background music may not show the preferred sparse and low-rank properties. In contrast, the authors propose to decompose the mixture spectrogram into three parts: a sparse spectrogram representing the singing voice, a low-rank spectrogram representing the background music, and a residual spectrogram for the components that are not identified by either the sparse or the low-rank spectrogram. Universal dictionaries for the singing voice and background music are prelearned from isolated singing voice and background music training data, through which prior knowledge of the voice and background music is introduced to the separation process. Evaluations on two datasets show that the proposed method is effective and efficient for both the separated singing voice and music accompaniment at various voice-to-music ratios.","2017","2023-07-12 07:10:00","2023-07-19 10:58:50","","377–388","","5","65","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DZNS6HLD","journalArticle","2000","Shlien, Seymour","Auditory Models for Gifted Listeners","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=12038","Some listeners are especially sensitive to minute codec quantization noise. Various psychoacoustic tests were performed in order to measure the characteristics of these listeners. Though the auditory filter bandwidths of these listeners appeared to be normal, some had unusual abilities to detect weak signals buried in noise.","2000","2023-07-12 07:10:03","2023-07-19 04:48:07","","1032–1044","","11","48","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RLW7HX2H","journalArticle","2018","Cuadrado, Francisco","Touch the Sound: Design and Development of a Tangible System for Sound Experimentation","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=19587","","2018","2023-07-12 07:10:06","2023-07-12 07:10:06","","478–485","","6","66","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TKLMTK7J","journalArticle","2020","Çakmak, Cem; Hamilton, Rob","od: Composing Spatial Multimedia for the Web","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=20991","","2020","2023-07-12 07:10:09","2023-07-12 07:10:09","","747–755","","10","68","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JTKRITAV","journalArticle","1961","McCoy, Donald S.","Distortion of Auditory Perspective Produced by Interchannel Mixing at High and Low Audio Frequencies","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=488","This paper describes an attempt to determine by subjective test, the nature and degree of distortium of auditory perspective produced when L-R or difference information of the two stereo channels is attenuated at either high or low audio frequencies.","1961","2023-07-12 07:10:13","2023-07-19 04:29:37","","13–18","","1","9","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NK9V4IT8","journalArticle","2017","Zhang, Mingfeng; Lu, Hengwei; Ren, Gang; Smith, Sarah; Beauchamp, James; Bocko, Mark F","A Matlab-Based Signal Processing Toolbox for the Characterization and Analysis of Musical Vibrato","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=18734","To assess and manipulate the vibrato in musical sounds, audio engineers either informally listen to the audio or visually inspect waveform envelopes or spectrographic representations. Unfortunately, detailed descriptions of the amplitude and frequency trajectories of harmonic partials are difficult to infer from audio spectrograms, which means quantitative information is limited. This paper describes a collection of signal processing methods and a toolbox for extracting and analyzing vibrato-related parameters from solo audio recordings. The Vibrato Analysis Toolbox (VAT) uses a method based on the Hilbert transform to extract the amplitude and frequency variations as feature tracks. A parameterization algorithm then extracts various descriptive parameters including vibrato depth, frequency, spectral centroid, relative amplitude-frequency modulation phase and time delay, and other relationships based on the vibrato tracks. Together, these parameters provide a quantitative characterization of vibrato. The VAT also provides visualization and resynthesis functions that enable users to interactively explore many musical features. Algorithms are written in the Matlab programming language for easy adaptation, enabling further development by researchers and developers. Applications include music performance pedagogy, musicological studies, music production, and voice analysis.","2017","2023-07-12 07:10:16","2023-07-19 10:59:14","","408–422","","5","65","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WDCI7QV9","journalArticle","2023","Anemüller, Carlotta; Adami, Alexander; Herre, Jürgen","Efficient Binaural Rendering of Spatially Extended Sound Sources","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=22131","In virtual/augmented reality or 3D applications with binaural audio, it is often desired to render sound sources with a certain spatial extent in a realistic way. A common approach is to distribute multiple correlated or decorrelated point sources over the desired spatial extent range, possibly derived from the original source signal by applying suitable decorrelation filters. Based on this basic model, a novel method for efficient and realistic binaural rendering of spatially extended sound sources is proposed. Instead of rendering each point source individually, the target auditory cues are synthesized directly from just two decorrelated input signals. This procedure comes with the advantage of low computational complexity and relaxed requirements for decorrelation filters. An objective evaluation shows that the proposed method matches the basic rendering model well in terms of perceptually relevant objective metrics. A subjective listening test shows, furthermore, that the output of the proposed method is perceptually almost identical to the output of the basic rendering model. The technique is part of the Reference Model architecture of the upcoming MPEG-I Immersive Audio standard.","2023","2023-07-12 07:10:19","2023-07-19 03:36:52","","281–292","","5","71","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6SBN9CZX","journalArticle","2001","Czerwinski, Eugene; Voishvillo, Alexander; Alexandrov, Sergei; Terekhov, Alexander","Multitone Testing of Sound System Components'Some Results and Conclusions, Part 1: History and Theory","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=10174","An historical retrospective analysis of the measurement of nonlinearities in audio is carried out. A quantitative analysis of the responses of various nonlinear systems (theoretical and experimental) to a multitone signal is made, and multitone testing is compared to conventional harmonic and intermodulation measurements. The multitone test provides more accurate information about the behavior of nonlinear systems when compared to standard harmonic, two-tone intermodulation, and total harmonic distortion measurements. Modeling of the nonlinear reaction of various sound system components to a multitone signal is described.","2001","2023-07-12 07:10:23","2023-07-19 03:50:54","","1011–1048","","11","49","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5NSHNF4Z","journalArticle","2012","Mendonça, Catarina; Campos, Guilherme; Dias, Paulo; Vieira, José; Ferreira, João P.; Santos, Jorge A.","On the Improvement of Localization Accuracy with Non-Individualized HRTF-Based Sounds","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=16555","Even though individual head-related transfer function (HRTF) filters produce better performance in virtual-reality environments, measuring individuals is labor intensive and expensive. Can training be used to enhance the performance of generic filters? This research shows that short training sessions with feedback allows for perceptual adaptation where simple exposure to generic HRTF filters did not. The benefits of training were observed not only for the trained sounds but also for other stimulus positions that were not part of the training. Apparently, subjects were actually adapting and generalizing to the generic HRTF filters, which is a manifestation of sensory neural plasticity. Learning profiles are unique to individuals. Any testing of localization performance should recognize the influence of training.","2012","2023-07-12 07:10:26","2023-07-19 04:30:34","","821–830","","10","60","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NV8FX9B7","journalArticle","2014","Pihlajamäki, Tapani; Santala, Olli; Pulkki, Ville","Synthesis of Spatially Extended Virtual Source with Time-Frequency Decomposition of Mono Signals","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=17339","","2014","2023-07-12 07:10:29","2023-07-12 07:10:29","","467–484","","7/8","62","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VATRESTS","journalArticle","2020","Vowels, M.J.; Mason, R.","Comparison of Pairwise Dissimilarity and Projective Mapping Tasks With Auditory Stimuli","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=20895","Two methods for undertaking subjective evaluation were compared: a pairwise dissimilarity task (PDT) and a projective mapping task (PMT). For a set of unambiguous, synthetic, auditory stimuli, the aim was to determine the following: whether the PMT limits the recovered dimensionality to two dimensions; how subjects respond using PMT’s two-dimensional response format; the relative time required for PDT and PMT; and hence, whether PMT is an appropriate alternative to PDT for experiments involving auditory stimuli. The results of both Multi-Dimensional Scaling (MDS) analyses and Multiple Factor Analyses (MFA) indicate that, with multiple participants, PMT allows for the recovery of three meaningful dimensions. The results from the MDS and MFA analyses of the PDT data, on the other hand, were ambiguous and did not enable recovery of more than two meaningful dimensions. This result was unexpected given that PDT is generally considered not to limit the dimensionality that can be recovered. Participants took less time to complete the experiment using PMT compared to PDT (a median ratio of approximately 1:4), and employed a range of strategies to express three perceptual dimensions using PMT’s two-dimensional response format. PMT may provide a viable and efficient means to elicit up to 3-dimensional responses from listeners.","2020","2023-07-12 07:10:48","2023-07-19 10:53:47","","638–648","","9","68","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CXDLSYTM","journalArticle","1983","Shepard, Roger N.","Demonstrations of Circular Components of Pitch","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=4555","Pitch is usually thought of as a one-dimensional psychological attribute corresponding to the one-dimensional physical variable of frequency. However, complex tones can be continuously varied between pitches along at least three different dimensions: (1) a rectilinear dimension of height, (2) a circular dimension of chroma, and (3) a second circular dimension of musical fifths. Accompanying sound demonstrations illustrate each of these three variations-including illusions in which a tone that is cyclically shifted around the chroma circle seems to go ever higher in pitch, and in which a tone that is simultaneously shifted in opposite directions in height and chroma seems always to be rising in pitch but is clearly lower at the end than at the beginning.","1983","2023-07-12 07:10:52","2023-07-19 04:47:31","","641–649","","9","31","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3XDX6CGU","journalArticle","2021","Yeoward, Christopher; Shukla, Rishi; Stewart, Rebecca; Sandler, Mark; Reiss, Joshua D.","Real-Time Binaural Room Modelling for Augmented Reality Applications","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=21532","","2021","2023-07-12 07:10:55","2023-07-12 07:10:55","","818–833","","11","69","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LPPJHR73","journalArticle","2013","Sunder, Kaushik; Tan, Ee-Leng; Gan, Woon-Seng","Individualization of Binaural Synthesis Using Frontal Projection Headphones","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=17076","Non-individualized head related transfer functions (HRTF) limit the spatial accuracy of conventional side projection headphones. This research explores the use of a frontal projection headphone, which customizes the HRTF by introducing idiosyncratic pinna cues. In addition, a robust headphone equalization technique is recommended for frontal projection headphone playback to preserve the embedded personal pinna cues. Perceptual experiments validated the effectiveness of frontal headphone playback over the conventional headphones with reduced front-back confusions and improved frontal localization. It was also observed that the individual spectral cues created by the frontal projection are sufficient for front-back discrimination even with the high frequency pinna cues removed from the non-individual HRTF.","2013","2023-07-12 07:10:59","2023-07-19 04:50:57","","989–1000","","12","61","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9MN4224U","journalArticle","1969","Lebo, Charles P.; Oliphant, Kenward P.","Music as a Source of Acoustic Trauma","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=1556","Earlier investigations reported by the authors generated considerable interest and comment. One comment, though hardly the most significant, offered a unique challenge -The Desire to Know.- The comment simply stated questioned the right to single out rock & roll as the sole musical cause for acoustic TRAUMA-and many further stated -live symphony music is equally severe.- The reader is invited to verify the findings contained in the paper presented herein.","1969","2023-07-12 07:11:02","2023-07-19 04:17:58","","535–538","","5","17","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A8WD2P36","journalArticle","2023","Klein, Florian; Surdu, Tatiana; Treybig, Lukas; Werner, Stephan","The Ability to Memorize Acoustic Features in a Discrimination Task","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=22129","How humans perceive, recognize, and remember room acoustics is of particular interest in the domain of spatial audio. For the creation of virtual or augmented acoustic environments, a room acoustic impression matches the expectations of certain room classes or a specific room. These expectations are based on the auditory memory of the acoustic room impression. In this paper, the authors present an exploratory study to evaluate the ability of listeners to recognize room acoustic features. The task of the listeners was to detect the reference room in a modified ABX double-blind stimulus test that featured a pre-defined playback order and a fixed time schedule. Furthermore, the authors explored distraction effects by employing additional nonacoustic interferences. The results show a significant decrease of the auditory memory capacity within 10 s, which is more pronounced when the listeners were distracted. However, the results suggest that auditory memory depends on what auditory cues are available.","2023","2023-07-12 07:11:05","2023-07-19 04:12:40","","254–266","","5","71","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BLMYSFB8","journalArticle","2017","Ronan, Malachy; Ward, Nicholas; Sazdov, Robert; Lee, Hyunkook","The Perception of Hyper-Compression by Mastering Engineers","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=19176","","2017","2023-07-12 07:11:08","2023-07-12 07:11:08","","613–621","","7/8","65","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WIABIGEX","journalArticle","2022","Compton, Stephen","Managing the Live-Sound Audio Engineer's Most Essential Critical Listening Tool","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=21567","Critical listening is the live-sound audio engineer's most essential tool for informed sonic assessment. In producing a cohesive mix that fulfills an event's aims, audio engineers affect the experience and well-being of all live-sound participants. This study compares the results from a 2020 international audio engineer survey with published research. The findings demonstrate that although in theory, engineers recognize their hearing as being their most essential critical listening tool, in practice, many have not foundways to manage their hearing and optimize their assessment ability effectively. Many engineers with impeded or impaired hearing continue to mix, believing that any negative impact on participants is minimal or nonexistent. The livesound experience and participant health and well-being are improved by promoting and acting on appropriate hearing management practices.","2022","2023-07-12 07:11:14","2023-07-19 03:49:22","","305–318","","4","70","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BSPEJYDD","journalArticle","2015","Francombe, Jon; Mason, Russell; Dewhirst, Martin; Bech, Søren","A Model of Distraction in an Audio-on-Audio Interference Situation with Music Program Material","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=17567","There are many situations in which multiple audio programs are replayed over loudspeakers in the same acoustic environment, allowing listeners to focus on their desired target program. Where this situation is deliberately created and the different program items are centrally controlled, each listener can be viewed as having a personal sound zone system. In order to evaluate and optimize such situations in a perceptually relevant manner, the authors created a predictive model using the features that contribute to the distraction from unwanted sounds. Feature extraction was motivated by a qualitative analysis of subject responses. Distraction ratings were collected for one hundred randomly created audio-on-audio interference situations with music target and interferer programs. The selected features were related to the overall loudness, loudness ratio, perceptual evaluation of audio source separation, and frequency content of the interferer. The model was found to predict accurately for the training and validation datasets.","2015","2023-07-12 07:11:18","2023-07-19 04:00:36","","63–77","","1/2","63","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"REHVZ3RD","journalArticle","2019","McGinnity, Siobhan; Mulder, Johannes; Beach, Elizabeth Francis; Cowan, Robert","Management of Sound Levels in Live Music Venues","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=20710","","2019","2023-07-12 07:11:21","2023-07-12 07:11:21","","972–985","","12","67","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4942REJY","journalArticle","1979","Cabot, Richard C.; Genter II, C. Roy; Lucke, Thomas","Sound Levels and Spectra of Rock Music","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=3211","The results of a survey of the sound levels encountered by attendees of rock-music entertainment are presented. Recordings were made at several discotheques, nightclubs, and band parties. These recordings were later analyzed for overall sound levels, octave-band levels, and peak-to-average level ratios. Perceived noise level, composite damage risk, and A-, B-, C-, and D-weighted levels were calculated from octave-band levels by means of a special FORTRAN program. Comparisons are made of the variations in levels over an evening, from evening to evening, and from location to location.","1979","2023-07-12 07:11:25","2023-07-19 03:46:23","","267–284","","4","27","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RLAVAGXW","journalArticle","2021","Hupke, Robert; Nophut, Marcel; Preihs, Stephan; Peissig, Jürgen","Toward Professional Distributed Performances: Effects of a Global Metronome on Networked Musical Ensemble Interactions","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=21467","","2021","2023-07-12 07:11:28","2023-07-12 07:11:28","","720–736","","10","69","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YCW4YX6H","journalArticle","2020","Keyes, Christopher J.; Tan, Alfred","Design and Evaluation of a Spectral Phase Rotation Algorithm for Upmixing to 3D Audio","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=20999","This paper details the design and evaluation of a novel frequency-domain digital signal processing algorithm intended for upmixing of previously recorded audio to larger 3D loudspeaker arrays either by itself or in combinationwith other upmixing techniques. The algorithm attempts to mimic the dynamic and complex phase variances experienced by listeners in concerts of acoustic music. Critical listening evaluations support the algorithm’s effectiveness in increasing the perceived spaciousness and liveliness and show a significant preference for its use.","2020","2023-07-12 07:11:32","2023-07-19 04:10:48","","856–864","","11","68","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3AKEKGNX","journalArticle","2022","Fyfe, Lawrence; Bedoya, Daniel; Chew, Elaine","Annotation and Analysis of Recorded Piano Performances on the Web","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=22020","Advancing knowledge and understanding about performed music is hampered by a lack of annotation data for music expressivity. To enable large-scale collection of annotations and explorations of performed music, the authors have created a workflow that is enabled by CosmoNote, aWeb-based citizen science tool for annotating musical structures created by the performer and experienced by the listener during expressive piano performances. To enable annotation tasks with CosmoNote, annotators can listen to the recorded performances and view synchronized music visualization layers including the audio waveform, recorded notes, extracted audio features such as loudness and tempo, and score features such as harmonic tension. Annotators have the ability to zoom into specific parts of a performance and see visuals and listen to the audio from just that part. The annotation of performed musical structures is done by using boundaries of varying strengths, regions, comments, and note groups. By analyzing the annotations collected with CosmoNote, performance decisions will be able to be modeled and analyzed in order to aid in the understanding of expressive choices in musical performances and discover the vocabulary of performed musical structures.","2022","2023-07-12 07:11:35","2023-07-19 04:01:02","","962–978","","11","70","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GEEXEKYS","journalArticle","2020","Hansen, Brian; Burchett, Joseph N.; Forbes, Angus G.","Quasar Spectroscopy Sound: Analyzing Intergalactic and Circumgalactic Media via Data Sonification","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=21000","","2020","2023-07-12 07:11:38","2023-07-12 07:11:38","","865–875","","11","68","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NSA7VCLL","journalArticle","1987","Fielder, Louis D.","Evaluation of the Audible Distortion and Noise Produced by Digital Audio Converters","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=5193","A quantitative measurement technique to evaluate audible impairments caused by the noise and distortion of digital audio conversion systems is discussed and is shown to correlate well with subjective impression. Performance at low, medium, and high signal levels is examined using the auditory critical-band concept, signal masking, environmental noise making, and hearing acuity. The technique applies sine-wave signals and divides the output spectrum into auditory critical bands, which are used to determine the audibility of the noise and distortion products.","1987","2023-07-12 07:11:41","2023-07-19 03:57:46","","517–535","","7/8","35","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7ZMVQ4XU","journalArticle","2019","Su, Hengwei; Marui, Atsushi; Kamekawa, Toru","The Auditory Source Widening Effect in Binaural Synthesis with Spatial Distribution of Frequency Bands","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=20545","","2019","2023-07-12 07:11:44","2023-07-12 07:11:44","","691–704","","9","67","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HKCCT62D","journalArticle","2019","Breebaart, Jeroen; Cengarle, Giulio; Lu, Lie; Mateos, Toni; Purnhagen, Heiko; Tsingos, Nicolas","Spatial Coding of Complex Object-Based Program Material","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=20487","Object-based audio (OBA) program material is challenging to distribute over low bandwidth channels and costly to render for thin clients. This research proposes a dynamic object-grouping solution that can represent a complex object-based scene as an equivalent reduced set of object groups while maintaining perceptually transparent rendering quality. This solution is a type of spatial coding. This paper introduces a real-time greedy simplification technique that addresses limitations of previous approaches by modeling spatial release from masking and distributing input objects into to multiple output groups. The core algorithm is extended to preserve other types of artistic metadata beyond object position. Results of perceptual tests show that this solution can achieve a 10:1 reduction in object count while maintaining high-quality audio playback and rendering flexibility at the endpoint. Spatial coding does not require perceptual coding of the objects’ audio essence but can be further combined with audio coding tools to deliver OBA content at low bit rates. This makes spatial coding a key component of an OBA production and distribution workflow. Object-based content creation, distribution, and rendering workflows require novel methods to process, combine, encode, and simplify complex auditory scenes to allow end-point rendering flexibility, efficiency, and adaptability as well as the means to cater for personalized experiences.","2019","2023-07-12 07:11:47","2023-07-19 03:44:42","","486–497","","7/8","67","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S5RA7GKF","journalArticle","2013","Bank, Balázs","Audio Equalization with Fixed-Pole Parallel Filters: An Efficient Alternative to Complex Smoothing","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=16666","A common method for displaying, modeling, and equalizing the frequency response of audio systems is to use smoothing to eliminate the raggedness of the response. Fixed-pole parallel filters, which produce modest computational loading for both signal filtering and parameter estimation, possess the beneficial properties of smoothing. This makes them an efficient method for modeling or equalizing audio systems. The resolution of smoothing is controlled by the choice of pole frequencies: for obtaining a smoothing with 1/ß-octave resolution, ß/2 pole pairs are placed in each octave (e.g., sixth-octave resolution is achieved by having three pole pairs per octave). In addition, an analysis shows the theoretical equivalence of parallel filters and Kautz filters; the formulas for converting the parameters of the two types of filter are given.","2013","2023-07-12 07:11:57","2023-07-19 03:38:31","","39–49","","1/2","61","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4X77APEE","journalArticle","2018","Burloiu, Grigore; Mihai, Valentin; Damian, Stefan","Layered Motion and Gesture Sonification in an Interactive Installation","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=19860","","2018","2023-07-12 07:12:00","2023-07-12 07:12:00","","770–778","","10","66","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GV3IEPE5","journalArticle","2019","Heilemann, Michael C.; Anderson, David A.; Bocko, Mark F.","Near-Field Object-Based Audio Rendering on Flat-Panel Displays","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=20491","","2019","2023-07-12 07:12:03","2023-07-12 07:12:03","","531–539","","7/8","67","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KJWU78D5","journalArticle","2022","Lindetorp, Hans; Falkenberg, Kjetil","Evaluating Web Audio for Learning, Accessibility, and Distribution","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=22019","Web Audio has a great potential for interactive audio content in which an open standard and easy integration with other web-based tools makes it particularly interesting. From earlier studies, obstacles for students to materialize creative ideas through programming were identified; focus shifted from artistic ambition to solving technical issues. This study builds upon 20 years of experience from teaching sound and music computing and evaluates howWeb Audio contributes to the learning experience. Data was collected from different student projects through analysis of source code, reflective texts, group discussions, and online self-evaluation forms. The result indicates that Web Audio serves well as a learning platform and that an XML abstraction of the API helped the students to stay focused on the artistic output. It is also concluded that an online tool can reduce the time for getting started with Web Audio to less than 1 h. Although many obstacles have been successfully removed, the authors argue that there is still a great potential for new online tools targeting audio application development in which the accessibility and sharing features contribute to an even better learning experience.","2022","2023-07-12 07:12:12","2023-07-19 04:20:34","","951–961","","11","70","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V7CAM8Q8","journalArticle","2020","Kim, Chungeun; Lim, Veranika; Picinali, Lorenzo","Investigation Into Consistency of Subjective and Objective Perceptual Selection of Non-individual Head-Related Transfer Functions","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=20996","","2020","2023-07-12 07:12:15","2023-07-12 07:12:15","","819–831","","11","68","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QSU9ZFU3","journalArticle","2018","Wierstorf, Hagen; Hold, Christoph; Raake, Alexander","Listener Preference for Wave Field Synthesis, Stereophony, and Different Mixes in Popular Music","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=19568","The mixing engineer and the reproduction system both influence the perception of a song by a listener. For unfamiliar music, the mix can significantly influence listener preferences. The goal of this research was to investigate the influence of the reproduction systems and mixing parameters by asking listeners for preference ratings in a paired comparison test. The study generated mixes of four different popular music recordings and introduced systematic changes to the wave field synthesis mix for one song. The mixing parameters were EQ, compression, reverb, and spatial positioning. Listeners rated their preference by comparing two channels with five channel stereophony and wave field synthesis using a circular array of 56 loudspeakers. Even when introducing relatively strong changes to the wave field synthesis mix, listeners still preferred that system most of the time. This preference was dependent on the actual content and might vary between different songs, or even song excerpts. The mixing condition disliked the most by listeners was a very wide arrangement of the foreground elements of popular music, such as vocals, snare and bass drum, and guitars. Overall, using a high number of loudspeakers is preferred by most listeners, and the differences between reproduction methods can have a larger influence than strong variations of single mixing parameters.","2018","2023-07-12 07:12:20","2023-07-19 10:55:35","","385–396","","5","66","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3BCW8XLW","journalArticle","2020","Liew, Kongmeng; Lindborg, PerMagnus","A Sonification of Cross-Cultural Differences in Happiness-Related Tweets","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=20715","Sonification can be defined as any technique that translates data into non-speech sound with a systematic, describable, and reproducible method, in order to reveal or facilitate communication, interpretation, or discovery of meaning that is latent in the data. This paper describes an approach for communicating cross-cultural differences in sentiment data through sonification, which is a powerful technique for the translation of patterns into sounds that are understandable, accessible, and musically pleasant. A machine-learning classifier was trained on sentiment information of two samples of Tweets from Singapore and New York with the keyword of ""happiness."" Positive-valence words that relate to the concept of happiness showed stronger influences on the classifier than negative words. For mapping, Tweet frequency differences of the semantic variable ""anticipation"" affected tempo, positive-affected pitch, and joy-affected loudness, while ""trust"" affected rhythmic regularity. The authors evaluated sonification of the original data from the two cities, together with a control condition generated from random mappings in a listening experiment. Results suggest that the original was rated as significantly more pleasant.","2020","2023-07-12 07:12:23","2023-07-19 04:20:16","","25–33","","1/2","68","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VZ9ZCZEC","journalArticle","2016","Aguilera, Emanuel; Lopez, Jose J.; Cooperstock, Jeremy R.","Spatial Audio for Audioconferencing in Mobile Devices: Investigating the Importance of Virtual Mobility and Private Communication and Optimizations","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=18138","","2016","2023-07-12 07:12:28","2023-07-12 07:12:28","","332–341","","5","64","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FQBRMZP4","journalArticle","1987","Strawn, John","Editing Time-Varying Spectra","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=10283","Time-varying spectral analysis is a useful tool for working with sound. Unfortunately a very large amount of data is involved. A menu-driven graphics-based editor for time-varying spectra has been implemented at the Center for Computer Research in Music and Acoustics (CCRMA), Stanford University. The features that have been developed for examining and modifying spectra are outlined, and suggestions are offered for the next generation of editors of this type.","1987","2023-07-12 07:12:31","2023-07-19 04:50:01","","337–352","","5","35","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F4B24AZT","journalArticle","2013","Lech, Michal; Kostek, Bozena","Testing A Novel Gesture-Based Mixing Interface","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=16822","","2013","2023-07-12 07:12:34","2023-07-12 07:12:34","","301–313","","5","61","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SW94YAR8","journalArticle","1976","Bernstein, Alan D.; Cooper, Ellis D.","The Piecewise-Linear Technique of Electronic Music Synthesis","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=2611","A new piecewise-linear generator permitting direct analog control of acoustic waveforms, the PL module, is shown to offer significant advantages in electronic music. A FORTRAN program, facilitating the computation of amplitude spectra for piecewise-linear waveforms, is used in discussing some of the properties of the PL module. Numerous applications to electronic music are suggested, beginning simply with generation of PL envelopes and waveforms.","1976","2023-07-12 07:12:38","2023-07-19 03:42:14","","446–454","","6","24","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AWSMFCGQ","journalArticle","2000","Härmä, Aki; Karjalainen, Matti; Savioja, Lauri; Välimäki, Vesa; Laine, Unto K.; Huopaniemi, Jyri","Frequency-Warped Signal Processing for Audio Applications","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=12039","Modern audio techniques, such as audio coding and sound reproduction, emphasize the modeling of auditory perception as one of the cornerstones for system design. A methodology, frequency-warped digital signal processing, is presented in a tutorial paper as a means to design and implement digital signal-processing algorithms directly in a way that is relevant for auditory perception. Several audio applications are considered in which this approach shows advantages when used as a design or implementation tool or as a conceptual framework of design.","2000","2023-07-12 07:12:41","2023-07-19 04:03:56","","1011–1031","","11","48","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GNWKT4N7","journalArticle","1966","Beauchamp, James W.","Additive Synthesis of Harmonic Musical Tones","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=1129","The imporance of harmonic tones in musical situations makes it highly desirable to be able to synthesize arbitrary harmonic spectra. the most flexible method for accomplishing this is by additive synthesis of the individual harmonic components. It is also necessary to have control over the time behaviors of the parameters which define a harmonic tone. Consequently, a solid-state additive synthesis device, called the Harmonic Tone Generator, has been constructed which generates an audio tone composed of six harmonics. The fundamental frequency (0 to 2400 Hz), the amplitudes of the individual harmonics and the second harmonic phase-shift are controlled independently by external voltages. Circuitry has also been built to provide independent harmonic amplitude control signals and for the actuation of sound events. The theory of separation of harmonic partials using ultrasonic frequencies is discussed.","1966","2023-07-12 07:12:45","2023-07-19 03:39:37","","332–342","","4","14","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3DAYV5IB","journalArticle","2022","Hill, Adam J.; Mulder, Johannes; Burton, Jon; Kok, Marcel; Lawrence, Michael","Sound Level Monitoring at Live Events, Part 3–Improved Tools and Procedures","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=21552","","2022","2023-07-12 07:12:48","2023-07-12 07:12:48","","73–82","","1/2","70","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JSXUB7F3","journalArticle","2023","McKenzie, Thomas; Meyer-Kahlen, Nils; Hold, Christoph; Schlecht, Sebastian J.; Pulkki, Ville","Auralization of Measured Room Transitions in Virtual Reality","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=22140","To auralize a room's acoustics in six degrees-of-freedom virtual reality (VR), a dense set of spatial room impulse response (SRIR) measurements is required, so interpolating between a sparse set is desirable. This paper studies the auralization of room transitions by proposing a baseline interpolation method for higher-order Ambisonic SRIRs and evaluating it in VR. The presented method is simple yet applicable to coupled rooms and room transitions. It is based on linear interpolation with RMS compensation, although direct sound, early reflections, and late reverberation are processed separately, whereby the input direct sounds are first steered to the relative direction-of-arrival before summation and interpolated early reflections are directionally equalized. The proposed method is first evaluated numerically, which demonstrates its improvements over a basic linear interpolation. A listening test is then conducted in six degrees-of-freedom VR, to assess the density of SRIR measurements needed in order to plausibly auralize a room transition using the presented interpolation method. The results suggest that, given the tested scenario, a 50-cm to 1-m inter-measurement distance can be perceptually sufficient.","2023","2023-07-12 07:12:51","2023-07-19 04:30:02","","326–337","","6","71","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UPINRUEF","journalArticle","1982","Clark, David","High-Resolution Subjective Testing Using a Double-Blind Comparator","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=3839","A system for the practical implementation of double-blind audibility tests is described. The controller is a self-contained unit, designed to provide setup and operational convenience while giving the user maximum sensitivity to detect differences. Standards for response matching and other controls are suggested as well as statistical methods of evaluating data. Test results to date are summarized.","1982","2023-07-12 07:12:55","2023-07-19 03:48:28","","330–338","","5","30","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3TIFENRY","journalArticle","2017","Ziemer, Tim; Bader, Rolf","Psychoacoustic Sound Field Synthesis for Musical Instrument Radiation Characteristics","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=18781","This research describes a sound field synthesis method that reconstructs a desired sound field within an extended listening area by taking into account psychoacoustic perceptual constraints. The proposed approach covers the complete system: (a) measuring the radiation characteristics by means of microphone array technique; (b) storing the radiation characteristics in a database, (c) propagating an arbitrary source sound toward an extended listening area by considering sources as complex point sources, and (d) reconstructing this sound field with a loudspeaker array by solving a linear equation system for discrete listening points that sample the listening area. By capturing and reconstructing the sound radiation characteristics of musical instruments, a spatial sound impression can be created. Psychoacoustic considerations are implemented to allow for wave fronts arriving from different angles and at different points in time while maintaining precise source localization and a natural and spatial sound impression. Furthermore, the psychoacoustic considerations reduce the computational costs, as illustrated by solving the linear equations for only 25 selected frequencies. Strengths and weaknesses and benefits and limitations of the psychoacoustic sound field synthesis approach are investigated in a listening test. A simulation demonstrates that the approach is valid up to a critical spatial frequency that is given by the distribution of the listening points.","2017","2023-07-12 07:12:59","2023-07-19 10:59:55","","482–496","","6","65","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RR2CYLH5","journalArticle","2007","Bai, Mingsian R.; Chen, Meng-chun","Intelligent Preprocessing and Classification of Audio Signals","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=14164","","2007","2023-07-12 07:13:02","2023-07-12 07:13:02","","372–384","","5","55","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8M5W4DLK","journalArticle","2021","Lefford, M. Nyssim; Bromham, Gary; Fazekas, György; Moffat, David","Context-Aware Intelligent Mixing Systems","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=21022","Intelligent Mixing Systems (IMS) are rapidly becoming integrated into music mixing and production workflows. The intelligences of a human mixer and IMS can be distinguished by their abilities to comprehend, assess, and appreciate context. Humans will factor context into decisions, particularly concerning the use and application of technologies. The utility of an IMS depends on both its affordances and the situation in which it is to be used. The appropriate use for conventional purposes, or its utility for misappropriation, is determined by the context. This study considers how context impacts mixing decisions and the use of technology, focusing on how the mixer’s understanding of context can inform the use of IMS, and how the use of IMS can aid in informing a mixer of different contexts.","2021","2023-07-12 07:13:04","2023-07-19 04:19:58","","128–141","","3","69","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"69VNJCPJ","journalArticle","2013","Colmenares, Juan A.; Peters, Nils; Eads, Gage; Saxton, Ian; Jacquez, Israel; Kubiatowicz, John D.; Wessel, David","A Multicore Operating System with QoS Guarantees for Network Audio Applications","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=16703","Efforts to create low-latency protocols to ensure quality of service (QoS) for audio networks often ignore the importance of the operating system (OS) in the computers at the ends of the network chain. An experimental OS called Tesselation, developed in the Parallel Computing Laboratory at UC Berkeley, was tailored to multicore processors with such features as guaranteed resource allocation and customizable user-level runtimes. To demonstrate performance isolation and service guarantees, the authors tested Tessellation under various conditions using a resource-demanding network application. This OS enables network audio applications to meet their time requirements.","2013","2023-07-12 07:13:08","2023-07-19 03:49:14","","174–184","","4","61","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A4AU64H3","journalArticle","1976","Bonello, Oscar J.","New Improvements in Audio Signal Processing for AM Broadcasting","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=2615","A new way of audio processing (amplitude and phase) is described, which gives an increase of 6 dB in the radiated energy with reference to the conventional system (compressor limiter) and allows coverage of twice the distance with the same transmission set. The energy graphic plots measured in the laboratory are analyzed and the experiences found under actual conditions in Argentina described.","1976","2023-07-12 07:13:12","2023-07-19 03:43:47","","379–383","","5","24","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SEJ5928C","journalArticle","2022","Moffat, David; De Man, Brecht; Reiss, Joshua D.","Semantic Music Production: A Meta-Study","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=21823","","2022","2023-07-12 07:13:15","2023-07-12 07:13:15","","548–564","","7/8","70","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QVHYEF8I","journalArticle","1992","Begault, Durand R.","Perceptual Effects of Synthetic Reverberation on Three-Dimensional Audio Systems","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=7027","","1992","2023-07-12 07:13:20","2023-07-12 07:13:20","","895–904","","11","40","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5XQ98GGV","journalArticle","1992","Heegaard, Fr.","The Reproduction of Sound in Auditory Perspective and a Compatible System of Stereophony","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=10280","A little more than a year ago we invited the late Holger Lauridsen to contribute to the E.B.U. Review an article describing his work on stereophonic sound reproduction and in particular the sys;tem that he had proposed for stereophonic broadcasting without most of the disadvantages of using separate transmitter chains for the left-ear and right-ear components. Many of our readers will recall Mr. Lauridsen's untimely death in December 1957, which put an end to his valuable contribution to the art and science of broadcasting. Recently, however, interest in the possibilities of stereophony, and particularly in stereophonic broadcasting, has become widespread, and Mr. Heegaard very kindly agreed to write the following article, which is based upon the work of Mr. Lauridsen.'Editor","1992","2023-07-12 07:13:24","2023-07-19 04:04:31","","802–808","","10","40","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UIWJ8GDF","journalArticle","2021","Meaux, Eric; Marchand, Sylvain","Synthetic Transaural Audio Rendering (STAR): A Perceptive 3D Audio Spatialization Method","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=21117","The synthetic transaural audio rendering (STAR) method aims at canceling the cross-talk signals between two loudspeakers and the ears of the listener (in a transaural way), with acoustic paths not measured but computed by some model (thus synthetic). Our model is based on perceptive cues used by the human auditory system for sound localization. The aim is to give the listener the sense of the position of each source rather than reconstruct the corresponding acoustic wave or field. Although the method currently focuses on the azimuth dimension, extensions to elevation and distance are now considered, for full 3D sound, with a discussion to conduct further works needed to improve overall quality and validate such extensions.","2021","2023-07-12 07:13:28","2023-07-19 04:30:10","","497–505","","7/8","69","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZEK3Y8B2","journalArticle","2005","Hawksford, Malcolm J.","System Measurement and Identification Using Pseudorandom Filtered Noise and Music Sequences","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=13411","System measurement using pseudorandom filtered noise and music sequences is investigated. A single-pass technique is used to evaluate simultaneously the transfer function and the spectral-domain signal-to-distortion ratio that is applicable to amplifiers, signal processors, digital-to-analog converters, loudspeakers, and perceptual coders. The technique is extended to include a simplified Volterra model expressed as a power series and linear filter bank where for compliant systems, nonlinear distortion can be estimated for an arbitrary excitation without a need for remeasurement.","2005","2023-07-12 07:13:29","2023-07-19 04:04:04","","275–296","","4","53","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EY9NQV8M","journalArticle","2017","Volk, Christer P.; Bech, Søren; Pedersen, Torben H.; Christensen, Flemming","Modeling Perceptual Characteristics of Loudspeaker Reproduction in a Stereo Setup","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=18729","","2017","2023-07-12 07:13:42","2023-07-12 07:13:42","","356–366","","5","65","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RQ8FKX9S","journalArticle","2017","Brinkmann, Fabian; Lindau, Alexander; Weinzierl, Stefan; Par, Steven van de; Müller-Trapet, Markus; Opdam, Rob; Vorländer, Michael","A High Resolution and Full-Spherical Head-Related Transfer Function Database for Different Head-Above-Torso Orientations","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=19357","Head-related transfer functions (HRTFs) capture the free-field sound transmission from a sound source to the listeners ears, incorporating all the cues for sound localization, such as interaural time and level differences as well as the spectral cues that originate from scattering, diffraction, and reflection on the human pinnae, head, and body. In this study, HRTFs were acoustically measured and numerically simulated for the FABIAN head-and-torso simulator on a full-spherical and high-resolution sampling grid. HRTFs were acquired for 11 horizontal head-above-torso orientations, covering the typical range of motion of +/-50°. This made it possible to account for head movements in dynamic binaural auralizations. Because of a lack of an external reference for the HRTFs, measured and simulated data sets were cross-validated by applying auditory models for localization performance and spectral coloration. The results indicate a high degree of similarity between the two data sets regarding all tested aspects, thus suggesting that they are free of systematic errors.","2017","2023-07-12 07:13:46","2023-07-19 03:45:27","","841–848","","10","65","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FILLRT7F","journalArticle","2017","Fleßner, Jan-Hendrik; Huber, Rainer; Ewert, Stephan D.","Assessment and Prediction of Binaural Aspects of Audio Quality","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=19361","Binaural or spatial presentation of audio signals has become increasingly important not only in consumer sound reproduction, but also for hearing-assistive devices like hearing aids, where signals in both ears might undergo extensive signal processing. Such processing may introduce distortions to the interaural signal properties that affect perception. In this research, an approach for intrusive binaural auditory-model-based quality prediction (BAM-Q) is introduced. BAM-Q uses a binaural auditory model as front-end to extract the three binaural features: interaural level difference, interaural time difference, and a measure of interaural coherence. The current approach focuses on the general applicability (with respect to binaural signal differences) of the binaural quality model to arbitrary binaural audio signals. Two listening experiments were conducted to subjectively measure the influence of these binaural features and their combinations on binaural quality perception. The results were used to train BAM-Q. Two different hearing aid algorithms were used to evaluate the performance of the model. The correlations between subjective mean ratings and model predictions are higher than 0.9.","2017","2023-07-12 07:13:49","2023-07-19 03:58:19","","929–942","","11","65","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F5BXLD8G","journalArticle","2013","van Waterschoot, Toon; Tirry, Wouter Joos; Moonen, Marc","Acoustic Zooming by Multi-Microphone Sound Scene Manipulation","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=16866","Camera zooming would be more compelling if the audio was subjected to a corresponding zoom that matched the video. Psychophysical and neuroimaging results suggest that a cross-modal approach to zooming facilitates multisensory integration. Because auditory distance perception is primarily determined by sound intensity, an audiovisual zoom effect can be obtained by matching the levels of different sources in a sound scene with their visually perceived distance. The authors propose a general theory for independent sound source level control that can be used to attain an acoustic zoom effect. The theory does not require sound source separation, which reduces computational load. An efficient implementation using fixed and adaptive spatial and spectral noise-reduction algorithms is proposed and evaluated. Experimental results using an array of a small number of low-cost microphones confirm that the proposed approach is particularly suited for consumer audiovisual capture applications.","2013","2023-07-12 07:13:53","2023-07-19 04:55:12","","489–507","","7/8","61","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9VW5DVQC","journalArticle","2022","Bank, Balázs","Warped, Kautz, and Fixed-Pole Parallel Filters: A Review","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=21793","In audio signal processing, the aim is the best possible sound quality for a given computational complexity. For this, taking into account the logarithmic frequency resolution of hearing is a good starting point. The present paper provides an overview on warped, Kautz, and fixed-pole parallel filters and demonstrates that they are all capable of achieving logarithmiclike frequency resolution, providing much more efficient filtering or equalization compared to straightforward finite impulse response (FIR) or infinite impulse response (IIR) filters. Besides presenting the historical development of the three methods, the paper discusses their relations and provides a comparison in terms of accuracy, computational requirements, and design complexity. The comparison includes loudspeaker--room response modeling and equalization examples.","2022","2023-07-12 07:13:56","2023-07-19 03:38:40","","414–434","","6","70","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TC96L9LK","journalArticle","1995","Sandell, Gregory J.; Martens, William L.","Perceptual Evaluation of Principal-Component-Based Synthesis of Musical Timbres","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=7919","Harmonic-based analysis and resynthesis of musical instrument tones, for example, using the phase vocoder method, is a valuable technique, but its data representation is very large. However, this data set is usually highly redundant. Principal components analysis (PCA) can be used to encode such data into a smaller set of orthogonal basis vectors with minimal loss of information. Techniques for applying PCA to such data are explored, and the aural impact of the method on three tones (cello, trombone, and clarinet) are studied in two perception experiments. Results show that nearly identical resyntheses can be produced with a 40-70% data reduction. A preprocessing step called variable-duration temporal partitioning (VDTP) is introduced, which also affords a natural-sounding method for time expansion and contraction of tones. An extension of the PCA technique is also introduced that implements a ""timbre space,"" or coordinate system for interpolation among a group of musical instruments.","1995","2023-07-12 07:14:00","2023-07-19 04:46:24","","1013–1028","","12","43","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P6X4F64S","journalArticle","2022","Fela, Randy Frans; Zacharov, Nick; Forchhammer, Søren","Assessor Selection Process for Perceptual Quality Evaluation of 360 Audiovisual Content","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=22010","For accurate and detailed perceptual evaluation of compressed omnidirectional multimedia content, it is imperative for assessor panels to be qualified to obtain consistent and high-quality data. This work extends existing procedures for assessor selection in terms of scope (360? videos with high-order ambisonic), time efficiency, and analytical approach, as described in detail. The main selection procedures consisted of a basic audiovisual screening and three successive discrimination experiments for audio (listening), video (viewing), and audiovisual using a triangle test. Additionally, four factors influencing quality of experience, including the simulator sickness questionnaire, were evaluated and are discussed. After the selection process, a confirmatory study was conducted using three experiments (audio, video, and audiovisual) and based on a rating scale methodology to compare performance between rejected and selected assessors. The studies showed that (i) perceptual discriminations are influenced by the samples, the encoding parameters, and some quality of experience factors; (ii) the probability of symptom occurrence is considerably low, indicating that the proposed procedure is feasible; and (iii) the selected assessors performed better in discrimination than the rejected assessors, indicating the effectiveness of the proposed procedure.","2022","2023-07-12 07:14:11","2023-07-19 03:56:34","","824–842","","10","70","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M3LW284N","journalArticle","1989","Olive, Sean E.; Toole, Floyd E.","The Detection of Reflections in Typical Rooms","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=6079","Reflected sounds influence the timbre and spatial character of live and reproduced sounds. Most investigations of reflections have focused on the performance of live sounds in large halls. Current interest in the acoustical interactions of rooms, loudspeakers, and listeners requires further and possibly more relevant data than have been available. In this study, the effects of reflected sounds were examined as they would occur in stereophonic reproduction in rooms of domestic or control-room size. Thresholds were determined as a function of level relative to the direct sound, the angle of incidence, spectrum, the temporal form of the signal, and reverberation. The relationships between audible effects and measurements, such as energy-time curves and frequency response, are discussed.","1989","2023-07-12 07:14:33","2023-07-19 04:35:58","","539–553","","7/8","37","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"55V9EFH7","journalArticle","2004","Algazi, V. Ralph; Duda, Richard O.; Thompson, Dennis M.","Motion-Tracked Binaural Sound","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=13028","A new method is presented for capturing, recording, and reproducing spatial sound that provides a vivid sense of realism. The method generalizes binaural recording, preserving the information needed for dynamic head-motion cues. These dynamic cues greatly reduce the need for customization to the listener. During either capture or recording, the sound field in the vicinity of the head is sampled with a microphone array. During reproduction, a head tracker is used to determine the microphones that are closest to the positions of the listener's ears. Interpolation procedures are used to produce the headphone signals. The properties of different methods for interpolating the microphone signals are presented and analyzed.","2004","2023-07-12 07:14:36","2023-07-19 03:35:28","","1142–1156","","11","52","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F2BENMUW","journalArticle","2000","Baileyi, Nicholas J.; Cooper, David","Sculptor: Exploring Timbral Spaces in Real Time","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=10265","Characterization of the timbre of a sound from its spectrum or time series is of limited use in the context of electroacoustics because of the huge data set that is usually involved. The concept of a timbral space offers the potential to characterize sounds using a smaller set of variables, but it is not clear how the signal-derived parameters map onto their psychoacoustic correlates. Sculptor is a package that enables the analysis, parameterization, and editing of sounds in real time, requiring only inexpensive hardware. State-space techniques are used to decompose models of a selected sound into parallel second-order sections. The second-order resonator parameters can then be edited and the results auditioned in real time. The sound code of the package is available, so that researchers may provide additional functionality as required.","2000","2023-07-12 07:14:41","2023-07-19 03:38:10","","174–180","","3","48","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3IUDVGJW","journalArticle","2003","Tan, Chin-Tuan; Moore, Brian C. J.; Zacharov, Nick","The Effect of Nonlinear Distortion on the Perceived Quality of Music and Speech Signals","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=12197","The effect of various types of nonlinear distortion on the perceived quality of speech and music signals was examined. In experiments 1 and 2, ""artificial"" distortions were used, including hard and soft symmetrical and asymmetrical peak clipping of various amounts, center clipping, and full-range waveform distortion produced by raising the instantaneous absolute value of the waveform to a power (≠1) while preserving the sign. Subjects were asked to rate the perceived amount of distortion on a ten-point scale (where 1 was most distorted and 10 least distorted). In experiment 1 the distortions were applied to the broadband signals. In experiment 2 the distortions were applied to subbands of the signal. Results were highly consistent across subjects and test sessions. Center clipping and soft clipping had only small effects on the ratings, whereas hard clipping and the full-range distortions had large effects. The subjective ratings were compared to physical measures of distortion based on multitone test signals. A distortion measure, DS, derived from the output spectrum of each nonlinear system in response to a 10-component multitone signal gave high negative correlations with the subjective ratings (correlations were negative as large values of DS were associated with low ratings). A further experiment was conducted using stimuli for which nonlinear distortion was introduced by recording the outputs of real transducers. The output signals were digitally filtered to reduce irregularities in the amplitude/frequency response as far as possible. The results showed moderately strong negative correlations between the subjective ratings and the objective measure DS. It was concluded, that an objective measure of nonlinear distortion based on the use of a multitone signal can predict the perceptual effects of nonlinear distortion reasonably well.","2003","2023-07-12 07:14:46","2023-07-19 04:51:15","","1012–1031","","11","51","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TU8MXUTI","journalArticle","2001","Cheng, Corey I.; Wakefield, Gregory H.","Introduction to Head-Related Transfer Functions (HRTFs): Representations of HRTFs in Time, Frequency, and Space","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=10196","In this tutorial, head-related transfer functions (HRTFs) are introduced and treated with respect to their role in the synthesis of spatial sound over headphones. HRTFs are formally defined, and are shown to be important in reducing the ambiguity with which the classical duplex theory decodes a free-field sound's spatial location. Typical HRTF measurement strategies are described, and simple applications of HRTFs to headphone-based spatialized sound synthesis are given. By comparing and contrasting representations of HRTFs in the time, frequency, and spatial domains, different analytic and signal processing techniques used to investigate the structure of HRTFs are highlighted.","2001","2023-07-12 07:14:49","2023-07-19 03:48:01","","231–249","","4","49","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FA95XYJC","journalArticle","2007","Rossiter, David; Tsang, Raymond; So, Richard H. Y.","Beat Deviation for Tempo Estimation Algorithms","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=14180","The series of beats in an arbitrary piece of music typically do not have a precisely consistent interval of time between them. A study was carried out to analyze beat deviation. Five musicians tapped beat sequences for 50 recordings taken from 16 different categories of music. A power curve was proposed to represent the beat deviation. The curve is shown to capture the majority (96.9%) of the beat data entered by the subjects in this study, with a minimum chance of nonbeat events being accepted as valid beats. The proposed power curve equation is compared to others in published research. Measures of BPM deviation used in previous studies are also considered.","2007","2023-07-12 07:14:53","2023-07-19 04:42:04","","967–980","","11","55","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TKS2VF9M","journalArticle","1989","Davis, Don; Davis, Carolyn","Application of Speech Intelligibility to Sound Reinforcement","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=6057","Sound reinforcement and reproduction systems have grown to a scale where church committees and auditorium owners spend up to $1,000,000 for them. In the past, such systems were purchased without any assurance that acceptable speech intelligibility would be achieved. Today speech intelligibility can be specified in advance, designed for, and objectively measured with an accuracy as good as that achieved using a panel of ""live"" listeners. The competing techniques are described and evaluated, and some of the remaining problem areas encountered in analyzing nonstandard systems are outlined. the Peutz percent articulation loss of consonants technique (%ALcons), the speech transmission index (STI), and the rapid speech transmission index (RASTI) are all defined, compared to live listener tests made with a large listener sample, and illustrated using currently available analyzers.","1989","2023-07-12 07:14:56","2023-07-19 03:51:36","","1002–1019","","12","37","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PBDBH3LH","journalArticle","1984","Ingebretsen, Robert B.; Stockham, Thomas G., Jr.","Random-Access Editing of Digital Audio","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=4522","The most striking characteristic of digital audio, and possibly the most controversial, is its intrinsically high sonic quality. However, this may not be the most significant benefit in terms of commercial applications. characteristics such as archivability, flexible processing techniques, time-base independence, and rapid accessibility offer efficient and powerful capabilities. The implementation of one unique feature is discussed: random-access editing. Through the use of large-capacity rotating magnetic media and a smoothing buffer, it is possible to create and/or modify splices rapidly, audition them, then play the various cuts in one continuous stream. Such a system also enables various forms of processing (including such standard functions as fading, mixing, and equalization) to be imposed on the signal, as well as permitting different forms of interaction including display of audio waveforms.","1984","2023-07-12 07:14:58","2023-07-19 04:07:57","","114–122","","3","32","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RPSHV9NU","journalArticle","2007","Short, Kevin M.; Garcia, Ricardo A.; Daniels, Michelle L.","Multichannel Audio Processing Using a Unified-Domain Representation","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=14155","","2007","2023-07-12 07:15:02","2023-07-12 07:15:02","","156–165","","3","55","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BPWMT25J","journalArticle","2017","Andreopoulou, Areti; Roginska, Agnieszka","Database Matching of Sparsely Measured Head-Related Transfer Functions","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=19171","The effectiveness of binaural reproductions depends on the accuracy of those spatialization cues that are unique to an individual’s personal physiology. These cues are embedded in the Head-Related Transfer Functions (HRTFs), which guide sound from a given source direction to a listener’s ears. This report discusses the design and evaluation of a HRTF database matching system that pairs users to premeasured HRTF sets created from a sparse set of individualized acoustic measurements. The utilized spatial grid, which was derived from an LDA classifier, consisted of 68 filters nonuniformly distributed across 5 elevations from -30° and +30°. A binaural localization study confirmed the original hypothesis that the similarity between subsets of binaural filters can be generalized to represent the relationship of the HRTFs of origin. Analysis of the participant responses provided strong evidence that HRTF database matching is useful. The designed implementation was successful in providing users with alternative HRTF datasets when the similarity of the matched data to the search query was above a certain similarity threshold. It was also shown that low-similarity HRTFs can lead to decreased spatial localization accuracy.","2017","2023-07-12 07:15:05","2023-07-19 03:36:43","","552–561","","7/8","65","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A37FFJ7W","journalArticle","1988","Martinez, Charles; Gilman, Samuel","Results of the 1986 AES Audiometric Survey","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=5131","Many members of the Audio Engineering Society (AES) are employed in positions that require critical listening to sounds, frequently at high-intensity levels. Previous audiometric surveys of the membership in 1975 and 1976 suggest that some of the members are at risk for hearing loss due to the high-intensity sound exposure. This prompted the Los Angeles Section of the AES to provide for a follow-up audiometric survey to reassess the hearing level of the AES members. The results of the survey, performed at the 1986 November meeting in Los Angeles, are reported.","1988","2023-07-12 07:15:08","2023-07-19 04:28:52","","686–691","","9","36","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C8KUK43G","journalArticle","2012","Huckvale, Mark; Hilkhuysen, Gaston","Performance-Based Measurement of Speech Quality with an Audio Proof-Reading Task","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=16358","","2012","2023-07-12 07:15:11","2023-07-12 07:15:11","","444–451","","6","60","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"72GVEU3Y","journalArticle","2016","Chau, Chuck-jee; Mo, Ronald; Horner, Andrew","The Emotional Characteristics of Piano Sounds with Different Pitch and Dynamics","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=18528","","2016","2023-07-12 07:15:15","2023-07-12 07:15:15","","918–932","","11","64","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JIJPL276","journalArticle","2016","Wilson, Alex; Fazenda, Bruno M.","Perception of Audio Quality in Productions of Popular Music","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=18102","","2016","2023-07-12 07:15:18","2023-07-12 07:15:18","","23–34","","1/2","64","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T3K2MYK9","journalArticle","1985","Borish, Jeffrey","An Auditorium Simulator for Domestic Use","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=4447","The enjoyment of music reproductions can be significantly increased by electronically simulating the early reflections characteristic of appropriate performance spaces. The simulation is based on a detailed mathematical modeling of the acoustics of various performing spaces. This analysis provides the impulse responses of the auditoriums for giving source and listener positions. The simulator convolves an audio signal obtained from standard stereo recordings with the desired impulse response in real time. Several impulse responses are stored in the simulator to provide listeners with a choice of environments to suit the musical style of their selection and their own personal taste. Only two additional loudspeakers are required to convey the lateral early reflections, and their positioning is uncritical. The medial reflections do not contribute to the desirable spatial impression, so no effort is made to present these sounds. Also, no effort is made to synthesize the late reflections because they can be and typically are recorded. Consideration of the properties of auditory perception led to other important simplifications. The system is simple to set up and operate, and provides music reproduction that experienced listeners have judged very natural.","1985","2023-07-12 07:15:22","2023-07-19 03:44:06","","330–341","","5","33","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QWUEXQSE","journalArticle","2015","Momose, Tomohiro; Otani, Makoto; Hashimoto, Masami; Kayama, Mizue; Itoh, Kazunori","Adaptive Amplitude and Delay Control for Stereophonic Reproduction that Is Robust against Listener Position Variations","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=17569","With stereo reproduction, sound images are correctly located when the listener is located in a small area, called the sweet spot. When the listener is laterally away from this ideal location, the observed interaural level differences, interaural time differences, and interaural phase differences do not match the listener’s assumptions because of unequal distances from the listener to the respective loudspeakers. In order to provide better localization beyond the sweet spot, the proposed system detects the listener’s position to adaptively control the amplitude ratio and delay difference of the two loudspeakers. Results of subjective experiments using the proposed method demonstrate that sound images are localized more accurately than without such a system.","2015","2023-07-12 07:15:26","2023-07-19 04:33:07","","90–98","","1/2","63","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ED6V8A7U","journalArticle","2011","Horner, Andrew B.; Beauchamp, James W.; So, Richard H. Y","Evaluation of Mel-Band and MFCC-Based Error Metrics for Correspondence to Discrimination of Spectrally Altered Musical Instrument Sounds","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=15930","An objective measure of the subjective timbral difference between two musical sounds is a difficult problem. Mel-band-based metrics and single mel-frequency ceptral coefficient were considered as a way of improving results obtained from previous methods based on harmonic and critical-band error metrics. Results indicate that timbral discrimination is determined by the first 5 to 10 harmonics rather than the broad spectral envelope. More sophisticated methods do not offer significant advantage.","2011","2023-07-12 07:15:30","2023-07-19 04:06:36","","290–303","","5","59","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PL67YHVB","journalArticle","2019","Howie, Will; Martin, Denis; Kim, Sungyoung; Kamekawa, Toru; King, Richard","Effect of Audio Production Experience, Musical Training, and Age on Listener Performance in 3D Audio Evaluation","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=20696","Well executed listening tests often require a great deal of time and resources for the creation or acquisition of appropriate stimuli, design of a testing interface, selection of subjects, and implementation of the experiment in an environment that is acoustically and technologically appropriate. The use of experienced, trained, or practiced subjects in listening tests has been shown in numerous previous studies to allow for a reduction in the number of subjects necessary to gather consistent, meaningful data. This study examined the effect of audio production experience, musical training, technical ear training, age, and previous experience listening to 3D music recordings on listener performance within the context of 3D audio evaluation. The results showed: (a) audio production was the most valuable type of previous experience for predicting listener consistency in making preference or ranking judgments; (b) music training was also found to be a good predictor of subject consistency; (c) technical ear training and previous experience hearing 3D music recordings had no influence on listener consistency; and (d) subjects in their early to mid 30s appear to occupy an optimal age range in terms of ability to focus on the types of listening test tasks described in this study. Stimuli used in this study were limited to orchestral music.","2019","2023-07-12 07:15:34","2023-07-19 04:07:03","","782–794","","10","67","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7Y5LUZBB","journalArticle","2021","Shier, Jordie; McNally, Kirk; Tzanetakis, George; Brooks, Ky Grace","Manifold Learning Methods for Visualization and Browsing of Drum Machine Samples","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=21015","","2021","2023-07-12 07:15:37","2023-07-12 07:15:37","","40–53","","1/2","69","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LSWQDPPF","journalArticle","2016","Thorogood, Miles; Fan, Jianyu; Pasquier, Philippe","Soundscape Audio Signal Classification and Segmentation Using Listeners Perception of Background and Foreground Sound","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=18334","","2016","2023-07-12 07:15:40","2023-07-12 07:15:40","","484–492","","7/8","64","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MUNRS8ML","journalArticle","2018","Lai, Wen-Hsing; Liang, Sen-Fu","Control of Fundamental Frequency Fluctuation in Taiwanese Singing Synthesis","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=19565","This paper analyzes the pitch fluctuations of different notes in Taiwanese singing in order to build an F0 note-type based control model that improves the naturalness of Taiwanese synthesized singing voice by producing the more natural F0 contours. The factors that significantly differentiate singing synthesis from speech synthesis must be taken into consideration when designing a singing synthesizer. Among these, the fundamental frequency (F0) contour is an important feature that deeply affects singing voice perception and needs to be controlled precisely. The F0 contour contains fluctuations instead of a predefined stepwise pitch curve derived from musical notes. These fluctuations are important features that should be taken into consideration in singing-related applications such as singing synthesis, singing voice detection, performance analysis, singing/music recognition, singing style identification, and query-by humming. Overshoot percentage and preparation percentage are proposed to solve the problems of determining the fluctuation extent. Statistics for each note category were established from a corpus of Taiwanese nursery rhymes. Different extents of the overshoot and preparation of separate categories of notes for males, females, and children were modeled according to the statistic results. A PID controller that controls a second-order system is proposed to quickly adjust to the correct F0 level of notes and remain sufficiently steady at the correct F0 level to produce a pleasant singing voice.","2018","2023-07-12 07:15:43","2023-07-19 04:17:02","","343–359","","5","66","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QDEU2MBQ","journalArticle","2010","Moore, Alastair H.; Tew, Anthony I.; Nicol, Rozenn","An Initial Validation of Individualized Crosstalk Cancellation Filters for Binaural Perceptual Experiments","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=15240","Delivering binaural stimuli with loudspeakers through crosstalk filters avoids the intrinsic artifacts of using headphones in localization experiments. However, one must first demonstrate that such a system is equivalent to that of a real soundfield. This study demonstrates that listeners did not perceive any meaningful difference between a real sound source at 0 degrees and a virtual rendering using crosstalk cancellation from a pair of loudspeakers at ±90 degrees. Three different stimuli were used: single bursts of wideband noise, click trains, and repeated harmonic pulses. Listeners could not discriminate between the two cases using a forced-choice paradigm.","2010","2023-07-12 07:15:47","2023-07-19 04:33:29","","36–45","","1/2","58","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2AA44D9T","journalArticle","2016","Rocchesso, Davide; Mauro, Davide Andrea; Drioli, Carlo","Organizing a sonic space through vocal imitations","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=18333","","2016","2023-07-12 07:15:52","2023-07-12 07:15:52","","474–483","","7/8","64","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J68RWW9C","journalArticle","2018","Allan, Jon; Berg, Jan","Evaluating Live Loudness Meters from Engineers’ Actions and Resulting Output Levels","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=19706","Loudness discrepancies in television and radio frequently produce listener annoyance. Variations in loudness can be traced to the use of quasi-PPM based audio level meters in conjunction with different amounts of compression dynamics. A satisfactory live loudness meter should assist the engineer to: (a) achieve the recommended target level for a program, (b) compensate for content-dependent delimited offsets in loudness, and (c) compensate for fast changes in loudness. This paper investigates how the ballistic properties of live loudness meters affect the engineers’ actions with fader position and the resulting output levels. In order to explore the quality of loudness meters, the researchers simulated a live broadcast show with mixing engineers who had different degrees of experience. The resulting output levels were analyzed and interpreted using a linear mixing model. The results showed that the meters with the slower integration times produced less dispersion of output levels for parts of the program. Varying integration times of the meters did not cause a significant difference in the reaction time.","2018","2023-07-12 07:16:04","2023-07-19 03:35:38","","556–577","","7/8","66","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y3FD22IU","journalArticle","2006","Berg, Jan; Rumsey, Francis","Identification of Quality Attributes of Spatial Audio by Repertory Grid Technique","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=13681","The evaluation of the perceived spatial quality of an audio system has become more important as the technical possibilities to render spatial information increase. In recent years the field of spatial quality evaluation has been the subject of more thorough investigations than previously, one of the problems being the development of attribute scales appropriate for this purpose. The generation of attributes of spatial audio by means of elements from the repertory grid technique is investigated. In an experiment personal constructs in the form of verbal descriptors were elicited. The constructs were classified by verbal protocol analysis and reduced to a limited number of attributes by cluster analysis. The results show that the repertory grid technique enables a number of attributes of spatial sound quality to be extracted from a group of subjects and that these attributes correspond well with attributes found in other studies. The results also indicate the importance of a definition of the part—the whole or a subset—of the auditory scene to which a specific attribute is referring.","2006","2023-07-12 07:16:08","2023-07-19 03:41:57","","365–379","","5","54","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VC48JRR8","journalArticle","2015","Satongar, Darius; Pike, Chris; Lam, Yiu W.; Tew, Anthony I.","The Influence of Headphones on the Localization of External Loudspeaker Sources","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=18043","When validating systems that use headphones to synthesize virtual sound sources, a direct comparison between virtual and real sources is sometimes needed but the method can be difficult to implement. Often, the listener must wear the headphones throughout the experiment, which will affect the sound transmission from the external loudspeakers to the ears. An analysis of the physical measurements highlighted the that headphones cause a measurable spectral error in HRTF. A maximum spectral ILD distortion of 26.52 dB was found for the close-back headphones. In a localization study, head movement data was used to obtain judgement profiles that showed participants took 0.2 s longer to reach their final judgements and used 0.1 more head-turns. The authors recommend care when choosing headphones for scenarios in which a listener is presented with external acoustic sources. Results for different headphone designs highlight that the use of electrostatic transducers could help maintain natural acoustical perception.","2015","2023-07-12 07:16:12","2023-07-19 04:46:48","","799–810","","10","63","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"II7TKSGA","journalArticle","2016","Fan, Jianyu; Thorogood, Miles; Pasquier, Philippe","Automatic Soundscape Affect Recognition Using A Dimensional Approach","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=18373","","2016","2023-07-12 07:16:18","2023-07-12 07:16:18","","646–653","","9","64","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q92NDRBS","journalArticle","1989","Komiyama, Setsu","Subjective Evaluation of Angular Displacement between Picture and Sound Directions for HDTV Sound Systems","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=6094","Several recent studies have suggested that ordinary stereophonic systems are not sufficient for HDTV use. These investigations have noted the localization error between picture and sound as a reason, but have not studied the extent to which this phenomenon causes viewer annoyance. The psychological experiment described was designed to investigate the acceptable extent of angular displacement between visual and auditory images for on-axis viewing. The results show that it is about 11 degrees for acoustic engineers and 20 degrees for the members of the general audience. In addition, the number of frontal channels in HDTV is discussed.","1989","2023-07-12 07:16:22","2023-07-19 04:15:58","","210–214","","4","37","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GYG9LH4L","journalArticle","2011","Sarroff, Andy M.; Bello, Juan P.","Toward a Computational Model of Perceived Spaciousness in Recorded Music","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=15975","","2011","2023-07-12 07:16:25","2023-07-12 07:16:25","","498–513","","7/8","59","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PJA7VF5K","journalArticle","2020","Howie, Will; Martin, Denis; Kim, Sungyoung; Kamekawa, Toru; King, Richard","Effect of Skill Level on Listener Performance in 3D Audio Evaluation","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=20894","A previous experiment (Part 1) found that, within the context of 3D audio evaluation, both audio production experience and musical training were significant predictors of listener consistency in making preference or attribute rating judgments of stimuli. In that study, 72 subjects ranging from highly experienced to na ¨ive listeners evaluated an excerpt of orchestral music captured by three different 3D music-recording techniques. Using the same data set from Part 1, the current study (Part 2) examines whether the results of skilled listeners can be generalized to the larger population of unskilled listeners within the context of 3D audio evaluation. Results show no significant changes in the rank order of recording technique attribute ratings or preferences as a function of listener skill. Results also show that using highly skilled participants will result in gains in sta- tistical power. This allows for the detection of subtler differences between stimuli or greater efficiency in the number of trials needed to achieve a significant result.","2020","2023-07-12 07:16:28","2023-07-19 04:07:11","","628–637","","9","68","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U5VFZXAI","journalArticle","2002","Larsen, Erik; Aarts, Ronald M.","Reproducing Low-Pitched Signals through Small Loudspeakers","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=11088","Ever since the invention of the electrodynamic loudspeaker there has been a need for greater acoustical output, especially at low frequencies. From a manufacturer's point of view it has been desirable for a long time to reduce the size of the loudspeaker (and cabinet). These two demands are physically contradictory. Options are being offered to evoke the illusion of a higher low-frequency response of the loudspeaker while the power radiated by the loudspeaker at those low frequencies remains the same, or is even lower. This is feasible by exploiting certain psychoacoustic phenomena. The required nonlinear signal processing is studied for a number of specific implementations. An elaborate analysis of the outcome of a listening test, aimed at assessing the subjective evaluation of the system presented, employing multidimensional scaling and biplots, is also presented.","2002","2023-07-12 07:16:37","2023-07-19 04:17:30","","147–164","","3","50","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A8X4FU2V","journalArticle","2021","Riionheimo, Janne; Lokki, Tapio","Movie Sound, Part 2: Preference and Attribute Ratings of Six Listening Environments","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=21017","","2021","2023-07-12 07:16:40","2023-07-12 07:16:40","","68–79","","1/2","69","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PMR97R8C","journalArticle","1983","Penkov, Georgi","Power and Real Signals in an Audio System","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=4572","Power requirements for the amplifiers and drivers in a one-, two-, or three-channel active loudspeaker system have been determined by analyzing the moving-power maxima in 70 sequences of recorded musical and speech signals for different time constants and frequency bands. It was found that the distribution of these maxima follows a double exponential law. A computer program was used to process the data.","1983","2023-07-12 07:16:44","2023-07-19 04:37:36","","423–429","","6","31","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6TQDFSWW","journalArticle","2021","Rovithis, Emmanouel; Moustakas, Nikolaos; Vogklis, Konstantinos; Drossos, Konstantinos; Floros, Andreas","Design Recommendations for a Collaborative Game of Bird Call Recognition Based on Internet of Sound Practices","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=21544","Citizen Science aims to engage people in research activities on important issues related to their well-being. Smart Cities aim to provide them with services that improve the quality of their life. Both concepts have seen significant growth in the last years and can be further enhanced by combining their purposes with Internet of Things technologies that allow for dynamic and large-scale communication and interaction. However, exciting and retaining the interest of participants is a key factor for such initiatives. In this paper we suggest that engagement in Citizen Science projects applied on Smart Cities infrastructure can be enhanced through contextual and structural game elements realized through augmented audio interactive mechanisms. Our inter-disciplinary framework is described through the paradigm of a collaborative bird call recognition game, in which users collect and submit audio data that are then classified and used for augmenting physical space. We discuss the Playful Learning, Internet of Audio Things, and Bird Monitoring principles that shaped the design of our paradigm and analyze the design issues of its potential technical implementation.","2021","2023-07-12 07:16:47","2023-07-19 04:42:21","","956–966","","12","69","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P54BP59G","journalArticle","2018","Axon, Louise; Goldsmith, Michael; Creese, Sadie","Sonification Mappings: Estimating Effectiveness, Polarities and Scaling in an Online Experiment","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=19875","","2018","2023-07-12 07:16:50","2023-07-12 07:16:50","","1016–1032","","12","66","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"73VI4YNL","journalArticle","2018","Francombe, Jon; Woodcock, James; Hughes, Richard J.; Mason, Russell; Franck, Andreas; Pike, Chris; Brookes, Tim; Davies, William J.; Jackson, Philip J. B.; Cox, Trevor J.; Fazi, Filippo M.; Hilton, Adrian","Qualitative Evaluation of Media Device Orchestration for Immersive Spatial Audio Reproduction","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=19581","","2018","2023-07-12 07:17:04","2023-07-12 07:17:04","","414–429","","6","66","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PE539B6J","journalArticle","2021","Brezina, Pavol","Perspectives of Advanced Ear Training Using Audio Plug-Ins","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=21039","","2021","2023-07-12 07:17:08","2023-07-12 07:17:08","","351–358","","5","69","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BIHDZTAI","journalArticle","2014","Künzel, Hermann J.; Alexander, Paul","Forensic Automatic Speaker Recognition with Degraded and Enhanced Speech","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=17136","Various types of noise and other forms of degradation in the acoustic signal are typical of speech recordings used in forensic speaker recognition. The results of this study suggest that certain speech enhancement algorithms can be a useful tool for preprocessing speech samples before attempting automated recognition. This is particularly true for additive noise such as instrumental music and noise inside of a moving car. Comparing equal-error rates of identification experiments for ten male speakers based on the original, degraded, and enhanced voice signals, the performance of the speaker recognition system was most affected by pop music in both single-channel and 2-channel recordings. In contrast, road traffic and restaurant noise do not markedly degrade recognition performance.","2014","2023-07-12 07:17:12","2023-07-19 04:16:44","","244–253","","4","62","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LBE8KWPB","journalArticle","1993","Nielsen, Søren H.","Auditory Distance Perception in Different Rooms","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=6982","A series of listening experiments was carried out to investigate how auditory distance is perceived in different rooms-an anechoic room, an IEC listening room, and a classroom. Loudspeakers playing back a voice signal were placed in the rooms. The results show that in normal rooms the sound is perceived at about the same distance as the physical distance, regardless of the playback level. In the anechoic room there is no correspondence between physical and perceived distance.","1993","2023-07-12 07:17:16","2023-07-19 04:34:58","","755–770","","10","41","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"44LX9TXI","journalArticle","2022","Hayes, Ben; Saitis, Charalampos; Fazekas, György","Disembodied Timbres: A Study on Semantically Prompted FM Synthesis","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=21740","Disembodied electronic sounds constitute a large part of the modern auditory lexicon, but research into timbre perception has focused mostly on the tones of conventional acoustic musical instruments. It is unclear whether insights from these studies generalize to electronic sounds, nor is it obvious how these relate to the creation of such sounds. This work presents an experiment on the semantic associations of sounds produced by FM synthesis with the aim of identifying whether existing models of timbre semantics are appropriate for such sounds. A novel experimental paradigm, in which experienced sound designers responded to semantic prompts by programming a synthesizer, was applied, and semantic ratings on the sounds they created were provided. Exploratory factor analysis revealed a five-dimensional semantic space. The first two factors mapped well to the concepts of luminance, texture, and mass. The remaining three factors did not have clear parallels, but correlation analysis with acoustic descriptors suggested an acoustical relationship to luminance and texture. The results suggest that further inquiry into the timbres of disembodied electronic sounds, their synthesis, and their semantic associations would be worthwhile and that this could benefit research into auditory perception and cognition and synthesis control and audio engineering.","2022","2023-07-12 07:17:19","2023-07-19 04:04:13","","373–391","","5","70","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"APNUEAFS","journalArticle","2023","Willemsen, Silvin; Nuijens, Helmer; Lasickas, Titas; Serafin, Stefania","The Sonic Interactions in Virtual Environments (SIVE) Toolkit","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=22143","In this paper, the Sonic Interactions in Virtual Environments (SIVE) toolkit, a virtual reality (VR) environment for building musical instruments using physical models, is presented. The audio engine of the toolkit is based on finite-difference time-domain (FDTD) methods and works in a modular fashion. The authors show how the toolkit is built and how it can be imported in Unity to create VR musical instruments, and future developments and possible applications are discussed.","2023","2023-07-12 07:17:22","2023-07-19 10:55:51","","363–373","","6","71","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IZBTCL7L","journalArticle","2022","Kim, Taeho; Pöntynen, Henri; Pulkki, Ville","Vertical Direction Control Using Difference-Spectrum Filters in Stereophonic Loudspeaker Reproduction","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=21555","","2022","2023-07-12 07:17:25","2023-07-12 07:17:25","","128–139","","3","70","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"855DQC7P","journalArticle","2006","Karjalainen, Matti; Mäki-patola, Teemu; Kanerva, Aki; Huovilainen, Antti","Virtual Air Guitar","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=13884","","2006","2023-07-12 07:17:29","2023-07-12 07:17:29","","964–980","","10","54","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FZ5TJTH6","journalArticle","2011","Sabin, Andrew Todd; Rafii, Zafar; Pardo, Bryan","Weighted-Function-Based Rapid Mapping of Descriptors to Audio Processing Parameters","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=15938","","2011","2023-07-12 07:17:32","2023-07-12 07:17:32","","419–430","","6","59","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8C4F49DD","journalArticle","2015","Baumgartner, Robert; Majdak, Piotr","Modeling Localization of Amplitude-Panned Virtual Sources in Sagittal Planes","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=17842","Vector-base amplitude panning (VBAP) aims at creating virtual sound sources at arbitrary directions within 3D multichannel sound reproduction systems. However, VBAP does not consistently produce listener-specific monaural spectral cues that are essential for localization of sound sources in sagittal planes, including the front-back and up-down dimensions. In order to better understand the limitations of VBAP, a functional model approximating human processing of spectro-spatial information was applied to assess accuracy in sagittal-plane localization of virtual sources created by means of VBAP. The model predicted a strong dependence on listeners’ individual head-related transfer functions, on virtual source directions, and on loudspeaker arrangements. In general, simulations showed a systematic degradation with increasing polar-angle span between neighboring loudspeakers.","2015","2023-07-12 07:17:35","2023-07-19 03:39:16","","562–569","","7/8","63","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4G4WZLJL","journalArticle","2016","Romblom, David; Depalle, Philippe; Guastavino, Catherine; King, Richard","Diffuse Field Modeling Using Physically-Inspired Decorrelation Filters and B-Format Microphones: Part I Algorithm","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=18127","A reverberant diffuse sound field is characterized by incoherent energy arriving from all directions and is perceptually described as an auditory event that is heard everywhere. It is common practice for sound recording engineers to use differing microphone strategies for the direct and diffuse fields. While there are a variety of techniques to record and reproduce point sources, a systematic tool for diffuse sound fields does not exist. Diffuse Field Modeling (DFM) is a physically-inspired method for approximating a diffuse field in order to create a natural-sounding room effect for arbitrary loudspeaker configurations. It is intended to function in parallel with point source techniques. Using a statistical description of reverberation, the decorrelation filters in DFM are based on physical acoustics, and the resulting diffuse fields are validated with simulations incorporating the Kirchhoff/Helmholtz Integral. The resulting diffuse fields have the expected spatial autocorrelation, and the channels of the array have the expected frequency-dependent correlation. The filters can be tuned to introduce random variation that has physically-plausible frequency autocorrelation, which strongly influences the spatial impression.","2016","2023-07-12 07:17:39","2023-07-19 04:41:47","","177–193","","4","64","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"52WBCGCH","journalArticle","2009","Cobos, Maximo; Lopez, Jose J.","Resynthesis of Sound Scenes on Wave-Field Synthesis from Stereo Mixtures Using Sound Source Separation Algorithms","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=14808","Because the vast majority of musical recordings are preserved in two-channel stereo format, special upconverters are required in order to use advanced spatial reproduction formats, such as wave-field synthesis. This paper evaluates the subjective quality of synthesized acoustic scenes when using virtual sources that were extracted as separate tracks from stereo mixes. Although wave-field synthesis has its own artifacts, the degradation produced by using separated sources includes timbre modification, burbling sounds, musical noise, and intersource residuals. However, masking effects make these artifacts less perceptible when the entire scene is being reproduced.","2009","2023-07-12 07:17:42","2023-07-19 03:48:57","","91–110","","3","57","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5XT4KJA2","journalArticle","2016","Mo, Ronald; So, Richard H. Y.; Horner, Andrew","An Investigation into How Reverberation Effects the Space of Instrument Emotional Characteristics","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=18533","Previous research has shown that musical instruments have distinctive emotional characteristics and that these characteristics can be significantly changed with reverberation. This research examines if the changes in character are relatively uniform or dependent on the instrument. A comparison of eight sustained instrument tones with different amounts and lengths of simple parametric reverberation over eight emotional characteristics was performed. The results showed a remarkable consistency in listener rankings of the instruments for each of the different types of reverberation with strong correlations ranging from 90 to 95%. This indicates that the underlying instrument space for emotional characteristics does not change significantly with reverberation. Each instrument has a particular footprint of emotional characteristics. Tested instruments cluster into two fairly distinctive groups: those where the positive energetic emotional characteristics are strong (e.g., oboe, trumpet, violin), and those where the low-arousal characteristics are strong (e.g., bassoon, clarinet, lute, horn). The saxophone was an outlier, and is somewhat strong for most emotional characteristics.","2016","2023-07-12 07:17:45","2023-07-19 04:31:59","","988–1002","","12","64","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4AXR22AT","journalArticle","2023","Engel, Isaac; Daugintis, Rapolas; Vicente, Thibault; Hogg, Aidan O. T.; Pauwels, Johan; Tournier, Arnaud J.; Picinali, Lorenzo","The SONICOM HRTF Dataset","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=22128","Immersive audio technologies, ranging from rendering spatialized sounds accurately to efficient room simulations, are vital to the success of augmented and virtual realities. To produce realistic sounds through headphones, the human body and head must both be taken into account. However, the measurement of the influence of the external human morphology on the sounds incoming to the ears, which is often referred to as head-related transfer function (HRTF), is expensive and time-consuming. Several datasets have been created over the years to help researcherswork on immersive audio; nevertheless, the number of individuals involved and amount of data collected is often insufficient for modern machine-learning approaches. Here, the SONICOM HRTF dataset is introduced to facilitate reproducible research in immersive audio. This dataset contains the HRTF of 120 subjects, as well as headphone transfer functions; 3D scans of ears, heads, and torsos; and depth pictures at different angles around subjects' heads.","2023","2023-07-12 07:17:48","2023-07-19 03:54:44","","241–253","","5","71","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DBHTVMPY","journalArticle","2015","Hendrickx, Etienne; Paquier, Mathieu; Koehl, Vincent","Audiovisual Spatial Coherence for 2D and Stereoscopic-3D Movies","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=18049","In movie theaters, sound sources such as dialog are often reproduced on the center loudspeaker without regard to the visual position on screen. Some sound engineers and researchers have suggested that spatial audiovisual coherence could improve the audience experience, especially for stereoscopic-3D (s-3D) movies. In the experiment described, subjects were asked to judge the suitability of several soundtracks for eight s-3D sequences. Depending on the soundtrack, sound sources could be more or less coherent in azimuth and depth. Results showed that sound suitability could be significantly improved for most of the sequences when coherence in azimuth was achieved. An improvement in the experience of depth was only observed with one sequence. When sequences were presented in nonstereoscopic (2D) version, there was no significant effect of stereoscopy. Subjects quickly became accustomed to azimuthal coherence, which improved sound suitability throughout the experiment. This suggests that the audience adaptation to a new cinematographic convention regarding spatialization of sound objects would not be a burden.","2015","2023-07-12 07:17:51","2023-07-19 04:05:04","","889–899","","11","63","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HG43S4L9","journalArticle","2021","Bown, Oliver; Ferguson, Sam; Dos Santos, Augusto Dias Pereira; Mikolajczyk, Kurt","Supporting Creative Practice in Wireless Distributed Sound Installations Given Technical Constraints","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=21470","","2021","2023-07-12 07:17:54","2023-07-12 07:17:54","","757–767","","10","69","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JHVR7NRY","journalArticle","1984","Staffeldt, Henrik","Measurement and Prediction of the Timbre of Sound Reproduction","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=4499","Based on experimental observations, models are derived which make possible the measurement and prediction of the timbre produced by a sound-reproducing system. The importance of using ear-related measuring techniques is emphasized if conformity of sound reproduction from different sound systems is the aim.","1984","2023-07-12 07:17:58","2023-07-19 04:49:01","","410–414","","6","32","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7IM3963H","journalArticle","2021","Heilemann, Michael C.; Anderson, David A.; Roessner, Stephen; Bocko, Mark F.","The Evolution and Design of Flat-Panel Loudspeakers for Audio Reproduction","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=21014","","2021","2023-07-12 07:18:01","2023-07-12 07:18:01","","27–39","","1/2","69","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B88DKIHP","journalArticle","2016","Drossos, Konstantinos; Kaliakatsos-Papakostas, Maximos; Floros, Andreas; Virtanen, Tuomas","On the Impact of The Semantic Content of Sound Events in Emotion Elicitation","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=18338","","2016","2023-07-12 07:18:04","2023-07-12 07:18:04","","525–532","","7/8","64","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DZVFLB6R","journalArticle","2021","Riionheimo, Janne; Lokki, Tapio","Movie Sound, Part 1: Perceptual Differences of Six Listening Environments","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=21016","The soundtracks of movies are composed and mixed in various listening environments and the final mix is reproduced in cinemas. The variation of electroacoustical properties between the rooms could be significant, and mixes do not translate easily from one location to another. This study aims to elicit the audible differences between six different movie listening environments, which are auralized to an anechoic listening room with 45 loudspeakers. A listening test was performed to determine the attributes that describe the alterations in the sound field between the rooms. Experienced listeners formulated a vocabulary and created an attribute set containing 19 descriptive attributes. The most important attribute was the sense of space when dialogue was evaluated. Moreover timbre and especially brightness were important when music was evaluated. Furthermore, the change of width and clarity of the sound field was considered important.","2021","2023-07-12 07:18:07","2023-07-19 04:40:45","","54–67","","1/2","69","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J7FNHF3T","journalArticle","1964","Olson, Harry F.","The RCA Victor DYNAGROOVE System","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=754","The RCA Victor DYNAGROOVE system is a comprehensive system of improvements in sound recording by means of disc records. All aspects of the process are taken into consideration, starting with the artist's conception of the music and ending with the reproduction of the sound in the listener's home.","1964","2023-07-12 07:18:11","2023-07-19 04:36:07","","98–114","","2","12","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9J72TBGK","journalArticle","2014","Borowiak, Adam; Reiter, Ulrich; Svensson, U. Peter","Momentary Quality of Experience: Users’ Audio Quality Preferences Measured Under Different Presentation Conditions","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=17135","Subjective evaluation of audio, video, and audiovisual material is typically performed in a static manner, after the sample has finished. This way, the possible temporal variability of the stimulus quality and its impact on quality perception are ignored. In this study, a new technique for momentary quality assessment was used in order to investigate the effect of content coherence/continuity as well as the influence of video stream on audio quality preferences. Obtained results show that the quality requirements are lower when the presented material is played in a continuous manner than when the same clip is cut into segments that are reproduced in a random order with short pauses in between. This may mean that subjective studies that use short audio stimuli extracted from long-duration content generate results that exaggerate the actual quality needs of consumers. Moreover, it has been shown that subjects’ quality preferences are higher when audio is played without the presence of an accompanying visual stimulus.","2014","2023-07-12 07:18:14","2023-07-19 03:44:15","","235–243","","4","62","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S5U9AL45","journalArticle","2020","Allan, Jon; Berg, Jan","Evaluation of the Momentary Time Scale for Live Loudness Metering","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=20729","Different ballistic definitions for the momentary time scale used in live loudness measurement were evaluated. Definitions from the ITU and EBU were compared as well as a faster version of the ITU version, two asymmetric time scales and the deprecated ballistics, defined in EBU Tech 3205-E, for peak program meters. The goal was to identify the ballistics definition that would function as the best complementary tool to a short-term time scale. Engineers within the broadcast industry and students in audio technology performed an audio alignment task in a simulated live broadcast environment using one ballistics definition per trial. Fader movements and output levels were recorded. After each trial, a set of assessment scales were rated by the subjects. Some results were: a decay time constant of 250 ms yielded better representation of the low-level parts of the dynamics in the signal compared to a 400-ms time constant; the present ITU version of the momentary time scale yielded an estimated less eye fatigue; effects on the resulting output levels, related the gate in ITU-R BS.1770 in conjunction with live compensation of unadjusted audio material were shown.","2020","2023-07-12 07:18:18","2023-07-19 03:35:53","","193–222","","3","68","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y324SHCL","journalArticle","1988","Toole, Floyd E.; Olive, Sean E.","The Modification of Timbre by Resonances: Perception and Measurement","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=5163","Resonances are fundamental to the production of musical pitch and timbre. they are also the principle source of coloration when they are added in the processes of sound recording and reproduction. The traditional problem in the design and evaluation of audio products has been to find the measurements necessary to recognize the presence of a resonance, the interpretation necessary to characterize its audibility, and the judgment of how much its form must be modified in order for it not to cause objectionable coloration. A review of previous work and new experimental results describe the thresholds of audibility of resonances as a function of frequency. Q, relative amplitude, time delay, program material, listener hearing performance, loudspeaker directivity, and terms of the measured amplitude and time responses of the systems through which the audio signal is passed. While the emphasis is on reproduced sound, there are some interesting relationships to the perceived timbre of sound in live performances.","1988","2023-07-12 07:18:21","2023-07-19 04:53:39","","122–142","","3","36","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"35MGLUIZ","journalArticle","1991","Macpherson, Ewan A.","A Computer Model of Binaural Localization for Stereo Imaging Measurement","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=5969","A binaural localization model has been developed for measuring the stereo imaging properties of recording and playback techniques. Ear signals from a dummy head are passed through a model of the inner ear, and interaural time and amplitude differences are extracted and processed to give image location and diffuseness. Experiments show that the model emulates human performance under anechoic and reverberant conditions.","1991","2023-07-12 07:18:25","2023-07-19 04:25:51","","604–622","","9","39","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4WW39QMA","journalArticle","2016","Reiss, Joshua D.","A Meta-Analysis of High Resolution Audio Perceptual Evaluation","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=18296","Over the last decade, there has been considerable debate over the benefits of recording and rendering high resolution audio beyond standard CD quality audio. This research involved a systematic review and meta-analysis (combining the results of numerous independent studies) to assess the ability of test subjects to perceive a difference between high resolution and standard (16 bit, 44.1 or 48 kHz) audio. Eighteen published experiments for which sufficient data could be obtained were included, providing a meta-analysis that combined over 400 participants in more than 12,500 trials. Results showed a small but statistically significant ability of test subjects to discriminate high resolution content, and this effect increased dramatically when test subjects received extensive training. This result was verified by a sensitivity analysis exploring different choices for the chosen studies and different analysis approaches. Potential biases in studies, effect of test methodology, experimental design, and choice of stimuli were also investigated. The overall conclusion is that the perceived fidelity of an audio recording and playback chain can be affected by operating beyond conventional resolution.","2016","2023-07-12 07:18:28","2023-07-19 04:40:27","","364–379","","6","64","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2TRH4KIL","journalArticle","2006","Neher, Tobias; Brookes, Tim; Rumsey, Francis","A Hybrid Technique for Validating Unidimensionality of Perceived Variation in a Spatial Auditory Stimulus Set","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=13675","Signal-processing algorithms that are meant to evoke a certain subjective effect often have to be perceptually equalized so that any unwanted artifacts are, as far as possible, eliminated. They can then be said to exhibit “unidimensionality of perceived variation.” Aiming to design a method that allows unidimensionality of perceived variation to be verified, established sensory evaluation approaches are examined in terms of their suitability for detailed, undistorted profiling and hence reliable validation of an algorithm’s subjective effects. It is found that a procedure combining multidimensional scaling with supplementary verbal elicitation constitutes the most appropriate approach. In the context of validating a signal-processing method intended to produce a specific spatial effect, this procedure is evaluated and some shortcomings are identified. However, following refinements, it is concluded that these can be overcome through additional data collection and analysis, resulting in a multistage hybrid validation technique.","2006","2023-07-12 07:18:32","2023-07-19 04:34:40","","259–275","","4","54","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CY9GW9VL","journalArticle","2021","Böhm, Christoph; Ackermann, David; Weinzierl, Stefan","A Multi-channel Anechoic Orchestra Recording of Beethoven’s Symphony No. 8 op. 93","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=21011","For the quality of model-based, virtual acoustic environments, not only the room acoustic simulation but also the quality and suitability of the source material play an important role. An optimal recording of real sound sources is characterized by an anechoic production and a high signal-to-noise ratio and crosstalk attenuation between the different recording channels. Furthermore a recording in the far field of the source is necessary to use correct directivities for room acoustic simulations. From an artistic point of view, the recording situation with its technical boundary conditions must be designed in a way that the musical or vocal rendering of professional performers is impaired as little as possible. To provide a high-quality source signal for acoustic simulations of orchestral content, a professional symphony orchestra was recorded in the anechoic chamber of TU Berlin performing the 8th Symphony of L. v. Beethoven. Through a combination of groupwise and sequential recordings with individual monitor mixes via headphones and video recordings of the conductor and concertmaster, an optimal compromise was sought with regard to artistic and technical aspects. The article presents the recording process and processing chain as well as the results achieved with respect to technical and artistical quality criteria.","2021","2023-07-12 07:18:36","2023-07-19 03:43:15","","977–984","","12","68","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T7DVPIRC","journalArticle","2018","Woodcock, James; Davies, William J.; Melchior, Frank; Cox, Trevor J.","Elicitation of Expert Knowledge to Inform Object-Based Audio Rendering to Different Systems","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=19375","Object-based audio (OBA) is an approach to sound storage, transmission, and reproduction whereby individual audio objects contain associated metadata information that is rendered at the client side of the broadcast chain. For example, metadata may indicate the object’s position and the level or language of a dialogue track. An experiment was conducted to investigate how content creators perceive changes in perceptual attributes when the same content is rendered to different systems and how they would change the mix if they had control of it. The main aims of this experiment were to identify a small number of the most common mix processes used by sound designers when mixing object-based content to loudspeaker systems with different numbers of channels and to understand how the perceptual attributes of OBA content changes when it is rendered to different systems. The goal is to minimize perceived changes in the context of standard Vector Base Amplitude Panning and matrix-based downmixes. Text mining and clustering of the content creators’ responses revealed 6 general mix processes: the spatial spread of individual objects, EQ and processing, reverberation, position, bass, and level. Logistic regression models show the relationships between the mix processes, perceived changes in perceptual attributes, and the rendering method/speaker layout. The relative frequency of different mix processes was found to differ among categories of audio object, suggesting that any downmix rules should be object category specific. These results give insight into how OBA can be used to improve listener experience.","2018","2023-07-12 07:18:39","2023-07-19 10:56:56","","44–59","","1/2","66","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SV344VRT","journalArticle","1980","Davis, Don; Davis, Chips","The LEDE- Concept for the Control of Acoustic and Psychoacoustic Parameters in Recording Control Rooms","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=3965","","1980","2023-07-12 07:18:42","2023-07-12 07:18:42","","585–595","","9","28","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ED86SUT2","journalArticle","1999","Savioja, Lauri; Huopaniemi, Jyri; Lokki, Tapio; Väänänen, Ritta","Creating Interactive Virtual Acoustic Environments","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=12095","The theory and techniques for virtual acoustic modeling and rendering are discussed. The creation of natural sounding audiovisual environments can be divided into three main tasks: sound source, room acoustics, and listener modeling. These topics are discussed in the context of both non-real-time and real-time virtual acoustic environments. Implementation strategies are considered, and a modular and expandable simulation software is described.","1999","2023-07-12 07:18:45","2023-07-19 04:46:56","","675–705","","9","47","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7GLQ43HN","journalArticle","1985","Fielder, Louis D.","Pre- and Postemphasis Techniques as Applied to Audio Recording Systems","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=4432","Audio recorders benefit from pre- and postemphasis, which reshapes the noise spectrum to match human audibility thresholds. A 10-dB increase in apparent dynamic range is realized for some digital audio systems. A first-order boost based on the CCITT J.17 preemphasis standard is shown to be appropriate for dynamic range expansion. A survey of peak acoustic levels present in 36 music performances is also included.","1985","2023-07-12 07:18:51","2023-07-19 03:57:37","","649–658","","9","33","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HJZE5SWN","journalArticle","2019","Rocamora, Martín; Cancela, Pablo; Biscainho, Luiz W.P.","Information Theory Concepts Applied to the Analysis of Rhythm in Recorded Music with Recurrent Rhythmic Patterns","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=20449","This paper proposes a novel approach for rhythmic analysis of recorded percussion music based on information theory. Given an audio recording of a percussion music performance, the algorithm computes a lossy representation that captures much of its underlying regularity but tolerates some amount of distortion. Within a rate-distortion theory framework, the trade-off between rate and distortion allows for the extraction of some relevant information about the performance. Downbeat detection is addressed using lossy coding of an accentuation feature under rate-distortion criteria assuming the correct alignment produces the simplest explanation for the data. Experiments were conducted in order to assess the usefulness of the proposed approach when applied to a dataset of candombe drumming audio recordings. In particular, different performances were compared according to a measure of their overall complexity drawn from the operational rate-distortion curve, yielding results that roughly correspond to subjective judgment and correlate well with personal style and expertise.","2019","2023-07-12 07:18:55","2023-07-19 04:41:03","","160–173","","4","67","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RBNED2DK","journalArticle","2017","Frank, Matthias; Sontacchi, Alois","Case Study on Ambisonics for Multi-Venue and Multi-Target Concerts and Broadcasts","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=19204","Ambisonics is a production format that can be used for 3D audio. It is based on the representation of the sound field by decomposing it into orthonormal basis functions, called spherical harmonics. This representation allows for a flexible production process that is independent of the target playback system, be it loudspeakers or headphones. The concert night at the International Conference on Spatial Audio 2015 employed the Ambisonics format to distribute the concert to different venues and broadcasts in real time: a concert venue with a 29-channel loudspeaker system, a monitor venue with a 25-channel loudspeaker system, an outside broadcasting van with a 23-channel loudspeaker system, as well as a 5.1 mixdown and a binaural headphone mixdown for national terrestrial and satellite radio broadcasting. This flexibility is achieved by the computation of suitable decoder matrices and weightings. The success of the sound system at ICSA 2015 encouraged the authors to carry out a live 3D concert with Al Di Meola in July 2016 that included spatial real-time effects and transmission to a neighboring venue.","2017","2023-07-12 07:18:59","2023-07-19 04:00:53","","749–756","","9","65","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DTPD2H29","journalArticle","2012","Lindau, Alexander; Kosanke, Linda; Weinzierl, Stefan","Perceptual Evaluation of Model- and Signal-Based Predictors of the Mixing Time in Binaural Room Impulse Responses","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=16633","When creating virtual acoustic environments, the computational demands can be reduced by using generic late reverberation. Beyond the “mixing time,” the diffuse reverberation no longer contains details of the specific location. Therefore, a perceptually validated model for predicting the mixing time of different spaces will be helpful. This study evaluates various predictors of the perceptual mixing time using 9 different spaces. Both model- and signal-based estimators of mixing time were examined for their ability to predict the results of a group of expert listeners. For a shoebox-shaped room, the average perceptual mixing time can be predicted by the enclosure’s ratio of volume over surface area V/S and by vV, which serve as indicators of the mean free path length and the reflection density, respectively. Moreover, the “echo density profile” by Abel and Huang (AES paper 6985) can be used to predict the perceptual mixing time from measured data.","2012","2023-07-12 07:19:07","2023-07-19 04:20:25","","887–898","","11","60","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2TQTJBR9","journalArticle","2023","Doma, Shaimaa; Ermert, Cosima A.; Fels, Janina","A Magnitude-Based Parametric Model Predicting the Audibility of HRTF Variation","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=22038","This work proposes a parametric model for just noticeable differences of unilateral differences in head-related transfer functions (HRTFs). For seven generic magnitude-based distance metrics, common trends in their response to inter-individual and intra-individual HRTF differences are analyzed, identifying metric subgroups with pseudo-orthogonal behavior. On the basis of three representative metrics, a three-alternative forced-choice experiment is conducted, and the acquired discrimination probabilities are set in relation with distance metrics via different modeling approaches. A linear model, with coefficients based on principal component analysis and three distance metrics as input, yields the best performance, compared to a simple multi-linear regression approach or to principal component analysis--based models of higher complexity.","2023","2023-07-12 07:19:10","2023-07-19 03:53:32","","155–172","","4","71","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W38FDB6M","journalArticle","1991","Wöhr, Martin; Theile, Günther; Goeres, Hans-Jürgen; Persterer, Alexander","Room-Related Balancing Technique: A Method for Optimizing Recording Quality","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=5968","","1991","2023-07-12 07:19:12","2023-07-12 07:19:12","","623–631","","9","39","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VMF435V4","journalArticle","1993","Horner, Andrew; Beauchamp, James; Haken, Lippold","Methods for Multiple Wavetable Synthesis of Musical Instrument Tones","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=7003","Spectrum matching of musical instrument tones is a fundamental problem in computer music. Two methods are presented for determining near-optimal parameters for the synthesis of harmonic musical instrument orvoice sounds using the addition of several fixed wavetables with time-varying weights. The overall objective is to find wavetable spectra and associated amplitude envelopes which together provide a close fit to an original time-varying spectrum. Techniques used for determining the wavetable spectra include a genetic algorithm (GA) and principal components analysis (PCA). In one study a GA was used to select spectra from the original signal at various time points. In another study PCA was used to obtain a set of orthogonal basis spectra for the wavetables. In both cases, least-squares solution is utilized to determine the associated amplitude envelopes. Both methods provide solutions which converge gracefully to the original as the number of tables is increased, but three to five wavetables frequently yield a good replica of the original sound. For the three instruments we analyzed, a trumpet, a guitar, and a tenor voice, the GA method seemed to offer the best results, especially when less than four wavetables were used. Comparative results using the methods are discussed and illustrated.","1993","2023-07-12 07:19:20","2023-07-19 04:06:44","","336–356","","5","41","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NKSELW2D","journalArticle","1972","Cable, Cecil R.","Acoustics and the Active Enclosure","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=2019","When a sound reinforcement is introduced into any passive acoustic enclosure, it becomes an integral element of the total acoustical network. Factors governing the -acoustics- become more controllable. Planning of the enclosure may profitably include the active elements to optimize the total network. Simplified formulas and a ready reckoner provide means to predict the final realization with greater accuracy.","1972","2023-07-12 07:19:22","2023-07-19 03:46:15","","823–826","","10","20","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3SCDJG24","journalArticle","2023","Pedersen, Rasmus Lundby; Picinali, Lorenzo; Kajs, Nynne; Patou, François","Virtual-Reality-Based Research in Hearing Science: A Platforming Approach","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=22144","","2023","2023-07-12 07:19:24","2023-07-12 07:19:24","","374–389","","6","71","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EAWL6HCB","journalArticle","1965","Clark, Melville; Luce, David","Intensities of Orchestral Instrument Scales Played at Prescribed Dynamic Markings","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=1209","The intensities of scales played on nonpercussive orchestral instruments at various dynamic markings and the resulting dynamic ranges are reported. We are able to deduce the size of quanta corresponding to one step in a dynamic marking and the numer of quanta in the dynamic range of a musical instrument using deviations from smoothed curves. The average dynamic range of the nonpercussive orchestral instruments is about 11 db between the dynamic markings of pianissimo and fortissimo; the average intensity level at 10 meters is about 59 db re 0.0002 dynes/cm/2.","1965","2023-07-12 07:19:33","2023-07-19 03:48:36","","151–157","","2","13","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5I9H6QJ9","journalArticle","2015","Kendrick, Paul; Li, Francis; Fazenda, Bruno; Jackson, Iain; Cox, Trevor","Perceived Audio Quality of Sounds Degraded by Nonlinear Distortions and Single-Ended Assessment Using HASQI","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=17873","","2015","2023-07-12 07:19:36","2023-07-12 07:19:36","","698–712","","9","63","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BCHHZEZR","journalArticle","1985","Toole, Floyd E.","Subjective Measurements of Loudspeaker Sound Quality and Listener Performance","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=4465","With adequate attention to the details of experiment design and the selection of participants, listening tests on loudspeakers yielded sound-quality ratings that were both reliable and repeatable. Certain listeners differed in the consistency of their ratings and in the ratings themselves. These differences correlated with both hearing threshold levels and age. Listeners with near normal hearing thresholds showed the smallest individual variations and the closest agreement with each others. Sound-quality ratings changed as a function of the hearing threshold level and age of the listener. The amount and direction of the change depended upon the specific products; some products were rated similarly by all listeners, whereas others had properties that caused them to be rated differently. Stereophonic and monophonic tests yielded similar sound-quality ratings for highly rated products, but in stereo, listeners tended to be less consistent and less critifal of products with distinctive characteristics. Assessments of stereophonic spatial and image qualities were closely related to sound-quality ratings. The relationship between these results and objective performance data is being pursued.","1985","2023-07-12 07:19:40","2023-07-19 04:53:21","","2–32","","1/2","33","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EZQCJNUV","journalArticle","2023","Meyer-Kahlen, Nils; Kastemaa, Miranda; Schlecht, Sebastian J.; Lokki, Tapio","Measuring Motion-to-Sound Latency in Virtual Acoustic Rendering Systems","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=22145","","2023","2023-07-12 07:19:43","2023-07-12 07:19:43","","390–398","","6","71","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K7QGM9UM","journalArticle","2013","Igumbor, Osedum P.; Foss, Richard","Control Protocol Command Translation for Device Interoperability on Ethernet AVB Networks","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=16707","Audio/Video Bridging (AVB) on Ethernet refers to a suite of standards that allows for deterministic and guaranteed delivery of audio and video content on Virtual Local Area Networks (VLAN). A requirement for the networking of audio devices is to allow for remote establishment and destruction of audio stream connections. There are a number of sound control protocols that utilize AVB transport, and this paper describes an approach for common control and interoperability among them. To demonstrate this approach, this paper describes the design and implementation of a command translator that enables communication between AES64 and OSC-networked AVB devices. Results from a quantitative analysis reveal that when a proxy is used for connection management, noticeable delays are not added to a user’s visual and auditory perception.","2013","2023-07-12 07:19:54","2023-07-19 04:07:46","","224–234","","4","61","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ESFUNTRP","journalArticle","2009","Stone, Michael A.; Moore, Brian C. J.; Füllgrabe, Christian; Hinton, Andrew C.","Multichannel Fast-Acting Dynamic Range Compression Hinders Performance by Young, Normal-Hearing Listeners in a Two-Talker Separation Task","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=14833","Because of the well-known benefits of dynamic range compression, sound engineers routinely use this tool as a normal part of their professional activities. Hearing aid designers also use compression. However, compression can impede perception of independent sound sources in a complex aural environment. When normal young listeners were given the task of recognizing keywords from two simultaneous talkers, their performance worsened when compression was applied to the mixed signal. Even when performance remained unchanged, the cognitive load, as measured using a secondary task, increased significantly. The results indicate that excessive compression can lead to increased listening effort.","2009","2023-07-12 07:19:58","2023-07-19 04:49:52","","532–546","","7/8","57","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UZ58CT84","journalArticle","2022","Liu, Lulu; Xie, Bosun","A High-Frequency–Band Timbre Equalization Method for Transaural Reproduction With Two Frontal Loudspeakers","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=21549","Non-ideal conditions in actual transaural reproduction, such as a slightly off-central listening position and reflections in the listening room, can impair the perfect reconstruction of binaural pressures and give rise to perceived timbre coloration. In the present work, a high-frequency band equalization method is proposed to further reduce the timbre coloration in transaural reproduction with two frontal loudspeakers. The high-frequency responses of a pair of transaural filters are equalized by a frequency-dependent factor so that the overall power spectra of the responses remain constant, and the low-frequency responses of transaural filters are kept intact. An analysis using Moore's revised loudness model indicates that the proposed method reduces the deviation between the binaural loudness level spectra in transaural reproduction and those of the target sound source. A further psychoacoustic experiment validates that the proposed method reduces the timbre coloration in transaural reproduction without introducing an obvious perceivable directional distortion for virtual source in the frontal quadrants of the horizontal plane.","2022","2023-07-12 07:20:01","2023-07-19 04:21:07","","36–49","","1/2","70","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YT6NGJ5H","journalArticle","2006","Weisser, Adam; Rindel, Jens Holger","Evaluation of Sound Quality, Boominess, and Boxiness in Small Rooms","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=13688","The acoustics of small rooms have been studied with emphasis on sound quality, boominess, and boxiness when the rooms are used for speech or music. Seven rooms with very different characteristics were used for the study. Subjective listening tests were made using binaural recordings of studio-produced music and anechoic speech. The test results were compared with a large number of objective acoustic parameters based on the frequencydependent reverberation times (RT) measured in the rooms. This has led to the proposal of three new acoustic parameters, which have shown high correlation with the subjective ratings. The classical bass ratio definitions showed poor correlation with all subjective ratings. The overall sound quality ratings gave different results for speech and music. For speech the preferred mean RT should be as low as possible, whereas for music a preferred range of between 0.3 and 0.5 s was found.","2006","2023-07-12 07:20:05","2023-07-19 10:54:48","","495–511","","6","54","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G7KYFK9Y","journalArticle","2018","Baird, Alice; Jørgensen, Stina Hasse; Parada-Cabaleiro, Emilia; Cummins, Nicholas; Hantke, Simone; Schuller, Björn","The Perception of Vocal Traits in Synthesized Voices: Age, Gender, and Human Likeness","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=19393","As computer-generated voice synthesis has become a significant part of communications between computers and people, there is a need to understand the role of paralinguistic attributes of the voice, such as age, personality, and gender. In many cases, the synthesized voice is produced by concatenating segments of recorded human speech, which can be experienced as a lifeless voice that lacks free expression and fluidness. Technology companies have been developing their own unique synthesized voice identities without paying attention to the stereotypical traits being heard. This study evaluated the responses of 18 listeners who were asked to consider the paralinguistic traits of age, gender, and human likeness from 13 voices in IBM’s Watson corpus. The results of this study were similar to a previous study, with no voice achieving complete human likeness, no voice being perceived within a single age frequency band, and none tied solidly to their given binary gender.","2018","2023-07-12 07:20:08","2023-07-19 03:38:20","","277–285","","4","66","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EQ9H9Y6B","journalArticle","2016","Bitzer, Joerg; Kissner, Sven; Holube, Inga","Privacy-Aware Acoustic Assessments of Everyday Life","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=18298","","2016","2023-07-12 07:20:11","2023-07-12 07:20:11","","395–404","","6","64","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T72GBYXK","journalArticle","2023","Lee, Ben; Rudzki, Tomasz; Skoglund, Jan; Kearney, Gavin","Context-Based Evaluation of the Opus Audio Codec for Spatial Audio Content in Virtual Reality","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=22037","This paper discusses the evaluation of Opus-compressed Ambisonic audio content through listening tests conducted in a virtual reality environment.The aim of this studywas to investigate the effect that Opus compression has on the Basic Audio Quality (BAQ) of Ambisonic audio in different virtual reality contexts---gaming, music, soundscapes, and teleconferencing. The methods used to produce the test content, how the tests were conducted, the results obtained and their significance are discussed. Key findings were that in all cases, Ambisonic scenes compressed with Opus at 64 kbps/ch using Channel Mapping Family 3 garnered a median BAQ rating not significantly different than uncompressed audio. Channel Mapping Family 3 demonstrated the least variation in BAQ across evaluated contexts, although there were still some significant differences found between contexts at certain bitrates and Ambisonic orders.","2023","2023-07-12 07:20:14","2023-07-19 04:18:15","","145–154","","4","71","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VFSMRXBJ","journalArticle","2017","Francombe, Jon; Brookes, Tim; Mason, Russell; Woodcock, James","Evaluation of Spatial Audio Reproduction Methods (Part 2): Analysis of Listener Preference","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=18556","","2017","2023-07-12 07:20:17","2023-07-12 07:20:17","","212–225","","3","65","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LHDPM8QH","journalArticle","2011","George, Sunish; Zielinski, Slawomir; Rumsey, Francis; Jackson, Philip; Conetta, Robert; Dewhirst, Martin; Meares, David; Bech, Søren","Development and Validation of an Unintrusive Model for Predicting the Sensation of Envelopment Arising from Surround Sound Recordings","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=15743","An objective prediction model for the sensation of sound envelopment in five-channel reproduction is important for evaluating spatial quality. Regression analysis was used to map the listening test scores on a variety of audio sources and the objective measures extracted from the recordings themselves. By following an iterative process, a prediction model with five features was constructed. The validity of the model was tested in a second set of subjective scores and showed a correlation coefficient of 0.9. Among the five features: sound distribution and interaural cross-correlation contributed substantially to the sensation of envelopment. The model did not require access to the original audio. Scales used for listening tests were defined by audible anchors.","2011","2023-07-12 07:20:20","2023-07-19 04:02:07","","1013–1031","","12","58","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DKLKGZD9","journalArticle","2019","Paulus, Jouni; Torcoli, Matteo; Uhle, Christian; Herre, Jürgen; Disch, Sascha; Fuchs, Harald","Source Separation for Enabling Dialogue Enhancement in Object-based Broadcast with MPEG-H","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=20489","","2019","2023-07-12 07:20:23","2023-07-12 07:20:23","","510–521","","7/8","67","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YVTJIZ5J","journalArticle","2015","Lee, Hyunkook","2D-to-3D Ambience Upmixing based on Perceptual Band Allocation","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=18044","3D multichannel audio systems employ additional elevated loudspeakers in order to provide listeners with a vertical dimension to their auditory experience. Listening tests were conducted to evaluate the feasibility of a novel vertical upmixing technique called “perceptual band allocation (PBA),” which is based on a psychoacoustic principle of vertical sound localization, the “pitch height” effect. The practical feasibility of the method was investigated using 4-channel ambience signals recorded in a reverberant concert hall using the Hamasaki-Square microphone technique. Results showed that the PBA-upmixed 3D stimuli were significantly stronger than or similar to 9-channel 3D stimuli in 3D listener-envelopment (LEV), depending on the sound source and the crossover frequency of PBA. They also significantly produced greater 3D LEV than the 7-channel 3D stimuli. For the preference tests, the PBA stimuli were significantly preferred over the original 9-channel stimuli.","2015","2023-07-12 07:20:26","2023-07-19 04:18:24","","811–821","","10","63","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KTZJYHC9","journalArticle","2022","Agrawal, Sarvesh; Bech, Søren; De Moor, Katrien; Forchhammer, Søren","Influence of Changes in Audio Spatialization on Immersion in Audiovisual Experiences","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=22009","Understanding the influence of technical system parameters on audiovisual experiences is important for technologists to optimize experiences. The focus in this study was on the influence of changes in audio spatialization (varying the loudspeaker configuration for audio rendering from 2.1 to 5.1 to 7.1.4) on the experience of immersion. First, a magnitude estimation experiment was performed to perceptually evaluate envelopment for verifying the initial condition that there is a perceptual difference between the audio spatialization levels. It was found that envelopment increased from 2.1 to 5.1 reproduction, but there was no significant benefit of extending from 5.1 to 7.1.4. An absolute-rating experimental paradigm was used to assess immersion in four audiovisual experiences by 24 participants. Evident differences between immersion scores could not be established, signaling that a change in audio spatialization and subsequent change in envelopment does not guarantee a psychologically immersive experience.","2022","2023-07-12 07:20:32","2023-07-19 03:34:32","","810–823","","10","70","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NZ3HYX63","journalArticle","2013","Kim, Chungeun; Mason, Russell; Brookes, Tim","Head Movements Made by Listeners in Experimental and Real-Life Listening Activities","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=16833","Understanding the way in which listeners move their heads must be part of any objective model for evaluating and reproducing the sonic experience of space. Head movement is part of the listening experience because it allows for sensing the spatial distribution of parameters. In the first experiment, the head positions of subjects was recorded when they were asked to evaluate perceived source location, apparent source width, envelopment, and timbre of synthesis stimuli. Head motion was larger when judging source width than when judging direction or timbre. In the second experiment, head movement was observed in natural listening activities such as concerts, movies, and video games. Because the statistics of movement were similar to that observed in the first experiment, laboratory results can to be used as the basis of an objective model of spatial behavior. The results were based on 10 subjects.","2013","2023-07-12 07:20:35","2023-07-19 04:11:32","","425–438","","6","61","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YY6VTWW2","journalArticle","2013","Rohr, Lukas; Corteel, Etienne; Nguyen, Khoa-Van; Lissek, Hervé","Vertical Localization Performance in a Practical 3-D WFS Formulation","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=17077","An experimental study investigated the performance of an innovative Wave Field Synthesis (WFS) system in terms of a listener’s ability to localize sound sources in the median plane. Performance was measured by localization accuracy, precision and response time under a variety of conditions that included two seating positions, five levels of elevations, and two spatial precision settings. Localization precision was 6°– 9° with only 24 loudspeakers in the WFS system covering the frontal quarter of the upper half sphere of the listening space. Localization performance was good in comparison to other studies with denser loudspeaker arrays or with other reproduction techniques. The implemented 3-D WFS technique is a serious alternative to other state-of-the-art spatialization methods.","2013","2023-07-12 07:20:38","2023-07-19 04:41:30","","1001–1014","","12","61","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DYSURFGX","journalArticle","1992","Jason, M. Raymond","Design Considerations for Loudspeaker Preference Experiments","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=7018","An overview is presented of some theoretical and practical problems in the experimental design of preference-based listening tests on loudspeakers. Measurement scales, statistical design techniques, and physical, procedural, and psychological variables are considered. Some consequences of present limitations in observation and theory are discussed. Specific improvements in design strategy are suggested.","1992","2023-07-12 07:20:41","2023-07-19 04:08:22","","979–996","","12","40","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9XEL6WI5","journalArticle","2021","Arend, Johannes M.; Brinkmann, Fabian; Pörschmann, Christoph","Assessing Spherical Harmonics Interpolation of Time-Aligned Head-Related Transfer Functions","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=21019","High-quality spatial audio reproduction over headphones requires head-related transfer functions (HRTFs) with high spatial resolution. However, acquiring datasets with a large number of (individual) HRTFs is not always possible, and using large datasets can be problematic for real-time applications with limited resources. Consequently, interpolation methods for sparsely sampled HRTFs are of great interest, with spherical harmonics (SH) interpolation becoming increasingly popular. However, the SH representation of sparse HRTFs suffers from spatial aliasing and order truncation errors. To mitigate this, preprocessing methods have been introduced that time-align the sparse HRTFs before SH interpolation. This reduces the effective SH order and thus the number of HRTFs required for SH interpolation. In this paper, we present a physical evaluation of four state-of-the-art preprocessing methods, which showed very similar performance of the methods with notable differences only at low SH orders and contralateral HRTFs. We also performed a listening experiment with one selected method to determine the minimum required SH order required for perceptually transparent interpolation. For the selected method, a sparse HRTF set of order N ˜ 7 is sufficient for interpolating a frontal source presenting speech or percussion. Higher orders are, however, required for a lateral source and noise.","2021","2023-07-12 07:20:44","2023-07-19 03:37:11","","104–117","","1/2","69","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4F4URDU8","journalArticle","2009","Martin, Aengus; Jin, Craig; Schaik, André van","Psychoacoustic Evaluation of Systems for Delivering Spatialized Augmented-Reality Audio","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=15234","","2009","2023-07-12 07:20:47","2023-07-12 07:20:47","","1016–1027","","12","57","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9RK8QBNN","journalArticle","2005","Knox, Don; Bailey, Nicholas; Stewart, Iain","A Simple Hybrid Approach to the Time-Scale Modification of Speech","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=13429","Time-domain methods of time-scale modification (TSM) are attractive from the point of view of computational effort. However, they suffer from audible artifacts for larger timestretch ratios (greater than 1.3 times the original duration). The occurrence of these artifacts is often the main justification for the use of more involved analysis/synthesis methods at these ratios. For speech signals these artifacts take the form of transient repetition—causing a “stuttering” effect and roughness due to spectral mismatch at segment boundaries—most obvious during voiced signal periods. These phenomena are not addressed by existing timedomain methods. A simple hybrid algorithm utilizing both time-domain and analysis/synthesis methods is presented which illustrates how these distortions may be minimized. Results of formal listening tests illustrate an improvement in basic audio quality for timestretched speech signals when compared to equivalent samples processed by the synchronized overlap and add (SOLA) algorithm.","2005","2023-07-12 07:20:51","2023-07-19 04:15:41","","612–619","","7/8","53","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D7P65JGV","journalArticle","2018","Mäkivirta, Aki; Liski, Juho; Välimäki, Vesa","Modeling and Delay-Equalizing Loudspeaker Responses","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=19869","This paper focuses on the modeling of the linear properties of loudspeakers. The impulse response of a generalized multi-way loudspeaker is modeled and delay-equalized using digital filters. The dominant features of a loudspeaker are its low- and high-frequency roll-off characteristics and its behavior at the crossover points. The proposed loudspeaker model also characterizes the main effects of the mass-compliance resonant system. The impulse response, its logarithm and spectrogram, and the magnitude and group-delay responses are visualized and compared with those measured from a high-quality two-way loudspeaker. The model explains the typical local group-delay variations and magnitude-response deviations from a flat response in the passband. The group-delay equalization of a three-way loudspeaker is demonstrated with three different methods. Time-alignment of the tweeter and midrange elements using a bulk delay is shown to cause ripple in the magnitude response. The frequency-sampling method for the design of an FIR group-delay equalizer is detailed and is used to flatten the group delay of the speaker model in both the whole and limited audio range. The full-band equalization is shown to lead to preringing in the impulse response. In contrast, group-delay equalization at mid- and high-frequencies only reduces the length of the loudspeaker impulse response without introducing preringing.","2018","2023-07-12 07:20:54","2023-07-19 04:26:25","","922–934","","11","66","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N7RU7ATZ","journalArticle","2016","Sunder, Kaushik; Gan, Woon-Seng","Individualization of Head-Related Transfer Functions in the Median Plane using Frontal Projection Headphones","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=18536","Using nonindividualized HRTFs in virtual audio synthesis produces front-back confusions, up-down reversals, in-head localization, and timbral coloration. Elevation and frontal localization are found to be most affected. In contrast, obtaining individualized HRTFs is a tedious process that involves complex acoustical measurements for each individual. Having a model of HRTF that does not involve tedious acoustical measurements would make the process much easier. In this research, individualization of the median plane HRTFs is explored using frontal projection headphones with a spherical head model because the frontal positioning of the headphone transducer inherently captures the idiosyncratic frontal spectral cues. To create the HRTFs, the important peaks (P1) and notches (N1, N2) are extracted first from the frontal headphone response and then shifted in frequency in accordance with the elevation angle. Detailed subjective experiments indicated that subjects were able to localize the virtual sound sources accurately with modeled HRTFs with results similar to individualized HRTFs.","2016","2023-07-12 07:20:57","2023-07-19 04:50:48","","1026–1041","","12","64","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SZBBZHZ6","journalArticle","2001","Czerwinski, Eugene; Voishvillo, Alexander; Alexandrov, Sergei; Terekhov, Alexander","Multitone Testing of Sound System Components'Some Results and Conclusions, Part 2: Modeling and Application","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=10168","An historical retrospective analysis of the measurement of nonlinearities in audio is carried out. A quantitative analysis of the responses of various nonlinear systems (theoretical and experimental) to a multitone signal is made, and multitone testing is compared to conventional harmonic and intermodulation measurements. The multitone test provides more accurate information about the behavior of nonlinear systems when compared to standard harmonic, two-tone intermodulation, and total harmonic distortion measurements. Modeling of the nonlinear reaction of various sound system components to a multitone signal is described.","2001","2023-07-12 07:21:01","2023-07-19 03:51:18","","1181–1192","","12","49","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NSF3AICZ","journalArticle","1994","Han, H. L.","Measuring a Dummy Head in Search of Pinna Cues","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=6964","Extensive measurements were performed on a dummy head to investigate how the pinnae encode directional information. Transfer functions and impulse responses were examined to identify the features that contribute to localization. The reults suggest that near-vertical spectral edges play a major role. This finding sheds a new light on the relationship between the characteristics of the external car and the results of earlier psychophysical experiments by Blauert and by Hebrank and Wright.","1994","2023-07-12 07:21:04","2023-07-19 04:03:20","","15–37","","1/2","42","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LVY9ZCUA","journalArticle","1995","Oomen, Werner; Groenewegen, Marc E.; van der Waal, Robbert G.; Veldhuis, Raymond","A Variable-Bit-Rate Buried-Data Channel for Compact Disc","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=7963","Recently an elegant method was published to add buried data to a CD signal in a compatible way. This method is based on subtractively dithered noise-shaped quantization and provides a fixed-rate buried-data channel. An adaptive extension to this method, resulting in a variable rate of higher average value, is described.","1995","2023-07-12 07:21:08","2023-07-19 04:36:26","","23–28","","1/2","43","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3Z78F8BF","journalArticle","1969","Klipsch, Paul W.","Modulation Distortion in Loudspeakers","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=1593","When comparing a loudspeaker with direct radiator bass system to one with horn loaded bass, the subjective judgment is that the one with the horn loaded bass is -cleaner.- The difference in listening quality appears to be due to modulation distortion. The mathematical analysis of modulation distortion is reviewed and spectrum analyzer measurements are described which have been correlated with listening tests. The spectrum analyses corroborate the mathematical analysis and the listening tests offer a subjective evaluation. It is concluded that frequency modulation in loudspeakers accounts in large measure for the masking of -inner voices.- Reduction of diaphragm excursions at low frequencies reduces FM distortion. Horn loading, properly applied, offers greatest reduction, while simultaneously improving bass power output capability.","1969","2023-07-12 07:21:12","2023-07-19 04:15:31","","194, 196, 198, 200, 202, 204, 206","","2","17","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3PXY92IU","journalArticle","2018","Agus, Natalie; Anderson, Hans; Chen, Jer-Ming; Lui, Simon; Herremans, Dorien","Minimally Simple Binaural Room Modeling Using a Single Feedback Delay Network","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=19862","The widespread adoption of acoustic modeling in such applications as 3D gaming and virtual reality simulation are generally hindered by the complexity of the implementation. The most efficient binaural acoustic modeling systems use a multi-tap delay to generate early reflections, which are then combined with a feedback delay network to produce generic late reverberation. This report presents a method of binaural acoustic simulation that uses one feedback delay network to simultaneously model both first-order reflections and late reverberation. The advantages are simplicity and efficiency. The proposed method is compared to existing methods for modeling binaural early reflections using a multi-tap delay line. Measurements of ISO standard evaluators including interaural correlation coefficient, decay time, clarity, definition, and center time indicate that the proposed method achieves a comparable accuracy to less efficient methods. The proposed method is implemented as an iOS application, and is able to auralize input signal directly without convolution and update in real time. This significantly reduces the computational time because it does not need to produce an impulse response after every parameter update.","2018","2023-07-12 07:21:15","2023-07-19 03:35:10","","791–807","","10","66","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9ERQQ7G8","journalArticle","1999","Preis, Douglas; Georgopoulos, Voula Chris","Wigner Distribution Representation and Analysis of Audio Signals: An Illustrated Tutorial Review","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=12082","The Wigner distribution provides a visual disply of quantitative information about how a signal's energy is distributed in both time and frequency. Through its low-order moments the Wigner distribution embodies the fundamentally important concepts of both Fourier analysis and time-domain analysis. Signal energy is distributed in such a way that specific frequencies are localized in time by the group-delay time (from classical filter Theory), and at specific instants in time the frequency is given by the instanteous frequency (from classical modulation theory). The energy spectrum (energy per frequency) and the instantaneous power (energy per time) are specified by the zero-order moments of the distribution. The net positive volume of the Wigner distribution is numerically equal to the signal's total energy. While the theoretical underpinnings of the Wigner distibution are mathematically elegant and do merit in-depth study, a substantial amount of practical insignt, understanding, and interpretive skill can be gained by carefully examining a wide variety of computed Wigner distributions such as those of the audio signals presented.","1999","2023-07-12 07:21:19","2023-07-19 04:39:01","","1043–1053","","12","47","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y9D5TQR9","journalArticle","2006","Corteel, Etienne","Equalization in an Extended Area Using Multichannel Inversion and Wave Field Synthesis","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=13892","Wave field synthesis (WFS) targets the synthesis of the physical characteristics of a sound field in an extended listening area. This synthesis is, however, accompanied by noticeable reconstruction artifacts. They are due to both loudspeaker radiation characteristics and approximations to the underlying physical principles. These artifacts may introduce coloration, which must be compensated for over the entire listening area. Multichannel equalization techniques allow for the control of the sound field produced by a loudspeaker array at a limited number of positions. The control can be extended to a large portion of space by employing a new method that combines multichannel equalization with a linear microphone array–based description of the sound field and accounts for WFS rendering characteristics and limitations. The proposed method is evaluated using an objective coloration criterion. Its benefits compared to conventional equalization techniques are pointed out for both ideal omnidirectional loudspeakers and multi-actuator panels.","2006","2023-07-12 07:21:22","2023-07-19 03:50:03","","1140–1161","","12","54","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7QXQW2ZM","journalArticle","1999","Beerends, John G.; De Caluwe, Frank E.","The Influence of Video Quality on Perceived Audio Quality and Vice Versa","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=12105","","1999","2023-07-12 07:21:25","2023-07-12 07:21:25","","355–362","","5","47","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DN3SAW56","journalArticle","1969","Luce, David; Clark, Melville, Jr.","A Real-Time Multipartial Waveform Analyzer-Synthesizer","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=1567","","1969","2023-07-12 07:21:28","2023-07-12 07:21:28","","439–444","","4","17","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D6MSAC8W","journalArticle","2020","Agrawal, Sarvesh; Simon, Adèle; Bech, Søren; Bæntsen, Klaus; Forchhammer, Søren","Defining Immersion: Literature Review and Implications for Research on Audiovisual Experiences","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=20857","The use of the term immersion to describe a multitude of varying experiences in the absence of a definitional consensus has obfuscated and diluted the term. The non-exhaustive literature review presented in this paper indicates that immersion is a psychological concept as opposed to being a property of the system or technology that facilitates an experience. An adaptable definition of immersion is synthesized based on the findings from the literature review: a state of deep mental in- volvement in which the individual may experience disassociation from the awareness of the physical world due to a shift in their attentional state. This definition is used to contrast and differentiate interchangeably used terms such as presence from immersion and outline the implications for conducting immersion research on audiovisual experiences. A new methodology for quantifying immersion is proposed and avenues for future work are briefly discussed.","2020","2023-07-12 07:21:31","2023-07-19 03:34:48","","404–417","","6","68","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UXB9JZ6V","journalArticle","2022","Gareis, Michael; Maas, Jürgen","Buckling Dielectric Elastomer Transducers as Loudspeakers","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=22012","In recent decades, dielectric elastomers (DE) have emerged as a promising transducing principle for various applications. They promise to be lightweight, efficient, and affordable alternatives to conventional electrodynamic or piezoelectric transducers and show large deformations at fast rates. In this work a loudspeaker concept is proposed, which relies on the elastic instability of a DE membrane. A multilayered DE membrane is clamped in a circular ring. Upon applying a DC voltage, its area increases, and themembrane buckles up. A superimposed signal voltage induces vibration and generates sound. To model the device mechanically, a system of partial differential equations is derived from Hamilton's principle. The mechanical model is then coupled to the linear assumed electrical and acoustical domains. Static, dynamic, and acoustic experiments on buckling DE transducers of three different diameters (10, 15, and 20 mm) and different thicknesses (0.4mmto 0.6 mm) as multilayer configurations are conducted to validate the model. Sound pressure levels of about 70 dB above 1 kHz are reached. Small loudspeakers like this may find application in mobile or array systems.","2022","2023-07-12 07:21:35","2023-07-19 04:01:27","","858–870","","10","70","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PYJB9BZL","journalArticle","2017","Adami, Alexander; Taghipour, Armin; Herre, Jürgen","On Similarity and Density of Applause Sounds","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=19359","","2017","2023-07-12 07:21:38","2023-07-12 07:21:38","","897–913","","11","65","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B4J6TT24","journalArticle","2022","McCormack, Leo; Politis, Archontis; McKenzie, Thomas; Hold, Christoph; Pulkki, Ville","Object-Based Six-Degrees-of-Freedom Rendering of Sound Scenes Captured with Multiple Ambisonic Receivers","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=21739","","2022","2023-07-12 07:21:42","2023-07-12 07:21:42","","355–372","","5","70","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VBZUU85T","journalArticle","2015","Conetta, Robert; Brookes, Tim; Rumsey, Francis; Zielinski, Slawomir; Dewhirst, Martin; Jackson, Philip; Bech, Søren; Meares, David; George, Sunish","Spatial Audio Quality Perception (Part 1): Impact of Commonly Encountered Processes","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=17557","Spatial audio processes (SAPs) commonly encountered in consumer audio reproduction systems are known to produce a range of impairments to spatial quality. By way of two listening tests, this paper investigated the degree of degradation of the spatial quality of six 5-channel audio recordings resulting from 48 such SAPs. Perceived degradation also depends on the particular listeners, the program content, and the listening location. For example, combining off-center listener with another SAP can reduce spatial quality significantly when compared to listening to that SAP from a central location. The choice of the SAP can have a large influence on the degree of degradation. Taken together these findings and the quality-annotated database can guide the development of a regression model of perceived overall spatial audio quality, incorporating previously developed spatially-relevant feature-extraction algorithms. The results can guide the development of an artificial-listener-based evaluation system.","2015","2023-07-12 07:21:45","2023-07-19 03:49:34","","831–846","","12","62","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XY9L8WJB","journalArticle","2020","Poirier-Quinot, David; Katz, Brian F.G.","Assessing the Impact of Head-Related Transfer Function Individualization on Task Performance: Case of a Virtual Reality Shooter Game","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=20731","This paper presents the results of an extended experiment to assess the impact of individualized binaural rendering on player performance in an ecologically valid use context, specifically that of a VR “shooter game,” as part of a larger project to characterize the impact of binaural rendering quality in various VR type applications. Participants played a simple game in which they were faced with successive targets approaching from random directions on a sphere. While audio-visual cues allowed for general target localization, only sections of the game that relied on audio cues were used for analysis. Two HRTF exposure protocols were used, comprising best and worst-match HRTFs from a “perceptually orthogonal” optimized set of HRTFs, during the course of six game sessions. Two groups performed the game sessions exclusively using either their best or worst-match HRTF. Two additional groups performed the game sessions alternating between best and worst-match HRTFs. Results suggest that HRTF quality had minimal general impact on in-game participant performance and improvement rate. However, performance for extreme elevation target positions was affected by the quality of HRTF matching. In addition, a subgroup of participants showed higher sensitivity to HRTF choice than others.","2020","2023-07-12 07:21:48","2023-07-19 04:38:27","","248–260","","4","68","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"86SW6Y3D","journalArticle","2010","Bispo, Bruno C.; Esquef, Paulo A. A.; Biscainho, Luiz W. P.; Lima, Amaro A. de; Freeland, Fabio P.; Jesus, Rafael A. de; Said, Amir; Lee, Bowon; Schafer, Ronald W.; Kalker, Ton","EW-PESQ: A Quality Assessment Method for Speech Signals Sampled at 48 kHz","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=15252","In order to broaden the utility of objective methods for perceptual evaluation of ultrawide-band (sampled at 48 kHz) speech, two extensions to the W-PESQ standard are proposed. In one approach the psychoacoustic model of W-PESQ is expanded to cover higher frequencies by means of data extrapolation. In the alternative method the psychoacoustic model is replaced with that of PEAQ. A performance analysis of both methods reveals that their predictions strongly correlate with measured mean opinion scores (MOS), bearing a cross-correlation coefficient around 97%. Tests used speech signals corrupted with white and broad-band environmental noises.","2010","2023-07-12 07:21:52","2023-07-19 03:42:22","","251–268","","4","58","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MWG7FIZS","journalArticle","2008","Herre, Jürgen; Kjörling, Kristofer; Breebaart, Jeroen; Faller, Christof; Disch, Sascha; Purnhagen, Heiko; Koppens, Jeroen; Hilpert, Johannes; Rödén, Jonas; Oomen, Werner; Linzmeier, Karsten; Chong, Kok Seng","MPEG Surround-The ISO/MPEG Standard for Efficient and Compatible Multichannel Audio Coding","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=14643","Finalized in 2006, the MPEG Surround specification enables the transmission of multichannel audio signals at data rates close to those of one- and two-channel systems. This paper describes the technical architecture and capabilities of the specification. Verification tests include several operational modes as they would be used in typical application scenarios. In order to achieve backward compatibility with legacy devices that are not compliant with MPEG Surround, the spatial side information is embedded in either an ancillary part of the downmix bit stream or in a separate stream. This approach is vastly superior to a matrixed system at the comparable data rates.","2008","2023-07-12 07:22:09","2023-07-19 04:05:24","","932–955","","11","56","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"28ZS78DE","journalArticle","2000","Karjalainen, Matti; Välimäki, Vesa; Penttinen, Henri; Saastamoinen, Harri","DSP Equalization of Electret Film Pickup for the Acoustic Guitar","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=12032","The response of a guitar bridge pickup does not correspond to the acoustic radiation of the instrument. Digital signal processing is applied to obtain high-quality acoustic sound using only an elastic electret film pickup and properly designed digital filtering for equalization. The most promising results are obtained with long FIR filters with possibly one or more body resonances modeled with separate digital resonators, or with warped IIR filters.","2000","2023-07-12 07:22:13","2023-07-19 04:10:23","","1183–1193","","12","48","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4VCED7LL","journalArticle","2015","Tervo, Sakari; Pätynen, Jukka; Kaplanis, Neofytos; Lydolf, Morten; Bech, Søren; Lokki, Tapio","Spatial Analysis and Synthesis of Car Audio System and Car Cabin Acoustics with a Compact Microphone Array","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=18051","This research proposes a spatial sound analysis and synthesis approach for automobile sound systems, where the acquisition of the measurement data is much faster than with the Binaural Car Scanning method. This approach avoids the problems that are typically found with binaural reproduction and dummy head measurements. In combination with a compact microphone array, the approach is based on the recently introduced parametric spatial sound analysis method, called the Spatial Decomposition Method (SDM). An objective analysis of the sound field with respect to direction and energy enables the synthesis of multichannel loudspeaker reproduction. Because of the extreme acoustics of an automobile cabin, the authors recommend several steps to improve both the objective and perceptual performance. Because SDM is a parametric approach to spatial impulse response analysis, this allows automobile audio systems to be tuned in a laboratory environment instead of in-situ.","2015","2023-07-12 07:22:16","2023-07-19 04:52:34","","914–925","","11","63","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RZIRWTBS","journalArticle","2017","Sena, Enzo De; Brookes, Mike; Naylor, Patrick A.; Waterschoot, Toon van","Localization Experiments with Reporting by Head Orientation: Statistical Framework and Case Study","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=19364","","2017","2023-07-12 07:22:19","2023-07-12 07:22:19","","982–996","","12","65","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WJLA4MVZ","journalArticle","2000","Tan, Chong-Jin; Gan, Woon-Seng","Direct Concha Excitation for Introduction of Individualized Hearing Cues","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=12055","Nonindividualized head-related transfer functions (HRTFs) are known to cause significant front-back and elevation confusions when used for three-dimensional sound systems. In addition headphones tend to induce in-head localization and rear perceptual bias. A method of concha excitation is proposed as a means of introducing individual cues without the need of individual HRTF measurements, which may overcome some of these difficulties. A prototype headphone was designed and tested.","2000","2023-07-12 07:22:23","2023-07-19 04:51:33","","642–653","","7/8","48","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VD49PBYN","journalArticle","2022","Ragano, Alessandro; Benetos, Emmanouil; Hines, Andrew","Automatic Quality Assessment of Digitized and Restored Sound Archives","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=21562","Archiving digital audio is conducted to preserve and make records accessible. However techniques for assessing the quality of experience (QoE) of sound archives are usually neglected. This paper presents a framework to assess the QoE of sound archives in an automatic fashion. The QoE influence factors, stakeholders, and audio archive degradations are described, and the above concepts are explored through a case study on the NASA Apollo audio archive. Each component of the framework is described in the audio archive life cycle based on digitization, restoration, and consumption. Insights and real-world examples are provided on why digitized and restored audio archives benefit from QoE assessment techniques similar to other multimedia applications, such as video calling and streaming services. The reasons why stakeholders, such as archivists, broadcasters, or public listeners, would benefit from the proposed framework are also provided.","2022","2023-07-12 07:22:26","2023-07-19 04:39:52","","252–270","","4","70","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VCL4IRC7","journalArticle","2013","Vilkamo, Juha; Pulkki, Ville","Minimization of Decorrelator Artifacts in Directional Audio Coding by Covariance Domain Rendering","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=16932","","2013","2023-07-12 07:22:29","2023-07-12 07:22:29","","637–646","","9","61","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DAVXAF94","journalArticle","2001","Müller, Swen; Massarani, Paulo","Transfer-Function Measurement with Sweeps","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=10189","Transfer-function measurements using sweeps as excitation signals rather than pseudo-noise signals show significantly higher immunity against distortion and time variance. Capturing binaural room impulse responses for high-quality auralization purposes requires a signal-to-noise ratio (SNR) greater that 90 dB, which is unattainable with maximum-length sequence (MLS) measurements because of loudspeaker nonlinearity, but it is fairly easy to reach with sweeps due to the possibility of complete rejection of harmonic distortion. Before investigating the differences and practical problems of measurements with MLS and sweeps and arguing why sweeps are the preferable choice for the majority of measurement tasks, the existing methods of obtaining transfer functions are reviewed. The continual need to use preemphasized excitation signals in acoustical measurements is also addressed. A method to create sweeps with arbitrary spectral contents, but constant orprescribed frequency-dependent temporal envelope, is presented. Finally, the possibility of simultaneously analyzing transfer functions and harmonics is investigated.","2001","2023-07-12 07:22:33","2023-07-19 04:34:14","","443–471","","6","49","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VSVRP9HC","journalArticle","2023","Ackermann, David; Domann, Julian; Brinkmann, Fabian; Arend, Johannes M.; Schneider, Martin; Pörschmann, Christoph; Weinzier, Stefan","Recordings of a Loudspeaker Orchestra With Multichannel Microphone Arrays for the Evaluation of Spatial Audio Methods","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=22032","","2023","2023-07-12 07:22:37","2023-07-12 07:22:37","","62–73","","1/2","71","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VF97BC3W","journalArticle","1982","Toole, Floyd E.","Listening Tests-Turning Opinion into Fact","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=3833","Listening tests of many kinds take place regularly in the audio industry. Most of them lack the necessary psychological and acoustical controls to produce results that are of real significance, yet the course of audio is regularly influenced by opinions derived from such tests. Some familiar and some not so familiar sources of variability in subjective evaluations of sound quality are reviewed, and the standardization of certain basic technical factors currently being chosen in an arbitrary manner is proposed.","1982","2023-07-12 07:22:41","2023-07-19 04:53:12","","431–445","","6","30","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JC8KTIBZ","journalArticle","2002","Fitz, Kelly; Haken, Lippold","On the Use of Time: Frequency Reassignment in Additive Sound Modeling","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=11058","A method of reassignment in sound modeling to produce a sharper, more robust additive representation is introduced. The reassigned bandwidth-enhanced additive model follows ridges in a time-frequency analysis to construct partials having both sinusoidal and noise characteristics. This model yields greater resolution in time and frequency than is possible using conventional additive techniques, and better preserves the temporal envelope of transient signals, even in modified reconstruction, without introducing new component types or cumbersome phase interpolation algorithms.","2002","2023-07-12 07:22:45","2023-07-19 03:58:10","","879–893","","11","50","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MPQY2B4J","journalArticle","1990","Wagenaars, Wil M.","Localization of Sound in a Room with Reflecting Walls","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=6050","The ability of subjects to localize sounds in a typical living room was tested for both direction and distance. A subject was seated in the center of two concentric circular arrays of eight loudspeakers, one having a 1-m and the other a 2-m radius. Eleven different stimuli were used. these were white noise and sinusoids with different temporal envelopoes, a 100-µs pulse, and music. Results show that noise, pulses, and music can be localized very well. Sinusoids with at least one abrupt transition (onset or offset) are localized reasonably well, but sinusoids with slow, 1-s onsets and offsets are localized poorly.","1990","2023-07-12 07:22:48","2023-07-19 10:54:12","","99–110","","3","38","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4B5VFXFI","journalArticle","2006","Bai, Mingsian R.; Lin, Wan-chi","Synthesis and Implementation of Virtual Bass System with a Phase-Vocoder Approach","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=13888","A bass enhancement technique based on a phase-vocoder approach is presented. Instead of direct bass boosting, the proposed method creates a bass impression by exploiting the psychoacoustic properties of humans. This technique is most useful in audio reproduction using small loudspeakers that have no low-frequency capability, where direct boosting will likely result in nonlinear distortions. In light of psychoacoustics, the bass effect is synthesized by augmenting the original signals with high-frequency harmonics. Unlike conventional methods that rely on nonlinear processing, the proposed method performs the required frequency transformation by using a phase-vocoder approach. Apart from frequency transformation, another key element of the proposed technique is the magnitude adjustment of the generated harmonics. The underlying principle for magnitude adjustment is based on a polynomial model of equal-loudness contours. The method is implemented on a digital signal processor with the aid of multirate signal processing. To validate the proposed technique, objective and subjective experiments are conducted for PC multimedia loudspeakers and handset loudspeakers. The subjective listening experiment followed the procedure of multistimuli with the hidden reference and anchor (MUSHRA), and the data were analyzed by using the multianalysis of variance (MANOVA) method. As indicated by the results, the proposed technique proved effective in rendering bass impression with acceptable audio quality.","2006","2023-07-12 07:22:52","2023-07-19 03:37:59","","1077–1091","","11","54","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZD8Q9MWN","journalArticle","2003","Moore, Brian C. J.; Glasberg, Brian R.; Stone, Michael A.","Why Are Commercials so Loud? ' Perception and Modeling of the Loudness of Amplitude-Compressed Speech*","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=12190","The level of broadcast sound is usually limited to prevent overmodulation of the transmitted signal. To increase the loudness of broadcast sounds, especially commercials, fastacting amplitude compression is often applied. This allows the root-mean-square (rms) level of the sounds to be increased without exceeding the maximum permissible peak level. In addition, even for a fixed rms level, compression may have an effect on loudness. To assess whether this was the case, we obtained loudness matches between uncompressed speech (short phrases) and speech that was subjected to varying degrees of four-band compression. All rms levels were calculated off line. We found that the compressed speech had a lower rms level than the uncompressed speech (by up to 3 dB) at the point of equal loudness, which implies that, at equal rms level, compressed speech sounds louder than uncompressed speech. The effect increased as the rms level was increased from 50 to 65 to 80 dB SPL. For the largest amount of compression used here, the compression would allow about a 58% increase in loudness for a fixed peak level (equivalent to a change in level of about 6 dB). With a slight modification, the model of loudness described by Glasberg and Moore [1] was able to account accurately for the results.","2003","2023-07-12 07:22:55","2023-07-19 04:33:37","","1123–1132","","12","51","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WGCIRMH6","journalArticle","2020","McCormack, Leo; Pulkki, Ville; Politis, Archontis; Scheuregger, Oliver; Marschall, Marton","Higher-Order Spatial Impulse Response Rendering: Investigating the Perceived Effects of Spherical Order, Dedicated Diffuse Rendering, and Frequency Resolution","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=20852","This article details an investigation into the perceptual effects of different rendering strategies when synthesizing loudspeaker array room impulse responses (RIRs) using microphone array RIRs in a parametric fashion. The aim of this rendering task is to faithfully reproduce the spatial characteristics of a captured space, encoded within the input microphone array RIR (or the spherical harmonic RIR derived from it), over a loudspeaker array. For this study, a higherorder formulation of the Spatial Impulse Response Rendering (SIRR) method is introduced and subsequently employed to investigate the perceptual effects of the following rendering configurations: the spherical harmonic input order, frequency resolution, and utilizing ded- icated diffuse stream rendering. Formal listening tests were conducted using a 64-channel loudspeaker array in an anechoic chamber, where simulated reference scenarios were compared against the outputs of different methods and rendering con- figurations. The test results indicate that dedicated diffuse stream rendering and higher analysis orders both yield noticeable perceptual improvements, particularly when employing problematic transient stimuli as input. Additionally, it was found that the frequency resolution employed during rendering has only a minor influence over the perceived accuracy of the reproduc- tion in comparison to the other two tested attributes.","2020","2023-07-12 07:22:59","2023-07-19 04:29:28","","338–354","","5","68","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JET5SCN9","journalArticle","2022","Engel, Isaac; Alon, David L.; Scheumann, Kevin; Crukley, Jeff; Mehra, Ravish","On the Differences in Preferred Headphone Response for Spatial and Stereo Content","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=21564","","2022","2023-07-12 07:23:01","2023-07-12 07:23:01","","271–283","","4","70","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"85H7KH74","journalArticle","2021","Villegas, Julián; Fukasawa, Naoki; Arevalo, Camilo","The Presence of a Floor Improves Subjective Elevation Accuracy of Binaural Stimuli Created With Non-Individualized Head-Related Impulse Responses","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=21534","We report the effect of the presence of floor on elevation estimation of audio spatialized with non-individualized Head-Related Impulse Responses (HRIRs). The results of two experiments (n = 21 and n = 39) suggest that using HRIRs captured when a floor simulator was present improved assessors' accuracy when judging elevation in the sagittal and coronal planes, especially at high elevations. Such improvements were not observed when signals delayed according to their computed first reflection were mixed with signals convolved with anechoic HRIRs. These findings suggest that capturing non-individualized HRIRs in hemi-anechoic rooms could improve accuracy of audio spatialization in virtual environments.","2021","2023-07-12 07:23:05","2023-07-19 10:53:08","","849–859","","11","69","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YT78YTZU","journalArticle","2000","Evans, Michael J.; Tew, Anthony I.; Angus, James A. S.","Perceived Performance of Loudspeaker-Spatialized Speech for Teleconferencing","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=12051","","2000","2023-07-12 07:23:08","2023-07-12 07:23:08","","771–785","","9","48","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G72SE4X9","journalArticle","2017","Francombe, Jon; Brookes, Tim; Mason, Russell","Evaluation of Spatial Audio Reproduction Methods (Part 1): Elicitation of Perceptual Differences","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=18555","An experiment was performed to determine the attributes that contribute to listener preference for a range of spatial audio reproduction methods. Experienced and inexperienced listeners made preference ratings for combinations of seven program items replayed over eight reproduction systems, and reported the reasons for their judgments. Automatic text clustering reduced redundancy in the responses by approximately 90%, thereby facilitating subsequent group discussions that produced clear attribute labels, descriptions, and scale end-points. Twenty-seven and twenty-four attributes contributed to preference for the experienced and inexperienced listeners respectively. The two sets of attributes contain a degree of overlap (ten attributes from the two sets were closely related); the experienced listeners used more technical terms while the inexperienced listeners used broader descriptive categories.","2017","2023-07-12 07:23:10","2023-07-19 03:58:37","","198–211","","3","65","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6KCN5ZR6","journalArticle","1999","Algazi, V. Ralph; Avendano, Carlos; Thompson, Dennis","Dependence of Subject and Measurement Position in Binaural Signal Acquisition","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=12085","A detailed evaluation of the dependence of the head-related transfer functions (HRTFs) on the position of the recording microphone along the ear canal for blocked and unblocked conditions is presented. Measurements at 250 source locations for a KEMAR mannequin and at 125 locations for two human subjects were performed. Conditions under which the magnitude transfer function from the HRTF acquisition position to the eardrum is essentially independent of the source location are shown quantitatively. These results are in agreement with and provide an extensive validation of other studies. The cause and magnitude of measurement errors are also analyzed in detail, and it is shown that these errors are subject dependent.","1999","2023-07-12 07:23:13","2023-07-19 03:35:19","","937–947","","11","47","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QV29HNE2","journalArticle","1975","Torick, Emil L.; DiMattia, Alfred L.; Staruk, Walter E., Jr.; Milner, Paul","A Wearable Master Hearing Aid","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=2689","An experimental wearable master hearing aid device has been developed for clinical studies of methods to improve perception capabilities of subjects having varied hearing impairments. In accordance with a specification of the National Institutes of Health, a multiplicity of parameter adjustments and transducer options provides more than 500 million permutations of operational modes.","1975","2023-07-12 07:23:18","2023-07-19 04:53:49","","361–368","","5","23","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9QPVR3JM","journalArticle","2006","Ramos, Germán; López, José J.","Filter Design Method for Loudspeaker Equalization Based on IIR Parametric Filters","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=13893","A novel method for the equalization of loudspeakers and other audio systems using IIR (infinite impulse response) parametric filters is presented. The main characteristic of the proposed filter design method resides in the fact that the equalization structure is planned from the beginning as a chain of SOSs (second-order sections), where each SOS is a low-pass, high-pass, or peak filter, defined by its parameters. The algorithm combines a direct search method with a heuristic parametric optimization process where constraints on the values could be imposed in order to obtain practical implementations. A psychoacoustic model based on the detection of peaks and dips in the frequency response has been employed to determine which ones need to be equalized, reducing the filter order without noticeable effect. The first computed sections of the designed filter are the ones that correct the response more effectively, allowing scalable solutions when hardware limitations exist or different degrees of correction are needed. The method has been validated with subjective testing and compared with other methods. Its results could be applied to passive and multiway active loudspeakers.","2006","2023-07-12 07:23:21","2023-07-19 04:40:01","","1162–1178","","12","54","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IH2YFCWB","journalArticle","2005","Loutridis, Spyros J.","Decomposition of Impulse Responses Using Complex Wavelets","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=13434","The application of the continuous wavelet transform, implemented with complex wavelets, to the decomposition of loudspeaker and room impulse responses is discussed. The wavelet transform possesses adaptive time–frequency resolution and is very well suited to the analysis of transient signals. It has the important property that significant signal information is concentrated on certain regions called ridges. Applications include separation of modal components with subsequent damping estimation and low-frequency coloration detection. Wavelets form filter banks and can be designed to have any desirable filter bandwidth. Wavelet filters are used for reverberation-time estimation. It is also suggested that complex wavelets might be used for envelope extraction and calculation of the instantaneous frequency and instantaneous spectral density of a signal.","2005","2023-07-12 07:23:25","2023-07-19 04:21:26","","796–811","","9","53","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2MLI2SYB","journalArticle","1994","van de Par, Steven L.; ten Kate, Warner R.; Kohlrausch, Armin; Houtsma, Adrianus J.","Bit-Rate Saving in Multichannel Sound: Using a Band-Limited Channel to Transmit the Center Signal","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=6934","A method is proposed to achieve full-frequency-range three-channel (left, right, and center) sound reproduction in systems that have only two full-range sound channels and some band-limited commentary channels. The low-frequency part of the center signal, which matches the bandwidth of the commentary channels, is added to the (multilingual) speech signals in each of the commentary channels. The remaining high-frequency part is added in the left and right channels as in conventional mixdowns. Sound reproduction of this signal by a conventional two-channel receiver remains unaltered. The low-frequency part of the center signal is mixed to the left and right signals together with the speech once the user has selected a commentary channel. Three-channel reproduction is obtained by routing the selected commentary channel to a central loudspeaker. Listening tests revealed that sound reproduction according to the proposed scheme could not be distinguished from original three-channel reproduction. This scheme can be applied to proposed standards such as D2MAC and MPEG2.","1994","2023-07-12 07:23:28","2023-07-19 04:55:04","","555–564","","7/8","42","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6Y9GPW59","journalArticle","2012","Nikunen, Joonas; Virtanen, Tuomas; Vilermo, Miikka","Multichannel Audio Upmixing by Time-Frequency Filtering Using Non-Negative Tensor Factorization","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=16553","The expanding use of portable multimedia devices has intensified the need for better forms of scalable spatial audio coding (SAC) that match the connectivity rate and multichannel playback capabilities of the receiving device. A new SAC method is based on the parameterization of multichannel audio by representing it as a linear combination of objects composed of fixed spectral bases with time-varying gain and channel-dependent spatial gain. Spatial parameters can be estimated from the original multichannel signal using psychoacoustic properties of sound source localization. The base audio can be monophonic or downmixed stereophonic. Listening tests showed that the proposed SAC algorithm achieved the performance of conventional spatial audio coding methods with similar bit rates. The sound separation performance was evaluated and found applicable for separating sound sources in the coding domain directly.","2012","2023-07-12 07:23:32","2023-07-19 04:35:06","","794–806","","10","60","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YS2TNLNP","journalArticle","2016","Ben Ali, Faten; Djaziri-Larbi, Sonia; Girin, Laurent","Low Bit-Rate Speech Codec Based on a Long-Term Harmonic Plus Noise Model","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=18522","In speech/music coders and analysis/synthesis systems, spectral modeling is generally performed on a short-term (ST) frame-by-frame basis, which is justified by the fact that the signal is only locally (quasi-) stationary. The vocal tract configuration moves slowly and smoothly thereby resulting in a high correlation between the spectral parameters of successive frames: this correlation property is exploited in long-term modeling of the ST parameters, which however results in longer modeling/coding delays. The short delay constraint can be relaxed in many applications, such as text-to-speech modification/synthesis, telephony surveillance data, digital answering machines, electronic voicemail, digital voice logging, electronic toys, and video games. The long-term harmonic plus noise model (LT-HNM) for speech shows additional data compression possibilities since it exploits the smooth evolution of the time trajectories of the short-term harmonic plus noise model parameters by applying a discrete cosine model (DCM). In this paper, the authors extend the LT-HNM to a complete low bit-rate speech coder that is based on a long-term approach ca. 200ms. The proposed LT-HNM coder reaches a bit-rate of 2.7kbps for wideband speech.","2016","2023-07-12 07:23:35","2023-07-19 03:41:22","","844–857","","11","64","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HZD5VWXW","journalArticle","2003","Fielder, Louis D.","Analysis of Traditional and Reverberation-Reducing Methods of Room Equalization","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=12249","Traditionally, electronic equalization has used linear filters of low complexity. The nature of spectral and temporal distortions of rooms limits useful equalization to minimum-phase filters of relatively low order, despite the existence of new and powerful digital signal processing tools. The high Q and non-minimum-phase nature of the room loudspeaker 'listener transfer function, caused by wave interference effects, creates severe problems for more complete equalization. A typical professional listening room and three cinema acoustic environments were used to investigate the difficulties inherent for more ambitious equalization approaches.","2003","2023-07-12 07:23:39","2023-07-19 03:57:54","","3–26","","1/2","51","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JMWZSV9Y","journalArticle","2018","Francombe, Jon; Brookes, Tim; Mason, Russell","Determination and Validation of Mix Parameters for Modifying Envelopment in Object-Based Audio","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=19381","With object-based audio transmission, a scene is distributed as a set of audio objects, as opposed to discrete audio channels. An object comprises an audio stream for a particular aspect of the scene, accompanied by some metadata, such as the desired level and spatial position of the object. Object-based audio offers the possibility of altering the rendering of an audio scene in order to modify or maintain perceptual attributes if the relationships between attributes and mix parameters are known. This research aims to determine the relationship between parameters of an object-based mix and the perception of envelopment (an important attribute of spatial audio reproduction systems), and to develop and test a system for manipulating envelopment in object-based audio in a perceptually relevant manner. An experiment was performed in which mixing engineers were asked to create mixes of object-based content at three levels of envelopment (low, medium, and high) while keeping the overall mix quality at an acceptable level. This enabled analysis of parameter values in order to assess how participants created different levels of envelopment. It was shown in a validation experiment that these parameters could be used to adjust envelopment to a target level.","2018","2023-07-12 07:23:42","2023-07-19 04:00:16","","127–145","","3","66","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I978M443","journalArticle","2017","Coleman, Philip; Franck, Andreas; Jackson, Philip J. B.; Hughes, Richard J.; Remaggi, Luca; Melchior, Frank","Object-Based Reverberation for Spatial Audio","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=18544","","2017","2023-07-12 07:23:46","2023-07-12 07:23:46","","66–77","","1/2","65","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GPGGHDYL","journalArticle","2020","Tylka, Joseph G.; Choueiri, Edgar Y.","Performance of Linear Extrapolation Methods for Virtual Sound Field Navigation","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=20725","Performance errors are characterized for two representative linear extrapolation methods for virtual navigation of higher-order ambisonics sound fields. For such methods, navigation is theoretically restricted to within the so-called region of validity, which extends spherically from the recording ambisonics microphone to its nearest source, but the precise consequences of violating that restriction has not been previously established. To that end, the errors introduced by each method are objectively evaluated in terms of metrics for sound level, spectral coloration, source localization, and diffuseness, through numerical simulations over a range of valid and invalid conditions. Under valid conditions, results show that the first method, based on translating along plane-waves, accurately reproduces both the level and localization of a source, whereas the second method, based on ambisonics translation coefficients, incurs significant errors in both level and spectral content that increase steadily with translation distance. Under invalid conditions, two common features of the performance of both methods are identified: significant localization errors are introduced and the reproduced level is too low. It is argued that these penalties are inherent to all methods that are bound by the region of validity restriction, including all linear extrapolation methods.","2020","2023-07-12 07:23:50","2023-07-19 04:54:07","","138–156","","3","68","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3FVATVVR","journalArticle","2011","Hur, Yoomi; Abel, Jonathan S.; Park, Young-Cheol; Youn, Dae Hee","Techniques for Synthetic Reconfiguration of Microphone Arrays","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=15937","Methods are presented for transforming signals from a specific microphone array into those that would have been recorded at a different array at the same location. In a nonparametric method, beams are formed at fixed directions using a low-sidelobe beamforming technique. In a parametric method, beams are formed adaptively using a direction-finding algorithm. In a hybrid method, point source signals and spatially diffuse residual signals are separately processed. Results show good agreement between measured and synthesized array outputs with signal correlation coefficients near 1.0 for all three methods. Informal listening tests confirmed effective sound field resynthesis.","2011","2023-07-12 07:23:53","2023-07-19 04:07:37","","404–418","","6","59","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8MXGJFHW","journalArticle","2016","Cecchi, Stefania; Virgulti, Marco; Primavera, Andrea; Piazza, Francesco; Bettarelli, Ferruccio; Li, Junfeng","Investigation on Audio Algorithms Architecture for Stereo Portable Devices","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=18106","","2016","2023-07-12 07:23:56","2023-07-12 07:23:56","","75–88","","1/2","64","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X8Y4FUKB","journalArticle","2019","Ma, Xiaohui; Hohnerlein, Christoph; Ahrens, Jens","Concept and Perceptual Validation of Listener-Position Adaptive Superdirective Crosstalk Cancellation Using a Linear Loudspeaker Array","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=20701","This paper presents a multiband approach for crosstalk cancellation based on superdirective near-field beamforming (SDB) that adapts dynamically to a change in the listener position. SDB requires the computation of a separate set of beamformer weights for each listener position. The beamformer uses weights that exhibit a smooth evolution for listening positions along a linear trajectory parallel to the array. The beamformer weights can therefore be parameterized by using only a few parameters for each frequency. Upon real-time execution, the beamformer weights are determined efficiently for any position from the parameters with negligible error. Simulations and measurements show that the proposed method provides high channel separation and is robust with respect to small uncertainties of the listener position. A user study with 20 subjects and binaural signals shows consistent auditory localization accuracy across the different tested listening positions that are comparable to the localization accuracy of headphone rendering. The study also confirms the previously informal observation that fewer front-back confusions are observed when the listeners face away from the loudspeaker array compared to the listeners facing toward the array.","2019","2023-07-12 07:24:16","2023-07-19 04:25:43","","871–881","","11","67","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BZISXD98","journalArticle","2019","Silzle, Andreas; Schmidt, Rebekka; Bleisteiner, Werner; Epain, Nicolas; Ragot, Martin","Quality of Experience Tests of an Object-based Radio Reproduction App on a Mobile Device","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=20495","","2019","2023-07-12 07:24:19","2023-07-12 07:24:19","","568–583","","7/8","67","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9YKIWHJN","journalArticle","1996","Cao, Yuchang; Sridharan, Sridha; Moody, Miles","Co-talker Separation Using the 'Cocktail Party Effect'","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=7875","An artificial neural network (ANN) speech-classifier-controlled iterative filtering system is described, which simulates the cocktail party effect for speech separation. The ANN speech classifier controls a modified iterative Wiener filter to cancel the interference by setting the filter's parameter's and the convergence criterion for the iteration. The proposed system has been employed successfully with multiple-microphone speech acquisition systems for co-talker speech separation. The simulation results have shown that the iterative processing controlled by the neural network consistently provides speech of good quality and intelligibility.","1996","2023-07-12 07:24:23","2023-07-19 03:47:16","","1084–1096","","12","44","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"27XUI7KI","journalArticle","1959","Somerville, T.; Gilford, C. L. S.","Acoustics of Large Orchestral Studios and Concert Halls","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=558","In order to establish design criteria for orchestral studios, which should be similar in performance to good ocncert halls, an extensive investigation has been in progress for many years. The effects of shape on the subjective acoustic qualities of a large enclosure are here examined with reference to a large number of concert halls and music studios, and a comparison is made, in particular, between concert halls of the traditional type and thos which have been built during the last few decades. The former were generally of rectangular plan with walls and ceilings overlaid with ornamentation, whereas most recent designs have fan-shaped plans, reflecting canopies and comparatively smooth surfaces. Measurements of sound levels in different parts of concert halls during orchestral concerts show that, for a given sound level in the neighborhood of the platform, the intensity at the back of the hall is no greater in halls with fan-shaped plans and reflectors than with the traditional rectangular shape. In the former case, the gain in the intensity of the first few reflections which results from the shape of the hall is offset by a reduced reverberant sound level. The authors conclude that the modern fashion of directing the early reflections towards the back of a concert hall, although it may improve the hearing of speech, has an adverse effect on the quality of music.","1959","2023-07-12 07:24:33","2023-07-19 04:48:43","","160–172","","4","7","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H2IJHL2U","journalArticle","2017","Brandt, Matthias; Doclo, Simon; Gerkmann, Timo; Bitzer, Joerg","Impulsive Disturbances in Audio Archives: Signal Classification for Automatic Restoration","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=19356","Historic recordings usually have degraded audio quality because of their age, improper storage, and the shortcomings of the original media. One typical problem is the presence of impulsive disturbances. Recordings that suffer from clicks and crackles can be processed by impulse-restoration algorithms to improve their audio quality. This report presents a new algorithm that classifies one-second frames of an audio recording based on the existence of impulsive disturbances. The algorithm uses supervised learning. It is shown that existing impulse-restoration algorithms suffer from degradation of the desired signal if the input SNR is high and if no manual parameter adjustment is possible. This would make automatic restoration of large amounts of diverse archive audio material unfeasible. The proposed classification algorithm can be used as a supplement to an existing impulse-restoration algorithm to alleviate this drawback. An evaluation using a large number of test signals shows that high classification accuracy can be achieved, making automatic impulse restoration possible. Results show that prewhitening of the input signal by means of a phase-only transform serves to increase the detectability of disturbance impulses, which can also be used as a detection enhancement method for impulse-restoration algorithms.","2017","2023-07-12 07:24:36","2023-07-19 03:44:33","","826–840","","10","65","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MVX5VVGU","journalArticle","2003","Esquef, Paulo A. A.; Biscainho, Luiz W. P.; Välimäki, Vesa","An Efficient Algorithm for the Restoration of Audio Signals Corrupted with Low-Frequency Pulses","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=12221","Digital audio restoration of old recordings is addressed, with a focus on the removal of long pulses with low-frequency content. The main drawback of the state-of-the-art method, which is based on the separation of autoregressive (AR) processes, is its high computational complexity. A method is proposed in which the pulse tails are first estimated via a nonlinear scheme called two-pass split-window (TPSW) filtering, followed by a polynominal smoothing stage. After removing the tail of each pulse by subtraction, the remaining initial clicks are suppressed through a model-based declicking algorithm. The proposed procedure is as effective for pulse removal as the AR-based method but has a substantially lower computational complexity. Moreover, from a user point of view, its processing parameters are more intuitive and easier to adjust.","2003","2023-07-12 07:24:39","2023-07-19 03:54:53","","502–517","","6","51","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"24EH3F3U","journalArticle","2015","Conetta, Robert; Brookes, Tim; Rumsey, Francis; Zielinski, Slawomir; Dewhirst, Martin; Jackson, Philip; Bech, Søren; Meares, David; George, Sunish","Spatial Audio Quality Perception (Part 2): A Linear Regression Model","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=17558","The QESTRAL (Quality Evaluation of Spatial Transmission and Reproduction using an Artificial Listener) system is intended to be an artificial-listener-based evaluation system capable of predicting the perceived spatial quality degradations resulting from SAPs (Spatial Audio Processes) commonly encountered in consumer audio reproduction. A generalizable model employing just five metrics and two principal components performs well in its prediction of the quality over a range of program types. Commonly-encountered SAPs can have a large deleterious effect on several spatial attributes including source location, envelopment, coverage angle, ensemble width, and spaciousness. They can also impact timbre, and changes to timbre can then influence spatial perception. Previously obtained data was used to build a regression model of perceived spatial audio quality in terms of spatial and timbral metrics. In conjunction with two simple probe signals, the resulting model can form the core of an evaluation system.","2015","2023-07-12 07:24:44","2023-07-19 03:49:44","","847–860","","12","62","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NW3KV4GA","journalArticle","2020","Geary, David; Torcoli, Matteo; Paulus, Jouni; Simon, Christian; Straninger, Davide; Travaglini, Alessandro; Shirley, Ben","Loudness Differences for Voice-Over-Voice Audio in TV and Streaming","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=20995","","2020","2023-07-12 07:24:47","2023-07-12 07:24:47","","810–818","","11","68","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"38EFXB88","journalArticle","2005","Naqvi, Amber; Rumsey, Francis","The Active Listening Room. A Novel Approach to Early Reflection Manipulation in Critical Listening Rooms","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=13418","A novel method of controlling reflections, using flat panel loudspeakers, in a reference listening room is described. Models and implementations are presented in the case of single-transducer monophonic reproduction as well as two-channel and five-channel stereophonic arrangements. The results of a pilot listening test showed that differences in reflection patterns were readily detected by a panel of experienced listeners.","2005","2023-07-12 07:24:51","2023-07-19 04:34:31","","385–402","","5","53","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I6IEW342","journalArticle","2007","Menzies, Dylan; Al-akaidi, Marwan","Ambisonic Synthesis of Complex Sources","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=14175","Exterior expansions of complex sound sources are presented as flexible objects for producing Ambisonic sound-field encodings. The sources can be synthesized or recorded directly, rotated, and positioned in space. Related techniques can also be used to efficiently add high-quality reverberation, depending on the orientation and location of the source and listener.","2007","2023-07-12 07:24:54","2023-07-19 04:30:50","","864–876","","10","55","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JK5FSBC4","journalArticle","2008","Beracoechea, J. A.; Torres-Guijarro, Soledad; García, L.; Casajús-Quirós, Francisco J.; Ortiz, L.","Subjective Intelligibility Evaluation in Multiple-Talker Situation for Virtual Acoustic Opening-Based Audio Environments","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=14388","","2008","2023-07-12 07:24:57","2023-07-12 07:24:57","","339–356","","5","56","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PJ94JFJA","journalArticle","2002","Bech, Søren","Requirements for Low-Frequency Sound Reproduction, Part I: The Audibility of Changes in Passband Amplitude Ripple and Lower System Cutoff Frequency and Slope","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=11070","The audibility of changes in passband amplitude ripple and lower system cutoff frequency and slope has been investigated for a loudspeaker system for two situations: a real loud-speaker in an anechoic chamber and a simulated system reproduced via headphones. The signals were standard program material, selected to ensure a sufficient energy content at the relevant frequencies. The experiments were conducted with six subjects with normal hearing using a paired-comparison procedure. The subjects assessed the attributes ""lower bass"" and ""upper bass"" in relation to a fixed reference condition. The first experiment investigated the influence of high-pass filter order (second, fourth, and sixth) and lower cutoff frequency (20, 35, and 50 Hz) at three reproduction levels and for four program items. The second experiment examined the influence of amplitude ripple corresponding to four reverberation times at three reproduction levels and for four program items. The results of the first experiment showed that the lower cutoff frequency has a significant influence on the perceived level of lower bass reproduction if the reproduction level is above the hearing threshold in the relevant frequency bands. The influence of high-pass filter order was not significant for the conditions investigated. The results of the second experiment showed that the amplitude ripple has a significant influence on the perceived level of lower and upper bass reproduction. The results also showed that there were no significant differences between the data produced by the two reproduction methods.","2002","2023-07-12 07:25:02","2023-07-19 03:39:46","","564–580","","7/8","50","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"84BSFG2H","journalArticle","2023","Kirsch, Christoph; Wendt, Torben; Van De Par, Steven; Hu, Hongmei; Ewert, Stephan D.","Computationally-Efficient Simulation of Late Reverberation for Inhomogeneous Boundary Conditions and Coupled Rooms","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=22040","For computational efficiency, acoustic simulation of late reverberation can be simplified by generating a limited number of incoherent signals with frequency-dependent exponential decay radiated by spatially distributed virtual reverberation sources (VRS). A sufficient number of VRS and adequate spatial mapping are required to approximate spatially anisotropic late reverberation, e.g., in rooms with inhomogeneous distribution of absorption or for coupled volumes. For coupled rooms, moreover, a dual-slope decay might be required. Here, an efficient and perceptually plausible method to generate and spatially render late reverberation is suggested. Incoherent VRS signals for (sub-) volumes are generated based on room dimensions and frequencydependent absorption coefficients at the boundaries. For coupled rooms, (acoustic) portals account for effects of sound propagation and diffraction at the room connection and energy transfer during the reverberant decay process. The VRS are spatially distributed around the listener, with weighting factors representing the spatially subsampled distribution of absorption on the boundaries and the location and solid angle covered by portals. A technical evaluation and listening tests demonstrate the validity of the approach in comparison to measurements in real rooms.","2023","2023-07-12 07:25:05","2023-07-19 04:12:30","","186–201","","4","71","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M67A5FHZ","journalArticle","2014","Tiemounou, Sibiri; Jeannès, Régine Le Bouquin; Ewert, Vincent Barriac","Perception-Based Automatic Classification of Background Noise in Super-Wideband Telephony","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=17552","Given the effort required to perform subjective tests of quality of service in super-wideband telephone networks, an objective model of perceived degradation was created. This paper describes an efficient classification model of background noise arising at the originating side of super-wideband telephony. Classification depends on the impact on the perceived voice quality at receiving side from originating noises. This approach extends the research findings of narrowband telephony. Subjective experiments showed that background noises can be divided into three relevant classes: environmental noise, breath noise, and crackling noise. Each of these corresponds respectively to spectral flow, acoustic power variations, and the noise spectral centroid. Based on three quality degradation indicators, tests showed 82% correct classification of unknown noise signals.","2014","2023-07-12 07:25:09","2023-07-19 04:53:01","","776–781","","11","62","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8NUA7MYI","journalArticle","1995","Boone, Marinus M.; Verheijen, Edwin N. G.; van Tol, Peter F.","Spatial Sound-Field Reproduction by Wave-Field Synthesis","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=7920","The wave-field synthesis method is used for a natural reproduction of sound in living rooms, cinemas, and theaters. Wave-field synthesis gives a much larger listening area with correct virtual directions and spatial impression than can be obtained with conventional reproduction methods. Starting with a summary of the theory for an infinitely long linear array of reproduction loudspeakers, simulations show the effects of finite array length and distance between the loudspeakers. A strategy is presented for practical realization of this new system by making use of the notional source concept, including compatibility with two-channel stereophony.","1995","2023-07-12 07:25:13","2023-07-19 03:43:57","","1003–1012","","12","43","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NNWB9AJU","journalArticle","2011","Parodi, Yesenia Lacouture; Rubak, Per","A Subjective Evaluation of the Minimum Channel Separation for Reproducing Binaural Signals over Loudspeakers","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=15974","While there are a variety of methods and tradeoffs for creating the necessary crosstalk cancellation when reproducing a binaural signal through loudspeakers in a real environment, there are no studies that reveal the minimum required crosstalk. In the current study the authors simulated varying degrees of crosstalk in order to determine the required threshold. For most audio signals crosstalk should be below –15 dB, and for broadband signals the crosstalk should be below –20 dB. Off-center locations require even lower crosstalk.","2011","2023-07-12 07:25:16","2023-07-19 04:37:02","","487–497","","7/8","59","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PHAQ3XES","journalArticle","2008","Zwan, Pawel; Kostek, Bozena","System for Automatic Singing Voice Recognition","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=14634","","2008","2023-07-12 07:25:19","2023-07-12 07:25:19","","710–723","","9","56","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SBPTEPMB","journalArticle","2002","Karjalainen, Matti; Esquef, Paulo A. A.; Antsalo, Poju; Mäkivirta, Aki; Välimäki, Vesa","Frequency-Zooming ARMA Modeling of Resonant and Reverberant Systems","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=11054","Discrete-time analysis and modeling of reverberant and resonating systems has many applications in audio and acoustics. The methodology of ARMA modeling by pole-zero filters for measured impulse responses was investigated. In addition to an overview of the standard AR and ARMA techniques, a spectral zooming technique is proposed, which is useful for resolving very closely positioned modes and high-density modal clusters. Application cases related to the analysis and modeling of room responses, loudspeaker room equalization, and the estimation of parameters for musical instrument modeling are studied.","2002","2023-07-12 07:25:22","2023-07-19 04:10:02","","1012–1029","","12","50","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8NP5GQAJ","journalArticle","2020","Pörschmann, Christoph; Arend, Johannes M.","A Method for Spatial Upsampling of Voice Directivity by Directional Equalization","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=20896","To describe the sound radiation of the human voice into all directions, measurements need to be performed on a spherical grid. However, the resolution of such captured directivity patterns is limited and methods for spatial upsampling are required, for example by interpolation in the spherical harmonics (SH) domain. As the number of measurement directions limits the resolvable SH order, the directivity pattern suffers from spatial aliasing and order-truncation errors. We present an approach for spatial upsampling of voice directivity by spatial equalization. It is based on preprocessing, which equalizes the sparse directivity pattern by spectral division with corresponding directional rigid sphere transfer functions, resulting in a time-aligned and spectrally matched directivity pattern that has a significantly reduced spatial complexity. The directivity pattern is then transformed into the SH domain, interpolated to a dense grid by an inverse spherical Fourier transform and subsequently de-equalized by spectral multiplication with corresponding rigid sphere transfer functions. Based on measurements of a dummy head with an integrated mouth simulator, we compare this approach to reference measurements on a dense grid. The results show that the method significantly decreases errors of spatial undersampling and this allows a meaningful high-resolution voice directivity to be determined from sparse measurements.","2020","2023-07-12 07:25:25","2023-07-19 04:38:44","","649–663","","9","68","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F5GCK7P7","journalArticle","2021","Mathews, Jonathan; Braasch, Jonas","Sparse Iterative Beamforming Using Spherical Microphone Arrays for Low-Latency Direction of Arrival Estimation in Reverberant Environments","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=21545","Acoustic direction of arrival estimation methods allows positional information about sound sources to be transmitted over a network using minimal bandwidth. For these purposes,methods that prioritize low computational overhead and consistent accuracy under non-ideal conditions are preferred. The estimation method introduced in this paper uses a set of steered beams to estimate directional energy at sparsely distributed orientations around a spherical microphone array. By iteratively adjusting beam orientations based on the orientation of maximum energy, an accurate orientation estimate of a sound source may be produced with minimal computational cost. Incorporating conditions based on temporal smoothing and diffuse energy estimation further refines this process. Testing under simulated conditions indicates favorable accuracy under reverberation and source discrimination when compared with several other contemporary localization methods. Outcomes include an average localization error of less than 10? under 2 s of reverberation time (T60) and the potential to separate up to four sound sources under the same conditions. Results from testing in a laboratory environment demonstrate potential for integration into real-time frameworks.","2021","2023-07-12 07:25:29","2023-07-19 04:29:11","","967–977","","12","69","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XAMSUR36","journalArticle","2020","Ackermann, David; Fiedler, Felicitas; Brinkmann, Fabian; Schneider, Martin; Weinzierl, Stefan","On the Acoustic Qualities of Dynamic Pseudo-Binaural Recordings","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=20858","","2020","2023-07-12 07:25:32","2023-07-12 07:25:32","","418–427","","6","68","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CM4ZKGTA","journalArticle","2018","He, Jianjun; Ranjan, Rishabh; Gan, Woon-Seng; Chaudhary, Nitesh Kumar; Hai, Nguyen Duy; Gupta, Rishabh","Fast Continuous Measurement of HRTFs with Unconstrained Head Movements for 3D Audio","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=19866","Head-related transfer function (HRTF) is an essential component of a system for creating an immersive listening experience over headphones in multimedia and virtual and augmented reality applications. A critical requirement is the measure of the HRTFs for each individual to accommodate ear idiosyncrasies. Conventional static stop-and-go HRTF measurement methods are tedious and time-consuming. Recently proposed continuous HRTF acquisition methods could improve the acquisition efficiency but they still restrict the movements of the subjects and must be conducted in a controlled environment. In this paper the authors propose a fast and continuous HRTF measurement system with an embedded head tracker that can drastically reduce the measurement duration, obtaining HRTFs at high resolution while still allowing unconstrained head movements in both azimuth and elevation directions. To extract the HRTFs from such dynamic binaural measurements with random head movements, an improved adaptive filtering algorithm is proposed by integrating direction quantization, variable step size, and including optimal HRTF selection into the progressive-based normalized least-mean-squares algorithm. Objective evaluations and subjective listening tests were conducted using measurement data obtained from human subjects. The experimental results demonstrate that the proposed system and algorithm can yield HRTFs that are very close to HRTFs obtained with conventional static methods.","2018","2023-07-12 07:25:35","2023-07-19 04:04:21","","884–900","","11","66","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RNJMQBBB","journalArticle","1998","Zacharov, Nick","Subjective Appraisal of Loudspeaker Directivity for Multichannel Reproduction","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=12155","A group of subjective experiments considering the loudspeaker directivity characteristics for five-channel audiovisual reproduction was examined. A large number of tests were performed with a screened and trained listening panel. The effects of listening position, loudspeaker directivity, and program were examined. Frontal and surround loudspeaker directivity characteristics were considered separately. Certain findings suggest that de facto standard approaches may not be optimal in terms of loudspeaker directivity.","1998","2023-07-12 07:25:38","2023-07-19 10:59:06","","288–303","","4","46","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PS7B96UT","journalArticle","1996","Møller, Henrik; Sørensen, Michael Friis; Jensen, Clemen Boje; Hammershøi, Dorte","Binaural Technique: Do We Need Individual Recordings?","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=7897","","1996","2023-07-12 07:25:41","2023-07-12 07:25:41","","451–469","","6","44","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FCLUV5IQ","journalArticle","2022","Majdak, Piotr; Zotter, Franz; Brinkmann, Fabian; De Muynke, Julien; Mihocic, Michael; Noisternig, Markus","Spatially Oriented Format for Acoustics 2.1: Introduction and Recent Advances","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=21824","","2022","2023-07-12 07:25:44","2023-07-12 07:25:44","","565–584","","7/8","70","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7ZN4XC2I","journalArticle","2018","Eichas, Felix; Zölzer, Udo","Gray-Box Modeling of Guitar Amplifiers","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=19874","","2018","2023-07-12 07:25:47","2023-07-12 07:25:47","","1006–1015","","12","66","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UNRNXS56","journalArticle","1992","D'Antonio, Peter; Konnert, John","The QRD Diffractal: A New One- or Two-Dimensional Fractal Sound Diffusor","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=7057","Number theoretic diffusors, as described by Schroeder, are characterized by a periodic grouping of a series of wells of equal width, but different depths, separated by thin dividers. Over the past 7 years the quadratic residue depth sequence has been used in over 1000 applications, including recording studios, concert halls, worship spaces, conference rooms, music education, and even home theater and music listening rooms. The frequency bandwidth is determined principally by the depth of the deepest well, which determines the low-frequency limit, and the well width, which determines the upper frequency limit. Physical manufacturing constraints pose a space limitation of approximately 1 in (25.4 mm) on the well width and a depth limitation of approximately 16 in (406.4 mm), after which the units become diaphragmetic and defeat the purpose of increasing the depth further. In an effort to provide full-spectrum sound diffusion in a single integrated diffusor, the self-similarity property of fractals was combined with the uniform scattering property of the number theoretic reflection phase grating to produce a patented new diffusing fractal called the Diffractal. The Diffractal is in effect a diffusor within a diffusor, with each covering a different frequency range, much like a multiway loudspeaker. The mid-high-frequency diffusors are placed on the wells of a dedicated stiff and massive low-frequency diffusor.Thepassband of the nested band-limited diffusors and the crossover points are completely calculable, and the overall bandwidth is limited only by the available depth and the surface detail. The theory of the one- and two-dimensional diffusor, fractal geometry, and the one- and two-dimensional Diffractal is reviewed. Two installations at Real World Studios, Bath, UK, and Crawford Post, Atlanta, GA, USA, are presented.","1992","2023-07-12 07:25:50","2023-07-19 03:51:28","","117–129","","3","40","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"35NLMSRE","journalArticle","2015","Zheng, Jianwen; Zhu, Tianyi; Lu, Jing; Qiu, Xiaojun","A Linear Robust Binaural Sound Reproduction System with Optimal Source Distribution Strategy","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=17875","When binaural audio signals containing directional cues are presented with loudspeakers, the listener should still be able to localize sound images and experience a realistic three-dimensional sound environment. Because acoustic crosstalk between loudspeaker channels degrades performance, it is necessary to preprocess the binaural signals with a crosstalk cancellation system. However, a limited sweet spot is still a challenge especially when the head is laterally misaligned. To increase the robustness of the reproduction system, a direct multidrive array configuration with multiple control points is combined into the optimal source distribution strategy. The research goal is to find a good trade-off between the crosstalk cancellation performance and a high tolerance to head misalignment. Both simulations and experiments demonstrate the efficacy of the method, and the system is well suited to large display devices.","2015","2023-07-12 07:25:54","2023-07-19 10:59:22","","725–735","","9","63","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X4IKBTZE","journalArticle","2006","Aarts, Ronald M.; Nieuwendijk, Joris A.; Ouweltjes, Okke","Efficient Resonant Loudspeakers with Large Form-Factor Design Freedom","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=13882","Small cabinet loudspeakers with a flat response are quite inefficient. Assuming that the frequency response can be manipulated electronically, systems that have a nonflat soundpressure level (SPL) response can provide greater usable efficiency. Such a nonflat design can deal with very compact housing, but for small drivers it would require a relatively large cone excursion to obtain a high SPL. A new solution is presented that uses a resonant combination of a coupling volume and a long pipe-shaped port. In this structure the efficient resonant coupling of the driver to the acoustic load enables small drivers with modest cone displacement to achieve a high SPL. Due to the high and narrow peak in the frequency response, the normal operating range of the driver decreases considerably. This makes the driver unsuitable for normal use. To overcome this, a second measure is applied. Nonlinear processing essentially compresses the bandwidth of a 20–120-Hz 2.5-octave bass signal down to a much narrower span, which is centered where the driver efficiency is maximum. This system allows very compact loudspeakers. An experimental example of such a design is described, and a working prototype is discussed. The new loudspeaker is compared with a closed cabinet and a bass-reflex cabinet using the same drivers. It appears that the new loudspeaker has the highest output in its working range.","2006","2023-07-12 07:25:58","2023-07-19 03:33:15","","940–953","","10","54","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3TTLGQ5M","journalArticle","2013","Wierstorf, Hagen; Raake, Alexander; Geier, Matthias; Spors, Sascha","Perception of Focused Sources in Wave Field Synthesis","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=16663","Wave Field Synthesis (WFS) can synthesize virtual sound sources that are perceived to be at locations between loudspeakers and the listener, called focused sources. Because of practical limitations in the density of loudspeakers, there are artifacts. This research explores the amount of perceptual artifacts and the localization of the focused sources. The results from a variety of listening configurations illustrate the trade-offs. The truncation of loudspeaker arrays creates two opposite effects: (a) fewer additional wave fronts reduce the perception of artifacts, (b) stronger diffraction reduces the size of the listening area with adequate binaural cues.","2013","2023-07-12 07:26:02","2023-07-19 10:55:43","","5–16","","1/2","61","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MP3WKIE3","journalArticle","2007","Majdak, Piotr; Balazs, Peter; Laback, Bernhard","Multiple Exponential Sweep Method for Fast Measurement of Head-Related Transfer Functions","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=14190","","2007","2023-07-12 07:26:06","2023-07-12 07:26:06","","623–637","","7/8","55","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A8DD2ILC","journalArticle","2003","Smithers, Michael J.; Crockett, Brett G.; Fielder, Louis D.","Ultra-High Quality Video Frame Synchronous Audio Coding","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=12196","","2003","2023-07-12 07:26:08","2023-07-12 07:26:08","","1032–1045","","11","51","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4VRTD7Z6","journalArticle","1986","Toole, Floyd E.","Loudspeaker Measurements and Their Relationship to Listener Preferences: Part 2","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=5270","Using the highly reliable subjective ratings from an earlier study, loudspeaker measurements have been examined for systematic relationships to listener preferences. The resuls has been a logical and orderly organization of measurements that can be used to anticipate listener opinion. With the restriction to listeners with near-normal hearing and loudspeakers of the conventional forward-facing configuration, the data offer convincing proof that a reliable ranking of loudspeaker sound quality can be achieved with specific combinations of high-resolution free-field amplitude-response data. Using such data obtained at several orientations it is possible to estimate loudspeaker performance in the listening room. Listening-room and sound-power measurements alone appear to be susceptible to error in that while truly poor loudspeakers can generally be identified, excellence may not be recognized. High-quality stereo reproduction is compatible with those loudspeakers yielding high sound quality; however, there appears to be an inherent trade-off between the illusions of specific image localization and the sense of spatial involvement.","1986","2023-07-12 07:26:12","2023-07-19 04:53:30","","323–348","","5","34","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VCTL3X8T","journalArticle","2021","Falcón Pérez, Ricardo; Götz, Georg; Pulkki, Ville","Spherical Maps of Acoustic Properties as Feature Vectors in Machine-Learning-Based Estimation of Acoustic Parameters","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=21460","This work suggests a method of presenting information about the acoustical and geometric properties of a room as spherical images to a machine-learning algorithm to estimate acoustical parameters of the room. The approach has the advantage that the spatial distribution of the properties can be presented in a generic and potentially compact way to machine learning methods. The estimation of reverberation time T60 is used as a proof-of-concept study here. The distribution of absorptive material is presented as a spherical map of feature values in which each value is formed by calculating the equivalent absorption area visible through the corresponding facet of a polyhedron as seen from the polyhedron’s center point. The pixel values are then used as feature vectors and the real measured T60 values of corresponding rooms are used as target data. This work presents the method and trains a set of neural networks with different spherical map resolutions using a dataset composed of real-world acoustical measurements of a single room with 831 different configurations of furniture and absorptive materials. The estimation of reverberation time using the proposed approach exhibits a much higher accuracy compared to simple analytic methods, which proves the validity of the approach.","2021","2023-07-12 07:26:16","2023-07-19 03:55:19","","632–643","","9","69","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AJMNK3BG","journalArticle","2015","Gauthier, Philippe-Aubert; Camier, Cédric; Padois, Thomas; Pasco, Yann; Berry, Alain","Sound Field Reproduction of Real Flight Recordings in Aircraft Cabin Mock-Up","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=17562","A mock-up of an airplane cabin can be a good simulation tool for the study, prediction, demonstration, and jury testing of interior aircraft sound quality. The authors used real flight recordings created with vibrational and microphone transducer arrays in combination with multichannel equalization with least-mean-square optimization techniques. The paper presents physical evaluations of reproduced sound fields on the basis of real flight recordings using an 80-channel microphone array and 41 reproduction sources in the cabin mock-up. To provide a faithfully reproduced sound environment, time, frequency, and spatial characteristics should be preserved. Results are satisfactory given the various limitations and constraints.","2015","2023-07-12 07:26:19","2023-07-19 04:01:36","","6–20","","1/2","63","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6W8NMI54","journalArticle","2022","Andreopoulou, Areti; Katz, Brian F. G.","Perceptual Impact on Localization Quality Evaluations of Common Pre-Processing for Non-Individual Head-Related Transfer Functions","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=21738","","2022","2023-07-12 07:26:23","2023-07-12 07:26:23","","340–354","","5","70","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VAGIX3PW","journalArticle","2006","Welti, Todd; Devantier, Allan","Low-Frequency Optimization Using Multiple Subwoofers","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=13680","At low frequencies the listening environment has a significant impact on the sound quality of an audio system. Standing waves within the room cause large frequency-response variations at the listening locations. Furthermore, the frequency response changes significantly from one listening location to another; therefore the system cannot be equalized effectively. However, through the use of multiple subwoofers the seat-to-seat variation in the frequency response can be reduced significantly, allowing subsequent equalization to be more effective. Three methods to reduce seat-to-seat variation are described, including a novel approach based on simple signal processing. The desired result in each case is to allow the system to be equalized over a seating area rather than just one seat. Results are shown for several listening rooms.","2006","2023-07-12 07:26:29","2023-07-19 10:54:57","","347–364","","5","54","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"37UGCZ99","journalArticle","2007","Muraoka, Teruo; Nakazato, Tomoaki","Examination of Multichannel Sound-Field Recomposition Utilizing Frequency-Dependent Interaural Cross Correlation (FIACC)","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=14158","The locations of loudspeakers were examined utilizing frequency-dependent interaural cross correlation (FIACC) for optimum sound-field recomposition in multichannel recording and reproduction processes. Experiments were conducted and sets of FIACC measurements compared, with one taken in an original sound field, the other in the reproduced sound field. Several sound-field reproduction methods using different microphone-array geometries and matching loudspeaker-array geometries were considered. The results presented support the ITU recommendation for loudspeaker arrangements in five-channel systems (BS.775-1).","2007","2023-07-12 07:26:34","2023-07-19 04:34:23","","236–256","","4","55","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W3QZAINS","journalArticle","2008","Kim, Sunmin; Kong, Donggeon; Jang, Seongcheol","Adaptive Virtual Surround Sound Rendering System for an Arbitrary Listening Position","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=14383","A smart virtual reality presentation system, using only two loudspeakers, allows for a dynamically selected sweet spot that can be positioned at the arbitrary location of the listener. An efficient asymmetric crosstalk cancellation creates the needed filters to reposition the sweet spot; and a specialized remote control held by the listener allows the system to determine the angle and distance to the listener. Informal listening tests showed that the proposed approach can enhance the surround sound effect for television listening. Compared to conventional playback, listeners preferred this system at every location.","2008","2023-07-12 07:26:44","2023-07-19 04:12:11","","243–254","","4","56","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GUVQ95UU","journalArticle","2002","Bolaños, Fernando","Experimental Evidence of Cooperation Phenomena Application to a Loudspeaker with Rub","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=11052","An experimental investigation into cooperation phenomena is presented, which in this case can be described as the contribution of energy from a random signal to the energy of a periodic signal under certain conditions. Previously cooperation phenomena have been described mainly from a theoretical point of view. However, well-known practical examples exist. For the present experiment a loudspeaker was used that had a slightly rubbing voice coil subjected simultaneously to excitation from a random signal and from a periodic signal. Test results clearly show the influence of cooperation on both the random and the periodic signals. The random signal acquires additional ""agility,"" allowing some of its energy to be transferred to the periodic signal. Experimental results are compared with theoretical analysis based on limit cycles and Van der Pol's oscillators. The application of limit cycles is then extended to friction-induced phenomena. The subject matter is of general interest in the dynamics of nonlinear systems and of more specific interest in the behavior and testing of loudspeakers.","2002","2023-07-12 07:26:48","2023-07-19 03:43:27","","1039–1053","","12","50","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W3I23B8Q","journalArticle","2005","Zielinski, Slawomir K.; Rumsey, Francis; Kassier, Rafael; Bech, Søren","Comparison of Basic Audio Quality and Timbral and Spatial Fidelity Changes Caused by Limitation of Bandwidth and by Down-mix Algorithms in 5.1 Surround Audio Systems","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=13407","The effect on audio quality of controlled multichannel audio bandwidth limitation and selected down-mix algorithms was quantified using one generic attribute (basic audio quality) and three specific attributes (timbral fidelity, frontal spatial fidelity, and surround spatial fidelity). The investigation was focused on the standard 5.1 multichannel audio setup (ITU-R BS.775-1) and was limited to the optimum listening position. The results obtained from a panel of experienced listeners indicate that the basic audio quality of multichannel recordings is more affected by timbral fidelity than by spatial fidelities. Therefore it can be concluded that in the case of broadcasting multichannel audio under highly restricted transmission conditions, it is better, in terms of basic audio quality, to sacrifice spatial fidelity by downmixing original multichannel audio material to a lower number of broadcast audio channels than to sacrifice the timbral fidelity by transmitting all channels with limited bandwidths.","2005","2023-07-12 07:26:51","2023-07-19 10:59:48","","174–192","","3","53","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"37BEE9A9","journalArticle","2022","Kaleris, Konstantinos; Stelzner, Bjoern; Hatziantoniou, Panagiotis; Trimis, Dimosthenis; Mourjopoulos, John","Laser-Sound Transduction From Digital ΣΔ Streams","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=21550","In this work, a novel optoacoustic transducer prototype capable of reproducing continuous sound waves from single or multi-bit ∑∆ digital audio streams is presented. The prototype is based on a pulsed nanosecond laser that generates acoustic N-waves via Laser-Induced Breakdown in air or indirect sound via the laser ablation effect on solid targets. Technical aspects of the prototype platform are presented, with emphasis on the laser control system and audio signal–processing techniques deployed for the modulation of the pulsed laser radiation. Experimental results from acoustic measurements of reproduced test audio signals are presented within the frequency range allowed by the specifications of the specific laser. The system’s audio performance characteristics are derived along with its impulse and frequency responses. The experimental results are compared with simulations of the optoacoustic transducer’s response via a computational model, showing good agreement.","2022","2023-07-12 07:26:56","2023-07-19 04:09:26","","50–61","","1/2","70","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SAMNII54","journalArticle","2014","Hendrickx, Etienne; Paquier, Mathieu; Koehl, Vincent","The Influence of Stereoscopy on the Sound Mixing of Movies: A Study on the Front/Rear Balance of Ambience","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=17548","","2014","2023-07-12 07:26:59","2023-07-12 07:26:59","","723–735","","11","62","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YG9LXGQY","journalArticle","2021","Agrawal, Sarvesh; Bech, Søren; Bærentsen, Klaus; De Moor, Katrien; Forchhammer, Søren","Method for Subjective Assessment of Immersion in Audiovisual Experiences","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=21462","Studying immersion in audiovisual experiences can help technologists deliver engaging and enhanced experiences. As a first step toward this goal this paper details an investigation conducted to establish an experimental paradigm for quantifying immersion and determining the influence of immersive tendency (susceptibility to become immersed) on immersion. A balanced incomplete block design was employed where 21 assessors rated 15 commercially available stimuli (representative of the highest quality encountered in domestic AV applications) without repetitions and simultaneous comparisons. The assessors were instructed to rate immersion on a graphic line scale and document their familiarity with the content. A questionnaire was administered to measure the immersive tendency after the rating experiment. The results show that the assessors can comprehend the description of immersion and follow the experimental protocol. It is found that immersion is a graded experience and the correlation between immersive tendencies and immersion ratings is predominantly statistically insignificant. The experimental paradigm presented in this paper can form the framework for assessing immersion and developing novel methods to thoroughly explore the concept of immersion in audiovisual experiences.","2021","2023-07-12 07:27:03","2023-07-19 03:34:21","","656–671","","9","69","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IYC9JUUC","journalArticle","2010","Faller II, Kenneth John; Barreto, Armando; Adjouadi, Malek","Augmented Hankel Total Least-Squares Decomposition of Head-Related Transfer Functions","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=15238","Filters based on head-related transfer functions (HRTFs) allow a monaural source to be localized in a three-dimensional virtual space. There are three ways to obtain HRTF impulse responses: (a) individually measured on each specific person, which requires extensive effort; (b) generic standardized responses, such as dummy heads, which are often inaccurate; and (c) derived responses based on anthropometric measurements of an individual’s head. This article proposes an approach for decomposing HRTFs that will facilitate the development of systems based on the third method. This method offers the potential to produce high accuracy without the extensive effort.","2010","2023-07-12 07:27:06","2023-07-19 03:55:37","","3–21","","1/2","58","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GWEV43XX","journalArticle","2017","Kodrasi, Ina; Cauchi, Benjamin; Goetze, Stefan; Doclo, Simon","Instrumental and Perceptual Evaluation of Dereverberation Techniques Based on Robust Acoustic Multichannel Equalization","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=18549","Speech signals recorded in an enclosed space by microphones at a distance from the speaker are often corrupted by reverberation, which arises from the superposition of many delayed and attenuated copies of the source signal. Because reverberation degrades the signal, removing reverberation would enhance quality. Dereverberation techniques based on acoustic multichannel equalization are known to be sensitive to room impulse response perturbations. In order to increase robustness, several methods have been proposed, as for example, using a shorter reshaping filter length, incorporating regularization, or applying a sparsity-promoting penalty function. This paper focuses on evaluating the performance of these methods for single-source multi-microphone scenarios, using instrumental performance measures as well as using subjective listening tests. By analyzing the correlation between the instrumental and the perceptual results, it is shown that signal-based performance measures are more advantageous than channel-based performance measures to evaluate the perceptual speech quality of signals that were dereverberated by equalization techniques. Furthermore, this analysis also demonstrates the need to develop more reliable instrumental performance measures.","2017","2023-07-12 07:27:09","2023-07-19 04:15:49","","117–129","","1/2","65","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TR9GXJ6V","journalArticle","1999","Møller, Henrik; Hammershøi, Dorte; Johnson, Clemen Boje; Sørensen, Michael Friis","Evaluation of Artificial Heads in Listening Tests","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=12115","The localization performance was studied when subjects listened 1) to a real sound field and 2) to artificial-head recordings of the same sound field. The experiments took place in a standard listening room where each stimulus (female speech) was emitted from one of 19 loudspeakers, and the subjects were to indicate the perceived sound source. The artificial-head recordings were made a) by the artificial heads' built-in microphones and b) by blocked ear canal microphones. The reproduction was carried out by carefully equalized headphones. Eight artificial heads were included in the investigation, and 20 subjects participated, except for the experiment with recordings from built-in microphones, which was performed for eight subjects. When compared to real life, the localization performance with the artificial heads resulted in an increased number of errors independent of the recording technique. In general, the directions in the median plane were frequently confused, not only with nearby directions, but also with directions further away. For some artificial heads there was also an increase in confusions of directions outside the median plane. A much better performance is obtainable with binaural recordings made in the ears of humans. This encourages the design and production of improved artificial heads.","1999","2023-07-12 07:27:13","2023-07-19 04:32:32","","83–100","","3","47","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H8D8GJGV","journalArticle","2023","Vidal, Adrien; Herzog, Philippe; Lambourg, Christophe; Chatron, Jacques","Comparison of Transaural Configurations Inside Usual Rooms","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=22041","This paper deals with the design of transaural systems in usual rooms, whose response has a strong influence on sound reproduction. The paper proposes to select configurations for the best perceptual rendering. However, realistic perceptive experiments cannot deal with the many possible room and loudspeaker configurations. Therefore, the authors propose to assess them using objective scores that are extrapolated from the results of perceptive tests assessing a suitable selection of rooms and loudspeaker configurations. This extrapolation then allows comparison of a much larger set of combinations, leading to the conclusion that close-to-ears configurations allow reduction of the room influence, leading to a good perceived fidelity---even inside usual rooms. Closer loudspeakers are, however, likely to be more sensitive to listener position, so the robustness of loudspeaker configurations to listenermisplacement were investigated. A suitable objective score, again based on a perceptive test, led to the surprising conclusion that some close-to-ears configurations are also robust to listener position.","2023","2023-07-12 07:27:16","2023-07-19 04:55:20","","202–215","","4","71","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2QMP5NQE","journalArticle","2021","Bernier, Antoine; Bouserhal, Rachel E.; Voix, Jérémie; Herzog, Philippe","Design and Assessment of an Active Musician's Hearing Protection Device With Occlusion Effect Reduction","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=21459","This paper presents the design and assessment of an active musician’s hearing protection device focusing on occlusion effect reduction through active noise control. The system is designed to adapt its feedback compensation to achieve a specified target performance across users, regardless of their ear canal acoustic properties. The detailed design process of the prototype earpiece and feedback compensation algorithm are presented, validated, and implemented. Experimental measurements show the system is able to maintain robust and stable occlusion effect reduction despite great variation in the acoustic properties of an adjustable ear simulator.","2021","2023-07-12 07:27:19","2023-07-19 03:42:05","","618–631","","9","69","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RSMAP3IQ","journalArticle","2008","James, B. St.; Hawksford, M. O. J.","Corpuscular Streaming and Parametric Modification Paradigm for Spatial Audio Teleconferencing","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=14639","This paper presents a new paradigm for spatial audio teleconferencing that exploits the corpuscular nature of general audio parametric coding for low bit-rate audio compression. The paradigm consists of several processing tools. The spatial aspect is enacted by a dynamic rendition tool that optimizes placement of speech sources within the soundscape; the temporal aspects of a phoneme protection tool misalign corruptive and vulnerable speech elements in a multitalking environment. A novel means of echo suppression eliminates the need for adaptive filtering and real-time echo cancellation, which is difficult for multichannel audio.","2008","2023-07-12 07:27:23","2023-07-19 04:08:06","","823–843","","10","56","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6YE4VXRF","journalArticle","2019","Stefanakis, Nikolaos; Mastorakis, Yannis; Alexandridis, Anastasios; Mouchtaris, Athanasios","Automating Mixing of User-Generated Audio Recordings from the Same Event","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=20452","When users attend the same public event, there may be multiple audiovisual recordings that are then posted on social media and websites. The availability of such a massive amount of user-generated recordings (UGR) has triggered new research directions related to the search, organization, and management of this content. And it has provided inspiration for new business models for content storage, retrieval, and consumption. The authors propose an approach to combine the available recordings based on a normalization step and a mixing step. The normalization step defines a fixed-with-time gain that is specific to each UGR. In the mixing step, a mechanism that reduces the master gain in accordance with the number of activated inputs at each time is employed. An approach called orthogonal mixing is presented, which is based on the assumption that the mixture components are mutually independent. The presented mixing process allows the combination of multiple short-duration UGRs to produce a longer audio stream, with potentially better quality than any one of its constituent parts. This property is exploited in the design of an automatic mixing process that exploits all the available audio recordings at each moment. Automatic mixing is then possible.","2019","2023-07-12 07:27:42","2023-07-19 04:49:09","","201–212","","4","67","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DBASJICJ","journalArticle","1987","Julstrom, Stephen","A High-Performance Surround Sound Process for Home Video","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=5192","Video disks, high-fidelity video cassettes, and stereo television bring to the consumer a substantial library of video entertainment with high-quality stereo sound tracks. A growing portion of these are encoded with surround sound using a 4-2-4 matrix-based method particularly suited to front-stage oriented film/video presentation. Home reproduction is accomplished with a processor incorporating dynamic matrix modification to stabilize and enhance directional effects and a delayed surround channel to aid forward localization of front sound.","1987","2023-07-12 07:27:46","2023-07-19 04:09:18","","536–549","","7/8","35","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MQY5RY8E","journalArticle","2023","Marchan, Mick; Allen, Andrew","Multi-Layered Architecture for Efficient and Accurate HRTF Rendering","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=22141","","2023","2023-07-12 07:27:50","2023-07-12 07:27:50","","338–348","","6","71","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DJNSA93M","journalArticle","2005","Aarts, Ronald M.","High-Efficiency Low-Bl Loudspeakers","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=13427","Normally, low-frequency sound reproduction with small transducers is quite inefficient. This is shown by calculating the efficiency and voltage sensitivity for loudspeakers with high, medium, and, in particular, low force factors. For these low-force-factor loudspeakers a practically relevant and analytically tractable optimality criterion, involving the loudspeaker parameters, will be defined. Actual prototype bass drivers are assessed according to this criterion. Because the magnet can be considerably smaller than usual, the loudspeaker can be of the moving-magnet type with a stationary coil. These so-called low-Bl drivers have a high efficiency, however, only in a limited frequency region. To deal with that, nonlinear processing essentially compresses the bandwidth of a 20–120-Hz bass signal down to a much more narrow span. This span is centered at the resonance of the low-Bl driver, where its efficiency is maximum. The signal processing preserves the temporal envelope modulations of the original bass signal. The compression is at the expense of a decreased sound quality and requires some additional electronics. This new, optimal design has a much higher power efficiency as well as a higher voltage sensitivity than current bass drivers, while the cabinet may be much smaller.","2005","2023-07-12 07:27:54","2023-07-19 03:32:59","","579–592","","7/8","53","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8QEUGQMZ","journalArticle","2022","Johansson, Jaan; Mäkivirta, Aki; Malinen, Matti; Saari, Ville","Interaural Time Difference Prediction Using Anthropometric Interaural Distance","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=22011","This paper studies the feasibility of predicting the interaural time difference (ITD) in azimuth and elevation once the personal anthropometric interaural distance is known, proposing an enhancement for spherical head ITD models to increase their accuracy. The method and enhancement are developed using data in a Head-Related Impulse Response (HRIR) data set comprising photogrammetrically obtained personal 3D geometries for 170 persons and then evaluated using three acoustically measured HRIR data sets containing 119 persons in total. The directions include 360° in azimuth and –15° to 60° in elevation. The prediction error for each data set is described, the proportion of persons under a given error in all studied directions is shown, and the directions in which large errors occur are analyzed. The enhanced spherical head model can predict the ITD such that the first and 99th percentile levels of the ITD prediction error for all persons and in all directions remains below 122 µs. The anthropometric interaural distance could potentially be measured directly on a person, enabling personalized ITD without measuring the HRIR. The enhanced model can personalize ITD in binaural rendering for headphone reproduction in games and immersive audio applications.","2022","2023-07-12 07:27:58","2023-07-19 04:08:49","","843–857","","10","70","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MRZLMXK3","journalArticle","1998","Gander, Mark R.","Fifty Years of Loudspeaker Developments as Viewed Through the Perspective of the Audio Engineering Society","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=12162","An exhaustive review of over 450 AES Journal loudspeaker papers and other select references is presented and categorized by subject area. The names and affiliations of the authors are included. Perspective is given on the technical significance, degree of influence, and historical context of the contributions and contributors. Except where otherwise noted, all references are from the Journal of the Audio Engineering Society and, where applicable, the volumes of the AES Loudspeakers anthology.","1998","2023-07-12 07:28:01","2023-07-19 04:01:20","","43–58","","1/2","46","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5KS8C42R","journalArticle","2019","Lee, Hyunkook","Capturing 360° Audio Using an Equal Segment Microphone Array (ESMA)","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=19883","Microphone array techniques for surround sound recording can be broadly classified into two groups: those that attempt to produce the continuous phantom imaging around 360° in the horizontal plane and those that treat the front and rear channels separately. The equal segment microphone array (ESMA) is a multichannel microphone technique that attempts to capture a sound field in 360° without any overlap between the stereophonic recording angle of each pair of adjacent microphones. This study investigated the optimal microphone spacing for a quadraphonic ESMA using cardioid microphones. Recordings of a speech source were made using the ESMAs with four different microphone spacings of 0 cm, 24 cm, 30 cm, and 50 cm, based on different psychoacoustic models for microphone array design. Multichannel and binaural stimuli were created with the reproduced sound field rotated over 45° intervals. Listening tests were conducted to examine the accuracy of phantom image localization for each microphone spacing, in both loudspeaker and binaural headphone reproductions. The results generally indicated that the 50-cm spacing, which was derived from an interchannel time and level trade-off model that is perceptually optimized for 90° loudspeaker base angle, produced more accurate localization results than the 24-cm and 30-cm ones, which were based on conventional models derived from the standard 60° loudspeaker setup. The 0-cm spacing produced the worst accuracy with the most frequent bimodal distributions of responses between the front and back regions. Findings from this study are expected to be useful for acoustic recording for virtual reality applications as well as for multichannel surround sound.","2019","2023-07-12 07:28:05","2023-07-19 04:18:52","","13–26","","1/2","67","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S6Q6VZS4","journalArticle","2003","Paatero, Tuomas; Karjalainen, Matti","Kautz Filters and Generalized Frequency Resolution: Theory and Audio Applications","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=12248","Frequency-warped filters have recently been applied successfully to a number of audio applications. The idea of all-pass delay elements replacing unit delays in digital filters allows for focusing enhanced frequency resolution on the lowest (or highest) frequencies and enables a good match to the psychoacoustical Bark scale. Kautz filters can be seen as a further generalization, where each all-pass element may be different, allowing also complexconjugate poles. This enables an arbitrary allocation of frequency resolution to filter design, such as modeling and equalization (inverse modeling) of linear systems. Strategies for using Kautz filters in audio applications are formulated. Case studies of loudspeaker equalization, room response modeling, and guitar body modeling for sound synthesis are presented.","2003","2023-07-12 07:28:10","2023-07-19 04:36:43","","27–44","","1/2","51","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J2JGZW52","journalArticle","2001","Minnaar, Pauli; Olesen, S. Krarup; Christensen, Flemming; Møller, Henrik","Localization with Binaural Recordings from Artificial and Human Heads","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=10193","","2001","2023-07-12 07:28:13","2023-07-12 07:28:13","","323–336","","5","49","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LTZ3VVKX","journalArticle","1976","Preis, Douglas","Linear Distortion","J. Audio Eng. Soc","","","","http://www.aes.org/e-lib/browse.cfm?elib=2618","Linear distortion is defined and exemplified. Important early contributions dealing with its fundamental properties as well as more recent work showing its occurrence in practical audio devices are mentioned. Necessary conventions for steady-state phase-shift measurements are presented along with a discussion and resolution of some associated ambiguities. The behavior of the phase-shift versus frequency characteristic is approximated within a frequency band by a two-term Taylor series, then a catalog of experimentally measured steady-state and transient response properties of a general minimum-phase system is given and qualitatively related to this approximation. Apart from known mathematical relationships, this establishes practical and intuitive relationships between time-domain and frequency-domain measurements. Definitions, limitations, and specific examples of phase delay and group delay are given, which are based upon the same Taylor series approximation. The importance of the group-delay versus frequency characteristic-including its flatness and distortion-is discussed. A significant early experiment which illustrates group-delay distortion is reviewed. Specific examples are given of various measured and calculated group-delay characteristics for a wide variety of practical audio devices, including power amplifiers, magnetic tape recorders, bandpass filters as well as wideband systems, and the general second-order system which is often representative of transducers such as microphones, loudspeakers, and phonograph cartridges. Intercept distortion and echo distortion are also discussed. Differential group-delay distortion is defined, and its occurrence in multichannel systems is both predicted theoretically and measured. Some contemporary methods for correcting linear distortion are briefly reviewed. It is concluded that complete specification of magnitude, phase and group-delay characteristics is essential to the proper technical assessment of audio quality.","1976","2023-07-12 07:28:22","2023-07-19 04:38:53","","346–367","","5","24","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YCHYGCQY","journalArticle","1997","Bosi, Marina; Brandenburg, Karlheinz; Quackenbush, Schuyler; Fielder, Louis; Akagiri, Kenzo; Fuchs, Hendrik; Dietz, Martin","ISO/IEC MPEG-2 Advanced Audio Coding","Journal of the Audio Engineering Society","","","","https://www.aes.org/e-lib/browse.cfm?elib=10271","The ISO/IEC MPEG-2 advanced audio coding (AAC) system was designed to provide MPEG-2 with the best audio quality without any restrictions due to compatibility requirements. The main features of the AAC system (ISO/IEC 13818-7) are described. MPEG-2 AAC combines the coding efficiency of a high-resolution filter bank, production techniques, and Huffman coding with additional functionalities aimed to deliver very high audio quality at a variety of data rates.","1997-10-01","2023-07-17 05:10:16","2023-07-17 05:10:16","2023-07-17 05:10:16","789-814","","10","45","","JAES","","","","","","","","English","","","","","www.aes.org","","Publisher: Audio Engineering Society","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""