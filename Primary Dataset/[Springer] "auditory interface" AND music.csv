"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"CFHB45EM","bookSection","2006","Murphy, Emma; Pirhonen, Antti; McAllister, Graham; Yu, Wai","A Semiotic Approach to the Design of Non-speech Sounds","Haptic and Audio Interaction Design","978-3-540-37595-1 978-3-540-37596-8","","","http://link.springer.com/10.1007/11821731_12","In the field of auditory display there is currently a lack of theoretical support for the design of non-speech sounds as elements of a user interface. Sound design methods are often based on ad hoc choices or the personal preferences of the designer. A method is proposed in this paper based on a semiotic approach to the design of non-speech sounds. In this approach, the design process is conceptualised by referring to structural semiotics, acknowledging the unique qualities of non-speech sounds, as a mode of conveying information. This method is based on a rich use scenario presented to a design panel. A case study where the design method has been applied is presented and evaluated. Finally recommendations for a practical design method are presented supported by this empirical investigation.","2006","2023-07-05 07:32:03","2023-07-20 00:15:41","2023-07-05 07:32:03","121-132","","","4129","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/11821731_12","","","","","","McGookin, David; Brewster, Stephen","Hutchison, David; Kanade, Takeo; Kittler, Josef; Kleinberg, Jon M.; Mattern, Friedemann; Mitchell, John C.; Naor, Moni; Nierstrasz, Oscar; Pandu Rangan, C.; Steffen, Bernhard; Sudan, Madhu; Terzopoulos, Demetri; Tygar, Dough; Vardi, Moshe Y.; Weikum, Gerhard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UKZ8B66Y","bookSection","2006","Coleman, Graeme W.; Macaulay, Catriona; Newell, Alan F.","Listen to This – Using Ethnography to Inform the Design of Auditory Interfaces","Haptic and Audio Interaction Design","978-3-540-37595-1 978-3-540-37596-8","","","http://link.springer.com/10.1007/11821731_13","Within the wider Human-Computer Interaction community, many researchers have turned to ethnography to inform systems design. However, such approaches have yet to be fully utilized within auditory interface research, a field hitherto driven by technology-inspired design work and the addressing of specific cognitive issues. It is proposed that the time has come to investigate the role ethnographic methods have to play within auditory interface design. We begin by discussing “traditional” ethnographic methods by presenting our experiences conducting a field study with a major UK-based computer games developer, highlighting issues pertinent to the design of auditory interfaces, before suggesting ways in which such techniques could be expanded to consider the role sound plays in people’s lived experiences and thus merit further research.","2006","2023-07-05 07:53:21","2023-07-20 00:14:30","2023-07-05 07:53:21","133-144","","","4129","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/11821731_13","","","","","","McGookin, David; Brewster, Stephen","Hutchison, David; Kanade, Takeo; Kittler, Josef; Kleinberg, Jon M.; Mattern, Friedemann; Mitchell, John C.; Naor, Moni; Nierstrasz, Oscar; Pandu Rangan, C.; Steffen, Bernhard; Sudan, Madhu; Terzopoulos, Demetri; Tygar, Dough; Vardi, Moshe Y.; Weikum, Gerhard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4NZG9K45","bookSection","2010","Sanderson, Penelope M.","The Power and the Puzzles of Auditory Interfaces","Human-Computer Interaction","978-3-642-15230-6 978-3-642-15231-3","","","http://link.springer.com/10.1007/978-3-642-15231-3_1","","2010","2023-07-05 07:53:21","2023-07-05 07:53:21","2023-07-05 07:53:21","1-2","","","332","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: IFIP Advances in Information and Communication Technology DOI: 10.1007/978-3-642-15231-3_1","","/Users/minsik/Zotero/storage/EIZGA7WP/Sanderson - 2010 - The Power and the Puzzles of Auditory Interfaces.pdf","","","","Forbrig, Peter; Paternó, Fabio; Mark Pejtersen, Annelise","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"53E972CW","bookSection","2009","Ferati, Mexhid; Bolchini, Davide; Mannheimer, Steve","Towards a Modeling Language for Designing Auditory Interfaces","Universal Access in Human-Computer Interaction. Applications and Services","978-3-642-02712-3 978-3-642-02713-0","","","http://link.springer.com/10.1007/978-3-642-02713-0_53","","2009","2023-07-05 07:53:21","2023-07-05 07:53:21","2023-07-05 07:53:21","502-511","","","5616","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","en","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-642-02713-0_53","","/Users/minsik/Zotero/storage/5XJ6WNAM/Ferati et al. - 2009 - Towards a Modeling Language for Designing Auditory.pdf","","","","Stephanidis, Constantine","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M3HXZUJM","journalArticle","2014","Kiriella, Dawpadee B.; Kumari, Shyama C.; Ranasinghe, Kavindu C.; Jayaratne, Lakshman","Music Training Interface for Visually Impaired through a Novel Approach to Optical Music Recognition","GSTF Journal on Computing (JoC)","","2010-2283","10.7603/s40601-013-0045-6","http://www.globalsciencejournals.com/article/10.7603/s40601-013-0045-6","Abstract                            Some inherited barriers which limits the human abilities can be surprisingly win through technology. This research focuses on defining a more reliable and a controllable interface for visually impaired people to read and study eastern music notations which are widely available in printed format. One of another concept behind was that differently-abled people should be assisted in a way which they can proceed interested tasks in an independent way. The research provide means to continue on researching the validity of using a controllable auditory interface instead using Braille music scripts converted with the help of 3               rd               parties. The research further summarizes the requirements aroused by the relevant users, design considerations, evaluation results on user feedbacks of proposed interface.","2014-05","2023-07-05 07:53:21","2023-07-05 07:53:21","2023-07-05 07:53:21","45","","4","3","","GSTF J Comput","","","","","","","","en","","","","","DOI.org (Crossref)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LUHESLME","bookSection","2004","Ku, Kyong-I; Won, Jae-Yong; Park, Jaehyun; Kim, Yoo-Sung","A Content-Based Music Retrieval System Using Multidimensional Index of Time-Sequenced Representative Melodies from Music Database","Advances in Databases and Information Systems","978-3-540-23243-8 978-3-540-30204-9","","","http://link.springer.com/10.1007/978-3-540-30204-9_17","In content-based music retrieval systems, since both the correctness and the performance of retrievals are important, a few content-based music retrieval systems have the melody index which contains the representative melodies of music to be likely used as users’ queries. In this paper, we describe the development of a content-based music retrieval system in which the multidimensional index of time-sequenced representative melodies extracted appropriately based on musical composition forms is used to support quick and appropriate retrievals to users’ melody queries. From the experimental results, we can see that the developed system can retrieve more relevant results than previous systems with smaller storage overhead than whole melody index.","2004","2023-07-05 07:53:21","2023-07-19 11:11:31","2023-07-05 07:53:21","246-258","","","3255","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-540-30204-9_17","","","","","","Benczúr, András; Demetrovics, János; Gottlob, Georg","Hutchison, David; Kanade, Takeo; Kittler, Josef; Kleinberg, Jon M.; Mattern, Friedemann; Mitchell, John C.; Naor, Moni; Nierstrasz, Oscar; Pandu Rangan, C.; Steffen, Bernhard; Sudan, Madhu; Terzopoulos, Demetri; Tygar, Dough; Vardi, Moshe Y.; Weikum, Gerhard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S6ILUD2H","bookSection","2005","Won, Jae-Yong; Lee, Jae-Heon; Ku, KyongI; Park, Jaehyun; Kim, Yoo-Sung","A Content-Based Music Retrieval System Using Representative Melody Index from Music Databases","Computer Music Modeling and Retrieval","978-3-540-24458-5 978-3-540-31807-1","","","http://link.springer.com/10.1007/978-3-540-31807-1_21","For content-based music retrieval, since not only the correctness of retrieval results but also the performance of retrievals is important, there are great needs for efficient content-based music retrieval systems that can quickly retrieve the relevant music on demand from large music database with low storage overhead. In this paper, we describe the design and implementation of a content-based music retrieval system in which the representative melody index is systemically constructed and used to support quick and appropriate retrievals to users’ melody queries. By using the proposed system for digital music libraries, it could save up to 65% of index space than that for the whole motifs index while the appropriateness of retrieval results is maintained.","2005","2023-07-05 07:53:21","2023-07-19 23:48:32","2023-07-05 07:53:21","280-294","","","3310","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-540-31807-1_21","","","","","","Wiil, Uffe Kock","Hutchison, David; Kanade, Takeo; Kittler, Josef; Kleinberg, Jon M.; Mattern, Friedemann; Mitchell, John C.; Naor, Moni; Nierstrasz, Oscar; Pandu Rangan, C.; Steffen, Bernhard; Sudan, Madhu; Terzopoulos, Demetri; Tygar, Dough; Vardi, Moshe Y.; Weikum, Gerhard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DHHSM4XX","bookSection","2010","Gygi, Brian; Shafiro, Valeriy","From Signal to Substance and Back: Insights from Environmental Sound Research to Auditory Display Design","Auditory Display","978-3-642-12438-9 978-3-642-12439-6","","","http://link.springer.com/10.1007/978-3-642-12439-6_16","","2010","2023-07-05 07:53:21","2023-07-05 07:53:21","2023-07-05 07:53:21","306-329","","","5954","","","From Signal to Substance and Back","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-642-12439-6_16","","/Users/minsik/Zotero/storage/FQE4JA2J/Gygi and Shafiro - 2010 - From Signal to Substance and Back Insights from E.pdf","","","","Ystad, Sølvi; Aramaki, Mitsuko; Kronland-Martinet, Richard; Jensen, Kristoffer","Hutchison, David; Kanade, Takeo; Kittler, Josef; Kleinberg, Jon M.; Mattern, Friedemann; Mitchell, John C.; Naor, Moni; Nierstrasz, Oscar; Pandu Rangan, C.; Steffen, Bernhard; Sudan, Madhu; Terzopoulos, Demetri; Tygar, Doug; Vardi, Moshe Y.; Weikum, Gerhard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DUWIKXFR","bookSection","2020","Huang, Yu Ting; Chu, Chi Nung","Multi-sensations Mechanism of Users on the Learning Platform Design of Music Aural Skills","Frontier Computing","9789811532498 9789811532504","","","http://link.springer.com/10.1007/978-981-15-3250-4_240","This paper discusses the nature of aural skills learning with technology implementation in multi-sensations mechanism. By providing the learning platform design of aural skills with different interface design guidelines, the use of technology with multi-sensations to assist teaching and learning could facilitate more novices to music world.","2020","2023-07-05 07:53:21","2023-07-20 00:06:42","2023-07-05 07:53:21","1803-1809","","","551","","","","","","","","Springer Singapore","Singapore","en","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Electrical Engineering DOI: 10.1007/978-981-15-3250-4_240","","","","","","Hung, Jason C.; Yen, Neil Y.; Chang, Jia-Wei","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H2D86RXQ","journalArticle","2018","Collares, Leandro; Tavares, Tiago F.; Gooch, Amy; Tzanetakis, George","Personalizing self-organizing music spaces with anchors: design and evaluation","Multimedia Tools and Applications","","1380-7501, 1573-7721","10.1007/s11042-017-4465-8","http://link.springer.com/10.1007/s11042-017-4465-8","We propose and evaluate a system for content-based visualization and exploration of music collections. The system is based on a modification of Kohonen’s Self-Organizing Map algorithm and allows users to choose the locations of clusters containing acoustically similar tracks on the music space. A user study conducted to evaluate the system shows that the possibility of personalizing the music space was perceived as difficult. Conversely, the user study and objective metrics derived from users’ interactions with the interface demonstrate that the proposed system helped individuals create playlists faster and, under some circumstances, more effectively. We believe that personalized browsing interfaces are an important area of research in Multimedia Information Retrieval, and both the system and user study contribute to the growing work in this field.","2018-03","2023-07-05 07:53:21","2023-07-21 04:31:53","2023-07-05 07:53:21","5525-5545","","5","77","","Multimed Tools Appl","Personalizing self-organizing music spaces with anchors","","","","","","","en","","","","","DOI.org (Crossref)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2AQ9JMP9","bookSection","2019","Rogozinsky, Gleb G.; Lyzhinkin, Konstantin; Egorova, Anna; Podolsky, Dmitry","Distributed Software Hardware Solution for Complex Network Sonification","Language, Music and Computing","978-3-030-05593-6 978-3-030-05594-3","","","http://link.springer.com/10.1007/978-3-030-05594-3_12","","2019","2023-07-05 07:53:21","2023-07-05 07:53:21","2023-07-05 07:53:21","149-160","","","943","","","","","","","","Springer International Publishing","Cham","","","","","","DOI.org (Crossref)","","Series Title: Communications in Computer and Information Science DOI: 10.1007/978-3-030-05594-3_12","","","","","","Eismont, Polina; Mitrenina, Olga; Pereltsvaig, Asya","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EP78HLJB","bookSection","1992","Holland, Simon","Interface Design for Empowerment: a Case Study from Music","Multimedia Interface Design in Education","978-3-540-55046-4 978-3-642-58126-7","","","http://link.springer.com/10.1007/978-3-642-58126-7_12","It is very seldom that psychological theory is applied to human - computer interface design — because very few theories have yet been formulated which are applicable. For the most part designers have to be content to use guidelines and models, which have less applicability. So, the work described in this chapter is unusual, because it describes an interface to a program which teaches about musical harmony, based on psychological theories. The success of that approach is borne out by the fact that the theories suggest the use of a specific style of interface, based on a two-dimensional spatial representation of harmony relationships. This in turn has been shown to be very successful in teaching novice users about harmony.","1992","2023-07-05 07:53:21","2023-07-21 04:30:50","2023-07-05 07:53:21","177-194","","","","","","Interface Design for Empowerment","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","en","","","","","DOI.org (Crossref)","","DOI: 10.1007/978-3-642-58126-7_12","","","","","","Edwards, Alistair D. N.; Holland, Simon","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4VFXQYKZ","bookSection","2017","Chung, Szu-Ming; Wu, Chun-Tsai","Mobile Device Applications for Head Start Experience in Music","Interactivity, Game Creation, Design, Learning, and Innovation","978-3-319-55833-2 978-3-319-55834-9","","","http://link.springer.com/10.1007/978-3-319-55834-9_22","This research intends to develop music games as mobile device applications on android system for head start experience in music. The study of design content includes the perception, knowledge formation, musical knowledge and ability, and children’s play and learning motivation. 8 mobile device applications across two levels have been created and 4 of the first game level are tested by 21 preoperational children. In the latter part of this qualitative research, researchers collect data from participants’ observation, video recording, and tablet input data records. The credibility and validation study consisted of two steps: analyzing and comparing 3 dimensions of attitude, interaction, and problem solving of collected data.","2017","2023-07-05 07:53:21","2023-07-20 06:37:21","2023-07-05 07:53:21","189-196","","","196","","","","","","","","Springer International Publishing","Cham","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering DOI: 10.1007/978-3-319-55834-9_22","","","","","","Brooks, Anthony L.; Brooks, Eva","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q98CXXAV","journalArticle","1999","Barrass, Stephen; Kramer, Gregory","Using sonification","Multimedia Systems","","0942-4962, 1432-1882","10.1007/s005300050108","http://link.springer.com/10.1007/s005300050108","","1999-01-01","2023-07-05 07:53:21","2023-07-05 07:53:21","2023-07-05 07:53:21","23-31","","1","7","","Multimedia Systems","","","","","","","","","","","","","DOI.org (Crossref)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FL4MAP4W","bookSection","2008","Devallez, Delphine; Rocchesso, Davide; Fontana, Federico","An Audio-Haptic Interface Concept Based on Depth Information","Haptic and Audio Interaction Design","978-3-540-87882-7 978-3-540-87883-4","","","http://link.springer.com/10.1007/978-3-540-87883-4_11","","2008","2023-07-05 07:53:21","2023-07-05 07:53:21","2023-07-05 07:53:21","102-110","","","5270","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","en","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-540-87883-4_11","","","","","","Pirhonen, Antti; Brewster, Stephen","Hutchison, David; Kanade, Takeo; Kittler, Josef; Kleinberg, Jon M.; Mattern, Friedemann; Mitchell, John C.; Naor, Moni; Nierstrasz, Oscar; Pandu Rangan, C.; Steffen, Bernhard; Sudan, Madhu; Terzopoulos, Demetri; Tygar, Doug; Vardi, Moshe Y.; Weikum, Gerhard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EQHW794T","journalArticle","2022","Costa, Daniel; Duarte, Carlos","Audio rendering smart TV apps through mobile devices","Universal Access in the Information Society","","1615-5289, 1615-5297","10.1007/s10209-021-00796-1","https://link.springer.com/10.1007/s10209-021-00796-1","TV service providers now offer a variety of features, including broadcast-related ones like electronic programme guides, catch-up and recording features, but also Internet access and a variety of TV applications. These new features turn TV devices into more versatile and interesting platforms, but also clog the screen with more content than ever. Since this content is mainly visual, this means that TVs have even more inaccessible content for visually impaired people. This paper presents the design of a solution that audio renders the TV application’s user interface through a mobile device. Resorting to a mix of accessibility experts and user studies, we compared multiple feedback versions containing different contextual information. Participants reported that the use of repetitive sentences should be avoided; concise feedback feels smoother and quicker but, for some, lacks information while extended feedback can be annoying and take too much time though is appropriate for learning phases. For menus, most participants suggested to include the position of an element and the number of elements. The results helped to identify the critical information to convey to the user and to tailor two modes differing in the amount of contextual information provided, suitable for differently skilled users. Additionally, we condensed the findings into a list of design guidelines which can be generalized to other auditory interfaces meant to be operated by a VI user.","2022-08","2023-07-05 07:53:21","2023-07-21 05:11:10","2023-07-05 07:53:21","675-689","","3","21","","Univ Access Inf Soc","","","","","","","","en","","","","","DOI.org (Crossref)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E4Y9MDAR","bookSection","2010","Wersényi, György","Auditory Representations of a Graphical User Interface for a Better Human-Computer Interaction","Auditory Display","978-3-642-12438-9 978-3-642-12439-6","","","http://link.springer.com/10.1007/978-3-642-12439-6_5","","2010","2023-07-05 07:53:21","2023-07-05 07:53:21","2023-07-05 07:53:21","80-102","","","5954","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-642-12439-6_5","","","","","","Ystad, Sølvi; Aramaki, Mitsuko; Kronland-Martinet, Richard; Jensen, Kristoffer","Hutchison, David; Kanade, Takeo; Kittler, Josef; Kleinberg, Jon M.; Mattern, Friedemann; Mitchell, John C.; Naor, Moni; Nierstrasz, Oscar; Pandu Rangan, C.; Steffen, Bernhard; Sudan, Madhu; Terzopoulos, Demetri; Tygar, Doug; Vardi, Moshe Y.; Weikum, Gerhard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G6TH8FE9","bookSection","2021","Men, Delai; Wu, Lingfang","The Investigation into Design Elements of Auditory Pleasure Experience for the Elderly Based on a Testing Tools Development","HCI International 2021 - Late Breaking Papers: Cognition, Inclusion, Learning, and Culture","978-3-030-90327-5 978-3-030-90328-2","","","https://link.springer.com/10.1007/978-3-030-90328-2_16","The vision system of the elderly will undergo age-related changes. Hearing, as a sensory channel for processing external information second only to vision, will impair the use and perception of products or services. User experience is a hot topic in design research related to the elderly in recent years. Designers also pay more attention to thinking about the experience needs of the elderly from the perspective of multi-sensory channels. However, the research on auditory aging design has not been fully developed yet. The purpose of this study was to investigate the design elements and characteristics of the elderly’s auditory pleasure experience, so as to provide a reference basis for the auditory dimension of the aging design. The research methods include literature study, questionnaire, test, and interview. This study defined and extracted the elements that affect the pleasure auditory experience. A set of materials and tools was innovatively developed for the elderly auditory audio test. 40 elderly people took the hearing test. Through qualitative and quantitative analysis, the study had drawn the conclusion of the key features of the design elements of the elderly’s auditory pleasure experience and proposed a suitable aging design strategy based on the elderly’s auditory pleasure experience. In sum, the current study has guiding significance for aging design in different fields. The elderly’s pleasant hearing experience test system developed and applied in this research is universal. The mapping relationship between the auditory design elements and the elderly’s pleasant hearing experience revealed by it makes the sound more in line with the elderly’s hearing experience preferences, which is helpful to enhance the interactive experience of products or services for the elderly.","2021","2023-07-05 07:53:21","2023-07-20 05:50:15","2023-07-05 07:53:21","258-276","","","13096","","","","","","","","Springer International Publishing","Cham","en","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-030-90328-2_16","","","","","","Stephanidis, Constantine; Harris, Don; Li, Wen-Chin; Schmorrow, Dylan D.; Fidopiastis, Cali M.; Antona, Margherita; Gao, Qin; Zhou, Jia; Zaphiris, Panayiotis; Ioannou, Andri; Sottilare, Robert A.; Schwarz, Jessica; Rauterberg, Matthias","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4DSRBIIP","journalArticle","2014","McNaull, James; Augusto, Juan Carlos; Mulvenna, Maurice; McCullagh, Paul","Flexible context aware interface for ambient assisted living","Human-centric Computing and Information Sciences","","2192-1962","10.1186/2192-1962-4-1","https://link.springer.com/10.1186/2192-1962-4-1","Abstract             A Multi Agent System that provides a (cared for) person, the subject, with assistance and support through an Ambient Assisted Living Flexible Interface (AALFI) during the day while complementing the night time assistance offered by NOCTURNAL with feedback assistance, is presented. It has been tailored to the subject’s requirements profile and takes into account factors associated with the time of day; hence it attempts to overcome shortcomings of current Ambient Assisted Living Systems. The subject is provided with feedback that highlights important criteria such as quality of sleep during the night and possible breeches of safety during the day. This may help the subject carry out corrective measures and/or seek further assistance. AALFI provides tailored interaction that is either visual or auditory so that the subject is able to understand the interactions and this process is driven by a Multi-Agent System. User feedback gathered from a relevant user group through a workshop validated the ideas underpinning the research, the Multi-agent system and the adaptable interface.","2014-12","2023-07-05 07:53:21","2023-07-05 07:53:21","2023-07-05 07:53:21","1","","1","4","","Hum. Cent. Comput. Inf. Sci.","","","","","","","","en","","","","","DOI.org (Crossref)","","","","/Users/minsik/Zotero/storage/74JQG5B4/McNaull et al. - 2014 - Flexible context aware interface for ambient assis.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z5GZJ7ZL","bookSection","2023","Bhattacharya, Arpita; Backonja, Uba; Le, Anh; Antony, Ria; Si, Yujia; Lee, Jin Ha","Understanding the Influence of Music on People’s Mental Health Through Dynamic Music Engagement Model","Information for a Better World: Normality, Virtuality, Physicality, Inclusivity","978-3-031-28034-4 978-3-031-28035-1","","","https://link.springer.com/10.1007/978-3-031-28035-1_8","Research shows that music helps people regulate and process emotions to positively impact their mental health, but there is limited research on how to build music systems or services to support this. We investigated how engagement with music can help the listener support their mental health through a case study of the BTS ARMY fandom. We conducted a survey with 1,190 BTS fans asking about the impact BTS’ music has on their mental health and wellbeing. Participants reported that certain songs are appropriate for specific types of mood regulations, attributed largely to lyrics. Reflection, connection, and comfort were the top three experiences listeners shared during and after listening to BTS’ music. External factors like knowledge about the context of a song’s creation or other fans’ reactions to a song also influenced people’s feelings toward the music. Our research suggests an expanded view of music’s impact on mental health beyond a single-modal experience to a dynamic, multi-factored experience that evolves over time within the interconnected ecosystem of the fandom. We present the Dynamic Music Engagement Model which represents the complex, multifaceted, context-dependent nature of how music influences people’s mental health, followed by design suggestions for music information systems and services.","2023","2023-07-05 07:53:21","2023-07-20 06:34:06","2023-07-05 07:53:21","91-108","","","13971","","","","","","","","Springer Nature Switzerland","Cham","en","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-031-28035-1_8","","","","","","Sserwanga, Isaac; Goulding, Anne; Moulaison-Sandy, Heather; Du, Jia Tina; Soares, António Lucas; Hessami, Viviane; Frank, Rebecca D.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7YHCTW2A","bookSection","2013","Wei, Ming-Hsuan; Hwang, Sheue-Ling; Chang, Hsin-Chang; Hung, Jian-Yung; Kuo, Chih-Chung","Ergonomics Design with Novice Elicitation on an Auditory-Only In-Vehicle Speech System","Human-Computer Interaction. Applications and Services","978-3-642-39261-0 978-3-642-39262-7","","","http://link.springer.com/10.1007/978-3-642-39262-7_74","This research is aimed to design an auditory-only in-vehicle speech system, named as Talking Car Novice Mode, and provide with elicitation that even a novice can easily handle. In this study, 19 participants were asked to use radio and music functions in two kinds of in-vehicle speech systems, the original Talking Car and Talking Car Novice Mode, while driving through a virtual world. Data of secondary task performance, the amount of time spent on tasks and the times of calling help function were recorded by a camera. The annoyed score of sentences, NASA-TLX questionnaire and subjective questionnaire were completed after the test. The result indicated that there was no significant difference between driving with and without tasks on either the reaction time of slamming the brake or the times user call for help. Besides, the learning curve of Talking Car Novice Mode is steep and ensures that Talking Car Novice Mode provides enough elicitation to novices. Hence, the Talking Car Novice Mode is expected to be friendlier and safer than original Talking Car in-vehicle speech system for a novice user.","2013","2023-07-05 07:53:21","2023-07-20 06:31:09","2023-07-05 07:53:21","654-660","","","8005","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","en","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-642-39262-7_74","","","","","","Kurosu, Masaaki","Hutchison, David; Kanade, Takeo; Kittler, Josef; Kleinberg, Jon M.; Mattern, Friedemann; Mitchell, John C.; Naor, Moni; Nierstrasz, Oscar; Pandu Rangan, C.; Steffen, Bernhard; Sudan, Madhu; Terzopoulos, Demetri; Tygar, Doug; Vardi, Moshe Y.; Weikum, Gerhard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EYYQJLUZ","bookSection","2006","O’Sullivan, Conor; Chang, Angela","An Activity Classification for Vibrotactile Phenomena","Haptic and Audio Interaction Design","978-3-540-37595-1 978-3-540-37596-8","","","http://link.springer.com/10.1007/11821731_14","We observe that the recent availability of audio-haptic actuators allow richer vibration content to be available in commercial devices. However, we note that consumers are unable to take advantage of these rich experiences, mainly due to the lack of a descriptive language for vibration. We analyze the current methods for classifying vibrations. We propose a new framework for describing vibrotactile haptic phenomena, based on an organizing the media based on content activity. We describe this naming system, based on Russolo’s families of noise, and address other pertinent issues to introducing vibration content into commercial devices.","2006","2023-07-05 07:55:08","2023-07-20 00:15:49","2023-07-05 07:55:08","145-156","","","4129","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/11821731_14","","/Users/minsik/Zotero/storage/8GR5M766/O’Sullivan and Chang - 2006 - An Activity Classification for Vibrotactile Phenom.pdf","","","","McGookin, David; Brewster, Stephen","Hutchison, David; Kanade, Takeo; Kittler, Josef; Kleinberg, Jon M.; Mattern, Friedemann; Mitchell, John C.; Naor, Moni; Nierstrasz, Oscar; Pandu Rangan, C.; Steffen, Bernhard; Sudan, Madhu; Terzopoulos, Demetri; Tygar, Dough; Vardi, Moshe Y.; Weikum, Gerhard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A7CN3T2Y","journalArticle","2007","Ardito, C.; Costabile, M. F.; De Angeli, A.; Pittarello, F.","Navigation help in 3D worlds: some empirical evidences on use of sound","Multimedia Tools and Applications","","1380-7501, 1573-7721","10.1007/s11042-006-0060-0","http://link.springer.com/10.1007/s11042-006-0060-0","","2007-05","2023-07-05 07:55:08","2023-07-05 07:55:08","2023-07-05 07:55:08","201-216","","2","33","","Multimed Tools Appl","Navigation help in 3D worlds","","","","","","","en","","","","","DOI.org (Crossref)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XRQXSJSR","bookSection","2008","Amatriain, Xavier; Castellanos, Jorge; Höllerer, Tobias; Kuchera-Morin, JoAnn; Pope, Stephen T.; Wakefield, Graham; Wolcott, Will","Experiencing Audio and Music in a Fully Immersive Environment","Computer Music Modeling and Retrieval. Sense of Sounds","978-3-540-85034-2 978-3-540-85035-9","","","http://link.springer.com/10.1007/978-3-540-85035-9_27","","2008","2023-07-05 07:55:08","2023-07-05 07:55:08","2023-07-05 07:55:08","380-400","","","4969","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","en","","","","","DOI.org (Crossref)","","ISSN: 0302-9743, 1611-3349 Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-540-85035-9_27","","/Users/minsik/Zotero/storage/2VA4QVAZ/Amatriain et al. - 2008 - Experiencing Audio and Music in a Fully Immersive .pdf","","","","Kronland-Martinet, Richard; Ystad, Sølvi; Jensen, Kristoffer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RTPJY36L","bookSection","2013","Rajan, Rahul; Hsiao, Joey; Lahoti, Deven; Selker, Ted","“Roger that!” — The Value of Adding Social Feedback in Audio-Mediated Communications","Human-Computer Interaction – INTERACT 2013","978-3-642-40497-9 978-3-642-40498-6","","","http://link.springer.com/10.1007/978-3-642-40498-6_37","Losing track of who is in a conversation, and what is being said, is always a problem especially on audio-only conference calls. This paper investigates how domain-independent social feedback can support such interactions, and improve communication, through the use of audio cues. In particular, we show how an agent can improve people’s ability to accurately identify and distinguish between speakers, reassure users about the presence of other collaborators on the line, and announce events like entry & exit with minimum impact on users cognitive ability.","2013","2023-07-05 07:55:08","2023-07-20 06:29:08","2023-07-05 07:55:08","471-488","","","8120","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-642-40498-6_37","","/Users/minsik/Zotero/storage/2DNNPXNL/Rajan et al. - 2013 - “Roger that!” — The Value of Adding Social Feedbac.pdf","","","","Kotzé, Paula; Marsden, Gary; Lindgaard, Gitte; Wesson, Janet; Winckler, Marco","Hutchison, David; Kanade, Takeo; Kittler, Josef; Kleinberg, Jon M.; Mattern, Friedemann; Mitchell, John C.; Naor, Moni; Nierstrasz, Oscar; Pandu Rangan, C.; Steffen, Bernhard; Sudan, Madhu; Terzopoulos, Demetri; Tygar, Doug; Vardi, Moshe Y.; Weikum, Gerhard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YF9CASXK","journalArticle","2004","Brown, Silas S.; Robinson, Peter","Transformation frameworks and their relevance in universal design","Universal Access in the Information Society","","1615-5289, 1615-5297","10.1007/s10209-004-0107-9","http://link.springer.com/10.1007/s10209-004-0107-9","Music, engineering, mathematics, and many other disciplines have established notations for writing their documents. Adjusting these notations can contribute to universal access by helping to address access difficulties, such as disabilities, cultural backgrounds, or restrictive hardware. Tools that support the programming of such transformations can also assist by allowing the creation of new notations on demand, which is an under-explored option in the relief of educational difficulties. This paper reviews some programming tools that can be used to effect such transformations. It also introduces a tool, called “4DML,” which allows the programmer to create a “model” of the desired result, from which the transformation is derived.","2004-10","2023-07-05 07:55:08","2023-07-21 05:10:51","2023-07-05 07:55:08","209-223","","3-4","3","","Univ Access Inf Soc","","","","","","","","en","","","","","DOI.org (Crossref)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PMJRWXH3","bookSection","2005","Nicol, Craig; Brewster, Stephen; Gray, Philip","A System for Manipulating Audio Interfaces Using Timbre Spaces","Computer-Aided Design of User Interfaces IV","978-1-4020-3145-8","","","http://link.springer.com/10.1007/1-4020-3304-4_29","","2005","2023-07-05 07:55:08","2023-07-05 07:55:08","2023-07-05 07:55:08","361-374","","","","","","","","","","","Springer-Verlag","Berlin/Heidelberg","en","","","","","DOI.org (Crossref)","","DOI: 10.1007/1-4020-3304-4_29","","","","","","Jacob, Robert J.K.; Limbourg, Quentin; Vanderdonckt, Jean","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MKN9ILHW","bookSection","2010","Neff, Flaithri; Mehigan, Tracey J.; Pitt, Ian","Accelerometer & Spatial Audio Technology: Making Touch-Screen Mobile Devices Accessible","Computers Helping People with Special Needs","978-3-642-14096-9 978-3-642-14097-6","","","http://link.springer.com/10.1007/978-3-642-14097-6_28","","2010","2023-07-05 07:55:08","2023-07-05 07:55:08","2023-07-05 07:55:08","170-177","","","6179","","","Accelerometer & Spatial Audio Technology","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-642-14097-6_28","","","","","","Miesenberger, Klaus; Klaus, Joachim; Zagler, Wolfgang; Karshmer, Arthur","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WLNSDPQB","journalArticle","2009","Valente, Luis; De Souza, Clarisse Sieckenius; Feijó, Bruno","Turn off the graphics: designing non-visual interfaces for mobile phone games","Journal of the Brazilian Computer Society","","0104-6500, 1678-4804","10.1007/BF03192576","https://journal-bcs.springeropen.com/articles/10.1007/BF03192576","Abstract             Mobile phones are a widespread platform for ICT applications because they are highly pervasive in contemporary society. Hence, we can think of mobile gaming as a serious candidate to being a prominent form of entertainment in the near future. However, most games (for computers, console and mobile devices) make extensive use of the visual medium, which tends to exclude visually-impaired users from the play. While mobile gaming could potentially reach many visually-impaired users, who are very familiar with this technology, currently there seems to be only very few alternatives for this community. In an attempt to explore new interactive possibilities for such users, this work presents an initial study on non-visual interfaces for mobile phone games. It is based on Semiotic Engineering principles, emphasizing communication through aural, tactile and gestural signs, and deliberately excluding visual information. Results include a number of issues that can be incorporated to a wider research agenda on mobile gaming accessibility, both for the visually-impaired and sighted.","2009-03","2023-07-05 07:55:08","2023-07-05 07:55:08","2023-07-05 07:55:08","45-58","","1","15","","J Braz Comp Soc","Turn off the graphics","","","","","","","en","","","","","DOI.org (Crossref)","","","","/Users/minsik/Zotero/storage/MVLXR4ZW/Valente et al. - 2009 - Turn off the graphics designing non-visual interf.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S3K8AN32","bookSection","2007","Ag. Ibrahim, Ag. Asri; Hunt, Andy","An HCI Model for Usability of Sonification Applications","Task Models and Diagrams for Users Interface Design","978-3-540-70815-5 978-3-540-70816-2","","","http://link.springer.com/10.1007/978-3-540-70816-2_18","","2007","2023-07-05 07:55:08","2023-07-05 07:55:08","2023-07-05 07:55:08","245-258","","","4385","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","en","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-540-70816-2_18","","","","","","Coninx, Karin; Luyten, Kris; Schneider, Kevin A.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KN5M7H34","journalArticle","2022","Fedotchev, A. I.","Correction of Stress-Induced States Using Sensory Stimulation Automatically Modulated by Endogenous Human Rhythms","Neuroscience and Behavioral Physiology","","0097-0549, 1573-899X","10.1007/s11055-022-01322-3","https://link.springer.com/10.1007/s11055-022-01322-3","This article considers the dynamics of the development of a potential approach to correcting stress-induced states in humans, i.e., adaptive neurostimulation. The approach consists of presenting sensory stimulation automatically modulated by intrinsic rhythmic human processes such as the respiratory rhythm, the heartbeat rhythm, and electroencephalograph (EEG) rhythms. Many examples have shown that real-time self-adjustment of the stimulation parameters by these rhythms leads to a high level personalization of therapeutic stimulation and increases in its efficacy in suppressing stress-induced states. The publications reviewed here point to the advantages of this approach for developing innovatory technologies using complex feedback from endogenous human rhythms to correct a wide spectrum of functional disorders.","2022-07","2023-07-05 07:55:08","2023-07-21 04:37:55","2023-07-05 07:55:08","947-952","","6","52","","Neurosci Behav Physi","","","","","","","","en","","","","","DOI.org (Crossref)","","","","/Users/minsik/Zotero/storage/8XBHNBI4/Fedotchev - 2022 - Correction of Stress-Induced States Using Sensory .pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KAIRA6R8","bookSection","2012","Kandemir, Melih; Klami, Arto; Vetek, Akos; Kaski, Samuel","Unsupervised Inference of Auditory Attention from Biosensors","Machine Learning and Knowledge Discovery in Databases","978-3-642-33485-6 978-3-642-33486-3","","","http://link.springer.com/10.1007/978-3-642-33486-3_26","We study ways of automatically inferring the level of attention a user is paying to auditory content, with applications for example in automatic podcast highlighting and auto-pause, as well as in a selection mechanism in auditory interfaces. In particular, we demonstrate how the level of attention can be inferred in an unsupervised fashion, without requiring any labeled training data. The approach is based on measuring the (generalized) correlation or synchrony between the auditory content and physiological signals reflecting the state of the user. We hypothesize that the synchrony is higher when the user is paying attention to the content, and show empirically that the level of attention can indeed be inferred based on the correlation. In particular, we demonstrate that the novel method of time-varying Bayesian canonical correlation analysis gives unsupervised prediction accuracy comparable to having trained a supervised Gaussian process regression with labeled training data recorded from other users.","2012","2023-07-05 07:55:08","2023-07-21 04:28:16","2023-07-05 07:55:08","403-418","","","7524","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-642-33486-3_26","","/Users/minsik/Zotero/storage/UQ32AD4N/Kandemir et al. - 2012 - Unsupervised Inference of Auditory Attention from .pdf","","","","Flach, Peter A.; De Bie, Tijl; Cristianini, Nello","Hutchison, David; Kanade, Takeo; Kittler, Josef; Kleinberg, Jon M.; Mattern, Friedemann; Mitchell, John C.; Naor, Moni; Nierstrasz, Oscar; Pandu Rangan, C.; Steffen, Bernhard; Sudan, Madhu; Terzopoulos, Demetri; Tygar, Doug; Vardi, Moshe Y.; Weikum, Gerhard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EN5I4QYM","bookSection","2010","Worrall, David","Using Sound to Identify Correlations in Market Data","Auditory Display","978-3-642-12438-9 978-3-642-12439-6","","","http://link.springer.com/10.1007/978-3-642-12439-6_11","","2010","2023-07-05 07:55:08","2023-07-05 07:55:08","2023-07-05 07:55:08","202-218","","","5954","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-642-12439-6_11","","","","","","Ystad, Sølvi; Aramaki, Mitsuko; Kronland-Martinet, Richard; Jensen, Kristoffer","Hutchison, David; Kanade, Takeo; Kittler, Josef; Kleinberg, Jon M.; Mattern, Friedemann; Mitchell, John C.; Naor, Moni; Nierstrasz, Oscar; Pandu Rangan, C.; Steffen, Bernhard; Sudan, Madhu; Terzopoulos, Demetri; Tygar, Doug; Vardi, Moshe Y.; Weikum, Gerhard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X9JQFEXG","bookSection","1998","Rigas, Dimitrios I.; Alty, James L.","How Can Multimedia Designers Utilize Timbre?","People and Computers XIII","978-3-540-76261-4 978-1-4471-3605-7","","","http://link.springer.com/10.1007/978-1-4471-3605-7_17","When musical sound is required during development of auditory or multimedia interfaces, designers often need to utilize different musical voices or timbre (usually produced via a multiple timbre synthesizer or a sound card) in order to communicate information. Currently, there is a limited set of guidelines assisting multimedia designers to select appropriate timbre. This paper reports a set of recall and recognition experiments on timbres produced by a multiple timbre synthesizer. Results indicate that a number of instruments were successfully recalled and recognized. A set of empirically derived guidelines are suggested to assist multimedia designers in selecting timbre.","1998","2023-07-05 07:55:08","2023-07-21 04:42:03","2023-07-05 07:55:08","273-286","","","","","","","","","","","Springer London","London","en","","","","","DOI.org (Crossref)","","DOI: 10.1007/978-1-4471-3605-7_17","","","","","","Johnson, Hilary; Nigay, Lawrence; Roast, Christopher","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4BNBP3B2","bookSection","2010","Brock, Derek; McClimens, Brian; Wasylyshyn, Christina; Trafton, J. Gregory; McCurry, Malcolm","Evaluating the Utility of Auditory Perspective-Taking in Robot Speech Presentations","Auditory Display","978-3-642-12438-9 978-3-642-12439-6","","","http://link.springer.com/10.1007/978-3-642-12439-6_14","","2010","2023-07-05 07:55:08","2023-07-05 07:55:08","2023-07-05 07:55:08","266-286","","","5954","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","en","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-642-12439-6_14","","/Users/minsik/Zotero/storage/PFWUIUC5/Brock et al. - 2010 - Evaluating the Utility of Auditory Perspective-Tak.pdf","","","","Ystad, Sølvi; Aramaki, Mitsuko; Kronland-Martinet, Richard; Jensen, Kristoffer","Hutchison, David; Kanade, Takeo; Kittler, Josef; Kleinberg, Jon M.; Mattern, Friedemann; Mitchell, John C.; Naor, Moni; Nierstrasz, Oscar; Pandu Rangan, C.; Steffen, Bernhard; Sudan, Madhu; Terzopoulos, Demetri; Tygar, Doug; Vardi, Moshe Y.; Weikum, Gerhard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RFV96P5Z","bookSection","2014","Qin, Xiangang","The Measurement of Perceived Quality of Various Audio: Sampling Rate and Frame Loss Rate","Engineering Psychology and Cognitive Ergonomics","978-3-319-07514-3 978-3-319-07515-0","","","http://link.springer.com/10.1007/978-3-319-07515-0_27","In this paper, the influence of Audio Sampling Rate (ASR) and Frame Loss Rate (FLR) on perceived Quality of Experience (QoE) was studied. The result indicated that users are very sensitive to the damaged auditory quality caused by frame loss at 8 kHz and 12 kHz no matter how much it losses. The perceived damage of auditory quality caused by frame loss at 16 kHz and 24 kHz is also much lower that at 8 kHz and 12 kHz. Users even failed to perceive the negative impact of frame loss on auditory quality at 32 kHz whatever the frame loss rate is. The interaction effect indicates that users are not so sensitive to the negative impact of frame loss when the sampling rates increase to 16 kHz or higher.","2014","2023-07-05 07:55:08","2023-07-19 23:58:58","2023-07-05 07:55:08","265-271","","","8532","","","The Measurement of Perceived Quality of Various Audio","","","","","Springer International Publishing","Cham","en","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-319-07515-0_27","","","","","","Harris, Don","Hutchison, David; Kanade, Takeo; Kittler, Josef; Kleinberg, Jon M.; Kobsa, Alfred; Mattern, Friedemann; Mitchell, John C.; Naor, Moni; Nierstrasz, Oscar; Pandu Rangan, C.; Steffen, Bernhard; Terzopoulos, Demetri; Tygar, Doug; Weikum, Gerhard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MMNPJJYR","bookSection","1993","Karshmer, Arthur I.; Oliver, Richard L.","Special computer interfaces for the visually handicapped: F.O.B. The manufacturer","Human-Computer Interaction","978-3-540-57433-0 978-3-540-48152-2","","","http://link.springer.com/10.1007/3-540-57433-6_56","Many techniques have been suggested, and some even brought to market, to allow the visually handicapped person to more easily interact with modern computing equipment Most of the work to date has focused on providing special purpose hardware and software to accomplish this task. In the current work, we describe an approach that would allow all computer manufacturers to ship systems based on today's popular graphical user interfaces (GUIs) that will also serve the needs of the visually handicapped user. By building the user interface into the GUI normally supplied by the manufacturer, the cost of such interfaces should go down, while the availability should go up.","1993","2023-07-05 07:55:08","2023-07-20 05:54:44","2023-07-05 07:55:08","272-280","","","753","","","Special computer interfaces for the visually handicapped","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/3-540-57433-6_56","","","","","","Bass, Leonard J.; Gornostaev, Juri; Unger, Claus","Goos, G.; Hartmanis, J.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6VFKMQWP","bookSection","2008","Salter, Christopher L.; Baalman, Marije A. J.; Moody-Grigsby, Daniel","Between Mapping, Sonification and Composition: Responsive Audio Environments in Live Performance","Computer Music Modeling and Retrieval. Sense of Sounds","978-3-540-85034-2 978-3-540-85035-9","","","http://link.springer.com/10.1007/978-3-540-85035-9_17","","2008","2023-07-05 07:56:42","2023-07-05 07:56:42","2023-07-05 07:56:42","246-262","","","4969","","","Between Mapping, Sonification and Composition","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","en","","","","","DOI.org (Crossref)","","ISSN: 0302-9743, 1611-3349 Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-540-85035-9_17","","/Users/minsik/Zotero/storage/APC8J8AE/Salter et al. - 2008 - Between Mapping, Sonification and Composition Res.pdf","","","","Kronland-Martinet, Richard; Ystad, Sølvi; Jensen, Kristoffer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NLD8XZDF","bookSection","2009","Kern, Dagmar; Marshall, Paul; Hornecker, Eva; Rogers, Yvonne; Schmidt, Albrecht","Enhancing Navigation Information with Tactile Output Embedded into the Steering Wheel","Pervasive Computing","978-3-642-01515-1 978-3-642-01516-8","","","http://link.springer.com/10.1007/978-3-642-01516-8_5","Navigation systems are in common use by drivers and typically present information using either audio or visual representations. However, there are many pressures on the driver's cognitive systems in a car and navigational systems can add to this complexity. In this paper, we present two studies which investigated how vibro-tactile representations of navigational information, might be presented to the driver via the steering wheel to ameliorate this problem. Our results show that adding tactile information to existing audio, or particularly visual representations, can improve both driving performance and experience.","2009","2023-07-05 07:56:42","2023-07-21 04:54:47","2023-07-05 07:56:42","42-58","","","5538","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-642-01516-8_5","","/Users/minsik/Zotero/storage/VYUI5TP9/Kern et al. - 2009 - Enhancing Navigation Information with Tactile Outp.pdf","","","","Tokuda, Hideyuki; Beigl, Michael; Friday, Adrian; Brush, A. J. Bernheim; Tobe, Yoshito","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CSRB9BU2","bookSection","1998","Pittarello, Fabio; Pittarello, Mauro; Italiano, Giuseppe F.","Architecture and Digital Exhibitions the Einstein Tower World","Virtual Environments ’98","978-3-211-83233-2 978-3-7091-7519-4","","","http://link.springer.com/10.1007/978-3-7091-7519-4_16","This work is part of a general research about three-dimensional worlds usability issues, aimed at analysing the current points of strength and weakness of immersive navigation in virtual worlds on the net and at developing new cognitive artefacts to improve the quality of these experiences. The Einstein Tower World, a system conceived in occasion of the German Expressionism exhibition held in 1997 at Palazzo Grassi in Venice, can be seen as a first implementation of the results achieved so far by our research. The Einstein Tower, a sun observatory built in Potsdam from 1919 to 1923 by Erich Mendelsohn and chosen as a symbol of the real exhibition in Venice, becomes the focus of a virtual exhibition where architecture, paintings, manifestos, cinema fragments and music melt into a unique composition, a small account of gesamtkunstwerk (an integrated esthetical experience achieved by eliminating the divisions between architecture, music and visual arts) proposed by expressionist artists.","1998","2023-07-05 07:56:42","2023-07-21 05:13:55","2023-07-05 07:56:42","162-171","","","","","","","","","","","Springer Vienna","Vienna","","","","","","DOI.org (Crossref)","","Series Title: Eurographics DOI: 10.1007/978-3-7091-7519-4_16","","","","","","Göbel, Martin; Landauer, Jürgen; Lang, Ulrich; Wapler, Matthias","Hansmann, W.; Hewitt, W. T.; Purgathofer, W.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A3BCII5R","bookSection","2021","Chen, Weiwen; Lu, Xiaobo; Tang, Xuelin","Toward a Theory-Driven Model of Emotional Interaction Design in Mobile Games Research","HCI in Games: Experience Design and Game Mechanics","978-3-030-77276-5 978-3-030-77277-2","","","https://link.springer.com/10.1007/978-3-030-77277-2_1","The rapid development of mobile information technology provides good opportunities for the maturity and growth of mobile games. In busy modern life, mobile games are playing an increasingly important role in people’s social connection. In addition to entertainment functions, mobile games in the near future have the potential to become a new method of teaching, by which users can learn a variety of knowledge in a lively and interesting way. What factors contributed to the birth of an excellent mobile game? Obviously, the emotional factors in interaction design play a vital role. Emotion-based interaction design can evoke various positive emotions of players, such as the sense of accomplishment, satisfaction, flow experience, awe, and other psychological experiences. Thus, it is of importance to analyze the emotional factors in mobile game interaction design and discuss emotional interaction design principles and methods. The purpose of this paper to establish an emotional interaction design model, which could provide the theoretical basis for improving mobile game design theory, expanding mobile game functions and value, meeting users’ more advanced emotional needs and guiding mobile game development and design practice. This paper first discusses the emotional design theory proposed by Professor Don Norman. And then it analyzes the intersection and integration of interaction design and psychology, human factors engineering, aesthetics, and other disciplines. Corresponding to the three levels of emotional design: visceral, behavioral, and reflective, it puts forward an emotional interaction design model consisting of user interface design, interaction operation design, and interaction experience design. Finally, it improves and applies the emotional interaction design model in mobile games through case studies.","2021","2023-07-05 07:56:42","2023-07-20 05:43:21","2023-07-05 07:56:42","3-19","","","12789","","","","","","","","Springer International Publishing","Cham","en","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-030-77277-2_1","","","","","","Fang, Xiaowen","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K6ZRED5I","bookSection","2014","Zhang, Yuxi; Huang, Yifeng; Yue, Junwei; Zhang, Liqing","Sonification for EEG Frequency Spectrum and EEG-Based Emotion Features","Neural Information Processing","978-3-319-12642-5 978-3-319-12643-2","","","http://link.springer.com/10.1007/978-3-319-12643-2_6","","2014","2023-07-05 07:56:42","2023-07-05 07:56:42","2023-07-05 07:56:42","42-49","","","8836","","","","","","","","Springer International Publishing","Cham","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-319-12643-2_6","","","","","","Loo, Chu Kiong; Yap, Keem Siah; Wong, Kok Wai; Beng Jin, Andrew Teoh; Huang, Kaizhu","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"37W7NFY4","journalArticle","2015","Hussain, Ibrar; Chen, Ling; Mirza, Hamid Turab; Chen, Gencai; Hassan, Saeed-Ul","Right mix of speech and non-speech: hybrid auditory feedback in mobility assistance of the visually impaired","Universal Access in the Information Society","","1615-5289, 1615-5297","10.1007/s10209-014-0350-7","http://link.springer.com/10.1007/s10209-014-0350-7","Despite the growing awareness about mobility issues surrounding auditory interfaces used by visually impaired people, designers still face challenges while creating sound for auditory interfaces. This paper presents a new approach of hybrid auditory feedback, which converts frequently used speech instructions to non-speech (i.e., spearcons), based on users’ travelled frequency and sound repetition. Using a within-subject design, twelve participants (i.e., blind people) carried out a task, using a mobility assistant application in an indoor environment. As surfaced from the study results, the hybrid auditory feedback approach is more effective than non-speech and it is pleasant compared with repetitive speech-only. In addition, it can substantially improve user experience. Finally, these findings may help researchers and practitioners use hybrid auditory feedback, rather than using speech- or non-speech-only, when designing or creating accessibility/assistive products and systems.","2015-11","2023-07-05 07:56:42","2023-07-21 05:11:32","2023-07-05 07:56:42","527-536","","4","14","","Univ Access Inf Soc","Right mix of speech and non-speech","","","","","","","en","","","","","DOI.org (Crossref)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DYXKS7F8","bookSection","2006","Frauenberger, C; Stockman, T; Putz, V; Höldrich, R","Design Patterns for Auditory Displays","People and Computers XIX — The Bigger Picture","978-1-84628-192-1 978-1-84628-249-2","","","http://link.springer.com/10.1007/1-84628-249-7_30","","2006","2023-07-05 07:56:42","2023-07-05 07:56:42","2023-07-05 07:56:42","473-488","","","","","","","","","","","Springer London","London","en","","","","","DOI.org (Crossref)","","DOI: 10.1007/1-84628-249-7_30","","","","","","McEwan, Tom; Gulliksen, Jan; Benyon, David","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X4SV7VKP","journalArticle","2021","Iber, Michael; Lechner, Patrik; Jandl, Christian; Mader, Manuel; Reichmann, Michael","Auditory augmented process monitoring for cyber physical production systems","Personal and Ubiquitous Computing","","1617-4909, 1617-4917","10.1007/s00779-020-01394-3","https://link.springer.com/10.1007/s00779-020-01394-3","Abstract             We describe two proof-of-concept approaches on the sonification of estimated operation states and conditions focusing on two scenarios: a laboratory setup of a manipulated 3D printer and an industrial setup focusing on the operations of a punching machine. The results of these studies form the basis for the development of an “intelligent” noise protection headphone as part of Cyber Physical Production Systems which provides auditorily augmented information to machine operators and enables radio communication between them. Further application areas are implementations in control rooms (equipped with multi-channel loudspeaker systems) and utilization for training purposes. As a first proof-of-concept, the data stream of error probability estimations regarding partly manipulated 3D printing processes were mapped to three sonification models, providing evidence about momentary operation states. The neural network applied indicates a high accuracy (> 93%) of the error estimation distinguishing between normal and manipulated operation states. None of the manipulated states could be identified by listening. An auditory augmentation, or sonification of these error estimations, provides a considerable benefit to process monitoring. For a second proof-of-concept, setup operations of a punching machine were recorded. Since all operations were apparently flawlessly executed, and there were no errors to be reported, we focused on the identification of operation phases. Each phase of a punching process could be algorithmically distinguished at an estimated probability rate of > 94%. In the auditory display, these phases were represented by different instrumentations of a musical piece in order to allow users to differentiate between operations auditorily.","2021-08","2023-07-05 07:56:42","2023-07-05 07:56:42","2023-07-05 07:56:42","691-704","","4","25","","Pers Ubiquit Comput","","","","","","","","en","","","","","DOI.org (Crossref)","","","","/Users/minsik/Zotero/storage/AAGIT7PY/Iber et al. - 2021 - Auditory augmented process monitoring for cyber ph.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SWPB65BZ","bookSection","2012","Murphy, Emma; Moussette, Camille; Verron, Charles; Guastavino, Catherine","Supporting Sounds: Design and Evaluation of an Audio-Haptic Interface","Haptic and Audio Interaction Design","978-3-642-32795-7 978-3-642-32796-4","","","http://link.springer.com/10.1007/978-3-642-32796-4_2","The design and evaluation of a multimodal interface is presented in order to investigate how spatial audio and haptic feedback can be used to convey the navigational structure of a virtual environment. The non-visual 3D virtual environment is composed of a number of parallel planes with either horizontal or vertical orientations. The interface was evaluated using a target-finding task to explore how auditory feedback can be used in isolation or combined with haptic feedback for navigation. Twenty-three users were asked to locate targets using auditory feedback in the virtual structure across both horizontal and vertical orientations of the planes, with and without haptic feedback. Findings from the evaluation experiment reveal that users performed the task faster in the bi-modal conditions (with combined auditory and haptic feedback) with a horizontal orientation of the virtual planes.","2012","2023-07-05 07:56:42","2023-07-20 00:15:32","2023-07-05 07:56:42","11-20","","","7468","","","Supporting Sounds","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-642-32796-4_2","","","","","","Magnusson, Charlotte; Szymczak, Delphine; Brewster, Stephen","Hutchison, David; Kanade, Takeo; Kittler, Josef; Kleinberg, Jon M.; Mattern, Friedemann; Mitchell, John C.; Naor, Moni; Nierstrasz, Oscar; Pandu Rangan, C.; Steffen, Bernhard; Sudan, Madhu; Terzopoulos, Demetri; Tygar, Doug; Vardi, Moshe Y.; Weikum, Gerhard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N25S2A5F","journalArticle","2020","Shoaib, Muhammad; Hussain, Ibrar; Mirza, Hamid Turab","Automatic switching between speech and non-speech: adaptive auditory feedback in desktop assistance for the visually impaired","Universal Access in the Information Society","","1615-5289, 1615-5297","10.1007/s10209-019-00696-5","http://link.springer.com/10.1007/s10209-019-00696-5","Continual enrichments in auditory interfaces of desktop applications allow visually impaired people to successfully use computers in education, employment, and social interaction. Designers face multiple challenges while producing sound for auditory interfaces. This paper presents a new method of adaptive auditory feedback, which converts speech-only instructions to non-speech (i.e., spearcons), based on users’ interaction with the application in the desktop environment. Using within-subject design, fifteen participants (i.e., visually impaired) were involved in the study. Results from the study demonstrate that the adaptive auditory feedback method is more efficient than non-speech and more pleasurable with respect to repetitive speech-only instructions. Furthermore, adaptive auditory feedback improves task completion time and action awareness as compared to speech-only. Lastly, these findings may benefit researchers and developers to use adaptive auditory feedback, instead of using speech-only or non-speech feedback while designing auditory feedback for interfaces in desktop environment for the people with visual impairment.","2020-11","2023-07-05 07:56:42","2023-07-21 05:12:59","2023-07-05 07:56:42","813-823","","4","19","","Univ Access Inf Soc","Automatic switching between speech and non-speech","","","","","","","en","","","","","DOI.org (Crossref)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LW7JZWFV","bookSection","2013","Jeon, Myounghoon; Lee, Ju-Hwan","The Ecological AUI (Auditory User Interface) Design and Evaluation of User Acceptance for Various Tasks on Smartphones","Human-Computer Interaction. Interaction Modalities and Techniques","978-3-642-39329-7 978-3-642-39330-3","","","http://link.springer.com/10.1007/978-3-642-39330-3_6","","2013","2023-07-05 07:56:42","2023-07-05 07:56:42","2023-07-05 07:56:42","49-58","","","8007","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","en","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-642-39330-3_6","","","","","","Kurosu, Masaaki","Hutchison, David; Kanade, Takeo; Kittler, Josef; Kleinberg, Jon M.; Mattern, Friedemann; Mitchell, John C.; Naor, Moni; Nierstrasz, Oscar; Pandu Rangan, C.; Steffen, Bernhard; Sudan, Madhu; Terzopoulos, Demetri; Tygar, Doug; Vardi, Moshe Y.; Weikum, Gerhard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XQUKQBTQ","bookSection","2012","Alharbi, Saad","Empirically Derived Guidelines for Audio-Visual E-mail Browsing","Advances in New Technologies, Interactive Interfaces and Communicability","978-3-642-34009-3 978-3-642-34010-9","","","http://link.springer.com/10.1007/978-3-642-34010-9_10","This paper presents a set of design guidelines for the use of information visualization techniques and non-speech sounds such as auditory icons and earcons in email browsing. These guidelines were derived based on a previous experimental work consisted of three experimental phases, each phase aimed at investigating different aspects of email browsing. Several key points were covered in these guidelines such as the presentation of email information, finding email information and using audio metaphors for communicating email information.","2012","2023-07-05 07:56:42","2023-07-19 11:12:46","2023-07-05 07:56:42","104-113","","","7547","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-642-34010-9_10","","","","","","Cipolla-Ficarra, Francisco; Veltman, Kim; Verber, Domen; Cipolla-Ficarra, Miguel; Kammüller, Florian","Hutchison, David; Kanade, Takeo; Kittler, Josef; Kleinberg, Jon M.; Mattern, Friedemann; Mitchell, John C.; Naor, Moni; Nierstrasz, Oscar; Pandu Rangan, C.; Steffen, Bernhard; Sudan, Madhu; Terzopoulos, Demetri; Tygar, Doug; Vardi, Moshe Y.; Weikum, Gerhard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"934RH594","bookSection","2013","Garcia, Franco Eusébio; De Almeida Neris, Vânia Paula","Design Guidelines for Audio Games","Human-Computer Interaction. Applications and Services","978-3-642-39261-0 978-3-642-39262-7","","","http://link.springer.com/10.1007/978-3-642-39262-7_26","This paper presents guidelines to aid on the design of audio games. Audio games are games on which the user interface and game events use primarily sounds instead of graphics to convey information to the player. Those games can provide an accessible gaming experience to visually impaired players, usually handicapped by conventional games. The presented guidelines resulted of existing literature research on audio games design and implementation, of a case study and of a user observation performed by the authors. The case study analyzed how audio is used to create an accessible game on nine audio games recommended for new players. The user observation consisted of a playtest on which visually impaired users played an audio game, on which some interaction problems were identified. The results of those three studies were analyzed and compiled in 50 design guidelines.","2013","2023-07-05 07:56:42","2023-07-20 06:30:57","2023-07-05 07:56:42","229-238","","","8005","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","en","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-642-39262-7_26","","/Users/minsik/Zotero/storage/8H6R92ZX/Garcia and De Almeida Neris - 2013 - Design Guidelines for Audio Games.pdf","","","","Kurosu, Masaaki","Hutchison, David; Kanade, Takeo; Kittler, Josef; Kleinberg, Jon M.; Mattern, Friedemann; Mitchell, John C.; Naor, Moni; Nierstrasz, Oscar; Pandu Rangan, C.; Steffen, Bernhard; Sudan, Madhu; Terzopoulos, Demetri; Tygar, Doug; Vardi, Moshe Y.; Weikum, Gerhard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LL9ZKKJL","bookSection","2002","Lorho, Gaëtan; Hiipakka, Jarmo; Marila, Juha","Structured Menu Presentation Using Spatial Sound Separation","Human Computer Interaction with Mobile Devices","978-3-540-44189-2 978-3-540-45756-5","","","http://link.springer.com/10.1007/3-540-45756-9_51","","2002","2023-07-05 07:56:42","2023-07-05 07:56:42","2023-07-05 07:56:42","419-424","","","2411","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","en","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/3-540-45756-9_51","","","","","","Paternò, Fabio","Goos, Gerhard; Hartmanis, Juris; Van Leeuwen, Jan","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZHKGFLC6","bookSection","2017","Sinclair, Peter; Cahen, Roland; Tanant, Jonathan; Gena, Peter","New Atlantis: Audio Experimentation in a Shared Online World","Bridging People and Sound","978-3-319-67737-8 978-3-319-67738-5","","","http://link.springer.com/10.1007/978-3-319-67738-5_14","","2017","2023-07-05 07:56:42","2023-07-05 07:56:42","2023-07-05 07:56:42","229-246","","","10525","","","New Atlantis","","","","","Springer International Publishing","Cham","en","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-319-67738-5_14","","/Users/minsik/Zotero/storage/ZBS6RVIZ/Sinclair et al. - 2017 - New Atlantis Audio Experimentation in a Shared On.pdf","","","","Aramaki, Mitsuko; Kronland-Martinet, Richard; Ystad, Sølvi","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MY8U375Z","bookSection","2013","Gross, Richard; Bockholt, Ulrich; Biersack, Ernst W.; Kuijper, Arjan","Multimodal Kinect-Supported Interaction for Visually Impaired Users","Universal Access in Human-Computer Interaction. Design Methods, Tools, and Interaction Techniques for eInclusion","978-3-642-39187-3 978-3-642-39188-0","","","http://link.springer.com/10.1007/978-3-642-39188-0_54","This paper discusses Kreader, a proof-of-concept for a new interface for blind or visually impaired users to have text read to them. We use the Kinect device to track the users body. All feedback is presented with auditory cues, while a minimal visual interface can be turned on optionally. Interface elements are organized in a list manner and placed ego-centric, in relation to the user’s body. Moving around in the room does not change the element’s location. Hence visually impaired users can utilize their ”body-sense” to find elements. Two test sessions were used to evaluate Kreader. We think the results are encouraging and provide a solid foundation for future research into such an interface, that can be navigated by sighted and visually impaired users.","2013","2023-07-05 07:56:42","2023-07-21 05:10:07","2023-07-05 07:56:42","500-509","","","8009","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","en","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-642-39188-0_54","","","","","","Stephanidis, Constantine; Antona, Margherita","Hutchison, David; Kanade, Takeo; Kittler, Josef; Kleinberg, Jon M.; Mattern, Friedemann; Mitchell, John C.; Naor, Moni; Nierstrasz, Oscar; Pandu Rangan, C.; Steffen, Bernhard; Sudan, Madhu; Terzopoulos, Demetri; Tygar, Doug; Vardi, Moshe Y.; Weikum, Gerhard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I3QIPIXT","bookSection","2001","Walker, Ashley; Brewster, Stephen; McGookin, David; Ng, Adrian","Diary in the Sky: A Spatial Audio Display for a Mobile Calendar","People and Computers XV—Interaction without Frontiers","978-1-85233-515-1 978-1-4471-0353-0","","","http://link.springer.com/10.1007/978-1-4471-0353-0_33","","2001","2023-07-05 07:56:42","2023-07-05 07:56:42","2023-07-05 07:56:42","531-539","","","","","","Diary in the Sky","","","","","Springer London","London","en","","","","","DOI.org (Crossref)","","DOI: 10.1007/978-1-4471-0353-0_33","","/Users/minsik/Zotero/storage/HMU2PISY/Walker et al. - 2001 - Diary in the Sky A Spatial Audio Display for a Mo.pdf","","","","Blandford, Ann; Vanderdonckt, Jean; Gray, Phil","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V96GMUSI","webpage","","","A multimodal psychological, physiological and behavioural dataset for human emotions in driving tasks | Scientific Data","","","","","https://www.nature.com/articles/s41597-022-01557-2","Human emotions are integral to daily tasks, and driving is now a typical daily task. Creating a multi-modal human emotion dataset in driving tasks is an essential step in human emotion studies. we conducted three experiments to collect multimodal psychological, physiological and behavioural dataset for human emotions (PPB-Emo). In Experiment I, 27 participants were recruited, the in-depth interview method was employed to explore the driver’s viewpoints on driving scenarios that induce different emotions. For Experiment II, 409 participants were recruited, a questionnaire survey was conducted to obtain driving scenarios information that induces human drivers to produce specific emotions, and the results were used as the basis for selecting video-audio stimulus materials. In Experiment III, 40 participants were recruited, and the psychological data and physiological data, as well as their behavioural data were collected of all participants in 280 times driving tasks. The PPB-Emo dataset will largely support the analysis of human emotion in driving tasks. Moreover, The PPB-Emo dataset will also benefit human emotion research in other daily tasks.","","2023-07-05 07:56:59","2023-07-21 07:42:47","2023-07-05 07:56:59","","","","","","","","","","","","","","","","","","","","","","","/Users/minsik/Zotero/storage/TYYIKAFV/s41597-022-01557-2.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J9LES69W","bookSection","2007","Korhonen, Hannu; Holm, Jukka; Heikkinen, Mikko","Utilizing Sound Effects in Mobile User Interface Design","Human-Computer Interaction – INTERACT 2007","978-3-540-74794-9 978-3-540-74796-3","","","http://link.springer.com/10.1007/978-3-540-74796-3_27","","2007","2023-07-05 07:58:12","2023-07-05 07:58:12","2023-07-05 07:58:12","283-296","","","4662","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-540-74796-3_27","","/Users/minsik/Zotero/storage/6YEZTAEU/Korhonen et al. - 2007 - Utilizing Sound Effects in Mobile User Interface D.pdf","","","","Baranauskas, Cécilia; Palanque, Philippe; Abascal, Julio; Barbosa, Simone Diniz Junqueira","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U5U6HD4H","bookSection","1997","Fernström, M.; Bannon, L.","Explorations in Sonic Browsing","People and Computers XII","978-3-540-76172-3 978-1-4471-3601-9","","","http://link.springer.com/10.1007/978-1-4471-3601-9_8","","1997","2023-07-05 07:58:12","2023-07-05 07:58:12","2023-07-05 07:58:12","117-131","","","","","","","","","","","Springer London","London","en","","","","","DOI.org (Crossref)","","DOI: 10.1007/978-1-4471-3601-9_8","","","","","","Thimbleby, Harold; O’Conaill, Brid; Thomas, Peter J.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2NDLLHXZ","bookSection","2014","Jeon, Myounghoon; Smith, Michael T.; Walker, James W.; Kuhl, Scott A.","Constructing the Immersive Interactive Sonification Platform (iISoP)","Distributed, Ambient, and Pervasive Interactions","978-3-319-07787-1 978-3-319-07788-8","","","http://link.springer.com/10.1007/978-3-319-07788-8_32","","2014","2023-07-05 07:58:12","2023-07-05 07:58:12","2023-07-05 07:58:12","337-348","","","8530","","","","","","","","Springer International Publishing","Cham","en","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-319-07788-8_32","","/Users/minsik/Zotero/storage/SEE8437Z/Jeon et al. - 2014 - Constructing the Immersive Interactive Sonificatio.pdf","","","","Streitz, Norbert; Markopoulos, Panos","Hutchison, David; Kanade, Takeo; Kittler, Josef; Kleinberg, Jon M.; Kobsa, Alfred; Mattern, Friedemann; Mitchell, John C.; Naor, Moni; Nierstrasz, Oscar; Pandu Rangan, C.; Steffen, Bernhard; Terzopoulos, Demetri; Tygar, Doug; Weikum, Gerhard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ETBKTG3P","bookSection","2010","Brazil, Eoin","A Review of Methods and Frameworks for Sonic Interaction Design: Exploring Existing Approaches","Auditory Display","978-3-642-12438-9 978-3-642-12439-6","","","http://link.springer.com/10.1007/978-3-642-12439-6_3","","2010","2023-07-05 07:58:12","2023-07-05 07:58:12","2023-07-05 07:58:12","41-67","","","5954","","","A Review of Methods and Frameworks for Sonic Interaction Design","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-642-12439-6_3","","","","","","Ystad, Sølvi; Aramaki, Mitsuko; Kronland-Martinet, Richard; Jensen, Kristoffer","Hutchison, David; Kanade, Takeo; Kittler, Josef; Kleinberg, Jon M.; Mattern, Friedemann; Mitchell, John C.; Naor, Moni; Nierstrasz, Oscar; Pandu Rangan, C.; Steffen, Bernhard; Sudan, Madhu; Terzopoulos, Demetri; Tygar, Doug; Vardi, Moshe Y.; Weikum, Gerhard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7HF2VA3P","journalArticle","2016","Tsonos, Dimitrios; Kouroupetroglou, Georgios","Prosodic mapping of text font based on the dimensional theory of emotions: a case study on style and size","EURASIP Journal on Audio, Speech, and Music Processing","","1687-4722","10.1186/s13636-016-0087-8","https://asmp-eurasipjournals.springeropen.com/articles/10.1186/s13636-016-0087-8","Current text-to-speech systems do not support the effective provision of the semantics and the cognitive aspects of the documents’ typographic cues (e.g., font type, style, and size). A novel approach is introduced for the acoustic rendition of text font based on the emotional analogy between the visual (text font cues) and the acoustic (speech prosody) modalities. The methodology is based on: a) modeling reader’s emotional state response (“Pleasure”, “Arousal” and “Dominance”) induced by the document’s font cues and b) the acoustic mapping of the emotional state using expressive speech synthesis. A case study was conducted for the proposed methodology by calculating the prosodic values on specific font cues (several font styles and font sizes) and by examining listeners’ preferences on the acoustic rendition of bold, italics, bold-italics, and various font sizes. The experimental results after the user evaluation indicate that the acoustic rendition of font size variations as well as bold and italics is recognized successfully, but bold-italics are confused with bold, due to the similarities of their prosodic variations.","2016-12","2023-07-05 07:58:12","2023-07-20 00:02:09","2023-07-05 07:58:12","8","","1","2016","","J AUDIO SPEECH MUSIC PROC.","Prosodic mapping of text font based on the dimensional theory of emotions","","","","","","","en","","","","","DOI.org (Crossref)","","","","/Users/minsik/Zotero/storage/FUKFEVFF/Tsonos and Kouroupetroglou - 2016 - Prosodic mapping of text font based on the dimensi.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H5GN6TN9","bookSection","2015","Sun, Yuanjing; Jeon, Myounghoon","Lyricon (Lyrics + Earcons) Improves Identification of Auditory Cues","Design, User Experience, and Usability: Users and Interactions","978-3-319-20897-8 978-3-319-20898-5","","","http://link.springer.com/10.1007/978-3-319-20898-5_37","","2015","2023-07-05 07:58:12","2023-07-05 07:58:12","2023-07-05 07:58:12","382-389","","","9187","","","","","","","","Springer International Publishing","Cham","en","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-319-20898-5_37","","","","","","Marcus, Aaron","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P26TNWC7","journalArticle","2022","Fedotchev, A. I.; Parin, S. B.; Polevaya, S. A.","Neural Interfaces Based on Endogenous Body Rhythms for Optimization of the Functional State of Humans and Cognitive Rehabilitation","Neuroscience and Behavioral Physiology","","0097-0549, 1573-899X","10.1007/s11055-022-01278-4","https://link.springer.com/10.1007/s11055-022-01278-4","We report here an analysis of studies in the last five years on a construction and management challenge in technogenic systems, i.e., neural interfaces and neurobiocontrol systems. Current approaches to the use of neural interfaces in medicine, engineering psychology, and cognitive rehabilitation of humans are addressed. The main focus of attention is on neural interfaces based on use of system-forming endogenous body rhythms – electroencephalogram (EEG) rhythms, heart rate, and the respiratory rhythm. The advantages, state of the art, and challenges in this line of research are discussed and potential pathways for answering its key questions are outlined. The results of the authors’ own developments in this direction are presented.","2022-05","2023-07-05 07:58:12","2023-07-21 04:38:20","2023-07-05 07:58:12","591-597","","4","52","","Neurosci Behav Physi","","","","","","","","en","","","","","DOI.org (Crossref)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"39S6Y2DN","bookSection","2006","Sánchez, Jaime; Baloian, Nelson","Issues in Implementing Awareness in Collaborative Software for Blind People","Computers Helping People with Special Needs","978-3-540-36020-9 978-3-540-36021-6","","","http://link.springer.com/10.1007/11788713_190","","2006","2023-07-05 07:58:12","2023-07-05 07:58:12","2023-07-05 07:58:12","1318-1325","","","4061","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/11788713_190","","","","","","Miesenberger, Klaus; Klaus, Joachim; Zagler, Wolfgang L.; Karshmer, Arthur I.","Hutchison, David; Kanade, Takeo; Kittler, Josef; Kleinberg, Jon M.; Mattern, Friedemann; Mitchell, John C.; Naor, Moni; Nierstrasz, Oscar; Pandu Rangan, C.; Steffen, Bernhard; Sudan, Madhu; Terzopoulos, Demetri; Tygar, Dough; Vardi, Moshe Y.; Weikum, Gerhard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CPYMZBR8","bookSection","2007","Spath, Dieter; Peissner, Matthias; Hagenmeyer, Lorenz; Ringbauer, Brigitte","New Approaches to Intuitive Auditory User Interfaces","Human Interface and the Management of Information. Methods, Techniques and Tools in Information Design","978-3-540-73344-7 978-3-540-73345-4","","","http://link.springer.com/10.1007/978-3-540-73345-4_110","This paper gives an overview of recent projects done at Fraunhofer IAO which take innovative approaches to the use of non-speech audio in human-computer interfaces. The examples illustrate the benefits that nonspeech sound - alone and in combination with other modalities - can provide for supporting an effective interaction.","2007","2023-07-05 07:58:12","2023-07-20 05:53:43","2023-07-05 07:58:12","975-984","","","4557","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","en","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-540-73345-4_110","","/Users/minsik/Zotero/storage/VJUIG9ZY/Spath et al. - 2007 - New Approaches to Intuitive Auditory User Interfac.pdf","","","","Smith, Michael J.; Salvendy, Gavriel","Hutchison, David; Kanade, Takeo; Kittler, Josef; Kleinberg, Jon M.; Mattern, Friedemann; Mitchell, John C.; Naor, Moni; Nierstrasz, Oscar; Pandu Rangan, C.; Steffen, Bernhard; Sudan, Madhu; Terzopoulos, Demetri; Tygar, Doug; Vardi, Moshe Y.; Weikum, Gerhard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BLIPVN2T","bookSection","2019","Siqueira Da Silva, Isabel Cristina","The Promotion of Empathy for the Experience of Users with Visual Impairment in the Game Design Education","Universal Access in Human-Computer Interaction. Theory, Methods and Tools","978-3-030-23559-8 978-3-030-23560-4","","","http://link.springer.com/10.1007/978-3-030-23560-4_24","People are constantly seeking new experiences through perceptions that involve practical and subjective aspects such as usability, efficiency, satisfaction, and accessibility. The advent of digital inclusion has encouraged the software development with support for accessibility, which is proposed to promote the improvement of the quality of life of people with some type of disability, although also reflects positively with people without disabilities. In this sense, accessible digital games constitute a growing demand and, among the different solutions that have been proposed, the audiogames propose to offer a differentiated user experience, with the exploration of different sound stimuli that complement the visual stimuli. Thus, audio features are explored with the aim of guiding the player about the game universe based on different sounds and such features are significant for the experience of visually impaired players. However, the development of audiogames that are really accessible and provide a satisfying interaction for visually impaired users is still a challenge for game designers, who need to develop empathy for their target audience by understanding their needs and expectations. This article presents an experience report involving the development of audiogames that, though considering the accessibility to visually impaired, focus on the experience provided to game designers without visually impaired so as to awaken in these the empathy for games accessible through the understanding of how sound stimuli can compensate for lack of vision.","2019","2023-07-05 07:58:12","2023-07-21 05:10:32","2023-07-05 07:58:12","326-341","","","11572","","","","","","","","Springer International Publishing","Cham","en","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-030-23560-4_24","","","","","","Antona, Margherita; Stephanidis, Constantine","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C4ZPDDUD","bookSection","1994","Rauterberg, Matthias; Styger, Erich","Positive effects of sound feedback during the operation of a plant simulator","Human-Computer Interaction","978-3-540-58648-7 978-3-540-49036-4","","","http://link.springer.com/10.1007/3-540-58648-2_24","An experiment was carried out to estimate the effect of sound feedback on the work of a plant operator. Eight students of computer science operated a process simulation program of an assembly line with computer numeric controlled (CNC) robots. Relevant information of disturbances and machine breakdowns was given only in a visual (test condition 1), and in visual and audible form (test condition 2). The results indicate, that the additional sound feedback improves significantly the operator performance and increases positively some mood aspects.","1994","2023-07-05 07:58:12","2023-07-20 05:55:06","2023-07-05 07:58:12","35-44","","","876","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/3-540-58648-2_24","","","","","","Blumenthal, Brad; Gornostaev, Juri; Unger, Claus","Goos, Gerhard.; Hartmanis, Juris; Leeuwen, Jan","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ENTFWZHY","journalArticle","2016","Metatla, Oussama; Martin, Fiore; Parkinson, Adam; Bryan-Kinns, Nick; Stockman, Tony; Tanaka, Atau","Audio-haptic interfaces for digital audio workstations: A participatory design approach","Journal on Multimodal User Interfaces","","1783-7677, 1783-8738","10.1007/s12193-016-0217-8","http://link.springer.com/10.1007/s12193-016-0217-8","","2016-09","2023-07-05 07:58:12","2023-07-05 07:58:12","2023-07-05 07:58:12","247-258","","3","10","","J Multimodal User Interfaces","Audio-haptic interfaces for digital audio workstations","","","","","","","en","","","","","DOI.org (Crossref)","","","","/Users/minsik/Zotero/storage/4U6DB5C7/Metatla et al. - 2016 - Audio-haptic interfaces for digital audio workstat.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3J398Q87","bookSection","2004","Lyon, Kirstin; Nürnberg, Peter J.","Interface Design – Use of Audio as an Output","Metainformatics","978-3-540-22010-7 978-3-540-24647-3","","","http://link.springer.com/10.1007/978-3-540-24647-3_7","","2004","2023-07-05 07:58:12","2023-07-05 07:58:12","2023-07-05 07:58:12","79-88","","","3002","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-540-24647-3_7","","","","","","Hicks, David L.","Kanade, Takeo; Kittler, Josef; Kleinberg, Jon M.; Mattern, Friedemann; Mitchell, John C.; Nierstrasz, Oscar; Pandu Rangan, C.; Steffen, Bernhard; Sudan, Madhu; Terzopoulos, Demetri; Tygar, Dough; Vardi, Moshe Y.; Weikum, Gerhard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U9QG2LF7","journalArticle","1998","Loomis, Jack M.; Klatzky, Roberta L.; Philbeck, John W.; Golledge, Reginald G.","Assessing auditory distance perception using perceptually directed action","Perception & Psychophysics","","0031-5117, 1532-5962","10.3758/BF03211932","http://link.springer.com/10.3758/BF03211932","","1998-09","2023-07-05 07:58:12","2023-07-05 07:58:12","2023-07-05 07:58:12","966-980","","6","60","","Perception & Psychophysics","","","","","","","","en","","","","","DOI.org (Crossref)","","","","/Users/minsik/Zotero/storage/4EIDND5X/Loomis et al. - 1998 - Assessing auditory distance perception using perce.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MDU3YM55","bookSection","2010","Dicke, Christina; Aaltonen, Viljakaisa; Billinghurst, Mark","Simulator Sickness in Mobile Spatial Sound Spaces","Auditory Display","978-3-642-12438-9 978-3-642-12439-6","","","http://link.springer.com/10.1007/978-3-642-12439-6_15","In this paper we summarize, evaluate, and discuss the effect of movement patterns in a spatial sound space on the perceived amount of simulator sickness, the pleasantness of the experience, and the perceived workload. During our user study nearly 48 percent of all participants showed mild to moderate symptoms of simulator sickness, with a trend towards stronger symptoms for those experiencing left to right movements. We found evidence for predictable left to right movements leading to a perceived unpleasantness that is significantly higher than for unpredictable or no movement at all. However none of the movement patterns had a noticable effect on the perceived cognitive load for simple tasks. We also found some differences in the perception of the sound space between men and women. Women tended to have a stronger dislike for the sound space and found the task to be more difficult.","2010","2023-07-05 07:58:12","2023-07-19 11:37:12","2023-07-05 07:58:12","287-305","","","5954","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-642-12439-6_15","","","","","","Ystad, Sølvi; Aramaki, Mitsuko; Kronland-Martinet, Richard; Jensen, Kristoffer","Hutchison, David; Kanade, Takeo; Kittler, Josef; Kleinberg, Jon M.; Mattern, Friedemann; Mitchell, John C.; Naor, Moni; Nierstrasz, Oscar; Pandu Rangan, C.; Steffen, Bernhard; Sudan, Madhu; Terzopoulos, Demetri; Tygar, Doug; Vardi, Moshe Y.; Weikum, Gerhard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C6EE2TLY","journalArticle","2004","Coward, Sean W.; Stevens, Catherine J.","Extracting Meaning from Sound: Nomic Mappings, Everyday Listening, and Perceiving Object Size from Frequency","The Psychological Record","","0033-2933, 2163-3452","10.1007/BF03395478","http://link.springer.com/10.1007/BF03395478","","2004-07","2023-07-05 07:58:12","2023-07-05 07:58:12","2023-07-05 07:58:12","349-364","","3","54","","Psychol Rec","Extracting Meaning from Sound","","","","","","","en","","","","","DOI.org (Crossref)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PBJ44XDM","journalArticle","2021","Cohen, Michael; Satō, Rintarō; Noji, Ryota; Iida, Takato; Tokumitsu, Yoshiki","Directional selectivity in panoramic and pantophonic interfaces: Flashdark, Narrowcasting for Stereoscopic Photospherical Cinemagraphy, Akabeko Ensemble","The Visual Computer","","0178-2789, 1432-2315","10.1007/s00371-021-02293-1","https://link.springer.com/10.1007/s00371-021-02293-1","We investigate the potential of interactive user interfaces with omnidirectional horizontal selection. Three novel multimodal interfaces have been developed, exploring different ways of displaying and controlling spaces that encourage panoramic and pantophonic experience by featuring selection of objects distributed around the subjective equator. Besides being explicitly omnidirectional, at least regarding azimuthal orientation, they are all stereoscopic “omni-stereo.” “Flashdark” allows the experience of actively darkening a physical area, inverting the usual polarity of lighting control by using a smartphone affordance with intuitive operation as a virtual “anti-light.” “Narrowcasting for Stereoscopic Photospherical Cinemagraphy” uses a visibility atlas to selectively animate articulated sectors of a photographically captured binocular scene. “Akabeko Ensemble” is visual music, using a keyboard controller to trigger pantophonic display of a helical chorus by an annular speaker array.","2021-12","2023-07-05 07:58:12","2023-07-21 05:07:28","2023-07-05 07:58:12","3125-3137","","12","37","","Vis Comput","Directional selectivity in panoramic and pantophonic interfaces","","","","","","","en","","","","","DOI.org (Crossref)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2RXN7G9R","journalArticle","2012","El-Shimy, Dalia; Grond, Florian; Olmos, Adriana; Cooperstock, Jeremy R.","Eyes-free environmental awareness for navigation","Journal on Multimodal User Interfaces","","1783-7677, 1783-8738","10.1007/s12193-011-0065-5","http://link.springer.com/10.1007/s12193-011-0065-5","","2012-05","2023-07-05 07:58:12","2023-07-05 07:58:12","2023-07-05 07:58:12","131-141","","3-4","5","","J Multimodal User Interfaces","","","","","","","","en","","","","","DOI.org (Crossref)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8X466UQI","bookSection","2014","Gerino, Andrea; Alabastro, Nicolò; Bernareggi, Cristian; Ahmetovic, Dragan; Mascetti, Sergio","MathMelodies: Inclusive Design of a Didactic Game to Practice Mathematics","Computers Helping People with Special Needs","978-3-319-08595-1 978-3-319-08596-8","","","http://link.springer.com/10.1007/978-3-319-08596-8_88","","2014","2023-07-05 07:58:12","2023-07-05 07:58:12","2023-07-05 07:58:12","564-571","","","8547","","","MathMelodies","","","","","Springer International Publishing","Cham","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-319-08596-8_88","","","","","","Miesenberger, Klaus; Fels, Deborah; Archambault, Dominique; Peňáz, Petr; Zagler, Wolfgang","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JXRHLEJZ","bookSection","2007","Taylor, Robyn; Kazakevich, Maryia; Boulanger, Pierre; Garcia, Manuel; Bischof, Walter F.","Multi-modal Interface for Fluid Dynamics Simulations Using 3–D Localized Sound","Smart Graphics","978-3-540-73213-6 978-3-540-73214-3","","","http://link.springer.com/10.1007/978-3-540-73214-3_17","","2007","2023-07-05 07:59:23","2023-07-05 07:59:23","2023-07-05 07:59:23","182-187","","","4569","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","en","","","","","DOI.org (Crossref)","","ISSN: 0302-9743, 1611-3349 Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-540-73214-3_17","","/Users/minsik/Zotero/storage/645L5L66/Taylor et al. - 2007 - Multi-modal Interface for Fluid Dynamics Simulatio.pdf","","","","Butz, Andreas; Fisher, Brian; Krüger, Antonio; Olivier, Patrick; Owada, Shigeru","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V95N6NH9","journalArticle","2017","Beun, Robbert Jan; Fitrianie, Siska; Griffioen-Both, Fiemke; Spruit, Sandor; Horsch, Corine; Lancee, Jaap; Brinkman, Willem-Paul","Talk and Tools: the best of both worlds in mobile user interfaces for E-coaching","Personal and Ubiquitous Computing","","1617-4909, 1617-4917","10.1007/s00779-017-1021-5","http://link.springer.com/10.1007/s00779-017-1021-5","In this paper, a user interface paradigm, called Talk-and-Tools, is presented for automated e-coaching. The paradigm is based on the idea that people interact in two ways with their environment: symbolically and physically. The main goal is to show how the paradigm can be applied in the design of interactive systems that offer an acceptable coaching process. As a proof of concept, an ecoaching system is implemented that supports an insomnia therapy on a smartphone. A human coach was replaced by a cooperative virtual coach that is able to interact with a human coachee. In the interface of the system, we distinguish between a set of personalized conversations (BTalk^) and specialized modules that form a coherent structure of input and output facilities (BTools^). Conversations contained a minimum of variation to exclude unpredictable behavior but included the necessary mechanisms for variation to offer personalized consults and support. A variety of system and user tests was conducted to validate the use of the system. After a 6-week therapy, some users spontaneously reported the experience of building a relationship with the e-coach. It is concluded that the addition of a conversational component fills an important gap in the design of current mobile systems.","2017-08","2023-07-05 07:59:23","2023-07-21 04:46:26","2023-07-05 07:59:23","661-674","","4","21","","Pers Ubiquit Comput","Talk and Tools","","","","","","","en","","","","","DOI.org (Crossref)","","","","/Users/minsik/Zotero/storage/9FYLG954/Beun et al. - 2017 - Talk and Tools the best of both worlds in mobile .pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BREADWIC","bookSection","1997","Brewster, Stephen","Navigating Telephone-Based Interfaces with Earcons","People and Computers XII","978-3-540-76172-3 978-1-4471-3601-9","","","http://link.springer.com/10.1007/978-1-4471-3601-9_3","Non-speech audio messages called earcons can provide powerful navigation cues in menu hierarchies. However, previous research on earcons has not addressed the particular problems of menus in telephone-based interfaces (TBI’s) such as: Does the lower quality of sound in TBI’s lower recall rates, can users remember earcons over a period of time and what effect does training type have on recall. An experiment was conducted and results showed that sound quality did lower the recall of earcons. However, redesign of the earcons overcame this problem with 73% recalled correctly. Participants could still recall earcons at this level after a week had passed. Training type also affected recall. With ‘personal training’ participants recalled 73% of the earcons but with purely textual training results were significantly lower. These results show that earcons can provide excellent navigation cues for telephonebased interfaces.","1997","2023-07-05 07:59:23","2023-07-21 04:39:27","2023-07-05 07:59:23","39-56","","","","","","","","","","","Springer London","London","en","","","","","DOI.org (Crossref)","","DOI: 10.1007/978-1-4471-3601-9_3","","/Users/minsik/Zotero/storage/3MPYII8P/Brewster - 1997 - Navigating Telephone-Based Interfaces with Earcons.pdf","","","","Thimbleby, Harold; O’Conaill, Brid; Thomas, Peter J.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3AUCPDCX","bookSection","2000","Semwal, Sudhanshu Kumar; Evans-Kamp, Debra Lee","Virtual Environments for Visually Impaired","Virtual Worlds","978-3-540-67707-9 978-3-540-45016-0","","","http://link.springer.com/10.1007/3-540-45016-5_25","","2000","2023-07-05 07:59:23","2023-07-05 07:59:23","2023-07-05 07:59:23","270-285","","","1834","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/3-540-45016-5_25","","","","","","Heudin, Jean-Claude","Goos, G.; Hartmanis, J.; Van Leeuwen, J.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E377BVXR","journalArticle","2007","Shajahan, Peer; Irani, Pourang","One family, many voices: Can multiple synthetic voices be used as navigational cues in hierarchical interfaces?","International Journal of Speech Technology","","1381-2416, 1572-8110","10.1007/s10772-006-9000-7","http://link.springer.com/10.1007/s10772-006-9000-7","","2007-03-14","2023-07-05 07:59:23","2023-07-05 07:59:23","2023-07-05 07:59:23","1-15","","1-2","9","","Int J Speech Technol","One family, many voices","","","","","","","en","","","","","DOI.org (Crossref)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"76PVVX3X","bookSection","2010","Okada, Noriko; Miki, Mitsunori; Hiroyasu, Tomoyuki; Yoshimi, Masato","Classified-Chime Sound Generation Support System Using an Interactive Genetic Algorithm","Artifical Intelligence and Soft Computing","978-3-642-13231-5 978-3-642-13232-2","","","http://link.springer.com/10.1007/978-3-642-13232-2_21","","2010","2023-07-05 07:59:23","2023-07-05 07:59:23","2023-07-05 07:59:23","173-180","","","6114","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-642-13232-2_21","","","","","","Rutkowski, Leszek; Scherer, Rafał; Tadeusiewicz, Ryszard; Zadeh, Lotfi A.; Zurada, Jacek M.","Hutchison, David; Kanade, Takeo; Kittler, Josef; Kleinberg, Jon M.; Mattern, Friedemann; Mitchell, John C.; Naor, Moni; Nierstrasz, Oscar; Pandu Rangan, C.; Steffen, Bernhard; Sudan, Madhu; Terzopoulos, Demetri; Tygar, Doug; Vardi, Moshe Y.; Weikum, Gerhard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N3UUIUKG","bookSection","2014","Sterkenburg, Jason; Jeon, Myounghoon; Plummer, Christopher","Auditory Emoticons: Iterative Design and Acoustic Characteristics of Emotional Auditory Icons and Earcons","Human-Computer Interaction. Advanced Interaction Modalities and Techniques","978-3-319-07229-6 978-3-319-07230-2","","","http://link.springer.com/10.1007/978-3-319-07230-2_60","","2014","2023-07-05 07:59:23","2023-07-05 07:59:23","2023-07-05 07:59:23","633-640","","","8511","","","Auditory Emoticons","","","","","Springer International Publishing","Cham","en","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-319-07230-2_60","","","","","","Kurosu, Masaaki","Hutchison, David; Kanade, Takeo; Kittler, Josef; Kleinberg, Jon M.; Kobsa, Alfred; Mattern, Friedemann; Mitchell, John C.; Naor, Moni; Nierstrasz, Oscar; Pandu Rangan, C.; Steffen, Bernhard; Terzopoulos, Demetri; Tygar, Doug; Weikum, Gerhard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TEZRQTXX","journalArticle","2016","Strayer, David L.; Cooper, Joel M.; Turrill, Jonna; Coleman, James R.; Hopman, Rachel J.","Talking to your car can drive you to distraction","Cognitive Research: Principles and Implications","","2365-7464","10.1186/s41235-016-0018-3","http://cognitiveresearchjournal.springeropen.com/articles/10.1186/s41235-016-0018-3","This research examined the impact of in-vehicle information system (IVIS) interactions on the driver’s cognitive workload; 257 subjects participated in a weeklong evaluation of the IVIS interaction in one of ten different model-year 2015 automobiles. After an initial assessment of the cognitive workload associated with using the IVIS, participants took the vehicle home for 5 days and practiced using the system. At the end of the 5 days of practice, participants returned and the workload of these IVIS interactions was reassessed. The cognitive workload was found to be moderate to high, averaging 3.34 on a 5-point scale and ranged from 2.37 to 4.57. The workload was associated with the intuitiveness and complexity of the system and the time it took participants to complete the interaction. The workload experienced by older drivers was significantly greater than that experienced by younger drivers performing the same operations. Practice did not eliminate the interference from IVIS interactions. In fact, IVIS interactions that were difficult on the first day were still relatively difficult to perform after a week of practice. Finally, there were long-lasting residual costs after the IVIS interactions had terminated. The higher levels of workload should serve as a caution that these voice-based interactions can be cognitively demanding and ought not to be used indiscriminately while operating a motor vehicle.","2016-12","2023-07-05 07:59:23","2023-07-19 23:47:01","2023-07-05 07:59:23","16","","1","1","","Cogn. Research","","","","","","","","en","","","","","DOI.org (Crossref)","","","","/Users/minsik/Zotero/storage/QTSSSIGJ/Strayer et al. - 2016 - Talking to your car can drive you to distraction.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KAXMYTJF","bookSection","2009","Eslambochilar, Parisa; Buchanan, George; Loizides, Fernando","Hear It Is: Enhancing Rapid Document Browsing with Sound Cues","Research and Advanced Technology for Digital Libraries","978-3-642-04345-1 978-3-642-04346-8","","","http://link.springer.com/10.1007/978-3-642-04346-8_9","","2009","2023-07-05 07:59:23","2023-07-05 07:59:23","2023-07-05 07:59:23","75-86","","","5714","","","Hear It Is","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-642-04346-8_9","","/Users/minsik/Zotero/storage/R7A5QV3T/Eslambochilar et al. - 2009 - Hear It Is Enhancing Rapid Document Browsing with.pdf","","","","Agosti, Maristella; Borbinha, José; Kapidakis, Sarantos; Papatheodorou, Christos; Tsakonas, Giannis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C59BSPXR","bookSection","2010","Larsson, Pontus","Tools for Designing Emotional Auditory Driver-Vehicle Interfaces","Auditory Display","978-3-642-12438-9 978-3-642-12439-6","","","http://link.springer.com/10.1007/978-3-642-12439-6_1","","2010","2023-07-05 07:59:23","2023-07-05 07:59:23","2023-07-05 07:59:23","1-11","","","5954","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-642-12439-6_1","","","","","","Ystad, Sølvi; Aramaki, Mitsuko; Kronland-Martinet, Richard; Jensen, Kristoffer","Hutchison, David; Kanade, Takeo; Kittler, Josef; Kleinberg, Jon M.; Mattern, Friedemann; Mitchell, John C.; Naor, Moni; Nierstrasz, Oscar; Pandu Rangan, C.; Steffen, Bernhard; Sudan, Madhu; Terzopoulos, Demetri; Tygar, Doug; Vardi, Moshe Y.; Weikum, Gerhard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WM9MHGQG","journalArticle","1995","Maybury, Mark T.","Research in multimedia and multimodal parsing and generation","Artificial Intelligence Review","","0269-2821, 1573-7462","10.1007/BF00849175","http://link.springer.com/10.1007/BF00849175","This overview introduces the emerging set of techniques for parsing and generating multiple media (e.g., text, graphics, maps, gestures) using multiple sensory modalities (e.g., auditory, visual, tactile). We first briefly introduce and motivate the value of such techniques. Next we describe various computational methods for parsing input from heterogeneous media and modalities (e.g., natural language, gesture, gaze). We subsequently overview complementary techniques for generating coordinated multimedia and multimodal output. Finally, we discuss systems that have integrated both parsing and generation to enable multimedia dialogue in the context of intelligent interfaces. The article concludes by outlining fundamental problems which require further research.","1995-06","2023-07-05 07:59:23","2023-07-19 11:34:36","2023-07-05 07:59:23","103-127","","2-3","9","","Artif Intell Rev","","","","","","","","en","","","","","DOI.org (Crossref)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QLTW2ZFM","bookSection","1997","Duce, David A.","Theory and practice in interactionally rich distributed systems","SOFSEM'97: Theory and Practice of Informatics","978-3-540-63774-5 978-3-540-69645-2","","","http://link.springer.com/10.1007/3-540-63774-5_105","","1997","2023-07-05 07:59:23","2023-07-05 07:59:23","2023-07-05 07:59:23","163-182","","","1338","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/3-540-63774-5_105","","","","","","Plášil, František; Jeffery, Keith G.","Goos, Gerhard; Hartmanis, Juris; Van Leeuwen, Jan","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DPCCD6AC","journalArticle","2007","Porta, Marco","Human–Computer input and output techniques: an analysis of current research and promising applications","Artificial Intelligence Review","","0269-2821, 1573-7462","10.1007/s10462-009-9098-5","http://link.springer.com/10.1007/s10462-009-9098-5","Personal computing applications are constantly increasing their potential power, thanks to steadily growing hardware capabilities and large diffusion of high-quality multimedia output devices. At the same time, mobile communication tools are becoming an integral part of our everyday life, with new advanced functionalities offered at an unrestrainable pace. Although the way we interact with information machines is substantially the same since 20 years—based on keyboard, mouse and window metaphor—other communication modalities are possible, and shortly may become popular as additional interaction methods. Given the paramount importance of the “interface” in present computer applications, no alternative should be ignored, as it could greatly improve the quality of both interaction processes and user cognitive performance. Without pretending to foresee the future, in this paper we provide an overview of the main current technologies which can enable potential novel interfaces, discussing their features, strengths, weaknesses and promising applications.","2007-10","2023-07-05 07:59:23","2023-07-19 11:34:44","2023-07-05 07:59:23","197-226","","3","28","","Artif Intell Rev","Human–Computer input and output techniques","","","","","","","en","","","","","DOI.org (Crossref)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E7R88KWB","bookSection","2010","Hug, Daniel","Investigating Narrative and Performative Sound Design Strategies for Interactive Commodities","Auditory Display","978-3-642-12438-9 978-3-642-12439-6","","","http://link.springer.com/10.1007/978-3-642-12439-6_2","","2010","2023-07-05 07:59:23","2023-07-05 07:59:23","2023-07-05 07:59:23","12-40","","","5954","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-642-12439-6_2","","","","","","Ystad, Sølvi; Aramaki, Mitsuko; Kronland-Martinet, Richard; Jensen, Kristoffer","Hutchison, David; Kanade, Takeo; Kittler, Josef; Kleinberg, Jon M.; Mattern, Friedemann; Mitchell, John C.; Naor, Moni; Nierstrasz, Oscar; Pandu Rangan, C.; Steffen, Bernhard; Sudan, Madhu; Terzopoulos, Demetri; Tygar, Doug; Vardi, Moshe Y.; Weikum, Gerhard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R8ZCPS3H","bookSection","2011","Wolf, Katrin; Naumann, Anja; Rohs, Michael; Müller, Jörg","A Taxonomy of Microinteractions: Defining Microgestures Based on Ergonomic and Scenario-Dependent Requirements","Human-Computer Interaction – INTERACT 2011","978-3-642-23773-7 978-3-642-23774-4","","","http://link.springer.com/10.1007/978-3-642-23774-4_45","This paper explores how microgestures can allow us to execute a secondary task, for example controlling mobile applications, without interrupting the manual primary task, for instance, driving a car. In order to design microgestures iteratively, we interviewed sports- and physiotherapists while asking them to use task related props, such as a steering wheel, a cash card , and a pen for simulating driving a car, an ATM scenario, and a drawing task. The primary objective here is to define microgestures that are easily performable without interrupting or interfering the primary task. Using expert interviews, we developed a taxonomy that classifies these gestures according to their task context. We also assessed the ergonomic and attentional attributes that influence the feasibility and task suitability of microinteractions, and evaluated their level of resources required. Accordingly, we defined 21 microgestures that allow performing microinteractions within a manual, dual task context. Our taxonomy poses a basis for designing microinteraction techniques.","2011","2023-07-05 07:59:23","2023-07-20 06:28:44","2023-07-05 07:59:23","559-575","","","6946","","","A Taxonomy of Microinteractions","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-642-23774-4_45","","/Users/minsik/Zotero/storage/NNDZNRFY/Wolf et al. - 2011 - A Taxonomy of Microinteractions Defining Microges.pdf","","","","Campos, Pedro; Graham, Nicholas; Jorge, Joaquim; Nunes, Nuno; Palanque, Philippe; Winckler, Marco","Hutchison, David; Kanade, Takeo; Kittler, Josef; Kleinberg, Jon M.; Mattern, Friedemann; Mitchell, John C.; Naor, Moni; Nierstrasz, Oscar; Pandu Rangan, C.; Steffen, Bernhard; Sudan, Madhu; Terzopoulos, Demetri; Tygar, Doug; Vardi, Moshe Y.; Weikum, Gerhard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HL7VRKCG","journalArticle","2005","Zotkin, Dmitry N.; Chi, Taishih; Shamma, Shihab A.; Duraiswami, Ramani","Neuromimetic Sound Representation for Percept Detection and Manipulation","EURASIP Journal on Advances in Signal Processing","","1687-6180","10.1155/ASP.2005.1350","https://asp-eurasipjournals.springeropen.com/articles/10.1155/ASP.2005.1350","","2005-12","2023-07-05 07:59:23","2023-07-05 07:59:23","2023-07-05 07:59:23","486137","","9","2005","","EURASIP J. Adv. Signal Process.","","","","","","","","en","","","","","DOI.org (Crossref)","","","","/Users/minsik/Zotero/storage/CV4I6Y2X/Zotkin et al. - 2005 - Neuromimetic Sound Representation for Percept Dete.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EFWFPACI","journalArticle","2010","Power, Christopher; Jürgensen, Helmut","Accessible presentation of information for people with visual disabilities","Universal Access in the Information Society","","1615-5289, 1615-5297","10.1007/s10209-009-0164-1","http://link.springer.com/10.1007/s10209-009-0164-1","Personal computers, palm top computers, media players and cell phones provide instant access to information from around the world. There are a wide variety of options available to make that information available to people with visual disabilities, so many that choosing one for use in any given context can often feel daunting to someone new to the field of accessibility. This paper reviews tools and techniques for the presentation of textual, graphic, mathematic and web documents through audio and haptic modalities to people with visual disabilities.","2010-06","2023-07-05 07:59:23","2023-07-21 05:12:41","2023-07-05 07:59:23","97-119","","2","9","","Univ Access Inf Soc","","","","","","","","en","","","","","DOI.org (Crossref)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MYSE8SZI","journalArticle","2007","Baldwin, Carryl L.","Cognitive implications of facilitating echoic persistence","Memory & Cognition","","0090-502X, 1532-5946","10.3758/BF03193314","http://link.springer.com/10.3758/BF03193314","","2007-06","2023-07-05 07:59:23","2023-07-05 07:59:23","2023-07-05 07:59:23","774-780","","4","35","","Memory & Cognition","","","","","","","","en","","","","","DOI.org (Crossref)","","","","/Users/minsik/Zotero/storage/AC5LGUND/Baldwin - 2007 - Cognitive implications of facilitating echoic pers.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I5BK9DX4","bookSection","2011","Rutkowski, Tomasz M.","Auditory Brain-Computer/Machine-Interface Paradigms Design","Haptic and Audio Interaction Design","978-3-642-22949-7 978-3-642-22950-3","","","http://link.springer.com/10.1007/978-3-642-22950-3_12","The paper discusses novel and interesting, from users’ point of view, design of auditory brain-computer/machine interfaces (BCI/ BMI) utilizing human auditory responses. Two concepts of auditory stimuli BCI/BMI are presented. The first paradigm is based on steady-state tonal or musical stimuli yielding satisfactory EEG response classification for several seconds long stimuli. The second discussed paradigm is based on spatial sound localization and the brain evoked responses estimation, requiring shorter than a second stimuli presentation. In conclusion the preliminary results are discussed and suggestions for further applications are drawn.","2011","2023-07-05 07:59:23","2023-07-20 00:16:39","2023-07-05 07:59:23","110-119","","","6851","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-642-22950-3_12","","","","","","Cooper, Eric W.; Kryssanov, Victor V.; Ogawa, Hitoshi; Brewster, Stephen","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZFV4Z3IK","journalArticle","2022","Misdariis, N.; Özcan, E.; Grassi, M.; Pauletto, S.; Barrass, S.; Bresin, R.; Susini, P.","Sound experts’ perspectives on astronomy sonification projects","Nature Astronomy","","2397-3366","10.1038/s41550-022-01821-w","https://www.nature.com/articles/s41550-022-01821-w","The Audible Universe project aims to create dialogue between two scientific domains investigating two distinct research objects: stars and sound. It has been instantiated within a collaborative workshop that began to mutually acculturate the two communities, by sharing and transmitting respective knowledge, skills and practices. One main outcome of this exchange was a global view on the astronomical data sonification paradigm for observing the diversity of tools, uses and users (including visually impaired people), but also the current limitations and potential methods of improvement. From this viewpoint, here we present basic elements gathered and contextualized by sound experts in their respective fields (sound perception/cognition, sound design, psychoacoustics, experimental psychology), to anchor sonification for astronomy in a more well informed, methodological and creative process.","2022-11","2023-07-05 07:59:35","2023-07-05 07:59:35","2023-07-05 07:59:35","1249-1255","","11","6","","Nat Astron","","","","","","","","en","2022 Springer Nature Limited","","","","www.nature.com","","Number: 11 Publisher: Nature Publishing Group","","/Users/minsik/Zotero/storage/KC6SKD2W/Misdariis et al. - 2022 - Sound experts’ perspectives on astronomy sonificat.pdf","","","Astronomy and astrophysics; Information theory and computation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C28DRLXL","bookSection","2001","Harding, Chris; Kakadiaris, Ioannis A.; Casey, John F.; Bowen Loftin, R.","A Case Study in Multi-Sensory Investigation of Geoscientific Data","Data Visualization 2001","978-3-211-83674-3 978-3-7091-6215-6","","","http://link.springer.com/10.1007/978-3-7091-6215-6_2","","2001","2023-07-05 08:00:53","2023-07-05 08:00:53","2023-07-05 08:00:53","3-14","","","","","","","","","","","Springer Vienna","Vienna","en","","","","","DOI.org (Crossref)","","Series Title: Eurographics DOI: 10.1007/978-3-7091-6215-6_2","","","","","","Ebert, David S.; Favre, Jean M.; Peikert, Ronald","Hansmann, W.; Purgathofer, W.; Sillion, F.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WLE3SY6W","journalArticle","2020","Patrick, Rafael N. C.; Letowski, Tomasz R.; McBride, Maranda E.","A multimodal auditory equal-loudness comparison of air and bone conducted sounds","Journal on Multimodal User Interfaces","","1783-7677, 1783-8738","10.1007/s12193-020-00320-4","http://link.springer.com/10.1007/s12193-020-00320-4","","2020-06","2023-07-05 08:00:53","2023-07-05 08:00:53","2023-07-05 08:00:53","199-206","","2","14","","J Multimodal User Interfaces","","","","","","","","en","","","","","DOI.org (Crossref)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T8RB79T2","bookSection","2003","Goldstein, Mikael; Öquist, Gustav; Björk, Staffan","Evaluating Sonified Rapid Serial Visual Presentation: An Immersive Reading Experience on a Mobile Device","Universal Access Theoretical Perspectives, Practice, and Experience","978-3-540-00855-2 978-3-540-36572-3","","","http://link.springer.com/10.1007/3-540-36572-9_39","","2003","2023-07-05 08:00:53","2023-07-05 08:00:53","2023-07-05 08:00:53","508-523","","","2615","","","Evaluating Sonified Rapid Serial Visual Presentation","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/3-540-36572-9_39","","","","","","Carbonell, Noëlle; Stephanidis, Constantine","Goos, Gerhard; Hartmanis, Juris; Van Leeuwen, Jan","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y4FKDSYE","journalArticle","2003","Pittarello, Fabio","Accessing information through multimodal 3D environments: towards universal access","Universal Access in the Information Society","","1615-5289, 1615-5297","10.1007/s10209-003-0044-z","http://link.springer.com/10.1007/s10209-003-0044-z","","2003-06-01","2023-07-05 08:00:53","2023-07-05 08:00:53","2023-07-05 08:00:53","189-204","","2","2","","Universal Access in the Information Society","Accessing information through multimodal 3D environments","","","","","","","","","","","","DOI.org (Crossref)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TMKQQLS7","bookSection","2012","Hachisu, Taku; Kajimoto, Hiroyuki","Augmentation of Toothbrush by Modulating Sounds Resulting from Brushing","Advances in Computer Entertainment","978-3-642-34291-2 978-3-642-34292-9","","","http://link.springer.com/10.1007/978-3-642-34292-9_3","Brushing teeth is a daily habit to maintain oral hygiene, including the maintenance of oral cleanliness and prevention of caries and periodontal disease. However, tooth brushing is often not carried out correctly or forgotten because the task is boring. Although several works have contributed to improving brushing performance and motivation, the feedback seems to be very remote from the brushing itself, i.e., not intuitive. In this study, we establish two objectives to deal with these issues. The first is not to present information on a visual display, but to augment the ordinary tooth brushing experience consisting of haptic and auditory sensations, while the other is to design the modulation so that users feel as if their teeth are gradually becoming cleaner, thereby providing the necessary motivation. To achieve these aims, we propose a novel approach to augment the tooth brushing experience by modulating the brushing sounds to make tooth brushing entertaining in an intuitive manner. A microphone embedded in the toothbrush records the brushing sounds, which are presented to users after being modified by a PC. In the experiment, we demonstrate that increasing the sound gain and manipulating the frequency can control the overall impression of brushing by giving a sense of comfort and accomplishment.","2012","2023-07-05 08:00:53","2023-07-19 11:11:05","2023-07-05 08:00:53","31-43","","","7624","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-642-34292-9_3","","","","","","Nijholt, Anton; Romão, Teresa; Reidsma, Dennis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CJDWYLQ7","bookSection","1998","Brewster, Stephen","Using Earcons to Improve the Usability of a Graphics Package","People and Computers XIII","978-3-540-76261-4 978-1-4471-3605-7","","","http://link.springer.com/10.1007/978-1-4471-3605-7_18","","1998","2023-07-05 08:00:53","2023-07-05 08:00:53","2023-07-05 08:00:53","287-302","","","","","","","","","","","Springer London","London","en","","","","","DOI.org (Crossref)","","DOI: 10.1007/978-1-4471-3605-7_18","","/Users/minsik/Zotero/storage/I8DCSHYB/Brewster - 1998 - Using Earcons to Improve the Usability of a Graphi.pdf","","","","Johnson, Hilary; Nigay, Lawrence; Roast, Christopher","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PYBDVY54","journalArticle","2012","Rosati, Giulio; Oscari, Fabio; Spagnol, Simone; Avanzini, Federico; Masiero, Stefano","Effect of task-related continuous auditory feedback during learning of tracking motion exercises","Journal of NeuroEngineering and Rehabilitation","","1743-0003","10.1186/1743-0003-9-79","http://jneuroengrehab.biomedcentral.com/articles/10.1186/1743-0003-9-79","Background: This paper presents the results of a set of experiments in which we used continuous auditory feedback to augment motor training exercises. This feedback modality is mostly underexploited in current robotic rehabilitation systems, which usually implement only very basic auditory interfaces. Our hypothesis is that properly designed continuous auditory feedback could be used to represent temporal and spatial information that could in turn, improve performance and motor learning. Methods: We implemented three different experiments on healthy subjects, who were asked to track a target on a screen by moving an input device (controller) with their hand. Different visual and auditory feedback modalities were envisaged. The first experiment investigated whether continuous task-related auditory feedback can help improve performance to a greater extent than error-related audio feedback, or visual feedback alone. In the second experiment we used sensory substitution to compare different types of auditory feedback with equivalent visual feedback, in order to find out whether mapping the same information on a different sensory channel (the visual channel) yielded comparable effects with those gained in the first experiment. The final experiment applied a continuously changing visuomotor transformation between the controller and the screen and mapped kinematic information, computed in either coordinate system (controller or video), to the audio channel, in order to investigate which information was more relevant to the user. Results: Task-related audio feedback significantly improved performance with respect to visual feedback alone, whilst error-related feedback did not. Secondly, performance in audio tasks was significantly better with respect to the equivalent sensory-substituted visual tasks. Finally, with respect to visual feedback alone, video-task-related sound feedback decreased the tracking error during the learning of a novel visuomotor perturbation, whereas controller-task-related sound feedback did not. This result was particularly interesting, as the subjects relied more on auditory augmentation of the visualized target motion (which was altered with respect to arm motion by the visuomotor perturbation), rather than on sound feedback provided in the controller space, i.e., information directly related to the effective target motion of their arm. Conclusions: Our results indicate that auditory augmentation of visual feedback can be beneficial during the execution of upper limb movement exercises. In particular, we found that continuous task-related information provided through sound, in addition to visual feedback can improve not only performance but also the learning of a novel visuomotor perturbation. However, error-related information provided through sound did not improve performance and negatively affected learning in the presence of the visuomotor perturbation.","2012","2023-07-05 08:00:53","2023-07-21 07:43:04","2023-07-05 08:00:53","79","","1","9","","J NeuroEngineering Rehabil","","","","","","","","en","","","","","DOI.org (Crossref)","","","","/Users/minsik/Zotero/storage/5NCZJYSE/Rosati et al. - 2012 - Effect of task-related continuous auditory feedbac.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DTCNDF9B","bookSection","2009","Duarte, Carlos; Carriço, Luís","When You Can’t Read It, Listen to It! An Audio-Visual Interface for Book Reading","Universal Access in Human-Computer Interaction. Applications and Services","978-3-642-02712-3 978-3-642-02713-0","","","http://link.springer.com/10.1007/978-3-642-02713-0_3","This paper presents a prototype of a mobile Digital Talking Book player, which, by combining visual and non-visual means of interaction, strives to achieve universal accessibility. Details on the non-visual aspects of the interaction, both input and output, are provided. To assess the validity of the proposed solutions, an experiment evaluates the non-visual operation of the prototype. Results show users can complete the same tasks with visual and non-visual interaction. However, some limitations are identified, and the observations prompt a discussion on how the use of multimodal interfaces can improve their accessibility and usability.","2009","2023-07-05 08:00:53","2023-07-21 05:08:55","2023-07-05 08:00:53","24-33","","","5616","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","en","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-642-02713-0_3","","","","","","Stephanidis, Constantine","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TETTD3IB","bookSection","2002","Hermann, Thomas; Nölker, Claudia; Ritter, Helge","Hand Postures for Sonification Control","Gesture and Sign Language in Human-Computer Interaction","978-3-540-43678-2 978-3-540-47873-7","","","http://link.springer.com/10.1007/3-540-47873-6_32","","2002","2023-07-05 08:00:53","2023-07-05 08:00:53","2023-07-05 08:00:53","307-316","","","2298","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/3-540-47873-6_32","","","","","","Wachsmuth, Ipke; Sowa, Timo","Goos, G.; Hartmanis, J.; Van Leeuwen, J.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HQ4MXB4X","journalArticle","2016","Tordini, Francesco; Bregman, Albert S.; Cooperstock, Jeremy R.","Prioritizing foreground selection of natural chirp sounds by tempo and spectral centroid","Journal on Multimodal User Interfaces","","1783-7677, 1783-8738","10.1007/s12193-016-0223-x","http://link.springer.com/10.1007/s12193-016-0223-x","","2016-09","2023-07-05 08:00:53","2023-07-05 08:00:53","2023-07-05 08:00:53","221-234","","3","10","","J Multimodal User Interfaces","","","","","","","","en","","","","","DOI.org (Crossref)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TZKRWAHR","bookSection","2006","Crombie, David","People with Disabilities: Accessible Content Processing","Computers Helping People with Special Needs","978-3-540-36020-9 978-3-540-36021-6","","","http://link.springer.com/10.1007/11788713_1","The Special Thematic Session (STS) on Accessible Content Processing is intended to provide a focus for several different activities which can be grouped under this area. The European Accessible Information Network (EUAIN) was established in order to bring together the different stakeholders in the accessible content processing chain and to build on common concerns. EUAIN has now completed a systemic overview of this area and will use this information to provide guidelines, training materials and input into standardisation activities. The papers in this STS address many of these issues.","2006","2023-07-05 08:00:53","2023-07-19 23:51:37","2023-07-05 08:00:53","1-5","","","4061","","","People with Disabilities","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/11788713_1","","","","","","Miesenberger, Klaus; Klaus, Joachim; Zagler, Wolfgang L.; Karshmer, Arthur I.","Hutchison, David; Kanade, Takeo; Kittler, Josef; Kleinberg, Jon M.; Mattern, Friedemann; Mitchell, John C.; Naor, Moni; Nierstrasz, Oscar; Pandu Rangan, C.; Steffen, Bernhard; Sudan, Madhu; Terzopoulos, Demetri; Tygar, Dough; Vardi, Moshe Y.; Weikum, Gerhard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WVCIAUP3","journalArticle","2012","Metatla, Oussama; Bryan-Kinns, Nick; Stockman, Tony","Interactive hierarchy-based auditory displays for accessing and manipulating relational diagrams","Journal on Multimodal User Interfaces","","1783-7677, 1783-8738","10.1007/s12193-011-0067-3","http://link.springer.com/10.1007/s12193-011-0067-3","","2012-05","2023-07-05 08:00:53","2023-07-05 08:00:53","2023-07-05 08:00:53","111-122","","3-4","5","","J Multimodal User Interfaces","","","","","","","","en","","","","","DOI.org (Crossref)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MAPUU43R","bookSection","2010","Schaar, Anne Kathrin; Ziefle, Martina","Potential of e-Travel Assistants to Increase Older Adults’ Mobility","HCI in Work and Learning, Life and Leisure","978-3-642-16606-8 978-3-642-16607-5","","","http://link.springer.com/10.1007/978-3-642-16607-5_9","In this empirical study we examine the willingness of travelers to use small screen devices providing electronic travel (“e-travel”) services. As in the near future increasingly more and older adults are travelling around, it is a basic question how we can support this wish for mobility. However, electronic travel services on mobile device are only accepted if it is understood in how far these devices meet the actual travel behavior on the one hand and user requirements respecting the usability of devices on the other. Yet, only little knowledge is prevalent regarding the individual reasons for the choice of means of transportation as well as the perceived needs when being supported by a device providing travel services. In order to get a broad insight into age-related mobility patterns, users of a wide age range (N = 151; 18-75 years of age) were questioned in a survey, in which the travel experience (frequency of using different means of transportation and their evaluation) as well as technical experience (Internet usage and handling of small screen devices) were explored. The findings show that age (but not gender) is a crucial factor regarding the acceptance of electronic travel assistants, and services. The crucial factor underlying age effects is the technical experience and travel expertise: The higher the familiarity with electronic services in general (Internet usage) and specifically (handling of mobile devices) and domain knowledge (travel experience), the higher is the perceived usefulness of future e-travel services. Outcomes might be helpful for the development of e-travel applications especially with for the intention to keep the elderly mobile and fit for travelling.","2010","2023-07-05 08:00:53","2023-07-20 05:43:54","2023-07-05 08:00:53","138-155","","","6389","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-642-16607-5_9","","","","","","Leitner, Gerhard; Hitz, Martin; Holzinger, Andreas","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9EZ5HXPQ","bookSection","2003","Djennane, Safia","3D-Audio News Presentation Modeling","Universal Access Theoretical Perspectives, Practice, and Experience","978-3-540-00855-2 978-3-540-36572-3","","","http://link.springer.com/10.1007/3-540-36572-9_22","","2003","2023-07-05 08:00:53","2023-07-05 08:00:53","2023-07-05 08:00:53","280-286","","","2615","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/3-540-36572-9_22","","","","","","Carbonell, Noëlle; Stephanidis, Constantine","Goos, Gerhard; Hartmanis, Juris; Van Leeuwen, Jan","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QACRTNPX","journalArticle","2015","Csapó, Ádám; Wersényi, György; Nagy, Hunor; Stockman, Tony","A survey of assistive technologies and applications for blind users on mobile platforms: a review and foundation for research","Journal on Multimodal User Interfaces","","1783-7677, 1783-8738","10.1007/s12193-015-0182-7","http://link.springer.com/10.1007/s12193-015-0182-7","This paper summarizes recent developments in audio and tactile feedback based assistive technologies targeting the blind community. Current technology allows applications to be efficiently distributed and run on mobile and handheld devices, even in cases where computational requirements are significant. As a result, electronic travel aids, navigational assistance modules, text-to-speech applications, as well as virtual audio displays which combine audio with haptic channels are becoming integrated into standard mobile devices. This trend, combined with the appearance of increasingly user-friendly interfaces and modes of interaction has opened a variety of new perspectives for the rehabilitation and training of users with visual impairments. The goal of this paper is to provide an overview of these developments based on recent advances in basic research and application development. Using this overview as a foundation, an agenda is outlined for future research in mobile interaction design with respect to users with special needs, as well as ultimately in relation to sensor-bridging applications in general.","2015-12","2023-07-05 08:00:53","2023-07-20 06:53:22","2023-07-05 08:00:53","275-286","","4","9","","J Multimodal User Interfaces","A survey of assistive technologies and applications for blind users on mobile platforms","","","","","","","en","","","","","DOI.org (Crossref)","","","","/Users/minsik/Zotero/storage/8CU5GFJL/Csapó et al. - 2015 - A survey of assistive technologies and application.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5CWMP4B8","bookSection","2010","Bonner, Matthew N.; Brudvik, Jeremy T.; Abowd, Gregory D.; Edwards, W. Keith","No-Look Notes: Accessible Eyes-Free Multi-touch Text Entry","Pervasive Computing","978-3-642-12653-6 978-3-642-12654-3","","","http://link.springer.com/10.1007/978-3-642-12654-3_24","Mobile devices with multi-touch capabilities are becoming increasingly common, largely due to the success of the Apple iPhone and iPod Touch. While there have been some advances in touchscreen accessibility for blind people, touchscreens remain inaccessible in many ways. Recent research has demonstrated that there is great potential in leveraging multi-touch capabilities to increase the accessibility of touchscreen applications for blind people. We have created No-Look Notes, an eyes-free text entry system that uses multi-touch input and audio output. No-Look Notes was implemented on Apple’s iPhone platform. We have performed a within-subjects (n = 10) user study of both No-Look Notes and the text entry component of Apple’s VoiceOver, the recently released official accessibility component on the iPhone. No-Look Notes significantly outperformed VoiceOver in terms of speed, accuracy and user preference.","2010","2023-07-05 08:00:53","2023-07-21 04:54:37","2023-07-05 08:00:53","409-426","","","6030","","","No-Look Notes","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-642-12654-3_24","","","","","","Floréen, Patrik; Krüger, Antonio; Spasojevic, Mirjana","Hutchison, David; Kanade, Takeo; Kittler, Josef; Kleinberg, Jon M.; Mattern, Friedemann; Mitchell, John C.; Naor, Moni; Nierstrasz, Oscar; Pandu Rangan, C.; Steffen, Bernhard; Sudan, Madhu; Terzopoulos, Demetri; Tygar, Doug; Vardi, Moshe Y.; Weikum, Gerhard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FB4Q8MYM","journalArticle","2021","Kim, Hubert; Asbeck, Alan T.","Just noticeable differences for elbow joint torque feedback","Scientific Reports","","2045-2322","10.1038/s41598-021-02630-3","https://www.nature.com/articles/s41598-021-02630-3","Abstract             Joint torque feedback is a new and promising means of kinesthetic feedback imposed by a wearable device. The torque feedback provides the wearer temporal and spatial information during a motion task. Nevertheless, little research has been conducted on quantifying the psychophysical parameters of how well humans can perceive external torques under various joint conditions. This study aims to investigate the just noticeable difference (JND) perceptual ability of the elbow joint to joint torques. The paper focuses on the ability of two primary joint proprioceptors, the Golgi-tendon organ (GTO) and muscle spindle (MS), to detect elbow torques, since touch and pressure sensors were masked. We studied 14 subjects while the arm was isometrically contracted (static condition) and was moving at a constant speed (dynamic condition). In total there were 10 joint conditions investigated, which varied the direction of the arm’s movement and the preload direction as well as torque direction. The JND torques under static conditions ranged from 0.097 Nm with no preload to 0.197 Nm with a preload of 1.28 Nm. The maximum dynamic JND torques were 0.799 Nm and 0.428 Nm, when the arm was flexing and extending at 213 degrees per second, respectively.","2021-12-07","2023-07-05 08:00:53","2023-07-05 08:00:53","2023-07-05 08:00:53","23553","","1","11","","Sci Rep","","","","","","","","en","","","","","DOI.org (Crossref)","","","","/Users/minsik/Zotero/storage/PBNTX5JP/Kim and Asbeck - 2021 - Just noticeable differences for elbow joint torque.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"37CTZ9IJ","bookSection","2002","Baloian, Nelson; Luther, Wolfram","Visualization for the Mind’s Eye","Software Visualization","978-3-540-43323-1 978-3-540-45875-3","","","http://link.springer.com/10.1007/3-540-45875-1_28","","2002","2023-07-05 08:00:53","2023-07-05 08:00:53","2023-07-05 08:00:53","354-367","","","2269","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/3-540-45875-1_28","","/Users/minsik/Zotero/storage/4LYAUS2Z/Baloian and Luther - 2002 - Visualization for the Mind’s Eye.pdf","","","","Diehl, Stephan","Goos, Gerhard; Hartmanis, Juris; Van Leeuwen, Jan","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XF8E4WLF","journalArticle","2006","Tahboub, Karim A.","Intelligent Human-Machine Interaction Based on Dynamic Bayesian Networks Probabilistic Intention Recognition","Journal of Intelligent and Robotic Systems","","0921-0296, 1573-0409","10.1007/s10846-005-9018-0","http://link.springer.com/10.1007/s10846-005-9018-0","In this article, a novel human–machine interaction based on the machine intention recognition of the human is presented. This work is motivated by the desire that intelligent machines as robots imitate human–human interaction, that is to minimize the need for classical direct human–machine interface and communication. A philosophical and technical background for intention recognition is discussed. Here, the intention–action–state scenario is modified and modeled by Dynamic Bayesian Networks to facilitate for probabilistic intention inference. The recognized intention, then, drives the interactive behavior of the machine such that it complies with the human intention in light of the real state of the world. An illustrative example of a human commanding a mobile robot remotely is given and discussed in details.","2006-01","2023-07-05 08:00:53","2023-07-20 06:47:25","2023-07-05 08:00:53","31-52","","1","45","","J Intell Robot Syst","","","","","","","","en","","","","","DOI.org (Crossref)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"47YIHHJZ","bookSection","2007","Duarte, Carlos; Carriço, Luís","Conveying Browsing Context Through Audio on Digital Talking Books","Universal Access in Human-Computer Interaction. Applications and Services","978-3-540-73282-2 978-3-540-73283-9","","","http://link.springer.com/10.1007/978-3-540-73283-9_30","This paper presents the results of a study comparing the use of auditory icons, earcons and speech in an audio only interface for a digital talking book player. The different techniques were evaluated according to the identification errors made, and subjective measures of understandability, intrusiveness and pleasurability. Results suggest the use of auditory icons combined with speech whenever necessary, in detriment to the use of earcons, for applications sharing the characteristics of digital talking book players.","2007","2023-07-05 08:00:53","2023-07-21 05:08:48","2023-07-05 08:00:53","259-268","","","4556","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","en","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-540-73283-9_30","","","","","","Stephanidis, Constantine","Hutchison, David; Kanade, Takeo; Kittler, Josef; Kleinberg, Jon M.; Mattern, Friedemann; Mitchell, John C.; Naor, Moni; Nierstrasz, Oscar; Pandu Rangan, C.; Steffen, Bernhard; Sudan, Madhu; Terzopoulos, Demetri; Tygar, Doug; Vardi, Moshe Y.; Weikum, Gerhard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V49BH9QU","conferencePaper","2011","Absar, Rafa; Guastavino, Catherine","Nonspeech Sound Design for a Hierarchical Information System","Human Centered Design","978-3-642-21753-1","","10.1007/978-3-642-21753-1_52","","This research describes a human-centered design methodology for creating nonspeech sounds to enhance navigation in a visual user interface. This paper describes how the sound design methodology proposed in [10][11] was extended to sonify a novel 3D-visualized information system for sighted users navigating a hierarchical structure. The method ensures that the sounds designed are not based on personal or ad hoc choices, and instead exploits the creativity of a user group as an application of participatory design in sound. Recommendations are derived from this case study on how to design auditory cues for familiar or novel user interfaces to convey structural information in an informative and intuitive way.","2011","2023-07-05 08:01:54","2023-07-05 08:01:54","","461-470","","","","","","","Lecture Notes in Computer Science","","","","Springer","Berlin, Heidelberg","en","","","","","Springer Link","","","","/Users/minsik/Zotero/storage/UXIQWD9P/Absar and Guastavino - 2011 - Nonspeech Sound Design for a Hierarchical Informat.pdf","","","Auditory Feedback; Depth Level; Panel Session; Sound Design; Task Description","Kurosu, Masaaki","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MEE7J2CR","bookSection","2007","Vilimek, Roman; Zimmer, Alf","Development and Evaluation of a Multimodal Touchpad for Advanced In-Vehicle Systems","Engineering Psychology and Cognitive Ergonomics","978-3-540-73330-0 978-3-540-73331-7","","","http://link.springer.com/10.1007/978-3-540-73331-7_92","Multimodal interaction can substantially improve human-computer interaction by employing multiple perceptual channels. We report on the development and evaluation of a touchpad with auditory, tactile and visual feedback for in-vehicle applications. In a simulator study, we assessed its suitability for interacting with a menu-based on-board system and investigated the effects of uni-, bi- and trimodal feedback on task and driving performance, workload and visual distraction in comparison to a conventional rotary push-button. In summary our results show that users clearly benefit from additional non-visual feedback while driving. When using the touchpad with multimodal feedback, our subjects also reached a higher level of performance compared to the rotary push-button.","2007","2023-07-05 08:02:36","2023-07-19 23:59:17","2023-07-05 08:02:36","842-851","","","4562","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","en","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-540-73331-7_92","","/Users/minsik/Zotero/storage/C2HUI4UK/Vilimek and Zimmer - 2007 - Development and Evaluation of a Multimodal Touchpa.pdf","","","","Harris, Don","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3K3CG2UU","bookSection","2007","Sánchez, Jaime; Galáz, Iván","AudioStoryTeller: Enforcing Blind Children Reading Skills","Universal Access in Human-Computer Interaction. Applications and Services","978-3-540-73282-2 978-3-540-73283-9","","","http://link.springer.com/10.1007/978-3-540-73283-9_85","Children tend to learn language conventions through processing environment stimuli. Thus, strategies for reading comprehension are commonly used for this purpose. This paper introduces AudioStoryTeller, a tool for pocketPC to support the development of reading and writing skills in learners with visual disabilities (LWVD) through storytelling, providing diverse evaluation tools to measure those skills. We implemented usability and cognitive evaluation to the AudioStoryTeller software. In the usability evaluation, the easiness of use of the proposed hardware by LWVD was established. The goal of the cognitive evaluation was to measure the development of reading skills through interactive audio narrations using a pocketPC device. Results indicate that users were able to utilize effortless the pocketPC device. AudioStoryTeller software together with cognitive tasks, can contribute to the development of cognitive skills in LWVD. This application allows LVD to have access to unlimited scope of books not available in printed Braille.","2007","2023-07-05 08:02:36","2023-07-21 05:09:40","2023-07-05 08:02:36","786-795","","","4556","","","AudioStoryTeller","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","en","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-540-73283-9_85","","/Users/minsik/Zotero/storage/WHHGJTVS/Sánchez and Galáz - 2007 - AudioStoryTeller Enforcing Blind Children Reading.pdf","","","","Stephanidis, Constantine","Hutchison, David; Kanade, Takeo; Kittler, Josef; Kleinberg, Jon M.; Mattern, Friedemann; Mitchell, John C.; Naor, Moni; Nierstrasz, Oscar; Pandu Rangan, C.; Steffen, Bernhard; Sudan, Madhu; Terzopoulos, Demetri; Tygar, Doug; Vardi, Moshe Y.; Weikum, Gerhard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QVCGMR8E","bookSection","2006","Fitzpatrick, D.","Mathematics: How and What to Speak","Computers Helping People with Special Needs","978-3-540-36020-9 978-3-540-36021-6","","","http://link.springer.com/10.1007/11788713_173","Access to mathematical content for blind and vision impaired people continues to be a problem. The inherently visual nature of this form of presentation is neither easily or readily accessible using the linear representations in common usage by this community. This paper proposes methodology for depicting mathematics in a non-visual manner. It will be shown how, through the prosodic component found in spoken language, the structure of mathematical formulae may be disambiguated. We will also discuss lexical cues which can be added to the utterance to further reduce the ambiguity which can be very evident in this form of material.","2006","2023-07-05 08:02:36","2023-07-19 23:51:47","2023-07-05 08:02:36","1199-1206","","","4061","","","Mathematics","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/11788713_173","","","","","","Miesenberger, Klaus; Klaus, Joachim; Zagler, Wolfgang L.; Karshmer, Arthur I.","Hutchison, David; Kanade, Takeo; Kittler, Josef; Kleinberg, Jon M.; Mattern, Friedemann; Mitchell, John C.; Naor, Moni; Nierstrasz, Oscar; Pandu Rangan, C.; Steffen, Bernhard; Sudan, Madhu; Terzopoulos, Demetri; Tygar, Dough; Vardi, Moshe Y.; Weikum, Gerhard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XWJH6XJ6","bookSection","2014","Kacorri, Hernisa; Riga, Paraskevi; Kouroupetroglou, Georgios","Performance Metrics and Their Extraction Methods for Audio Rendered Mathematics","Computers Helping People with Special Needs","978-3-319-08595-1 978-3-319-08596-8","","","http://link.springer.com/10.1007/978-3-319-08596-8_95","We introduce and compare three approaches to calculate structure- and content-based performance metrics for user-based evaluation of math audio rendering systems: Syntax Tree alignment, Baseline Structure Tree alignment, and MathML Tree Edit Distance. While the first two require “manual” tree transformation and alignment of the mathematical expressions, the third obtains the metrics without human intervention using the minimum edit distance algorithm on the corresponding MathML representations. Our metrics are demonstrated in a pilot user study evaluating the Greek audio rendering rules of MathPlayer with 7 participants and 39 stimuli. We observed that the obtained results for the metrics are significantly correlated between all three approaches.","2014","2023-07-05 08:02:36","2023-07-19 23:52:05","2023-07-05 08:02:36","614-621","","","8547","","","","","","","","Springer International Publishing","Cham","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-319-08596-8_95","","","","","","Miesenberger, Klaus; Fels, Deborah; Archambault, Dominique; Peňáz, Petr; Zagler, Wolfgang","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VBYILI8H","bookSection","2010","Tünnermann, René; Kolbe, Lukas; Bovermann, Till; Hermann, Thomas","Surface Interactions for Interactive Sonification","Auditory Display","978-3-642-12438-9 978-3-642-12439-6","","","http://link.springer.com/10.1007/978-3-642-12439-6_9","","2010","2023-07-05 08:02:36","2023-07-05 08:02:36","2023-07-05 08:02:36","166-183","","","5954","","","","","","","","Springer Berlin Heidelberg","Berlin, Heidelberg","","","","","","DOI.org (Crossref)","","Series Title: Lecture Notes in Computer Science DOI: 10.1007/978-3-642-12439-6_9","","/Users/minsik/Zotero/storage/3RFRYQ2M/Tünnermann et al. - 2010 - Surface Interactions for Interactive Sonification.pdf","","","","Ystad, Sølvi; Aramaki, Mitsuko; Kronland-Martinet, Richard; Jensen, Kristoffer","Hutchison, David; Kanade, Takeo; Kittler, Josef; Kleinberg, Jon M.; Mattern, Friedemann; Mitchell, John C.; Naor, Moni; Nierstrasz, Oscar; Pandu Rangan, C.; Steffen, Bernhard; Sudan, Madhu; Terzopoulos, Demetri; Tygar, Doug; Vardi, Moshe Y.; Weikum, Gerhard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HZQPQZFX","conferencePaper","1994","Karshmer, Arthur I.; Ogden, Bill; Brawner, Pres; Kaugars, Karlis; Reiswig, George","Adapting graphical user interfaces for use by visually handicapped computer users: Current results and continuing research","Computers for Handicapped Persons","978-3-540-48989-4","","10.1007/3-540-58476-5_100","","The use of modern computers and software by the visually handicapped has become more difficult over the past few years. In earlier systems the user interface was a simple character based environment. In those systems, simple devices like screen readers, braille output and speech synthesizers were effective. Current systems now run Graphical User Interfaces (GUIs) which have rendered these simple aids almost useless. In no area has this problem become more important than in technologies for the handicapped. What has become enabling technology for the sighted has become disabling technology for the visually impaired. In the current work we discuss new and innovative approaches to permit non-sighted users to interface with GUIs, having the salutary effect of gaining needed access to the most modern computing equipment for a subset of our population that is otherwise excluded from such access.","1994","2023-07-05 08:12:36","2023-07-05 08:12:36","","16-24","","","","","","Adapting graphical user interfaces for use by visually handicapped computer users","Lecture Notes in Computer Science","","","","Springer","Berlin, Heidelberg","en","","","","","Springer Link","","","","/Users/minsik/Zotero/storage/VBAICP6Y/Karshmer et al. - 1994 - Adapting graphical user interfaces for use by visu.pdf","","","Impaired User; Menu Structure; Mouse Click; Speech Synthesizer; Visually Handicap","Zagler, Wolfgang L.; Busby, Geoffrey; Wagner, Roland R.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5MN26HNJ","journalArticle","","","A Haptic Emotional Model for Audio System Interface","","","","","","","","2023-08-03 03:14:23","2023-08-03 03:14:39","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""