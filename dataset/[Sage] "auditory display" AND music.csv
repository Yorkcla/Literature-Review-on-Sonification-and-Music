"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"7H7IZRQM","journalArticle","2019","Winters, R. Michael; Joshi, Neel; Cutrell, Edward; Morris, Meredith Ringel","Strategies for Auditory Display of Social Media","Ergonomics in Design","","1064-8046","10.1177/1064804618788098","https://doi.org/10.1177/1064804618788098","Social media is an overwhelmingly visual medium, and we ask the simple question: How can the data and images of social media posts be transformed into something as meaningful and vivid in the auditory sense? Such a design would be useful for eyes-free browsing and could enhance the existing visual media. Our strategy first uses artificial intelligence systems to transform low-level input data into high-level sociocultural features. These features are then conveyed using a multifactored temporal design that uses speech, sonification, auditory scenes, and music.","2019-01-01","2023-07-06 06:27:20","2023-07-06 06:27:20","2023-07-06 06:27:05","11-15","","1","27","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/96GIY5C4/Winters et al. - 2019 - Strategies for Auditory Display of Social Media.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DXRHDGUF","journalArticle","2000","Blattner, Meera M","A Design for Auditory Display","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/154193120004400159","https://doi.org/10.1177/154193120004400159","Auditory messages in home, office, and medical environments consist of little more than beeps, bells, and buzzers. Warning signals are particularly inappropriate for these environments because they startle, annoy, but do not inform listeners as to the source of the difficulty. As home automation becomes prevalent, unpleasant sounds will not be tolerated. Earcons are musical sounds that are easy to learn; yet designed to inform listeners of the status of automated systems. We discuss problems such as simultaneous sounds and levels of urgency below.","2000-07-01","2023-07-06 06:27:20","2023-07-06 06:27:20","2023-07-06 06:27:07","219-222","","1","44","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/5GFBKBZ7/Blattner - 2000 - A Design for Auditory Display.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9QN3I2R2","journalArticle","2013","Ho, Anson; Burns, Catherine","Music as an Auditory Display: Interaction Effects of Mode and Tempo on Perceived Urgency","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/1541931213571256","https://doi.org/10.1177/1541931213571256","Currently, there are very few guidelines on parameters needed to create an effective auditory display. Auditory displays can be intrusive and may not be used effectively if they are poorly designed. However, music is often in our environments as ambient noise and, instead of being intrusive, can be perceived as making the environment calmer and more productive. We present the initial steps of exploring the option of using music as a medium to develop an auditory display capable of conveying normal state information and warning information. An important feature that may impact the effectiveness of auditory warnings is perceived urgency: the impression of urgency that a sound evokes on a listener. To explore whether music could convey urgency as needed for auditory warnings, we evaluated four different musical phrases that varied in time and key signature as a method of measuring the effects of mode and tempo on perceived urgency. The effectiveness of the study was tested with twenty subjects split into a two by two factorial design: gender (male vs. female) and musical experience (experienced vs. non-experienced). The applications of this research can help develop concrete guidelines when designing effective auditory displays in order to improve users’ performance when dealing with complex interfaces.","2013-09-01","2023-07-06 06:27:20","2023-07-06 06:27:20","2023-07-06 06:27:09","1149-1153","","1","57","","","Music as an Auditory Display","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/9UXA3A2S/Ho and Burns - 2013 - Music as an Auditory Display Interaction Effects .pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4VFRX9LF","journalArticle","2008","Thompson, Matthew B.; Sanderson, Penelope M.","Multisensory Integration with a Head-Mounted Display and Auditory Display","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/154193120805201829","https://doi.org/10.1177/154193120805201829","Human operators who use head-mounted displays (HMDs) in their work may benefit from auditory support. It is unclear whether auditory support is better delivered in free-field or via earpiece, and what the effect of walking is. To examine this problem, a novel multisensory integration task was created in which participants identified mismatches between sounds and visual information on an HMD. Participants listened to the sounds either via earpiece or free-field while they either sat or walked about the test room. When using an earpiece, participants performed the mismatch task equally well whether walking or sitting, but when using free-field sound, participants performed the task significantly worse when walking than when sitting. The worse performance for participants using free-field sound while walking may relate to spatial and motion inconsistencies between the sound and vision or because of misperceptions of the time at which the sounds occurred. The results underscore the need for representative design of experiments exploring multisensory integration and they suggest auditory conditions that might influence effective multisensory integration with HMDs.","2008-09-01","2023-07-06 06:27:20","2023-07-06 06:27:20","2023-07-06 06:27:10","1292-1296","","18","52","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/8LEGGP3N/Thompson and Sanderson - 2008 - Multisensory Integration with a Head-Mounted Displ.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IUTWGDH7","journalArticle","2019","Li, Simon Y. W.; Tse, Man-Kei; Brecknell, Birgit; Sanderson, Penelope M.","Spearcon Sequences for Monitoring Multiple Patients: Laboratory Investigation Comparing Two Auditory Display Designs","Human Factors","","0018-7208","10.1177/0018720818797502","https://doi.org/10.1177/0018720818797502","Objective:The aim was to compare the effectiveness of two auditory displays, implemented with spearcons (time-compressed speech), for monitoring multiple patients.Background:Sequences of sounds can convey information about patients’ vital signs, such as oxygen saturation (SpO2) and heart rate (HR). We tested whether participants could monitor five patients using spearcon-based sound sequences.Method:A 2 × 3 within-subjects design was used. The first factor was interface, with two levels: the ALL interface used spearcons to convey vital signs for all five patients, whereas the ABN (abnormal) interface represented patients who had normal vital signs with a low-pitched single-tone sound and patients who had at least one abnormal vital sign with spearcons. The second factor was the number of patients who had at least one abnormal vital sign: there were one, two, or three such patients in each monitoring sequence. Participants were 40 nonclinicians.Results:Participants identified abnormal patients’ SpO2 and HR levels and located abnormal patients in the sound sequence more accurately with the ABN interface than the ALL interface. Accuracy declined as the number of abnormal patients increased. Participants associated ABN with easier identification of vital signs, resulting in higher ratings of confidence and pleasantness compared with ALL.Conclusion:Sequences of spearcons may support effective eyes-free monitoring of multiple patients.Application:Sequences of spearcons may be useful in monitoring multiple patients and the underlying design principles may extend to monitoring in other domains such as industrial process control or control of multiple autonomous vehicles.","2019-03-01","2023-07-06 06:27:20","2023-07-06 06:27:20","2023-07-06 06:27:12","288-304","","2","61","","Hum Factors","Spearcon Sequences for Monitoring Multiple Patients","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/2798FPR2/Li et al. - 2019 - Spearcon Sequences for Monitoring Multiple Patient.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"85PAGLHW","journalArticle","2013","Janata, Petr; Edwards, William H.","A Novel Sonification Strategy for Auditory Display of Heart Rate and Oxygen Saturation Changes in Clinical Settings","Human Factors","","0018-7208","10.1177/0018720812455433","https://doi.org/10.1177/0018720812455433","Objective:The aim of this study was development of a sonification scheme to convey deviations in heart rate and oxygen saturation from a desired target level.Background:Maintaining physiologic parameters, such as oxygen saturation, within desired ranges, is challenging in many clinical situations. High rates of false positive alarms in clinical settings limit the utility of the alarms that trigger when thresholds are exceeded. Auditory displays that consider the semantic connotations of sounds and the processing limitations of human perception and cognition may improve monitoring.Method:Across two experiments, clinical practi-tioners were tested on their ability to (a) discriminate pairs of sounds (two-note discrimination task), (b) infer and discern the intended physiological connotation of each acoustic attribute (name-the-variable task), and (c) categorize the amount of change in an implied physiological variable into three levels of change: none, small, and large (change-magnitude task).Results:Considerable variation in performance was observed across the set of practitioners, ranging from near-perfect performance on all tasks, even with no prior exposure to the stimuli, to failure to reach a target accuracy criterion of 87.5% after ~80 min of training. On average, performance was well above chance on the name-the-variable and change-magnitude tasks during initial exposure and reached criterion within ~20 min of training on each task.Conclusion:The described sonification strategy may effectively communicate information about current heart rate and oxygen saturation status relative to desired target levels.Application:The results can be applied to clinical monitoring settings in which a stream of discrete auditory informational items is indicated.","2013-04-01","2023-07-06 06:27:20","2023-07-06 06:27:20","2023-07-06 06:27:13","356-372","","2","55","","Hum Factors","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/AW9UC98H/Janata and Edwards - 2013 - A Novel Sonification Strategy for Auditory Display.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LNQWP2RY","journalArticle","2019","Zestic, Jelena; Brecknell, Birgit; Liley, Helen; Sanderson, Penelope","A Novel Auditory Display for Neonatal Resuscitation: Laboratory Studies Simulating Pulse Oximetry in the First 10 Minutes After Birth","Human Factors","","0018-7208","10.1177/0018720818793769","https://doi.org/10.1177/0018720818793769","Objective:We tested whether enhanced sonifications would improve participants’ ability to judge the oxygen saturation levels (SpO2) of simulated neonates in the first 10 min after birth.Background:During the resuscitation of a newborn infant, clinicians must keep the neonate’s SpO2 levels within the target range, however the boundaries for the target range change each minute during the first 10 min after birth. Resuscitation places significant demand on the clinician’s visual attention, and the pulse oximeter’s sonification could provide eyes-free monitoring. However, clinicians have difficulty judging SpO2 levels using the current sonification.Method:In two experiments, nonclinicians’ ability to detect SpO2 range and direction—while performing continuous arithmetic problems—was tested with enhanced versus conventional sonifications. In Experiment 1, tremolo signaled when SpO2 had deviated below or above the target range. In Experiment 2, tremolo plus brightness signaled when SpO2 was above target range, and tremolo alone when SpO2 was below target range.Results:The tremolo sonification improved range identification accuracy over the conventional display (81% vs. 63%, p < .001). The tremolo plus brightness sonification further improved range identification accuracy over the conventional display (92% vs. 62%, p <.001). In both experiments, there was no difference across conditions in arithmetic task accuracy (p >.05).Conclusion:Using the enhanced sonifications, participants identified SpO2 range more accurately despite a continuous distractor task.Application:An enhanced pulse oximetry sonification could help clinicians multitask more effectively during neonatal resuscitations.","2019-02-01","2023-07-06 06:27:20","2023-07-06 06:27:20","2023-07-06 06:27:15","119-138","","1","61","","Hum Factors","A Novel Auditory Display for Neonatal Resuscitation","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/SWE8QG23/Zestic et al. - 2019 - A Novel Auditory Display for Neonatal Resuscitatio.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RL24WK5H","journalArticle","2014","Towers, John; Burgess-Limerick, Robin; Riek, Stephan","Concurrent 3-D Sonifications Enable the Head-Up Monitoring of Two Interrelated Aircraft Navigation Instruments","Human Factors","","0018-7208","10.1177/0018720814536443","https://doi.org/10.1177/0018720814536443","Objective:The aim of this study was to enable the head-up monitoring of two interrelated aircraft navigation instruments by developing a 3-D auditory display that encodes this navigation information within two spatially discrete sonifications.Background:Head-up monitoring of aircraft navigation information utilizing 3-D audio displays, particularly involving concurrently presented sonifications, requires additional research.Method:A flight simulator’s head-down waypoint bearing and course deviation instrument readouts were conveyed to participants via a 3-D auditory display. Both readouts were separately represented by a colocated pair of continuous sounds, one fixed and the other varying in pitch, which together encoded the instrument value’s deviation from the norm. Each sound pair’s position in the listening space indicated the left/right parameter of its instrument’s readout. Participants’ accuracy in navigating a predetermined flight plan was evaluated while performing a head-up task involving the detection of visual flares in the out-of-cockpit scene.Results:The auditory display significantly improved aircraft heading and course deviation accuracy, head-up time, and flare detections. Head tracking did not improve performance by providing participants with the ability to orient potentially conflicting sounds, suggesting that the use of integrated localizing cues was successful.Conclusion:A supplementary 3-D auditory display enabled effective head-up monitoring of interrelated navigation information normally attended to through a head-down display.Application:Pilots operating aircraft, such as helicopters and unmanned aerial vehicles, may benefit from a supplementary auditory display because they navigate in two dimensions while performing head-up, out-of-aircraft, visual tasks.","2014-12-01","2023-07-06 06:27:20","2023-07-06 06:27:20","2023-07-06 06:27:17","1414-1427","","8","56","","Hum Factors","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/3AIR3JGE/Towers et al. - 2014 - Concurrent 3-D Sonifications Enable the Head-Up Mo.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YNHP5SCG","journalArticle","2007","Watson, Marcus O.; Sanderson, Penelope M.","Designing for Attention With Sound: Challenges and Extensions to Ecological Interface Design","Human Factors","","0018-7208","10.1518/001872007X312531","https://doi.org/10.1518/001872007X312531","Objective: We explore whether ecological interface design (EID) principles can be applied to the design of an auditory display for anesthesia monitoring. Background: EID examples focus almost exclusively on visual displays. In the anesthesia work environment, however, auditory displays may provide better individual and team awareness of patient state. Method: Using a work domain analysis of physiological monitoring in anesthesia, we identify information to display. Using the skills, rules, and knowledge distinction we identify cognitive control needed. Using semantic mapping we map physiological variables and constraints to auditory dimensions. Results: EID principles do not address when information should be displayed and to whom. An attentional mapping stage helps to specify answers to these questions so that a workable auditory display for anesthesia monitoring is achieved. Conclusion: EID principles of representing work domain functional structure and minimizing resource-demanding cognitive control are necessary but insufficient to specify requirements for an effective auditory display. Also needed are analyses of control tasks, strategies, and the social organization of work. Such analyses are an integral part of the broader cognitive work analysis framework from which EID emerged.  Application: Actual or potential uses of this research include the design of displays that support continuous peripheral awareness in collaborative multimodal work environments.","2007-04-01","2023-07-06 06:27:20","2023-07-06 06:27:20","2023-07-06 06:27:18","331-346","","2","49","","Hum Factors","Designing for Attention With Sound","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/425RAVEX/Watson and Sanderson - 2007 - Designing for Attention With Sound Challenges and.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IPWS6A6F","journalArticle","1993","Begault, Durand R.","Head-Up Auditory Displays for Traffic Collision Avoidance System Advisories: A Preliminary Investigation","Human Factors","","0018-7208","10.1177/001872089303500409","https://doi.org/10.1177/001872089303500409","The advantage of a head-up auditory display was evaluated in a preliminary experiment designed to measure and compare the acquisition time for capturing visual targets under two auditory conditions: standard one-earpiece presentation and two-earpiece three-dimensional (3D) audio presentation. Twelve commercial airline crews were tested under full mission simulation conditions at the NASA Ames Man-Vehicle Systems Research Facility advanced concepts flight simulator. Scenario software generated visual targets corresponding to aircraft that would activate a traffic collision avoidance system (TCAS) aural advisory; the spatial auditory position was linked to the visual position with 3D audio presentation. Results showed that crew members using a 3D auditory display acquired targets approximately 2.2 s faster than did crew members who used one-earpiece headsets, but there was no significant difference in the number of targets acquired.","1993-12-01","2023-07-06 06:27:20","2023-07-06 06:27:20","2023-07-06 06:27:20","707-717","","4","35","","Hum Factors","Head-Up Auditory Displays for Traffic Collision Avoidance System Advisories","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V6DDX3KR","journalArticle","2019","Jeon, Myounghoon","Exploring Design Constructs In Sound Design With A Focus On Perceived Affordance","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/1071181319631340","https://doi.org/10.1177/1071181319631340","While design theories in visual displays have been well developed and further refined, relatively little research has been conducted on design theories and models in auditory displays. The existing discussions mainly account for functional mappings between sounds and referents, but these do not fully address design aspects of auditory displays. To bridge the gap, the present proposal focuses on design affordances in sound design among many design constructs. To this end, the definition and components of design affordances are briefly explored, followed by the auditory display examples of those components to gauge whether sound can deliver perceived affordances in interactive products. Finally, other design constructs, such as feedback and signifier, are discussed together with future work. This exploratory proposal is expected to contribute to elaborating sound design theory and practice.","2019-11-01","2023-07-06 06:27:49","2023-07-06 06:27:49","2023-07-06 06:27:33","1199-1203","","1","63","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/BYXW26HW/Jeon - 2019 - Exploring Design Constructs In Sound Design With A.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C32KF4UX","journalArticle","2018","Nees, Michael A.","Auditory Graphs Are Not the “Killer App” of Sonification, But They Work","Ergonomics in Design","","1064-8046","10.1177/1064804618773563","https://doi.org/10.1177/1064804618773563","The search for the elusive “killer app” of sonification has been a recurring theme in sonification research. In this comment, I argue that the killer-app criterion of success stems from interdisciplinary tensions about how to evaluate sonifications. Using auditory graphs as an example, I argue that the auditory display community has produced successful examples of sonic information design that accomplish the human factors goal of improving human interactions with systems. Still, barriers to using sonifications in interfaces remain, and reducing those barriers could result in more widespread use of audio in systems.","2018-10-01","2023-07-06 06:27:49","2023-07-06 06:27:49","2023-07-06 06:27:34","25-28","","4","26","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/A2ZJ8KD2/Nees - 2018 - Auditory Graphs Are Not the “Killer App” of Sonifi.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"52WK9TJW","journalArticle","2022","Yang, Jiajun; Hunt, Andy","Assisting Dumbbell Curls via Interactive Sonification of Arm Movement and Muscular Signals","Ergonomics in Design","","1064-8046","10.1177/1064804619829664","https://doi.org/10.1177/1064804619829664","We developed an interactive sonification system that lets users listen to their own hand/arm movement and bicep muscle signals as sonic feedback during biceps curls exercise. The system aims to improve the exercise quality and user motivation. Based on two studies, we found that the sonification was more effective in providing temporal cues to slow down the repetition but not as effective as hoped in extending the vertical movement range and increasing repetition amount. The studies provide some design guidelines for multivariate sonification and also reflect a wider potential for applications that include general fitness, physiotherapy, and sports training.","2022-07-01","2023-07-06 06:27:49","2023-07-06 06:27:49","2023-07-06 06:27:36","11-15","","3","30","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/HJFKUDHK/Yang and Hunt - 2022 - Assisting Dumbbell Curls via Interactive Sonificat.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UH5TBWE6","journalArticle","2019","Cave, James; Eyes, Ben","Combining Composition and Sonic Information Design in a New Electroacoustic Work","Ergonomics in Design","","1064-8046","10.1177/1064804618792647","https://doi.org/10.1177/1064804618792647","It might be suggested that composition and sonic information design are fundamentally different. However, some academic commentators and composers have explored the intersection between these disciplines. The authors presented one such work, Eonsounds: Fiamignano Gorge, at International Community of Auditory Display 2017. We argue that analysis of the aesthetic and informational choices in such hybrid works is essential to the development of sonic information design, with implications for the emergence of sonic information design as a subtype of human factors design. By acknowledging the relationship between aesthetics and information presentation, sound designers may develop designs that are safer and more user-friendly.","2019-01-01","2023-07-06 06:27:49","2023-07-06 06:27:49","2023-07-06 06:27:38","20-22","","1","27","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/DY4PZBNS/Cave and Eyes - 2019 - Combining Composition and Sonic Information Design.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4EHYDYAH","journalArticle","2015","Werner, Steffen; Hauck, Christopher; Roome, Nicholas; Hoover, Connor; Choates, Daniel","Can VoiceScapes Assist in Menu Navigation?","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/1541931215591157","https://doi.org/10.1177/1541931215591157","Providing better information access to blind users is an important goal in the context of accessible interface design. Similarly, designers of user interfaces benefit from alternative interface techniques for usage scenarios in which visual (graphical) interfaces are either not possible or suboptimal. In our study we compared a traditional serial aural presentation of menu items to a new simultaneous aural presentation of up to seven menu items. These continuously present VoiceScapes allow the user to actively scan the auditory display to find the most appropriate command. While VoiceScapes are more difficult and attentionally more demanding than other formats of presentation, extended use might allow experienced users to more efficiently navigate complex menu hierarchies. A first pilot experiment with 13 sighted participants presented here tested the basic viability of this approach.","2015-09-01","2023-07-06 06:27:49","2023-07-06 06:27:49","2023-07-06 06:27:39","1095-1099","","1","59","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/CZUVZILJ/Werner et al. - 2015 - Can VoiceScapes Assist in Menu Navigation.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EB2XPXK7","journalArticle","2008","Nees, Michael A.; Walker, Bruce N.","Encoding of Information in Auditory Displays: Initial Research on Flexibility and Processing Codes in Dual-task Scenarios","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/154193120805202208","https://doi.org/10.1177/154193120805202208","Interest in the use of sound as a means of information display in human-machine systems has surged in recent years. While researchers have begun to address issues surrounding good auditory display design as well as potential domains of application, little is known about the cognitive processes involved in interpreting auditory displays. In multi-tasking scenarios, dividing concurrent information display across modalities (e.g., vision and audition) may allow the human operator to receive (i.e., to sense and perceive) more information, yet higher-level conflicts in the encoding and representation of information may persist. Surprisingly few studies to date have examined auditory information display in dual-task scenarios. This study examined the flexibility of encoding of information and processing code conflicts in a dual-task paradigm with auditory graphs—a specific class of auditory displays that represent quantitative information with sound. Results showed that 1) patterns of dual-task interference were task dependent, and 2) a verbal interference task was relatively more disruptive to auditory graph performance than a visuospatial interference task, particularly for point estimation.","2008-09-01","2023-07-06 06:27:49","2023-07-06 06:27:49","2023-07-06 06:27:41","1820-1824","","22","52","","","Encoding of Information in Auditory Displays","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/8ABIRKYB/Nees and Walker - 2008 - Encoding of Information in Auditory Displays Init.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PV9W73G6","journalArticle","2017","Hickling, Anna; Brecknell, Birgit; Loeb, Robert G.; Sanderson, Penelope","Using a Sequence of Earcons to Monitor Multiple Simulated Patients","Human Factors","","0018-7208","10.1177/0018720816670986","https://doi.org/10.1177/0018720816670986","Objective:The aim of this study was to determine whether a sequence of earcons can effectively convey the status of multiple processes, such as the status of multiple patients in a clinical setting.Background:Clinicians often monitor multiple patients. An auditory display that intermittently conveys the status of multiple patients may help.Method:Nonclinician participants listened to sequences of 500-ms earcons that each represented the heart rate (HR) and oxygen saturation (SpO2) levels of a different simulated patient. In each sequence, one, two, or three patients had an abnormal level of HR and/or SpO2. In Experiment 1, participants reported which of nine patients in a sequence were abnormal. In Experiment 2, participants identified the vital signs of one, two, or three abnormal patients in sequences of one, five, or nine patients, where the interstimulus interval (ISI) between earcons was 150 ms. Experiment 3 used the five-sequence condition of Experiment 2, but the ISI was either 150 ms or 800 ms.Results:Participants reported which patient(s) were abnormal with median 95% accuracy. Identification accuracy for vital signs decreased as the number of abnormal patients increased from one to three, p < .001, but accuracy was unaffected by number of patients in a sequence. Overall, identification accuracy was significantly higher with an ISI of 800 ms (89%) compared with an ISI of 150 ms (83%), p < .001.Conclusion:A multiple-patient display can be created by cycling through earcons that represent individual patients.Application:The principles underlying the multiple-patient display can be extended to other vital signs, designs, and domains.","2017-03-01","2023-07-06 06:27:49","2023-07-06 06:27:49","2023-07-06 06:27:43","268-288","","2","59","","Hum Factors","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/6YSFBQQK/Hickling et al. - 2017 - Using a Sequence of Earcons to Monitor Multiple Si.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TKHKC2N7","journalArticle","1993","Gerth, Jeffrey M.","Identification of Sounds with Multiple Timbres","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/154193129303700905","https://doi.org/10.1177/154193129303700905","The present research examined identification of complex sounds created by simultaneously playing two or more component sounds in various combinations. Sixteen component sounds were used, created by imposing four distinct temporal patterns on four basic timbres, two musical timbres and two complex real-world timbres. In the present experiment, complex sounds were created by simultaneously playing one to four component sounds, each with a different timbre. Subjects heard a complex sound, followed by a second complex sound that always differed from the first by adding a component, deleting a component or substituting a component. Subjects indicated which component had been added, deleted, or substituted. Sound changes were identified with moderate accuracy (above 60 percent). The errors committed varied with temporal pattern, timbre, sound change and density. The analyses of identification confusions indicated that subjects identified the correct timbre of the sound change even when temporal patterning was confused. The finding that temporal patterns were confused largely within the sound category of the correct response limits the previous interpretation of other research, which found that similar temporal patterns are confusable even with differences in spectra. Results of the present investigation suggest that multiple, temporal patterns with varying timbres can be presented from a single physical location to convey a change in state or status of an informative sound source. Design contributions of the present research to auditory information systems such as virtual reality are discussed. For such an application, a combination of physical separation and multiple patterns with varying timbres could provide a coherent, yet informationally complex, auditory display.","1993-10-01","2023-07-06 06:27:49","2023-07-06 06:27:49","2023-07-06 06:27:46","539-543","","9","37","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LMZZP2PK","journalArticle","2008","Simpson, Brian D.; Brungart, Douglas S.; Dallman, Ronald C.; Yasky, Richard J.; Romigh, Griffin D.","Flying by Ear: Blind Flight with a Music-Based Artificial Horizon","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/154193120805200103","https://doi.org/10.1177/154193120805200103","Two experiments were conducted in actual flight operations to evaluate an audio artificial horizon display that imposed aircraft attitude information on pilot-selected music. The first experiment examined a pilot's ability to identify, with vision obscured, a change in aircraft roll or pitch, with and without the audio artificial horizon display. The results suggest that the audio horizon display improves the accuracy of attitude identification overall, but differentially affects response time across conditions. In the second experiment, subject pilots performed recoveries from displaced aircraft attitudes using either standard visual instruments, or, with vision obscured, the audio artificial horizon display. The results suggest that subjects were able to maneuver the aircraft to within its safety envelope. Overall, pilots were able to benefit from the display, suggesting that such a display could help to improve overall safety in general aviation.","2008-09-01","2023-07-06 06:27:49","2023-07-06 06:27:49","2023-07-06 06:27:48","6-10","","1","52","","","Flying by Ear","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/NPCS5D3W/Simpson et al. - 2008 - Flying by Ear Blind Flight with a Music-Based Art.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KICZQUFV","journalArticle","2019","Winters, R. Michael; Tomlinson, Brianna J.; Walker, Bruce N.; Moore, Emily B.","Sonic Interaction Design for Science Education","Ergonomics in Design","","1064-8046","10.1177/1064804618797399","https://doi.org/10.1177/1064804618797399","The PhET project is a collection of over 130 interactive simulations (or “sims”) designed to teach physics concepts to students from elementary to university levels. The sims rely heavily on visual representation, making them inaccessible to students with disabilities, including those with visual impairments. We present the theory, methods, and process behind our audio design and provide example mapping strategies from two of the simulations. We compare physical, abstract, and musical mapping strategies, noting the strengths of each. We conclude with design recommendations that have arisen in our work, and for which we think would benefit the field at large.","2019-01-01","2023-07-06 06:27:49","2023-07-06 06:27:49","2023-07-06 06:27:49","5-10","","1","27","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/GN6MKU6V/Winters et al. - 2019 - Sonic Interaction Design for Science Education.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6C2JF8SJ","journalArticle","2013","Walker, Bruce N.; Lindsay, Jeffrey; Nance, Amanda; Nakano, Yoko; Palladino, Dianne K.; Dingler, Tilman; Jeon, Myounghoon","Spearcons (Speech-Based Earcons) Improve Navigation Performance in Advanced Auditory Menus","Human Factors","","0018-7208","10.1177/0018720812450587","https://doi.org/10.1177/0018720812450587","Objective:The goal of this project is to evaluate a new auditory cue, which the authors call spearcons, in comparison to other auditory cues with the aim of improving auditory menu navigation.Background:With the shrinking displays of mobile devices and increasing technology use by visually impaired users, it becomes important to improve usability of non-graphical user interface (GUI) interfaces such as auditory menus. Using nonspeech sounds called auditory icons (i.e., representative real sounds of objects or events) or earcons (i.e., brief musical melody patterns) has been proposed to enhance menu navigation. To compensate for the weaknesses of traditional nonspeech auditory cues, the authors developed spearcons by speeding up a spoken phrase, even to the point where it is no longer recognized as speech.Method:The authors conducted five empirical experiments. In Experiments 1 and 2, they measured menu navigation efficiency and accuracy among cues. In Experiments 3 and 4, they evaluated learning rate of cues and speech itself. In Experiment 5, they assessed spearcon enhancements compared to plain TTS (text to speech: speak out written menu items) in a two-dimensional auditory menu.Results:Spearcons outperformed traditional and newer hybrid auditory cues in navigation efficiency, accuracy, and learning rate. Moreover, spearcons showed comparable learnability as normal speech and led to better performance than speech-only auditory cues in two-dimensional menu navigation.Conclusion: These results show that spearcons can be more effective than previous auditory cues in menu-based interfaces.Application:Spearcons have broadened the taxonomy of nonspeech auditory cues. Users can benefit from the application of spearcons in real devices.","2013-02-01","2023-07-06 06:28:16","2023-07-06 06:28:16","2023-07-06 06:28:01","157-182","","1","55","","Hum Factors","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/NXC5GQ34/Walker et al. - 2013 - Spearcons (Speech-Based Earcons) Improve Navigatio.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MJFS3Q3U","journalArticle","2016","Jeon, Myounghoon","How Is Nonverbal Auditory Information Processed? Revisiting Existing Models and Proposing a Preliminary Model","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/1541931213601351","https://doi.org/10.1177/1541931213601351","Use of multimodal displays is getting more prevalent in Human Factors and Human-Computer Interaction. Existing information processing models and theories predict the benefits of multimodality in user interfaces. While the models have been refined regarding vision, more granularity is still required regarding audition. The existing models mainly account for verbal processing in terms of representation, encoding, and retrieving, but these models do not provide sufficient explanations for nonverbal processing. In the present paper, I point out research gaps in nonverbal information processing of the representative models at the working memory and attention level. Then, I propose a preliminary conceptual model supported by neural and behavioral level evidence, and provide evaluations of the model and future works.","2016-09-01","2023-07-06 06:28:16","2023-07-06 06:28:16","2023-07-06 06:28:04","1529-1533","","1","60","","","How Is Nonverbal Auditory Information Processed?","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/8WESSR6C/Jeon - 2016 - How Is Nonverbal Auditory Information Processed R.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KDY63RCN","journalArticle","2012","Duarte, Emília; Rebelo, Francisco; Teles, Júlia; Wogalter, Michael S.","A Personalized Speech Warning Facilitates Compliance in an Immersive Virtual Environment","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/1071181312561427","https://doi.org/10.1177/1071181312561427","The effect of a personalized technology-based warning on compliance was assessed using an immersive virtual environment (IVE). Sixty university students performed an end-of-day routine security check in the IVE. Participants were asked to search for and activate safety-related devices, which involved entering several rooms. Just prior to abandoning the first room, participants were incidentally exposed to a posted warning (mandatory to disconnect the music generator) consisting of either a personal warning (i.e., a speech message with the participant’s first name) or an impersonal warning (i.e., a auditory beep signal). Compliance was determined by observing whether or not the participants pressed the button-switch as directed by the warning. Results reveal that compliance rate was significantly greater when the warning was personalized. No significant gender differences were found. Implications of these results are discussed in terms of the benefits of effective warnings.","2012-09-01","2023-07-06 06:28:16","2023-07-06 06:28:16","2023-07-06 06:28:06","2045-2049","","1","56","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/5BZNCZ33/Duarte et al. - 2012 - A Personalized Speech Warning Facilitates Complian.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DENTKRHQ","journalArticle","2022","Clarke, Hugh; Leav, Samnang; Zestic, Jelena; Mohamed, Ismail; Salisbury, Isaac; Sanderson, Penelope","Enhanced Neonatal Pulse Oximetry Sounds for the First Minutes of Life: A Laboratory Trial","Human Factors","","0018-7208","10.1177/00187208221118472","https://doi.org/10.1177/00187208221118472","ObjectiveAuditory enhancements to the pulse oximetry tone may help clinicians detect deviations from target ranges for oxygen saturation (SpO2) and heart rate (HR).BackgroundClinical guidelines recommend target ranges for SpO2 and HR during neonatal resuscitation in the first 10 minutes after birth. The pulse oximeter currently maps HR to tone rate, and SpO2 to tone pitch. However, deviations from target ranges for SpO2 and HR are not easy to detect.MethodForty-one participants were presented with 30-second simulated scenarios of an infant’s SpO2 and HR levels in the first minutes after birth. Tremolo marked distinct HR ranges and formants marked distinct SpO2 ranges. Participants were randomly allocated to conditions: (a) No Enhancement control, (b) Enhanced HR Only, (c) Enhanced SpO2 Only, and (d) Enhanced Both.ResultsParticipants in the Enhanced HR Only and Enhanced SpO2 Only conditions identified HR and SpO2 ranges, respectively, more accurately than participants in the No Enhancement condition, ps < 0.001. In the Enhanced Both condition, the tremolo enhancement of HR did not affect participants’ ability to identify SpO2 range, but the formants enhancement of SpO2 may have attenuated participants’ ability to identify tremolo-enhanced HR range.ConclusionTremolo and formant enhancements improve range identification for HR and SpO2, respectively, and could improve clinicians’ ability to identify SpO2 and HR ranges in the first minutes after birth.ApplicationEnhancements to the pulse oximeter tone to indicate clinically important ranges could improve the management of oxygen delivery to the neonate during resuscitation in the first 10 minutes after birth.","2022-08-21","2023-07-06 06:28:16","2023-07-06 06:28:16","2023-07-06 06:28:09","00187208221118472","","","","","Hum Factors","Enhanced Neonatal Pulse Oximetry Sounds for the First Minutes of Life","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/PFI39TME/Clarke et al. - 2022 - Enhanced Neonatal Pulse Oximetry Sounds for the Fi.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L8RICBAG","journalArticle","2022","Dam, Abhraneil; Siddiqui, Arsh; Leclerq, Charles; Jeon, Myounghoon","Extracting a Definition and Taxonomy for Audio Augmented Reality (AAR) Using Grounded Theory","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/1071181322661434","https://doi.org/10.1177/1071181322661434","The concept of Augmented Reality (AR) has evolved over the years since its inception in 1957. However, as of today, AR is mostly realized using a visual medium. Almost all applications of AR rely on the user’s ability to see. A few recent works have attempted to explore a new modality for AR–e.g., audio. However, the concept of using audio to augment reality has been considered debatable and there is no specific definition of the concept. To better understand this new concept, we launched a study using Grounded Theory to develop a definition and taxonomy for the concept of Audio Augmented Reality (AAR). This paper shares the preliminary results based on the activities conducted thus far, and hopes to generate discussion on using audio to augment reality within the Human Factors community.","2022-09-01","2023-07-06 06:28:16","2023-07-06 06:28:16","2023-07-06 06:28:11","1220-1224","","1","66","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/DBENITL3/Dam et al. - 2022 - Extracting a Definition and Taxonomy for Audio Aug.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LZWVQ8Y5","journalArticle","2002","D'Orazio, Jason; Walker, Bruce N.","Designing Better Traveler Information Systems: Cognitive and Task-Related Factors","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/154193120204602217","https://doi.org/10.1177/154193120204602217","Advanced Traveler Information Systems (ATIS) attempt to enhance the navigational performance of drivers. Such assistance is greatly wanted and needed by drivers. In order to create systems that help, and not hinder, individuals, designers of ATIS should consider many aspects of human factors. One important issue of ATIS is the appropriate use and design of displays, particularly auditory displays. The use of landmarks in auditory displays may also augment navigation performance, safety, and cognitive maps. Moreover, an ATIS should be designed so that the user can perform tasks of navigation planning more naturally. Finally, the goals of an ATIS should be aligned as closely as possible to the goals of the user, in order to increase user acceptance. Consideration of the above issues will result in enhanced performance, safety, and usability of ATIS. Pilot questionnaire data has been collected that supports some of the ideas suggested in the paper.","2002-09-01","2023-07-06 06:28:16","2023-07-06 06:28:16","2023-07-06 06:28:13","1858-1862","","22","46","","","Designing Better Traveler Information Systems","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/2ZEKL6Y6/D'Orazio and Walker - 2002 - Designing Better Traveler Information Systems Cog.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CQTL3W5L","journalArticle","2013","Yang, Shiyan; You, No Young; Ferris, Thomas K.","Supporting drivers in concurrent lane and speed tracking tasks with novel visual, auditory, and tactile speedometer displays","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/1541931213571429","https://doi.org/10.1177/1541931213571429","Driving can be described as performing multiple concurrent tracking tasks. These tasks primarily involve processing visual feedback, and the competition for visual resources may limit overall performance. Providing feedback via different sensory channels may improve multi-tracking performance; however, not much is known about basic human abilities to perform multiple controlled tracking tasks, nor about the use of nonvisual feedback in those tasks. This study measured the performance of participants in lane and speed tracking tasks when speed information was encoded into ambient visual, auditory, and tactile displays. The findings show that all three of these novel displays significantly improved speed tracking over a baseline condition without significantly impacting lane tracking performance. Dual-tracking performance was best supported with ambient visual and auditory displays, and participants preferred the auditory and tactile displays. The findings provide insight into multi-tracking abilities when feedback is distributed among sensory channels, and can inform design of in-vehicle displays.","2013-09-01","2023-07-06 06:28:16","2023-07-06 06:28:16","2023-07-06 06:28:14","1918-1922","","1","57","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/Q2NUMJDT/Yang et al. - 2013 - Supporting drivers in concurrent lane and speed tr.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U7I4PNP4","journalArticle","2016","Paterson, Estrella; Sanderson, Penelope; Paterson, Neil; Liu, David; Loeb, Robert","The effect of a secondary task on identification accuracy of oxygen saturation ranges using an enhanced pulse oximetry sonification: A laboratory study","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/1541931213601143","https://doi.org/10.1177/1541931213601143","In the operating theatre, anesthesiologists monitor an anesthetized patient’s oxygen saturation (SpO2) with a visual display but also with an auditory tone, or sonification. However, if the anesthesiologist must divide their attention across tasks, they may be less effective at recognising their patient’s SpO2 level. Previous research indicates that a sonification enhanced with additional sound dimensions of tremolo and brightness more effectively supports participants’ identification of SpO2 ranges than a conventional sonification does. This laboratory study explored the effect of a secondary task on participants’ ability to identify SpO2 range when using a conventional sonification (LogLinear sonification) versus an enhanced sonification (Stepped Effects sonification). Nineteen non-clinician participants who used the Stepped Effects sonification were significantly more effective at identifying SpO2 range (Md = 100%) than were 18 participants using the LogLinear sonification (Md = 80%). Range identification performance of participants using the Stepped Effects sonification tended to be less disrupted by a concurrent arithmetic task (drop from Md = 100% to 95%) than it was for participants using the LogLinear sonification (drop from Md = 80% to 73%). However, the disruption effect in each case was small, and the difference in disruption across sonifications was not statistically significant. Future research will test the sonifications under more intense cognitive load and in the presence of ambient noise.","2016-09-01","2023-07-06 06:28:16","2023-07-06 06:28:16","2023-07-06 06:28:16","628-632","","1","60","","","The effect of a secondary task on identification accuracy of oxygen saturation ranges using an enhanced pulse oximetry sonification","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/2W7U9YV3/Paterson et al. - 2016 - The effect of a secondary task on identification a.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D8BX23BM","journalArticle","2015","Yang, Shiyan; Nevins, Lashawn; Ferris, Thomas K.","Investigating Redundant Multimodal Speedometer Displays for Supporting Concurrent Lane and Speed Tracking","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/1541931215591341","https://doi.org/10.1177/1541931215591341","Driving heavily requires visual processing resources. This study seeks to investigate the effectiveness of novel speedometer displays that offload the visual channel by encoding speed data in auditory and tactile presentations. Building on previous work, this study specifically examined dimensional effects in these displays to see whether simple or redundantly-encoded displays were better for supporting multitask performance. Four displays relayed information about current vehicle speed relative to a target speed and performance effects in concurrent lane-tracking and speed-tracking tasks were compared. The experimental results showed that the spatial location dimension in both modalities significantly improved the speed-tracking performance and also the total performance; whereas the displays with redundant beat patterns did not further improve performance beyond the spatial displays. An understanding of the dimensional effects provides better support the design of multimodal display for multi-tracking performance in driving scenarios and other domains.","2015-09-01","2023-07-06 06:28:42","2023-07-06 06:28:42","2023-07-06 06:28:28","1578-1582","","1","59","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/QFBLIHHI/Yang et al. - 2015 - Investigating Redundant Multimodal Speedometer Dis.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NMWPRXYH","journalArticle","2011","Horiguchi, Yukio; Yasuda, Keisuke; Nakanishi, Hiroaki; Sawaragi, Tetsuo","Data-To-Sound Mapping To Sonify Ongoing System Status In Continuous Manual Control Task","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/1071181311551257","https://journals.sagepub.com/doi/abs/10.1177/1071181311551257","This study empirically examines parameter-mapping sonifications to represent the difference or error between the desired state and the current state of the system being controlled using the non-speech audio. Eight different types of data-to-sound mappings were prepared by which the error was mapped onto either or both of two acoustic parameters of intensity and frequency. The mappings were tested through an experiment using a one-dimensional tracking task. The experimental results shows the following points: 1) as for the tracking task, the mappings are preferable in which the sound intensity falls as the error decreases, 2) no audible sound when no error remains is effective because listeners can easily identify the achievement to the goal from the sound itself, and 3) it seems more effective to map the error to the intensity and frequency redundantly than only to either of them, if perceptual interaction between changes in loudness and pitch is considered enough.","2011-09-01","2023-07-06 06:28:42","2023-07-06 06:28:42","2023-07-06 06:28:29","1235-1239","","1","55","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/JE6H297R/Horiguchi et al. - 2011 - Data-To-Sound Mapping To Sonify Ongoing System Sta.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BWJ4VG6X","journalArticle","2002","Flowers, John H.; Grafel, Douglas C.","Perception of Sonified Daily Weather Records","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/154193120204601711","https://doi.org/10.1177/154193120204601711","Human participants performed a perceptual task in which they sorted auditory (musical) displays of one-month long daily weather summaries (temperature, rainfall, and snowfall) based on perceived similarity of weather patterns. Displays for fifteen winter months and fifteen summer months were sorted by separate groups of participants. Each group sorted two sets of displays that varied in presentation speed. Multidimensional scaling analyses indicated that these displays were effective in conveying weather features important for climate comparisons for both winter and summer months, and that the faster (7.1 sec) displays were more effective than the slower (14.2 sec) displays. These results show that sonification can be an effective tool for exploring multivariate time series data, but that optimization of such displays may require consideration of the temporal constraints of auditory sensory memory and working memory.","2002-09-01","2023-07-06 06:28:42","2023-07-06 06:28:42","2023-07-06 06:28:31","1579-1583","","17","46","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/ZQPSCILU/Flowers and Grafel - 2002 - Perception of Sonified Daily Weather Records.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JK9J7I4P","journalArticle","2021","Šabić, Edin; Chen, Jing; MacDonald, Justin A.","Toward a Better Understanding of In-Vehicle Auditory Warnings and Background Noise","Human Factors","","0018-7208","10.1177/0018720819879311","https://doi.org/10.1177/0018720819879311","ObjectiveThe effectiveness of three types of in-vehicle warnings was assessed in a driving simulator across different noise conditions.BackgroundAlthough there has been much research comparing different types of warnings in auditory displays and interfaces, many of these investigations have been conducted in quiet laboratory environments with little to no consideration of background noise. Furthermore, the suitability of some auditory warning types, such as spearcons, as car warnings has not been investigated.MethodTwo experiments were conducted to assess the effectiveness of three auditory warnings (spearcons, text-to-speech, auditory icons) with different types of background noise while participants performed a simulated driving task.ResultsOur results showed that both the nature of the background noise and the type of auditory warning influenced warning recognition accuracy and reaction time. Spearcons outperformed text-to-speech warnings in relatively quiet environments, such as in the baseline noise condition where no music or talk-radio was played. However, spearcons were not better than text-to-speech warnings with other background noises. Similarly, the effectiveness of auditory icons as warnings fluctuated across background noise, but, overall, auditory icons were the least efficient of the three warning types.ConclusionOur results supported that background noise can have an idiosyncratic effect on a warning’s effectiveness and illuminated the need for future research into ameliorating the effects of background noise.ApplicationThis research can be applied to better present warnings based on the anticipated auditory environment in which they will be communicated.","2021-03-01","2023-07-06 06:28:42","2023-07-06 06:28:42","2023-07-06 06:28:32","312-335","","2","63","","Hum Factors","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/TKE3PM2H/Šabić et al. - 2021 - Toward a Better Understanding of In-Vehicle Audito.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2RAHIGIK","journalArticle","1991","Gerth, Jeffrey M.","Identifying the Temporal Patterning Confusions in Audio Displays: Developing Guidelines for Complex Audio Displays","Proceedings of the Human Factors Society Annual Meeting","","0163-5182","10.1177/154193129103501034","https://doi.org/10.1177/154193129103501034","Current guidelines and recommendations for auditory displays suggest that human auditory discrimination performance is limited and that auditory displays should be used only for alarm and alerting signals. Auditory warnings are likely to be confused even when their spectra are very different. Reducing confusion between warnings should increase the number of auditory signals which can be presented. The present research investigated the ability of human listeners to discriminate sounds varying in temporal patterning in several sound categories.Although overall accuracy was 92 percent across the 45 dissimilar sound sequences, 7 sequences were found to be easily confused and accounted for 64 percent of the total errors made by listeners, regardless of sound category. According to subject reports, multiple simultaneously presented temporally patterned sounds within each sound category were not perceived as multiple sources but rather were fused into a single complex temporal pattern. Implications for developing complex audio displays by increasing the number and complexity of sounds and planned continuing research are also discussed.","1991-09-01","2023-07-06 06:28:42","2023-07-06 06:28:42","2023-07-06 06:28:35","723-727","","10","35","","","Identifying the Temporal Patterning Confusions in Audio Displays","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PNPCCXGZ","journalArticle","2007","Sanderson, P.M.; Watson, M.O.; Jenkins, S.; Liu, D.; Russell, W.J.; Green, N.; Cole, P.","Summative evaluation with a full-scale patient simulator: Challenges and adaptations","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/154193120705101135","https://doi.org/10.1177/154193120705101135","In this paper we outline considerations that went into designing and executing a full-scale simulator-based summative evaluation of four different display configurations for presenting information about anesthetized patients to an anesthesiologist. Although patient simulators appear to provide a “natural laboratory” for evaluating medical device innovations and equipment interface concepts, the software underlying patient simulators can be unequal to the challenges posed by the need for good representation of patient physiology and good experimental control. Moreover, the opportunities that full-scale patient simulators can offer for completely interactive, event-driven scenarios can present problems for experimental control and can promote participant hypervigilance. We describe the design of our experimental scenarios, the challenges our scenarios posed for simulator software and how we overcame those challenges, the design of a distractor task, and the methodology used to ensure we collected behavioral data sensitive to the manipulations of interest. Our adaptations in the face of challenges posed by the full-scale simulator context let us design an experiment that was highly informative about the advantages and disadvantages of the display configurations of interest.","2007-10-01","2023-07-06 06:28:42","2023-07-06 06:28:42","2023-07-06 06:28:36","770-774","","11","51","","","Summative evaluation with a full-scale patient simulator","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/REH2UN8J/Sanderson et al. - 2007 - Summative evaluation with a full-scale patient sim.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JZE2F6HP","journalArticle","2004","Anderson, Janet; Sanderson, Penelope","Designing Sonification for Effective Attentional Control in Complex Work Domains","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/154193120404801606","https://doi.org/10.1177/154193120404801606","Complex safety-critical work domains such as anesthesia require human operators to direct their attention appropriately. A sonification is a possible method for directing attention to relevant changes while still allowing monitoring under divided attention conditions. However, there is currently little information to guide the design of sonification. Two experiments investigated the effect of the number of auditory streams on ability to detect changes (Experiment 1), and the effect of the number of auditory streams under different attention conditions (Experiment 2). When monitoring with selective attention, participants noted changes more accurately with three streams than with one or two streams, but when there were also distracter changes participants noted changes more accurately in multiple streams. Overall, accuracy was lower when attention was divided than when it was selective, but accuracy was especially low in the three-stream configuration. Distracter changes increased divided attention accuracy. The results suggest that the number of streams should be minimized if operators' attention will be divided between monitoring and other tasks.","2004-09-01","2023-07-06 06:28:42","2023-07-06 06:28:42","2023-07-06 06:28:37","1818-1822","","16","48","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/NEMEXBE5/Anderson and Sanderson - 2004 - Designing Sonification for Effective Attentional C.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6DCVQD2Q","journalArticle","1993","Begault, Durand R.; Wenzel, Elizabeth M.","Headphone Localization of Speech","Human Factors","","0018-7208","10.1177/001872089303500210","https://doi.org/10.1177/001872089303500210","Three-dimensional acoustic display systems have recently been developed that synthesize virtual sound sources over headphones based on filtering by headrelated transfer functions (HRTFs), the direction-dependent spectral changes caused primarily by the pinnae. In this study 11 inexperienced subjects judged the apparent spatial location of headphone-presented speech stimuli filtered with nonindividualized HRTFs. About half of the subjects ""pulled"" their judgments toward either the median or the lateral-vertical planes, and estimates were almost always elevated. Individual differences were pronounced for the distance judgments; 15% to 46% of stimuli were heard inside the head, with the shortest estimates near the median plane. The results suggest that most listeners can obtain useful azimuth information from speech stimuli filtered by nonindividualized HRTFs. Measurements of localization error and reversal rates are comparable with a previous study that used broadband noise stimuli.","1993-06-01","2023-07-06 06:28:42","2023-07-06 06:28:42","2023-07-06 06:28:39","361-376","","2","35","","Hum Factors","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VV6ZZ49W","journalArticle","2014","Nees, Michael A.; Walker, Bruce N.","Performance of a Sonification Task in the Presence of Verbal, Visuospatial, and Auditory Interference Tasks","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/1541931214581249","https://doi.org/10.1177/1541931214581249","An experiment examined performance with sonifications—a general term for nonspeech auditory displays—as a function of working memory encoding and the demands of three different types of interference tasks. Participants encoded the sonifications as verbal representations, visuospatial images, or auditory images. After encoding, participants engaged in brief verbal, visuospatial, or auditory interference tasks before responding to point estimation queries about the sonifications. Results were expected to show selective impact on sonification task performance when the interference task demands matched the working memory encoding strategy, but instead a pattern of general working memory interference emerged in addition to auditory modal interference. In practical applications, results suggested that performance with auditory displays will be impacted by any interference task, though auditory tasks likely will cause more interference than verbal or visuospatial tasks.","2014-09-01","2023-07-06 06:28:42","2023-07-06 06:28:42","2023-07-06 06:28:40","1194-1198","","1","58","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/35QNA6ZZ/Nees and Walker - 2014 - Performance of a Sonification Task in the Presence.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PR4A5KBT","journalArticle","1990","Allen, R. Wade; Hogue, Jeffrey R.; Stein, Anthony C.; Aponso, Bimal L.; Rosentha, Theodore J.","Low Cost, Real Time Simulation Based on Microcomputers","Proceedings of the Human Factors Society Annual Meeting","","0163-5182","10.1177/154193129003400913","https://doi.org/10.1177/154193129003400913","This paper describes a general approach for implementing fixed base, person-in-the-loop, vehicle control simulations on IBM-PC compatible computers. The elements of fixed base (no motion) simulations are reviewed, including the vehicle math model, auditory and visual displays, and performance measurement. Two simulation examples are discussed, including a highway vehicle control task and a parachute maneuvering task.","1990-10-01","2023-07-06 06:28:42","2023-07-06 06:28:42","2023-07-06 06:28:42","640-644","","9","34","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"26W9JSC6","journalArticle","1997","Flowers, John H.; Buhman, Dion C.; Turnage, Kimberly D.","Cross-Modal Equivalence of Visual and Auditory Scatterplots for Exploring Bivariate Data Samples","Human Factors","","0018-7208","10.1518/001872097778827151","https://doi.org/10.1518/001872097778827151","The equivalence of visual and auditory scatterplots was examined in two experiments. Experiment 1 examined the relationship between actual Pearson's r and visual and auditory judgments of direction and magnitude of correlation for 24 bivariate data samples. Experiment 2 directly evaluated visual and auditory perceptual sensitivity to outliers by examining changes in perceived magnitude and direction of correlation estimates for scatterplots from Experiment 1 that were altered by the addition of outlier points. Results suggest that the information conveyed by visual and auditory scatterplots is used very similarly by the two modalities. Both visual and auditory scatterplots are quite efficient in conveying sign and magnitude of correlation, and the effect of outliers on judged magnitude of correlation is similar for the two types of data display.","1997-09-01","2023-07-06 06:29:07","2023-07-06 06:29:07","2023-07-06 06:28:52","341-351","","3","39","","Hum Factors","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J3NU8EXQ","journalArticle","2008","Thompson, Matthew B.; Sanderson, Penelope M.","Multisensory Integration with a Head-Mounted Display: Sound Delivery and Self-Motion","Human Factors","","0018-7208","10.1518/001872008X312323","https://journals.sagepub.com/doi/abs/10.1518/001872008X312323","Objective: We tested whether the method of sound delivery affects people's ability to integrate information from multiple modalities when they are walking and using a head-mounted display (HMD). Background: HMDs increasingly support mobile work. Human operators may benefit from auditory support when using an HMD. However, it is unclear whether sound is better delivered publicly in free field or privately via earpiece and what the effect of walking is. Method: Participants identified mismatches between sounds and visual information on an HMD. Participants heard the sounds via either earpiece or free field while they either sat or walked about the test room. Results: When using an earpiece, participants performed the mismatch task equally well whether sitting or walking, but when using free-field sound, participants performed the task significantly worse when walking than when sitting (p = .006).  Conclusion: The worse performance for participants using free-field sound while walking may relate to spatial and motion inconsistencies between visual events on the head-referenced HMD and auditory events from world-referenced speakers. Researchers should more frequently examine the effect of self-motion on people's ability to perform various multisensory tasks. Application: When multisensory integration tasks are performed with an HMD and free-field delivery of sound, as may happen in medicine, transportation, or industry, performance may suffer when the relative location of sound changes as the user moves.","2008-10-01","2023-07-06 06:29:07","2023-07-06 06:29:07","2023-07-06 06:28:53","789-800","","5","50","","Hum Factors","Multisensory Integration with a Head-Mounted Display","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/K82CM2V2/Thompson and Sanderson - 2008 - Multisensory Integration with a Head-Mounted Displ.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EFY8EKY3","journalArticle","2009","Sanderson, Penelope M.","Auditory alarms for medical equipment: How do we ensure they convey their meanings?","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/154193120905300422","https://doi.org/10.1177/154193120905300422","For systems to be effective and to earn their users' trust, their signals must be readily interpreted. An international standard IEC 60601–1–8 was released in 2005 that provides guidelines on how to make auditory alarms on medical electrical equipment more recognisable and discriminable. Since the release of the standard, there have been concerns about the adequacy of its recommendations and, in particular, its proposal that manufacturers should use melodies to distinguish alarms from different sources. The melodies presented in the standard are just suggestions, but the standard does not indicate how an acceptable set of melodies can be established. Moreover, the standard does not require that developers perform thorough testing with representative users before implementing any melodies. The paper reviews studies performed over the last few years that demonstrate that the melodies suggested in IEC 60601–1–8 are ineffective. The paper also critiques suggestions that have been put forward for alternative alarm sounds, using speech synthesis techniques, better urgency mapping, and so on. Finally, criteria for future design and evaluation efforts are indicated.","2009-10-01","2023-07-06 06:29:07","2023-07-06 06:29:07","2023-07-06 06:28:55","264-268","","4","53","","","Auditory alarms for medical equipment","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/J7QTL7YH/Sanderson - 2009 - Auditory alarms for medical equipment How do we e.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QFLGRUX9","journalArticle","2020","Collett, Renae; Salisbury, Isaac; Loeb, Robert G.; Sanderson, Penelope M.","Smooth or Stepped? Laboratory Comparison of Enhanced Sonifications for Monitoring Patient Oxygen Saturation","Human Factors","","0018-7208","10.1177/0018720819845742","https://doi.org/10.1177/0018720819845742","Background:The pulse oximeter (PO) provides anesthesiologists with continuous visual and auditory information about a patient’s oxygen saturation (SpO2). However, anesthesiologists’ attention is often diverted from visual displays, and clinicians may inaccurately judge SpO2 values when relying on conventional PO auditory tones. We tested whether participants could identify SpO2 value (e.g., “97%”) better with acoustic enhancements that identified three discrete clinical ranges by either changing abruptly at two threshold values (stepped-effects) or changing incrementally with each percentage value of SpO2 (smooth-effects).Method:In all, 79 nonclinicians participated in a between-subjects experiment that compared performance of participants using the stepped-effects display with those who used the smooth-effects display. In both conditions, participants heard sequences of 72 tones whose pitch directly correlated to SpO2 value, and whose value could change incrementally. Primary outcome was percentage of responses that correctly identified the absolute SpO2 percentage, ±1, of the last pulse tone in each sequence.Results:Participants using the stepped-effects auditory tones identified absolute SpO2 percentage more accurately (M = 53.7%) than participants using the smooth-effects tones (M = 47.9%, p = .038). Identification of range and detection of transitions between ranges showed even stronger advantages for the stepped-effects display (p < .005).Conclusion:The stepped-effects display has more pronounced auditory cues at SpO2 range transitions, from which participants can better infer absolute SpO2 values. Further development of a smooth-effects display for this purpose is not necessary.","2020-02-01","2023-07-06 06:29:07","2023-07-06 06:29:07","2023-07-06 06:28:57","124-137","","1","62","","Hum Factors","Smooth or Stepped?","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/5NSRRDIF/Collett et al. - 2020 - Smooth or Stepped Laboratory Comparison of Enhanc.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EIB4FGFG","journalArticle","2004","Smith, Daniel R.; Walker, Bruce N.","Effects of Training and Auditory Context on Performance of a Point Estimation Sonification Task","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/154193120404801608","https://doi.org/10.1177/154193120404801608","Research on auditory graphs has investigated mappings, scalings, and polarities (Walker, 2002), as well as the addition of some contextual design features (Bonebright, Nees, Connerley, & McCain, 2001; Flowers, Buhman, & Turnage, 1997), in order to improve performance. However, little has been done to quantify the performance effects of such features, or to investigate effects of training in specific sonification tasks such as point estimation. Smith and Walker (2002) took a step towards quantifying and comparing the effects of adding several contextual design features. Presented here are selected results from a comprehensive follow-on study comparing effects of adding auditory context, either with or without training. The overall results indicate that some kinds of auditory context improved performance, while others did not. Training improved performance, and an interaction was discovered between type of auditory context and type of training (Smith, 2003). Implications are discussed.","2004-09-01","2023-07-06 06:29:07","2023-07-06 06:29:07","2023-07-06 06:28:58","1828-1831","","16","48","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/KQU34SBL/Smith and Walker - 2004 - Effects of Training and Auditory Context on Perfor.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"94HCTIMR","journalArticle","1960","Burrows, Alan A.","Acoustic Noise, An Informational Definition","Human Factors","","0018-7208","10.1177/001872086000200308","https://doi.org/10.1177/001872086000200308","Some theoretical considerations are made on the previous definitions of acoustic noise and the classification of its effects on organisms. A definition is proposed relating acoustic noise to its environmental source and the informational content of the specific task in which it occurs. An experimental study explores this proposal.","1960-08-01","2023-07-06 06:29:07","2023-07-06 06:29:07","2023-07-06 06:29:00","163-168","","3","2","","Hum Factors","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MW7UZS64","journalArticle","2011","Garcia, Adrian; Peres, S. Camille; Ritchey, Paul; Kortum, Philip; Stallmann, Kurt","Auditory Progress Bars: Estimations of Time Remaining","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/1071181311551278","https://journals.sagepub.com/doi/abs/10.1177/1071181311551278","Auditory Progress Bars (APB) were originally intended to augment Visual Progress Bars (VPB) to create multimodal displays. More recently, APBs have been tested in absence of VPBs for use in the on-hold telephone setting. In this setting, APBs are a viable option for communicating the probable time remaining in the on-hold wait. However, past studies measure the effectiveness of APBs retrospectively, which is appropriate for understanding how accurately callers can judge how long they have been waiting on hold, but is not appropriate for determining if APBs are intuitively communicating the probable time remaining in the wait—which is more relevant to the caller’s needs. Here, we measure the effectiveness of 3 distinct APBs prospectively which is more consistent with the caller’s concern of how much longer the wait will be before their call is answered. Furthermore, we make APBs more similar to VPBs by playing the APB’s endpoint before the APB’s beginning point. We found evidence that the accuracy of prospective estimations is a product of APB design, and that the awareness of the endpoint has no affect on the accuracy of prospective estimations.","2011-09-01","2023-07-06 06:29:07","2023-07-06 06:29:07","2023-07-06 06:29:02","1338-1341","","1","55","","","Auditory Progress Bars","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/Z9ZRMK8Y/Garcia et al. - 2011 - Auditory Progress Bars Estimations of Time Remain.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L5NB788J","journalArticle","2004","Watson, Marcus; Sanderson, Penelope","Sonification Supports Eyes-Free Respiratory Monitoring and Task Time-Sharing","Human Factors","","0018-7208","10.1518/hfes.46.3.497.50401","https://doi.org/10.1518/hfes.46.3.497.50401","Three experiments explored the effectiveness of continuous auditory displays, or sonifications, for conveying information about a simulated anesthetized patient's respiration. Experiment 1 established an effective respiratory sonification. Experiment 2 showed an effect of expertise in the use of respiratory sonification and revealed that some apparent differences in sonification effectiveness could be accounted for by response bias. Experiment 3 showed that sonification helps anesthesiologists to maintain high levels of awareness of the simulated patient's state while performing other tasks more effectively than when relying upon visual monitoring of the simulated patient state. Overall, sonification of patient physiology beyond traditional pulse oximetry appears to be a viable and useful adjunct to visual monitors. Actual and potential applications of this research include monitoring in a wide variety of busy critical care contexts.","2004-09-01","2023-07-06 06:29:07","2023-07-06 06:29:07","2023-07-06 06:29:04","497-517","","3","46","","Hum Factors","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/CLES6Z2W/Watson and Sanderson - 2004 - Sonification Supports Eyes-Free Respiratory Monito.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E4H3G2EM","journalArticle","2013","Kelling, Nicholas; Bedwell, Wendy; Corso, Gregory M.; Cuevas, Haydee M.; Keebler, Joseph R.; Peres, S. Camille; Walker, Bruce N.","Life, the Universe, and Academia: An Interactive Discussion on Balance and Early Success for Potential Academics","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/1541931213571095","https://doi.org/10.1177/1541931213571095","The human factors discipline has always benefited from a strong connection between industry and academia. However, the increasing need of an educated industry workforce has created a potential concern of maintaining a viable academic workforce. Students, in particular, have previously voiced apprehensions regarding academic careers when compared to industry options. The balance between industry and academia should be preserved. Therefore, to aid in this equilibrium, an open discussion centered on student inquiries about early academia is needed to maintain an understanding of the current academic environment. Specifically, the most beneficial interaction may be through discussions between those interested in academia and those currently entrenched in multiple facets of success in early academic careers.","2013-09-01","2023-07-06 06:29:07","2023-07-06 06:29:07","2023-07-06 06:29:05","438-442","","1","57","","","Life, the Universe, and Academia","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/MFPIVWXI/Kelling et al. - 2013 - Life, the Universe, and Academia An Interactive D.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BAF3Z9H2","journalArticle","2012","Scerra, Veronica E.; Brill, J. Christopher","Effect of Task Modality on Dual-Task Performance, Response Time, and Ratings of Operator Workload","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/1071181312561409","https://doi.org/10.1177/1071181312561409","The purpose of this study was to use established measures of attentional reserve capacity to test for the existence of tactile-specific resources in the context of Wickens’ (1984, 2002) Multiple Resource Theory. Participants performed a primary counting task in the tactile modality and were presented with a concurrent secondary attention task in the visual, auditory, and tactile modalities. The data indicate a significant difference in performance based on whether the dual-task conditions were performed crossmodally or unimodally, in terms of percent correct and response time to target stimuli. Specifically, participants performed significantly worse in tactile-tactile dual-task conditions, suggesting performance was degraded as a function of resource depletion. Furthermore, participants rated the unimodal dual-task conditions as significantly harder, using a subjective workload rating, than either of the dual-task crossmodal conditions, or the single task condition. The results suggest that task interference was a function of resource limitation rather than structural interference, providing direct empirical evidence supporting the inclusion of tactile resources in Wickens’ Multiple Resource Theory.","2012-09-01","2023-07-06 06:29:07","2023-07-06 06:29:07","2023-07-06 06:29:07","1456-1460","","1","56","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/75NSCWU8/Scerra and Brill - 2012 - Effect of Task Modality on Dual-Task Performance, .pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PVU5FXYE","journalArticle","1992","Schumacher, Robert M.","Phone-Based Interfaces: Research and Guidelines","Proceedings of the Human Factors Society Annual Meeting","","0163-5182","10.1177/154193129203601408","https://doi.org/10.1177/154193129203601408","The telephone is the most ubiquitous computer input/output device with over 200 million units in the U.S. Thousands of applications – from airline reservations to zoo schedules – employ audio output and touch-tone input to control the flow and content of information. Because of the limited information capacity of the telephone, designing useful and usable phone-based interfaces presents a strong challenge to the designer. This paper will focus on the strengths and weaknesses of phone-based interfaces, present design guidelines, and discuss future directions.","1992-10-01","2023-07-06 06:29:26","2023-07-06 06:29:26","2023-07-06 06:29:17","1051-1055","","14","36","","","Phone-Based Interfaces","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MFTB3NTA","journalArticle","2001","Lee, Mark D.","Multichannel Auditory Search: Toward Understanding Control Processes in Polychotic Auditory Listening","Human Factors","","0018-7208","10.1518/001872001775900959","https://doi.org/10.1518/001872001775900959","Two experiments are presented that serve as a framework for exploring auditory information processing. The framework is referred to as polychotic listening or auditory search, and it requires a listener to scan multiple simultaneous auditory streams for the appearance of a target word (the name of a letter such as A or M). Participants' ability to scan between two and six simultaneous auditory streams of letter and digit names for the name of a target letter was examined using six loudspeakers. The main independent variable was auditory load, or the number of active audio streams on a given trial. The primary dependent variables were target localization accuracy and reaction time. Results showed that as load increased, performance decreased. The performance decrease was evident in reaction time, accuracy, and sensitivity measures. The second study required participants to practice the same task for 10 sessions, for a total of 1800 trials. Results indicated that even with extensive practice, performance was still affected by auditory load. The present results are compared with findings in the visual search literature. The implications for the use of multiple auditory displays are discussed. Potential applications include cockpit and automobile warning displays, virtual reality systems, and training systems.","2001-06-01","2023-07-06 06:29:26","2023-07-06 06:29:26","2023-07-06 06:29:19","328-342","","2","43","","Hum Factors","Multichannel Auditory Search","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/4IZZ6Q76/Lee - 2001 - Multichannel Auditory Search Toward Understanding.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5SBQHSW2","journalArticle","2012","Suh, Hyewon; Jeon, Myounghoon; Walker, Bruce N.","Spearcons Improve Navigation Performance and Perceived Speediness in Korean Auditory Menus","Proceedings of the Human Factors and Ergonomics Society Annual Meeting","","2169-5067","10.1177/1071181312561390","https://doi.org/10.1177/1071181312561390","For decades, auditory menus using both speech (usually text-to-speech, TTS) and non-speech sounds have been extensively studied. Researchers have developed situation-optimized auditory menus involving such cues as auditory icons, earcons, spearcons, and spindex. Spearcons have generally outperformed other cues in terms of providing both contextual information and item-specific information. However, little research has been devoted to exploration of spearcons in languages other than English, or the use of spearcon-only auditory menus. In this study, we evaluated the use of spearcons in Korean menus, as well as the use of spearcons alone. Twenty-five native Korean speakers navigated through a two-dimensional auditory menu presented via TTS, with or without spearcon enhancements. Korean spearcons were successful. Participants also rated the spearcon-enhanced menu as seeming speedier and more fun than the TTS-only menu. After a short learning period, mean time-to-target in the auditory menu was even faster with spearcons alone, compared to traditional TTS-only menus.","2012-09-01","2023-07-06 06:29:26","2023-07-06 06:29:26","2023-07-06 06:29:20","1361-1365","","1","56","","","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/UYWY83XW/Suh et al. - 2012 - Spearcons Improve Navigation Performance and Perce.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M9UNR993","journalArticle","2016","Hinckfuss, Kelly; Sanderson, Penelope; Loeb, Robert G.; Liley, Helen G.; Liu, David","Novel Pulse Oximetry Sonifications for Neonatal Oxygen Saturation Monitoring: A Laboratory Study","Human Factors","","0018-7208","10.1177/0018720815617406","https://doi.org/10.1177/0018720815617406","ObjectiveWe aimed to test whether the use of novel pulse oximetry sounds (sonifications) better informs listeners when a neonate’s oxygen saturation (SpO2) deviates from the recommended range.BackgroundVariable-pitch pulse oximeters do not accurately inform clinicians via sound alone when SpO2 is outside the target range of 90% to 95% for neonates on supplemental oxygen. Risk of blindness, organ damage, and death increase if SpO2 remains outside the target range. A more informative sonification may improve clinicians’ ability to maintain the target range.MethodIn two desktop experiments, nonclinicians’ ability to detect SpO2 range and direction of change was tested with novel versus conventional sonifications of simulated patient data. In Experiment 1, a “shoulder” sonification used larger pitch differences between adjacent saturation percentages for SpO2 values outside the target range. In Experiment 2, a “beacon” sonification used equal-appearing pitch differences, but when SpO2 was outside the target range, a fixed-pitch reference tone from the center of the target SpO2 range preceded every fourth pulse tone.ResultsThe beacon sonification improved range identification accuracy over the control display (85% vs. 60%; p < .001), but the shoulder sonification did not (55% vs. 52%).ConclusionThe beacon provided a distinct auditory alert and reference that significantly improved nonclinical participants’ ability to identify SpO2 range.ApplicationAdding a beacon to the variable-pitch pulse oximeter sound may help clinicians identify when, and by how much, a neonate’s SpO2 deviates from the target range, particularly during patient transport situations when auditory information becomes essential.","2016-03-01","2023-07-06 06:29:26","2023-07-06 06:29:26","2023-07-06 06:29:22","344-359","","2","58","","Hum Factors","Novel Pulse Oximetry Sonifications for Neonatal Oxygen Saturation Monitoring","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/KQICU55S/Hinckfuss et al. - 2016 - Novel Pulse Oximetry Sonifications for Neonatal Ox.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UQEBZT9P","journalArticle","2011","So, Richard H. Y.; Leung, N. M.; Horner, Andrew B.; Braasch, Jonas; Leung, K. L.","Effects of Spectral Manipulation on Nonindividualized Head-Related Transfer Functions (HRTFs)","Human Factors","","0018-7208","10.1177/0018720811406883","https://doi.org/10.1177/0018720811406883","Background: Directional sounds simulated using nonindividualized head-related transfer functions (HRTFs) often result in front-back confusion.Objective: This study was designed to examine how manipulating these nonindividualized HRTF spectra can reduce front-back confusion in headphone-simulated directional sounds.Method: HRTFs of six ear-level directions were studied (angles of 0°, 45°, 135°, 180°, 225°, and 315°). The HRTF gains in each of six frequency bands (200 to 690 Hz, 690 to 2400 Hz, 2400 to 6500 Hz, 6500 to 10000 Hz, 10000 to 14000 Hz, and 14000 to 22000 Hz) were amplified or attenuated by 0, 12, or 18 dB. Each manipulated HRTF generated a directional sound stimulus. For this study, 32 participants were invited to localize the randomly ordered stimuli.Results: The results indicate that a 12- or 18-dB manipulation of five of the six frequency bands produced significantly better directional accuracy, with significantly less front-back confusion. A reduction of up to 70% in localization error was obtained, along with 66% less front-back confusion. Significant interactions were found between the manipulation level and frequency.Conclusion: A 12-dB spectral manipulation of selected HRTF frequency bands produces better directional accuracy.Application: The results of this research could be applied to the development of tunable nonindividualized HRTFs for audio products.","2011-06-01","2023-07-06 06:29:26","2023-07-06 06:29:26","2023-07-06 06:29:24","271-283","","3","53","","Hum Factors","","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","/Users/minsik/Zotero/storage/3WF7UEK6/So et al. - 2011 - Effects of Spectral Manipulation on Nonindividuali.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JIHGPPFS","journalArticle","1993","Hsu, Sheng-Hsiung; Peng, Yu","Control/Display Relationship of the Four-Burner Stove: A Reexamination","Human Factors","","0018-7208","10.1177/001872089303500413","https://doi.org/10.1177/001872089303500413","Several previous studies concerning the arrangement of the control/burner relationship of a four-burner stove showed discrepancy in their results. For this reason, a further analysis of this arrangement is necessary and worthwhile. Two research methods were adopted to duplicate earlier studies. One was the paper-pencil test in which subjects took three different questionnaire forms that used alphabetical, sign, and numerical code systems. The other method was computer simulation in which subjects took part in a performance test of four arrangements of con troll burner designs, and reaction time and error rate were measured. The results indicated the existence of a suggestive effect, which is a tendency by some stimulicues to induce a specific response unawares in subjects. This confounding variable must be controlled in the test tool design. Results also revealed a population stereotype in the controllburner linkage relationship that was different for Chinese subjects and for American subjects. The equivalence of research methods between the paper-pencil test and computer simulation was not completely assured.","1993-12-01","2023-07-06 06:29:26","2023-07-06 06:29:26","2023-07-06 06:29:26","745-749","","4","35","","Hum Factors","Control/Display Relationship of the Four-Burner Stove","","","","","","","en","","","","","SAGE Journals","","Publisher: SAGE Publications Inc","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""