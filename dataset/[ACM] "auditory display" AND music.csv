"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"8WTUL365","conferencePaper","2011","McGregor, Iain; Larsson, Pontus; Turner, Phil","Evaluating a vehicle auditory display: comparing a designer's expectations with listeners' experiences","Proceedings of the 29th Annual European Conference on Cognitive Ergonomics","978-1-4503-1029-1","","10.1145/2074712.2074731","https://dl.acm.org/doi/10.1145/2074712.2074731","This paper illustrates a method for the early evaluation of auditory displays in context. A designer was questioned about his expectations of an auditory display for Heavy Goods Vehicles, and the results were compared to the experiences of 10 listeners. Sound design is essentially an isolated practice and by involving listeners the process can become collaborative. A review of the level of agreement allowed the identification of attributes that might be meaningful for the design of future auditory displays. Results suggest that traditional auditory display design guidelines that focus on the acoustical properties of sound might not be suitable.","2011-08-24","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","89–92","","","","","","Evaluating a vehicle auditory display","ECCE '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/MZQTYNYM/McGregor et al. - 2011 - Evaluating a vehicle auditory display comparing a.pdf","","","auditory display; designer's expectations; evaluation; listeners' experiences; vehicle","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"64N6EICX","conferencePaper","2013","McFarlane, Stuart; Feltham, Frank; Verhagen, Darrin","Exploring internet CO2 emissions as an auditory display","Proceedings of the 25th Australian Computer-Human Interaction Conference: Augmentation, Application, Innovation, Collaboration","978-1-4503-2525-7","","10.1145/2541016.2541081","https://dl.acm.org/doi/10.1145/2541016.2541081","This research project explores the effectiveness of an auditory display (AD) prototype for the sonification of perceived internet e-waste of CO2 emissions to a small user group within their office context. To date, methods do not exist for the reporting of e-waste to users of personal computing while they perform simple internet enquiries. Underpinning the theoretical development of this project is a focus on AD guided by a soundscape theory, and on approaches to sonification to convey subtle, unobtrusive, and useful information. Evaluation of the prototype takes place as a field study in an office context. The following paper gives an account of the design and development of the AD prototype and its respective sonification, the design methodology employed and the research findings, and concludes with recommendations for further exploration of the balance between ambient and salient information.","2013-11-25","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","225–228","","","","","","","OzCHI '13","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/7FN4VJP4/McFarlane et al. - 2013 - Exploring internet CO2 emissions as an auditory di.pdf","","","sonification; auditory display; e-waste; internet CO2 emissions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VV7XR2AL","conferencePaper","2013","Fagerlönn, Johan; Larsson, Stefan; Lindberg, Stefan","An auditory display that assist commercial drivers in lane changing situations","Proceedings of the 8th Audio Mostly Conference","978-1-4503-2659-9","","10.1145/2544114.2544120","https://dl.acm.org/doi/10.1145/2544114.2544120","This paper presents a simulator study that evaluates four auditory displays to assist commercial drivers in lane changing situations. More specifically, the displays warned the drivers about vehicles in the adjacent lane. Three displays utilized different variants of graded auditory warnings (early and late signals) while one display contained a single-stage warning (late signal). For all graded warnings, a manipulation of the turn indicator sound was utilized to alert the driver. The study investigated whether the graded warnings had different effects on safety and driver acceptance compared to a single stage warning. In addition, the study examined whether the idea of changing the turn indicator sound influenced traffic safety and initial acceptance. The results support that graded warnings are more effective compared to single stage warnings. Manipulating the turn indicator was effective and the acceptance for the solution was high. The implications for design based on the results are presented.","2013-09-18","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","1–7","","","","","","","AM '13","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/YZI8K9DQ/Fagerlönn et al. - 2013 - An auditory display that assist commercial drivers.pdf","","","auditory display; safety; alarm; alert; auditory warning; driving","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S365B8WB","conferencePaper","2009","Kim, Si-Jung; Thangjitham, Jennifer; Winchester, Woodrow","Assessing the efficacy of a mixed-modal auditory display system for enhancing auditory sensation","Proceedings of the 47th Annual Southeast Regional Conference","978-1-60558-421-8","","10.1145/1566445.1566520","https://dl.acm.org/doi/10.1145/1566445.1566520","This paper presents the design and evaluation of a new type of mixed-modal auditory display for enhancing auditory sensation. The purpose of this study is to determine whether or not a light apparatus in which LED lights are installed in front of a speaker panel and alternating lights based on sound frequency and intensity can support user awareness of the auditory source. Five different auditory sources were used, and a user study with 20 participants revealed that all auditory sources were better recognized when listened to with the light apparatus. The music and the emergency alert auditory source were best represented by the light apparatus. The experiment showed synchronized visual and audio representation enhanced the user's auditory sensation. Findings suggest that the light apparatus could be useful when auditory signal displays are not universally applicable because people who suffer from hearing loss are unable to use them effectively. It is expected that the result of this study could contribute to the design of hearing aids, emergency alarm device/mechanisms, communication trust or other assistive technologies that seek to provide context to received data.","2009-03-19","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","1–2","","","","","","","ACM-SE 47","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/LN9NCNYV/Kim et al. - 2009 - Assessing the efficacy of a mixed-modal auditory d.pdf","","","auditory display; hearing aids; mixed modal interface; speaker","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XC9GTFVV","conferencePaper","2017","Feltham, Frank; Loke, Lian","Felt Sense through Auditory Display: A Design Case Study into Sound for Somatic Awareness while Walking","Proceedings of the 2017 ACM SIGCHI Conference on Creativity and Cognition","978-1-4503-4403-6","","10.1145/3059454.3059461","https://dl.acm.org/doi/10.1145/3059454.3059461","Walking is an everyday act that we, as humans, often take for granted. To walk requires the synergy of somatosensory, neurological and physiological processes for us to move at a regular pace by lifting and setting down each foot in turn. It can be argued that walking is also a source of creativity and exploration when conducted as an intentional act of somatic or self-awareness. This design case study aims to explore the kinds of somatic awareness and aesthetic engagement of walking apparent through the introduction of a pressure mediated sound generating surface with a group of Feldenkrais movement practitioners. These explorations reveal that there is an awareness of tempo and rhythm during the step cycle. This awareness takes on an internal focus as shifts in attention and bodily organization. Another key finding is that exploration and play are enabled due to the rich timbral qualities of the pressure mediated auditory feedback. The significance and contribution in this work is in the implications it has for the design of technologies that support kinaesthetic awareness through aesthetic and exploratory strategies.","2017-06-22","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","287–298","","","","","","Felt Sense through Auditory Display","C&amp;C '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/IZ7SP2EF/Feltham and Loke - 2017 - Felt Sense through Auditory Display A Design Case.pdf","","","auditory feedback; walking; creativity; aesthetics of interaction; design case study.; kinaesthetic awareness","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KS4S98QM","conferencePaper","2007","Frauenberger, C.; Stockman, T.; Bourguet, M. L.","Pattern design in the context space: paco - a methodological framework for designing auditory display with patterns","Proceedings of the 14th Conference on Pattern Languages of Programs","978-1-60558-411-9","","10.1145/1772070.1772091","https://dl.acm.org/doi/10.1145/1772070.1772091","This paper introduces a methodological framework for contextual design with patterns (paco). Its development was driven by the lack of guidance in designing audio in the user interface and by the need to communicate design knowledge within the community and to designers outside the field. The fundamental concepts presented in this paper, however, are generic and might be applicable similarly to other disciplines. The framework provides methods to create, apply and refine design patterns considering the particularities of small or pre-mature scientific disciplines which have less successful examples to draw upon - such as auditory display. After providing background on research in auditory display and current design practice, a set of requirements for the framework is developed, an appropriate format for design patterns is discussed and the context space is introduced as a key concept to facilitate the workflow within the framework. An example workflow shows the usage of the framework during the life-cycle of a design pattern and we elaborate on the next steps discussing an online design tool and the evaluation of the framework.","2007-09-05","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","1–7","","","","","","Pattern design in the context space","PLOP '07","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/DMSYJJLI/Frauenberger et al. - 2007 - Pattern design in the context space paco - a meth.pdf","","","auditory display; design patterns; design methodology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VAFB38TA","conferencePaper","2012","McGookin, David; Brewster, Stephen","PULSE: the design and evaluation of an auditory display to provide a social vibe","Proceedings of the SIGCHI Conference on Human Factors in Computing Systems","978-1-4503-1015-4","","10.1145/2207676.2208580","https://dl.acm.org/doi/10.1145/2207676.2208580","We present PULSE, a mobile application designed to allow users to gain a 'vibe', an intrinsic understanding of the people, places and activities around their current location, derived from messages on the Twitter social networking site. We compared two auditory presentations of the vibe. One presented message metadata implicitly through modification of spoken message attributes. The other presented the same metadata, but through additional auditory cues. We compared both techniques in a lab and real world study. Additional auditory cues were found to allow for smaller changes in metadata to be more accurately detected, but were least preferred when PULSE was used in context. Results also showed that PULSE enhanced and shaped user understanding, with audio presentation allowing a closer coupling of digital data to the physical world.","2012-05-05","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","1263–1272","","","","","","PULSE","CHI '12","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/TGIRIW5X/McGookin and Brewster - 2012 - PULSE the design and evaluation of an auditory di.pdf","","","auditory display; geo-social media; location-based services; twitter","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B7SLCIMH","conferencePaper","2016","Goudarzi, Visda","Exploration of sonification design process through an interdisciplinary workshop","Proceedings of the Audio Mostly 2016","978-1-4503-4822-5","","10.1145/2986416.2986422","https://dl.acm.org/doi/10.1145/2986416.2986422","In sonification of scientific data, designers know very little about the domain science and domain scientists are not familiar with the sonification methodology. The knowledge about the domain science is not given, but evolved during the problem-solving process. We discuss design challenges in auditory display design regarding user-centered approaches and suggest a method to involve domain scientists throughout sonification designs. We explore this within a workshop in which sonification experts, domain experts, and programmers worked together to better understand and solve problems collaboratively. The sonification framework that is used during the workshops is briefly described and the workshop process and how each group worked together during the workshop sessions are examined. Participants worked on pre-defined and exploratory tasks to sonify climate data. Furthermore, they grasped each other's domains; climate scientists especially became more open to use auditory display and sonification as a tool in their data mining tasks. Resulting sonification prototypes and workshop sessions are documented on a wiki to be used by the sonification community. To get started, we used some of the sonification designs created during the workshop for an online study where participants from science, engineering, and humanities were asked questions about the data behavior by listening to sonifcations of bivariate time series. Results indicate that sonic representation of data from resulting sonification allows most users (even with little or no knowledge of sound and music) to successfully complete some common data exploration tasks.","2016-10-04","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","147–153","","","","","","","AM '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/FC8LBDLS/Goudarzi - 2016 - Exploration of sonification design process through.pdf","","","Sonification; Auditory Display; Participatory Design; User Experience","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WVGGBGWA","conferencePaper","2017","Ferguson, Jamie; Brewster, Stephen A.","Evaluation of psychoacoustic sound parameters for sonification","Proceedings of the 19th ACM International Conference on Multimodal Interaction","978-1-4503-5543-8","","10.1145/3136755.3136783","https://dl.acm.org/doi/10.1145/3136755.3136783","Sonification designers have little theory or experimental evidence to guide the design of data-to-sound mappings. Many mappings use acoustic representations of data values which do not correspond with the listener's perception of how that data value should sound during sonification. This research evaluates data-to-sound mappings that are based on psychoacoustic sensations, in an attempt to move towards using data-to-sound mappings that are aligned with the listener's perception of the data value's auditory connotations. Multiple psychoacoustic parameters were evaluated over two experiments, which were designed in the context of a domain-specific problem - detecting the level of focus of an astronomical image through auditory display. Recommendations for designing sonification systems with psychoacoustic sound parameters are presented based on our results.","2017-11-03","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","120–127","","","","","","","ICMI '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/2PALR6BB/Ferguson and Brewster - 2017 - Evaluation of psychoacoustic sound parameters for .pdf","","","Sonification; Psychoacoustics; Auditory Display","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BIBVLZIM","conferencePaper","2017","Fagerlönn, Johan; Hammarberg, Kristin; Lindberg, Stefan; Sirkka, Anna; Larsson, Sofia","Designing a Multimodal Warning Display for an Industrial Control Room","Proceedings of the 12th International Audio Mostly Conference on Augmented and Participatory Sound and Music Experiences","978-1-4503-5373-1","","10.1145/3123514.3123516","https://dl.acm.org/doi/10.1145/3123514.3123516","This paper presents the development of a multimodal warning display for a paper mill control room. In previous work, an informative auditory display for control room warnings was proposed. The proposed auditory solution conveys information about urgent events by using a combination of auditory icons and tonal components. The main aim of the present study was to investigate if a complementary visual display could increase the effectiveness and acceptance of the existing auditory solution. The visual display was designed in a user-driven design process with operators. An evaluation was conducted both before and after the implementation. Subjective ratings showed that operators found it easier to identify the alarming section using the multimodal display. These results can be useful for any designer intending to implement a multimodal display for warnings in an industrial context.","2017-08-23","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","1–5","","","","","","","AM '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/NUR2GPTS/Fagerlönn et al. - 2017 - Designing a Multimodal Warning Display for an Indu.pdf","","","auditory display; multimodal interaction; alarms; process industry; Warnings","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SIEVCGLD","conferencePaper","2015","Feng, Feng; Stockman, Tony; Bryan-Kinns, Nick; AI-Thani, Dena","An investigation into the comprehension of map information presented in audio","Proceedings of the XVI International Conference on Human Computer Interaction","978-1-4503-3463-1","","10.1145/2829875.2829896","https://dl.acm.org/doi/10.1145/2829875.2829896","The growth in mobile and multimodal Computing is leading to the consideration of alternative modes of information presentation, particularly in situations such as driving or walking in unfamiliar locations where the eyes are needed for primary navigation. We report the results of an experiment in which map information is presented to 10 normally sighted participants using an auditory display. Several measures of performance are reported, including the time to navigate a virtual route, keystroke errors and the ability to construct a visual representation of the route travelled based on audio instructions only. The results show significant variability in levels of performance between individuals, though most participants were able to make sense of the auditory display and produce a reasonable visual representation of the virtual route i.e. participants were able to comprehend the presented audio map.","2015-09-07","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","1–8","","","","","","","Interacci&#xf3;n '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/SD5R3KQ7/Feng et al. - 2015 - An investigation into the comprehension of map inf.pdf","","","Auditory display; audio information understanding; audio map system; spatial information","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BZDFXEVR","conferencePaper","2020","Seiça, Mariana; Roque, Licínio; Martins, Pedro; Cardoso, F. Amílcar","Contrasts and similarities between two audio research communities in evaluating auditory artefacts","Proceedings of the 15th International Audio Mostly Conference","978-1-4503-7563-4","","10.1145/3411109.3411146","https://dl.acm.org/doi/10.1145/3411109.3411146","The design of auditory artefacts has been establishing its practice as a scientific area for more than 20 years, with a crucial element in this process being how to properly evaluate acoustic outputs. In this paper, we sought to map the evaluation methods applied in a general search inside two main audio-focused conferences: Audio Mostly and the International Conference on Auditory Display (ICAD). Revisiting last year's editions, as well as a keyword-based search in the last ten years, we attempted to gather and classify each evaluation method according to the level of user involvement, their role, and the authors intentions in using each method. We propose an initial mapping for this gathering, in a framework of evaluation approaches which can reinforce and expand current practices in the creation of auditory artefacts.","2020-09-16","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","183–190","","","","","","","AM '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/JKCRQKXB/Seiça et al. - 2020 - Contrasts and similarities between two audio resea.pdf","","","auditory display; evaluation method; interacting with audio; literature review","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LH3IJS2P","conferencePaper","2011","Weinberg, Garrett; Harsham, Bret; Medenica, Zeljko","Evaluating the usability of a head-up display for selection from choice lists in cars","Proceedings of the 3rd International Conference on Automotive User Interfaces and Interactive Vehicular Applications","978-1-4503-1231-8","","10.1145/2381416.2381423","https://dl.acm.org/doi/10.1145/2381416.2381423","It has been established that head-down displays (HDDs), such as those commonly placed in the dashboard of commercial automobiles, negatively affect drivers' visual attention [1]. This problem can be exacerbated when screens are ""busy"" with graphics or rich information. In this paper, which is an extension of a user-preference study [23], we present the results of a driving simulator experiment where we examined two potential alternatives to HDDs for presenting textual lists. Subjects conducted a series of street name finding tasks using each of three system variants: one with a head-down display (HDD), one with a head-up display (HUD), and one with only an auditory display. We found that the auditory display had the least impact on driving performance and mental load, but at the expense of task completion efficiency. The HUD variant had a low impact on mental load and scored highest in user satisfaction, and therefore appears to be the most viable target for future study.","2011-11-30","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","39–46","","","","","","","AutomotiveUI '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/M36436EI/Weinberg et al. - 2011 - Evaluating the usability of a head-up display for .pdf","","","auditory display; driving simulation; HDD; head-down display; head-up display; HUD; speech recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JK2ZMAPB","conferencePaper","2012","Oki, Maho; Tsukada, Koji; Kurihara, Kazutaka; Siio, Itiro","HomeOrgel: interactive music box for the aural representation of home activities","Proceedings of the 10th asia pacific conference on Computer human interaction","978-1-4503-1496-1","","10.1145/2350046.2350083","https://dl.acm.org/doi/10.1145/2350046.2350083","We propose a music-box-type interface, ""HomeOrgel"", that can express various activities in the home using sound. Users can also control the volume and content using common methods for controlling a music box: opening the cover and winding the spring. Users can hear the sounds of past home activities, such as cooking and the opening/closing of doors with the background music (BGM) mechanism of the music box. We developed the HomeOrgel device and installed it in an actual house. We also verify the effectiveness of our system through evaluation and discussion.","2012-08-28","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","177–186","","","","","","HomeOrgel","APCHI '12","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/ZYTVGRBH/Oki et al. - 2012 - HomeOrgel interactive music box for the aural rep.pdf","","","auditory display; smart home; ubiquitous computing; music box","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HYJD38QG","conferencePaper","2009","Jeon, Myounghoon; Davison, Benjamin K.; Nees, Michael A.; Wilson, Jeff; Walker, Bruce N.","Enhanced auditory menu cues improve dual task performance and are preferred with in-vehicle technologies","Proceedings of the 1st International Conference on Automotive User Interfaces and Interactive Vehicular Applications","978-1-60558-571-0","","10.1145/1620509.1620528","https://dl.acm.org/doi/10.1145/1620509.1620528","Auditory display research for driving has mainly focused on collision warning signals, and recent studies on auditory in-vehicle information presentation have examined only a limited range of tasks (e.g., cell phone operation tasks or verbal tasks such as reading digit strings). The present study used a dual task paradigm to evaluate a plausible scenario in which users navigated a song list. We applied enhanced auditory menu navigation cues, including spearcons (i.e., compressed speech) and a spindex (i.e., a speech index that used brief audio cues to communicate the user's position in a long menu list). Twenty-four undergraduates navigated through an alphabetized song list of 150 song titles---rendered as an auditory menu---while they concurrently played a simple, perceptual-motor, ball-catching game. The menu was presented with text-to-speech (TTS) alone, TTS plus one of three types of enhanced auditory cues, or no sound at all. Both performance of the primary task (success rate of the game) and the secondary task (menu search time) were better with the auditory menus than with no sound. Subjective workload scores (NASA TLX) and user preferences favored the enhanced auditory cue types. Results are discussed in terms of multiple resources theory and practical IVT design applications.","2009-09-21","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","91–98","","","","","","","AutomotiveUI '09","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/77ZTKGLE/Jeon et al. - 2009 - Enhanced auditory menu cues improve dual task perf.pdf","","","auditory display; auditory menus; dual task; infotainment; IVTs (in-vehicle technologies); multiple resources; spearcon; spindex; TTS (text-to-speech)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I7G84WK4","conferencePaper","2018","Ferguson, Jamie; Brewster, Stephen A.","Investigating Perceptual Congruence between Data and Display Dimensions in Sonification","Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems","978-1-4503-5620-6","","10.1145/3173574.3174185","https://dl.acm.org/doi/10.1145/3173574.3174185","The relationships between sounds and their perceived meaning and connotations are complex, making auditory perception an important factor to consider when designing sonification systems. Listeners often have a mental model of how a data variable should sound during sonification and this model is not considered in most data:sound mappings. This can lead to mappings that are difficult to use and can cause confusion. To investigate this issue, we conducted a magnitude estimation experiment to map how roughness, noise and pitch relate to the perceived magnitude of stress, error and danger. These parameters were chosen due to previous findings which suggest perceptual congruency between these auditory sensations and conceptual variables. Results from this experiment show that polarity and scaling preference are dependent on the data:sound mapping. This work provides polarity and scaling values that may be directly utilised by sonification designers to improve auditory displays in areas such as accessible and mobile computing, process-monitoring and biofeedback.","2018-04-21","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","1–9","","","","","","","CHI '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/TSAN5G6R/Ferguson and Brewster - 2018 - Investigating Perceptual Congruence between Data a.pdf","","","sonification; auditory display; mental models; psychoacoustics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"89ITA6RW","conferencePaper","2016","Hermann, Thomas; Yang, Jiajun; Nagai, Yukie","EmoSonics: Interactive Sound Interfaces for the Externalization of Emotions","Proceedings of the Audio Mostly 2016","978-1-4503-4822-5","","10.1145/2986416.2986437","https://dl.acm.org/doi/10.1145/2986416.2986437","This paper presents a novel approach for using sound to externalize emotional states so that they become an object for communication and reflection both for the users themselves and for interaction with other users such as peers, parents or therapists. We present an abstract, vocal, and physiology-based sound synthesis model whose sound space each covers various emotional associations. The key idea in our approach is to use an evolutionary optimization approach to enable users to find emotional prototypes which are then in turn fed into a kernel-regression-based mapping to allow users to navigate the sound space via a low-dimensional interface, which can be controlled in a playful way via tablet interactions. The method is intended to be used for supporting people with autism spectrum disorder.","2016-10-04","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","61–68","","","","","","EmoSonics","AM '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/2AAUBU4U/Hermann et al. - 2016 - EmoSonics Interactive Sound Interfaces for the Ex.pdf","","","Sound; Auditory Display; Autism Spectrum Disorder (ASD); Emotions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PU7ELWGM","conferencePaper","2015","Dicke, Christina; Müller, Jörg","Evaluating Mid-air List Interaction for Spatial Audio Interfaces","Proceedings of the 3rd ACM Symposium on Spatial User Interaction","978-1-4503-3703-8","","10.1145/2788940.2788945","https://dl.acm.org/doi/10.1145/2788940.2788945","Selecting items from lists is a common task in many applications. For wearable devices where no display is available, list selection can be challenging. To explore potential solutions we present four user studies evaluating mid-air gestures to interact with lists in an eyes-free interface. We found that a spatialized audio list in the shape of a 110~degree arc angled towards the dominant hand was a comfortable and usable layout for most users. A selection takes less than 10.6 seconds on average and error rates are below 4% when users locate and select an item in an unknown, unordered list of 20 items. For lists of 10 items the mean selection time is 5.5 seconds or less, and error rates drop below 1.4%. We compared monophonic to binaural playback of feedback sounds (musicons) and found no statistical difference for task completion times or error rates between the conditions. We also implemented and evaluated a music player application to showcase spatial audio list selection in an applied scenario.","2015-08-08","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","24–33","","","","","","","SUI '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/TIYNACKV/Dicke and Müller - 2015 - Evaluating Mid-air List Interaction for Spatial Au.pdf","","","auditory display; direct manipulation; list selection; mid-air gestures","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EV3RFM67","conferencePaper","2017","Pigrem, Jon; Barthet, Mathieu","Datascaping: Data Sonification as a Narrative Device in Soundscape Composition","Proceedings of the 12th International Audio Mostly Conference on Augmented and Participatory Sound and Music Experiences","978-1-4503-5373-1","","10.1145/3123514.3123537","https://dl.acm.org/doi/10.1145/3123514.3123537","Soundscape composition is an art form that has grown from acoustic ecology and soundscape studies. Current practices foster a wide range of approaches, from the educational and documentary function of the world soundscape project (WSP) to the creation of imaginary sonic worlds supported by theories of acousmatic and electroacoustic music. Sonification is the process of rendering audio in response to data, and is often used in scenarios where visual representations of data are impractical. The field of auditory display has grown in isolation to soundscape composition, however fosters conceptual similarities in its representation of information in sonic form. This paper investigates the use of data sonification as a narrative tool in soundscape composition. A soundscape has been created using traditional concrete sounds (fixed media recorded sound objects), augmented with sonified real-time elements. An online survey and listening experiment was conducted, which asked participants to rate the soundscape on its ability to communicate specific detail with regard to environmental and social elements contained within. Research data collected shows a strong ability in participants to decode and comprehend additional layers of narrative information communicated through the soundscape.","2017-08-23","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","1–8","","","","","","Datascaping","AM '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/N5G459SH/Pigrem and Barthet - 2017 - Datascaping Data Sonification as a Narrative Devi.pdf","","","data sonification; acoustic ecology; generative music; soundscape composition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6TVGV43Z","conferencePaper","2019","Weger, Marian; Höldrich, Robert","A hear-through system for plausible auditory contrast enhancement","Proceedings of the 14th International Audio Mostly Conference: A Journey in Sound","978-1-4503-7297-8","","10.1145/3356590.3356593","https://dl.acm.org/doi/10.1145/3356590.3356593","In many of our everyday and professional routines, we rely on knowledge we gather from the auditory feedback of physical interactions. In an attempt to facilitate some of these listening practices (particularly percussion), we introduce a hear-through system for intra-stimulus Auditory Contrast Enhancement (ACE) in real time. Plausible spectral ACE is achieved by adopting the neural mechanism of lateral inhibition. Additional decay prolongation facilitates pitch perception. Perceptual plausibility of the augmented auditory feedback from the observer-perspective is investigated in an experiment with auditory-visual stimuli. Measured plausibility forms material-specific patterns depending on spectral dynamics and decay prolongation.","2019-09-18","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","1–8","","","","","","","AM'19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/KL8WTAML/Weger and Höldrich - 2019 - A hear-through system for plausible auditory contr.pdf","","","auditory display; auditory augmentation; ace; auditory contrast enhancement; augmented auditory feedback; auscultation; cartoonification; percussion; spectral contrast","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8YH5WCPI","conferencePaper","2008","Stockholm, Jack; Pasquier, Philippe","Eavesdropping: audience interaction in networked audio performance","Proceedings of the 16th ACM international conference on Multimedia","978-1-60558-303-7","","10.1145/1459359.1459434","https://dl.acm.org/doi/10.1145/1459359.1459434","Eavesdropping is an internet-based, interactive audio system that explores network mediated, musical performance in shared public spaces. The project aims to develop an environment which increases audience interaction and connectedness in a localized, computer-controlled performance. The system is a client-server architecture made of three components: (1) an audio preparation interface, (2) an interactive performance interface, and (3) a machine learning-based conductor. An artificial conductor mixes an acoustic ecology based on mood data entered by participants while learning from their feedback. Technicalities and early evaluation are presented.","2008-10-26","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","559–568","","","","","","Eavesdropping","MM '08","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/KNIZ9VPG/Stockholm and Pasquier - 2008 - Eavesdropping audience interaction in networked a.pdf","","","artificial intelligence; auditory display; acoustic ecology; computer music; net art; reinforcement learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QS5CE2CE","conferencePaper","2009","McGookin, David; Brewster, Stephen","Eyes-free overviews for mobile map applications","Proceedings of the 11th International Conference on Human-Computer Interaction with Mobile Devices and Services","978-1-60558-281-8","","10.1145/1613858.1613959","https://dl.acm.org/doi/10.1145/1613858.1613959","We outline two new auditory interaction techniques which build upon existing visual techniques to display off-screen points of interest (POI) in map based mobile computing applications. SonicPie uses a pie menu and compass metaphor, allowing a user to scroll around the environment, hearing off-screen POIs in a spatialised auditory environment. EdgeTouch integrates with the Wedge technique of Gustafson et al. [2], sonifying the POIs as the user comes into contact with them when moving his or her finger around a ""sonification border"".","2009-09-15","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","1–2","","","","","","","MobileHCI '09","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/H3RZ6IVX/McGookin and Brewster - 2009 - Eyes-free overviews for mobile map applications.pdf","","","auditory display; digital maps; off-screen data presentation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8Q4UV49B","conferencePaper","2019","Iber, Michael; Lechner, Patrik; Jandl, Christian; Mader, Manuel; Reichmann, Michael","Auditory Augmented Reality for Cyber Physical Production Systems","Proceedings of the 14th International Audio Mostly Conference: A Journey in Sound","978-1-4503-7297-8","","10.1145/3356590.3356600","https://dl.acm.org/doi/10.1145/3356590.3356600","We describe a proof-of-concept approach on the sonification of estimated operation states of 3D printing processes. The results of this study form the basis for the development of an ""intelligent"" noise protection headphone as part of Cyber Physical Production Systems, which provides auditorily augmented information to machine operators and enables radio communication between them. Further application areas are implementations in control rooms (equipped with multichannel loudspeaker systems) and utilization for training purposes. The focus of our research lies on situation-specific acoustic processing of conditioned machine sounds and operation related data with high information content, considering the often highly auditorily influenced working knowledge of skilled workers. As a proof-of-concept the data stream of error probability estimations regarding partly manipulated 3D printing processes was mapped to three sonification models, giving evidence about momentary operation states. The neural network applied indicates a high accuracy (>93%) concerning error estimation distinguishing between normal and manipulated operation states. None of the manipulated states could be identified by listening. An auditory augmentation, respectively sonification of these error estimations provides a considerable benefit to process monitoring.","2019-09-18","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","53–60","","","","","","","AM'19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/RTBWHY8I/Iber et al. - 2019 - Auditory Augmented Reality for Cyber Physical Prod.pdf","","","auditory display; auditory augmentation; cyber physical production systems; error prediction estimation; process monitoring","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LGVX6HMK","conferencePaper","2021","Ferguson, Jamie; Freeman, Euan; Brewster, Stephen","Investigating the Effect of Polarity in Auditory and Vibrotactile Displays Under Cognitive Load","Proceedings of the 2021 International Conference on Multimodal Interaction","978-1-4503-8481-0","","10.1145/3462244.3479911","https://dl.acm.org/doi/10.1145/3462244.3479911","When users are undertaking mentally demanding visuals tasks, it can be beneficial to convey information through the auditory or tactile modality instead. A fundamental problem when mapping information to sound or vibration is establishing which polarity the mapping should use. Magnitude estimation is a popular method of establishing polarity preferences, however the effectiveness of this approach remains unclear, especially in more ecologically valid contexts. We investigate what impact the polarity of a data-sound or data-vibration mapping has on how well users can interpret these mappings, under two different levels of mental workload. Our results show that polarity does not affect error rate or cognitive workload, although may affect response time. We also found that induced cognitive load may influence usability. An implication of this is that commonly used methods of establishing data mappings need to be revisited, with cognitive load in mind, to help designers create more usable auditory and vibrotactile displays.","2021-10-18","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","379–386","","","","","","","ICMI '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/J7PGAIT7/Ferguson et al. - 2021 - Investigating the Effect of Polarity in Auditory a.pdf","","","Sonification; Auditory Display; Cognitive Load; Polarity; Vibrotactile; Vibrotactile Display","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WDH3EG5K","conferencePaper","2011","Delle Monache, Stefano; Rocchesso, Davide","The curse of the where-rabbit: research through design of auditory trajectories","Proceedings of the 9th ACM SIGCHI Italian Chapter International Conference on Computer-Human Interaction: Facing Complexity","978-1-4503-0876-2","","10.1145/2037296.2037318","https://dl.acm.org/doi/10.1145/2037296.2037318","Computation can be considered a fundamental dimension of design, together with other elements like materials, colour, sound, form and function. Positioned between acoustics, computer science and design, sonic interaction design is about shaping the sonic behaviour of artefacts, by designing relevant sonic interactions. In the light of Research through Design (RtD) method of inquiry, recently emerged in HCI, we tackled the design problem of distributing short sequences of sounds in space as well in time, by exploring a non-visual illusion called auditory saltation effect. Spatially distributing auditory displays can be important for many applications, including the signaling of hidden hot spots.","2011-09-13","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","79–84","","","","","","The curse of the where-rabbit","CHItaly","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/38HAXFHR/Delle Monache and Rocchesso - 2011 - The curse of the where-rabbit research through de.pdf","","","auditory perception; auditory display; sonic interaction design; research through design","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UL2KG3YH","conferencePaper","2010","Shahab, Qonita; Terken, Jacques; Eggen, Berry","Auditory messages for speed advice in advanced driver assistance systems","Proceedings of the 2nd International Conference on Automotive User Interfaces and Interactive Vehicular Applications","978-1-4503-0437-5","","10.1145/1969773.1969783","https://dl.acm.org/doi/10.1145/1969773.1969783","Simple tones in in-car systems are mostly used for status indication or warning and alerting purposes. We argue that simple tones can also be used for the purpose of advising drivers through an Advanced Driver Assistance System (ADAS). Our ADAS application is called Cooperative Speed Assistance (CSA), where drivers receive advice to slow down or speed up to coordinate their speed with the speed of other vehicles in the traffic. Two concepts of auditory messages are presented: Looping messages are played as long as the advice applies, while Toggle messages mark the beginning and the end of an advice. For each concept, two prototypes of simple-tone signals were designed based on existing guidelines about sound characteristics affecting urgency and evaluation by users. The temporal characteristics of the signals indicated how much or how fast drivers should adapt their speed. The concepts were evaluated by having users drive in a driving simulator. Objective measurements indicated that there was no difference in effectiveness between the two concepts. Subjective evaluation indicated that users preferred the Toggle concept.","2010-11-11","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","50–56","","","","","","","AutomotiveUI '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/CRK53HUT/Shahab et al. - 2010 - Auditory messages for speed advice in advanced dri.pdf","","","auditory display; sound design; ADAS; automotive user interfaces","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TURQDIZW","conferencePaper","2013","Hermann, Thomas; Neumann, Alexander; Schnier, Christian; Pitsch, Karola","Sonification for supporting joint attention in dyadic augmented reality-based cooperation","Proceedings of the 8th Audio Mostly Conference","978-1-4503-2659-9","","10.1145/2544114.2597651","https://dl.acm.org/doi/10.1145/2544114.2597651","This paper presents a short evaluation of auditory representations for object interactions as support for cooperating users of an Augmented Reality(AR) system. Particularly head-mounted AR displays limit the field of view and thus cause users to miss relevant activities of their interaction partner, such as object interactions or deictic references that normally would be effective to establish joint attention. We start from an analysis of the differences between face-to-face interaction and interaction via the AR system, using interaction linguistic conversation analysis. From that we derive a set of features that are relevant for interaction partners to co-ordinate their activities. We then present five different interactive sonifications which make object manipulations of interaction partners audible by sonification that convey information about the kind of activity.","2013-09-18","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","1–6","","","","","","","AM '13","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/GCSKF2NF/Hermann et al. - 2013 - Sonification for supporting joint attention in dya.pdf","","","sonification; auditory display; assistive technology; mediated communication; social interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QUD8QVM8","conferencePaper","2018","Studley, Thomas; Vella, Richard; Scott, Nathan; Nesbitt, Keith","A definition of creative-based music games","Proceedings of the Australasian Computer Science Week Multiconference","978-1-4503-5436-3","","10.1145/3167918.3167921","https://dl.acm.org/doi/10.1145/3167918.3167921","Growing interest in the study of video game music has led an increasing base of scholars to pursue a multi-faceted investigation of music-based games. Within this domain, a distinct subset of 'creative-based' music games are emerging as a fertile new ground for the examination of music in interactive gaming environments. This paper aims to analyse the nature of these 'creative-based music games'. We review the current state of game music literature and show that music traditionally occupies a 'supportive' role in games. The diverse genre of 'music-games' is then framed as a departure from this supportive paradigm, introducing a further review covering the existing classifications of 'music-games'. Discussion of the component elements in 'creative-based music games' provides a more formal definition of this class of games. To illustrate this definition further an early prototype for an original game design ('EvoMusic') is then described. The rules, mechanics, and underlying concept of EvoMusic are examined in detail and then discussed in relation to a comparable game from the field (Soundrop). We conclude that the classification of 'creative-based music games' suggests key design dimensions that help distinguish games like EvoMusic from other closely related modes of 'exploratory' musical interaction. Using this classification there is the potential to explore, develop and evaluate as yet untapped design features for musical games.","2018-01-29","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","1–10","","","","","","","ACSW '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/2LB5D9WI/Studley et al. - 2018 - A definition of creative-based music games.pdf","","","ludomusicology; music games; video game music","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QWWQFJQX","conferencePaper","2011","Kostiainen, Juho; Erkut, Cumhur; Piella, Ferran Boix","Design of an audio-based mobile journey planner application","Proceedings of the 15th International Academic MindTrek Conference: Envisioning Future Media Environments","978-1-4503-0816-8","","10.1145/2181037.2181056","https://dl.acm.org/doi/10.1145/2181037.2181056","Using public transportation is a context in which awareness of time is important. Providing information related to both time and place by means of ambient media can not only remove the need to keep looking at the time in order to depart on time but also create the feel of being in control, by knowing the time available and the progress of the journey. In the mobile context, hands and eyes are often occupied, which significantly limits the amount of information that can be provided by typical applications based on textual and graphical interfaces. In this paper, we introduce a mobile journey planner application that utilizes audio in providing useful information as well as the user experience prototyping and design process behind it.","2011-09-28","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","107–113","","","","","","","MindTrek '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/YVVQQ2MS/Kostiainen et al. - 2011 - Design of an audio-based mobile journey planner ap.pdf","","","auditory display; sonic interaction design; experience and video prototyping; journey and route planning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EYFW4NCZ","conferencePaper","2022","Ziemer, Tim; Schultheis, Holger","Both Rudimentary Visualization and Prototypical Sonification can Serve as a Benchmark to Evaluate New Sonification Designs","Proceedings of the 17th International Audio Mostly Conference","978-1-4503-9701-8","","10.1145/3561212.3561228","https://dl.acm.org/doi/10.1145/3561212.3561228","Comparing sonification with visualization is like comparing apples and oranges. While visualizations are ubiquitous to the public and have established names, principles, application areas, and sophisticated designs, sonifications tend to be unique, self-made and completely new to users. In this study we developed a rudimentary visualization that is related closely to the principle of the sonification designs that we want to evaluate. In addition, we implemented a prototypical sonification that uses the most common mapping principles. Experiment results show that participants perform similarly well using the rudimentary visualization and the prototypical sonification, which is much better than chance but significantly worse than using our new sonification design. We therefore argue that both rudimentary visualization and prototypical sonifications can serve as a suitable benchmark to evaluate new sonifications designs against.","2022-10-10","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","24–31","","","","","","","AM '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/UJTNYCVW/Ziemer and Schultheis - 2022 - Both Rudimentary Visualization and Prototypical So.pdf","","","visualization; auditory display evaluation; sonification evaluation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AG9LY2UP","conferencePaper","2020","Lutz, Otto Hans-Martin; Kröger, Jacob Leon; Schneiderbauer, Manuel; Kopankiewicz, Jan Maria; Hauswirth, Manfred; Hermann, Thomas","That password doesn't sound right: interactive password strength sonification","Proceedings of the 15th International Audio Mostly Conference","978-1-4503-7563-4","","10.1145/3411109.3412299","https://dl.acm.org/doi/10.1145/3411109.3412299","Despite 2-factor authentication and other modern approaches, authentication by password is still the most commonly used method on the Internet. Unfortunately, as analyses show, many users still choose weak and easy-to-guess passwords. To alleviate the significant effects of this problem, systems often employ textual or graphical feedback to make the user aware of this problem, which often falls short on engaging the user and achieving the intended user reaction, i.e., choosing a stronger password. In this paper, we introduce auditory feedback as a complementary method to remedy this problem, using the advantages of sound as an affective medium. We investigate the conceptual space of creating usable auditory feedback on password strength, including functional and non-functional requirements, influences and design constraints. We present web-based implementations of four sonification designs for evaluating different characteristics of the conceptual space and define a research roadmap for optimization, evaluation and applications.","2020-09-16","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","206–213","","","","","","That password doesn't sound right","AM '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/4KRPBYX5/Lutz et al. - 2020 - That password doesn't sound right interactive pas.pdf","","","sonification; interactive sonification; auditory feedback; auditory display; password security; password strength; usable security","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EGCLPEBF","conferencePaper","2012","Hermann, Thomas; Neumann, Alexander; Zehe, Sebastian","Head gesture sonification for supporting social interaction","Proceedings of the 7th Audio Mostly Conference: A Conference on Interaction with Sound","978-1-4503-1569-2","","10.1145/2371456.2371469","https://dl.acm.org/doi/10.1145/2371456.2371469","In this paper we introduce two new methods for real-time sonification of head movements and head gestures. Head gestures such as nodding or shaking the head are important non-verbal back-channelling signals which facilitate coordination and alignment of communicating interaction partners. Visually impaired persons cannot interpret such non-verbal signals, same as people in mediated communication (e.g. on the phone), or cooperating users whose visual attention is focused elsewhere. We introduce our approach to tackle these issues, our sensing setup and two different sonification methods. A first preliminary study on the recognition of signals shows that subjects understand the gesture type even without prior explanation and can estimate gesture intensity and frequency with no or little training.","2012-09-26","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","82–89","","","","","","","AM '12","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/MS6C8W8A/Hermann et al. - 2012 - Head gesture sonification for supporting social in.pdf","","","sonification; auditory display; assistive technology; head gestures; interaction technology; mediated communication; social interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"43E7L6YG","conferencePaper","2017","Wang, MinJuan; Lyckvi, Sus Lundgren; Chen, Chenhui; Dahlstedt, Palle; Chen, Fang","Using Advisory 3D Sound Cues to Improve Drivers' Performance and Situation Awareness","Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems","978-1-4503-4655-9","","10.1145/3025453.3025634","https://dl.acm.org/doi/10.1145/3025453.3025634","Within vehicle Human Machine Interface design, visual displays are predominant, taking up more and more of the visual channel for each new system added to the car, e.g. navigation systems, blind spot information and forward collision warnings. Sounds however, are mainly used to alert or warn drivers together with visual information. In this study we investigated the design of auditory displays for advisory information, by designing a 3D auditory advisory traffic information system (3DAATIS) which was evaluated in a drive simulator study with 30 participants. Our findings indicate that overall, drivers' performance and situation awareness improved when using this system. But, more importantly, the results also point towards the advantages and limitations of the use of advisory 3D-sounds in cars, e.g. attention capture vs. limited auditory resolution. These findings are discussed and expressed as design implications.","2017-05-02","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","2814–2825","","","","","","","CHI '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/FX2TXXEQ/Wang et al. - 2017 - Using Advisory 3D Sound Cues to Improve Drivers' P.pdf","","","auditory display; 3d auditory advisory traffic information system; drive behavior; in-vehicle design","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T95RPRI5","conferencePaper","2013","Ng, Patrick; Nesbitt, Keith","Informative sound design in video games","Proceedings of The 9th Australasian Conference on Interactive Entertainment: Matters of Life and Death","978-1-4503-2254-6","","10.1145/2513002.2513015","https://dl.acm.org/doi/10.1145/2513002.2513015","The importance of sound is quite well known in video games. Although frequently in the past sound was simply used to increase the immersion of the player. Now there is a growing interest in using sound as a means for providing the player with additional information. While the use of sound for displaying information has been a topic of research for a number of years, research into the area of informative sound design for games hasn't been widely investigated as such. As a result proper guidelines for game developers to follow when attempting to design informative sound for a game haven't been broadly established. In addition, there has been almost no work done in considering specific genres such as Real Time Strategy and First-Person Shooter games and how sounds can be best used to provide players with information in these types of games. In this work we review previous approaches to sound design including the use of patterns. We then review these approaches in relation to sound design for both FPS and RTS games. Finally we present some key design patterns in relation to these genres.","2013-09-30","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","1–9","","","","","","","IE '13","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/BQN54GNZ/Ng and Nesbitt - 2013 - Informative sound design in video games.pdf","","","auditory display; speech; auditory icons; earcons; sound design; computer games; design patterns; informative sound","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"75A2CZV3","conferencePaper","2020","Payne, William Christopher; Xu, Alex Yixuan; Ahmed, Fabiha; Ye, Lisa; Hurst, Amy","How Blind and Visually Impaired Composers, Producers, and Songwriters Leverage and Adapt Music Technology","Proceedings of the 22nd International ACM SIGACCESS Conference on Computers and Accessibility","978-1-4503-7103-2","","10.1145/3373625.3417002","https://dl.acm.org/doi/10.1145/3373625.3417002","Today, music creation software and hardware are central to the workflow of most professional composers, producers, and songwriters. Music is an aural art form, but it is notated graphically, and highly visual mainstream technologies pose significant accessibility barriers to blind and visually impaired users. Very few studies address the current state of accessibility in music technologies, and fewer propose alternative designs. To address a lack of understanding about the experiences of blind and visually impaired music technology users, we conducted an interview study with 11 music creators who, we demonstrate, find ingenious workarounds to bend inaccessible technologies to their needs, but still face persistent barriers including a lack of options, a limited but persistent need for sighted help, and accessibility features that fail to cover all use cases. We reflect on our findings and present opportunities and guidelines to promote more inclusive design of future music technologies.","2020-10-29","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","1–12","","","","","","","ASSETS '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/UZVYF8JC/Payne et al. - 2020 - How Blind and Visually Impaired Composers, Produce.pdf","","","accessibility; music technology; blindness; visual impairments; design; music creation; music learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7TD99YD7","conferencePaper","2010","Wolf, Katrin; Dicke, Christina; Grasset, Raphael","Touching the void: gestures for auditory interfaces","Proceedings of the fifth international conference on Tangible, embedded, and embodied interaction","978-1-4503-0478-8","","10.1145/1935701.1935772","https://dl.acm.org/doi/10.1145/1935701.1935772","Nowadays, mobile devices provide new possibilities for gesture interaction due to the large range of embedded sensors they have and their physical form factor. In addition, auditory interfaces can now be more easily supported through advanced mobile computing capabilities. Although different types of gesture techniques have been proposed for handheld devices, there is still little knowledge about the acceptability and use of some of these techniques, especially in the context of an auditory interface. In this paper, we propose a novel approach to the problem by studying the design space of gestures proposed by end-users for a mobile auditory interface. We discuss the results of this explorative study, in terms of the scope of the gestures proposed, the tangible aspects, and the users' preferences. This study delivers some initial gestures recommendations for eyes-free auditory interfaces.","2010-01-22","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","305–308","","","","","","Touching the void","TEI '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/C7EACREF/Wolf et al. - 2010 - Touching the void gestures for auditory interface.pdf","","","auditory display; gestures; embodied interaction; mobile; eyes-free; participatory design.; tangible interface","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A3RKV2CQ","conferencePaper","2017","Jeon, Myounghoon; FakhrHosseini, Maryam; Vasey, Eric; Nees, Michael A.","Blueprint of the Auditory Interactions in Automated Vehicles: Report on the Workshop and Tutorial","Proceedings of the 9th International Conference on Automotive User Interfaces and Interactive Vehicular Applications Adjunct","978-1-4503-5151-5","","10.1145/3131726.3131743","https://dl.acm.org/doi/10.1145/3131726.3131743","Vehicle automation is becoming more widespread. As automation increases, new opportunities and challenges have emerged. Given that vision is heavily taxed in driving, much research has been conducted on an auditory channel. To identify new design spaces and solutions, we have organized successive workshops and tutorial at International Conference on Auditory Display (ICAD) and AutoUI Conference for several years. In this report, we address novel opportunities and directions of auditory interactions in automated vehicles that we have discussed in the workshop and tutorial to design better driver user experience and secure road safety.","2017-09-24","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","178–182","","","","","","Blueprint of the Auditory Interactions in Automated Vehicles","AutomotiveUI '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/V4WV5QXB/Jeon et al. - 2017 - Blueprint of the Auditory Interactions in Automate.pdf","","","sonification; Auditory displays; situation awareness; exterior sound; sonic branding; speech; take-over request","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PM3QC3P8","conferencePaper","2009","Berman, Lewis I.; Gallagher, Keith B.","Using sound to understand software architecture","Proceedings of the 27th ACM international conference on Design of communication","978-1-60558-559-8","","10.1145/1621995.1622019","https://dl.acm.org/doi/10.1145/1621995.1622019","Use of non-speech sound can facilitate the understanding of a software program. Non-speech sound has been shown to be useful in dynamic program comprehension, that is, understanding the dynamic behavior of a program. We have developed a sonification scheme to describe static software entities in Java programs, and we show that it is useful in static program comprehension, notably concerning low-level architecture. The scheme is implemented via a tool in which an Eclipse IDE is integrated with a CSound synthesis engine. The tool is intended for use by sighted software developers in a static browsing/editing environment. A validation study of the concept has been performed via one-on-one sessions with experienced software developers. Preliminary results indicate that software developers are easily able to learn and recognize sonified characteristics of software entities and their relationships by listening to sequences of mapped sound constructs. Identification of specific entities is more problematic. Developers have indicated that they would find the tool useful during both exploration and more focused programming activities. Their additional perceptions have been collected using grounded qualitative means.","2009-10-05","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","127–134","","","","","","","SIGDOC '09","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/MQKEZATT/Berman and Gallagher - 2009 - Using sound to understand software architecture.pdf","","","sonification; multimodal; auditory display; comprehension; architecture; eclipse; non-visual representations; program comprehension; software architecture","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MGF9H8NW","conferencePaper","2016","Grønbæk, Jens Emil; Jakobsen, Kasper Buhl; Petersen, Marianne Graves; Rasmussen, Majken Kirkegård; Winge, Jakob; Stougaard, Jeppe","Designing for Children's Collective Music Making: How Spatial Orientation and Configuration Matter","Proceedings of the 9th Nordic Conference on Human-Computer Interaction","978-1-4503-4763-1","","10.1145/2971485.2971552","https://dl.acm.org/doi/10.1145/2971485.2971552","Hitmachine empowers children to make music through building physical, shared interactive instruments from Lego Mindstorms™ and playing them to a beat. The design rationale for Hitmachine draws upon the collective interaction model, theories of proxemics and F-formations, as well as a framework for social interaction. Hitmachine was evaluated during a 4-day workshop where 150 children aged 3-13 engaged with the system. Based on lessons from this workshop we point to key issues to consider when designing for collective music making. This includes designing for multiple access points and spatial orientation of these, designing for sense of impact as well as sense of control, and giving careful consideration to how the spatial configuration of technological artifacts and furniture can provide opportunities for social interaction.","2016-10-23","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","1–10","","","","","","Designing for Children's Collective Music Making","NordiCHI '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/FWEX22T9/Grønbæk et al. - 2016 - Designing for Children's Collective Music Making .pdf","","","Collective interaction; Embodied constraints; F-formations; Proxemics; Social interaction; Tangible music","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"USHA29PF","conferencePaper","2011","Schaffert, Nina; Mattes, Klaus; Effenberg, Alfred O.","Examining effects of acoustic feedback on perception and modification of movement patterns in on-water rowing training","Proceedings of the 6th Audio Mostly Conference: A Conference on Interaction with Sound","978-1-4503-1081-9","","10.1145/2095667.2095685","https://dl.acm.org/doi/10.1145/2095667.2095685","This paper describes a concept for providing acoustic feedback during on-water training to elite rowers and its implementation into the training process. The final aim was to improve the mean boat velocity by a reduction of intra-cyclic interruptions in the boat acceleration. It was assumed to enhance athletes' perception for the modification of movement patterns and control in technique training because sound conveys time-critical structures subliminally. That is of crucial importance for the precision of modifying movements to improve their execution. Advances in technology allow the design for innovative feedback systems to communicate feedback information audibly to athletes. The acoustic feedback system Sofirow was designed and field-tested with elite athletes. The device presents the boat acceleration-time trace audibly and online to athletes and coaches. The results showed a significant increase in the mean boat velocity during the sections with acoustic feedback compared to the sections without. It is thus very supportive to implement acoustic feedback regularly into training processes for elite athletes. A behavioral dynamics approach was invoked to provide a theoretical basis for this concept.","2011-09-07","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","122–129","","","","","","","AM '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/5JJYLRRF/Schaffert et al. - 2011 - Examining effects of acoustic feedback on percepti.pdf","","","interactive sonification; auditory display; movement sonification; acoustic feedback; auditory information; elite athletes; motion perception; movement optimization; multi-sensory information; online feedback training; rowing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UVA58L4C","conferencePaper","2016","Yu, Bin; Hu, Jun; Funk, Mathias; Feijs, Loe","A Study on User Acceptance of Different Auditory Content for Relaxation","Proceedings of the Audio Mostly 2016","978-1-4503-4822-5","","10.1145/2986416.2986418","https://dl.acm.org/doi/10.1145/2986416.2986418","The use of auditory interface at the relaxation-assisted interactive system is becoming increasingly popular. This study aims to investigate the effects of different types of auditory content on the subjective relaxation experience. The participants listened to fifteen sound samples from five categories: (a) nature white noise, (b) natural soundscape, (c) ambient music, (d) instrumental music, (e) instrumental music mixed with the natural soundscape. These auditory contents were selected or designed specifically for assisting relaxation. The study measured the subjective relaxation rating after listening to each sample and interviewed the listeners to understand what causes the differences in relaxation experience. The results indicate that the instrumental music and the combination of nature soundscape and music might be a better auditory content or audio form to induce relaxation compared to the ambient music, pure natural soundscape, and nature white noise. The findings of this study can be used in the design of musical and auditory display in many interactive systems for stress mitigation and relaxation exercises.","2016-10-04","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","69–76","","","","","","","AM '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/W5MNWCYN/Yu et al. - 2016 - A Study on User Acceptance of Different Auditory C.pdf","","","Music; Auditory interface; Nature sounds; Relaxation; User experience","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WJLK6DNB","conferencePaper","2022","Zheng, Haiyun; Jiang, Zhengqing","Comparative Study of Music Visualization based on CiteSpace at China and the World","Proceedings of the 2021 5th International Conference on Computer Science and Artificial Intelligence","978-1-4503-8415-5","","10.1145/3507548.3507604","https://dl.acm.org/doi/10.1145/3507548.3507604","Music visualization is a visual art form for understanding, analyzing and comparing the internal structure and expressive features of music. It meets the aesthetic demand of the masses in the digital age. This paper reviews the development and research status of the music visualization literature in the past 20 years, comprehensively analyzes the research process and current hotspots of music visualization, and speculates the future development trend. We have used Web of Science (WoS) and China National Knowledge Infrastructure (CNKI) as data sources, used CiteSpace software to compare and analyze the year, country, subject distribution and hot keywords of music visualization literature at China and the world from 2000 to 2020 by the method of Mapping Knowledge Domain. The results show that the research on music visualization at China and other countries is showing an upward trend, and it presents the characteristics of multi-disciplinary integration. Different application scenarios, research methods and development stages lead to different research hotspots between different countries. The shortcomings of Chinese research in this field lies in that the research content needs to be deepened, the interdisciplinary content needs to be integrated, and applications of music visualization needs to be popularized.","2022-03-09","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","365–371","","","","","","","CSAI '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/BDY7JQEJ/Zheng and Jiang - 2022 - Comparative Study of Music Visualization based on .pdf","","","CiteSpace; Mapping Knowledge Domain; Music Visualization; Visual Analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2PQ4CN89","conferencePaper","2010","Cohen, Michael","Under-explored dimensions in spatial sound","Proceedings of the 9th ACM SIGGRAPH Conference on Virtual-Reality Continuum and its Applications in Industry","978-1-4503-0459-7","","10.1145/1900179.1900199","https://dl.acm.org/doi/10.1145/1900179.1900199","An introduction to spatial sound in the context of hypermedia, interactive multimedia, and virtual reality is presented. Basic principals of relevant physics and psychophysics are reviewed (ITDs: interaural time differences, IIDs: interaural intensity differences, and frequency-dependent attenuation capturable by transfer functions). Modeling of sources and sinks (listeners) elaborates such models to include such as intensity, radiation, distance attenuation & filtering, and reflections & reverberation. Display systems---headphones and headsets, loudspeakers, nearphones, stereo, home theater and other surround systems, discrete speaker systems, speaker arrays, WFS (wave field synthesis), and spatially immersive displays---are described. Distributed applications are surveyed, including stereotelephony, chat-spaces, and massively multiplayer online role-playing games (MMORPGs), with references to immersive virtual environments.","2010-12-12","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","95–102","","","","","","","VRCAI '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/NGWREIY8/Cohen - 2010 - Under-explored dimensions in spatial sound.pdf","","","ambient media; awareware; impulse response; narrowcasting; pervasive computing; transfer function; ubicomp (ubiquitous computing); virtual auditory display; wearware; whereware","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EBFAWN3K","conferencePaper","2022","Weger, Marian; Svoronos-Kanavas, Iason; Höldrich, Robert","Schrödinger’s box: an artifact to study the limits of plausibility in auditory augmentations","Proceedings of the 17th International Audio Mostly Conference","978-1-4503-9701-8","","10.1145/3561212.3561222","https://dl.acm.org/doi/10.1145/3561212.3561222","For every physical interaction with our environment, we have some expectations concerning the resulting sound. As these expectations are quite rough, the auditory feedback can be modulated to convey additional information, without restricting the object’s original purpose. Such auditory augmentation is calm and unobtrusive as long it stays plausible with respect to the performed action. The plausibility range defines a hard limit for the information capacity of the auditory display. In order to maximize the information capacity of auditory augmentations, an estimate of the plausibility range of augmented auditory feedback is required. Here we present Schrödinger’s box, a mobile hardware- and software-platform that is designed for exploring the limits of plausibility of auditory feedback for unknown sounding objects. It renders augmented auditory feedback for its one and only affordance: striking it with a mallet. While hiding all electronics from the users, it meets the extreme requirements of latency that are necessary so that the original auditory feedback is effectively masked by the synthetic auditory feedback. With Schrödinger’s box, we now have a valuable research tool, not only for optimizing auditory augmentations, but also for investigating the plausibility of auditory feedback in general.","2022-10-10","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","15–23","","","","","","Schrödinger’s box","AM '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/XM68LLI2/Weger et al. - 2022 - Schrödinger’s box an artifact to study the limits.pdf","","","auditory feedback; sonic interaction design; augmented reality; auditory augmentation; onset detection; plausibility; sounding object","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8NYUJGLK","conferencePaper","2012","Neidhardt, Annika; Rüppel, Anna","Multiplayer audio-only game: Pong on a massive multichannel loudspeaker system","Proceedings of the 7th Audio Mostly Conference: A Conference on Interaction with Sound","978-1-4503-1569-2","","10.1145/2371456.2371477","https://dl.acm.org/doi/10.1145/2371456.2371477","Interactive auditory displays are an interesting possibility presenting information in an alternative way. There have been lots of interesting works using binaural techniques. The use of a loudspeaker system has the advantage that more people can listen to the same data simultaneously. One application, where this is very important, is the audio gaming domain, as multiplayer games are usually more exciting. Additionally, the use of a loudspeaker system allows different dimensions of the game design. The main challenge in developing an interactive auditory display for a loudspeaker system is the design of the data sonification and the interaction for data exploration. In this paper we present an example implementation of such an interactive auditory display. The famous game Pong has been implemented using an audio-only loudspeaker display instead of a graphical. The goal of this investigation is to gather more experience in the perception of spatial audio-only representation of information.","2012-09-26","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","130–134","","","","","","Multiplayer audio-only game","AM '12","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/FNLM3KY8/Neidhardt and Rüppel - 2012 - Multiplayer audio-only game Pong on a massive mul.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2YEDABTA","conferencePaper","2017","Roddy, S.","Composing The Good Ship Hibernia and the Hole in the Bottom of the World","Proceedings of the 12th International Audio Mostly Conference on Augmented and Participatory Sound and Music Experiences","978-1-4503-5373-1","","10.1145/3123514.3123520","https://dl.acm.org/doi/10.1145/3123514.3123520","This paper explores topics in embodied cognition, soundscape composition and sonification. It explains the compositional decisions and technical considerations that went into the composition of the piece The Good Ship Hibernia, which is an example of embodied soundscape sonification. This explanation is undertaken within the context of an approach to both sonification design and music composition that accounts for and exploits the embodied aspects of meaning-making in auditory cognition as described in the embodied cognitive science literature.","2017-08-23","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","1–6","","","","","","","AM '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/8MW7XZMV/Roddy - 2017 - Composing The Good Ship Hibernia and the Hole in t.pdf","","","Sonification; Music; Composition; Data-driven; Financial Data","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U88JTUAX","conferencePaper","2021","Winters, R. Michael; Walker, Bruce N.; Leslie, Grace","Can You Hear My Heartbeat?: Hearing an Expressive Biosignal Elicits Empathy","Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems","978-1-4503-8096-6","","10.1145/3411764.3445545","https://dl.acm.org/doi/10.1145/3411764.3445545","Interfaces designed to elicit empathy provide an opportunity for HCI with important pro-social outcomes. Recent research has demonstrated that perceiving expressive biosignals can facilitate emotional understanding and connection with others, but this work has been largely limited to visual approaches. We propose that hearing these signals will also elicit empathy, and test this hypothesis with sounding heartbeats. In a lab-based within-subjects study, participants (N = 27) completed an emotion recognition task in different heartbeat conditions. We found that hearing heartbeats changed participants’ emotional perspective and increased their reported ability to “feel what the other was feeling.” From these results, we argue that auditory heartbeats are well-suited as an empathic intervention, and might be particularly useful for certain groups and use-contexts because of its musical and non-visual nature. This work establishes a baseline for empathic auditory interfaces, and offers a method to evaluate the effects of future designs.","2021-05-07","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","1–11","","","","","","Can You Hear My Heartbeat?","CHI '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/7P7NBKWC/Winters et al. - 2021 - Can You Hear My Heartbeat Hearing an Expressive .pdf","","","music; emotion; physiology; AAC; affect; ASD; communication; empathy; heart rate; rhythm; sound","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D6RR5W44","conferencePaper","2013","Schuett, Jonathan H.; Walker, Bruce N.","Measuring comprehension in sonification tasks that have multiple data streams","Proceedings of the 8th Audio Mostly Conference","978-1-4503-2659-9","","10.1145/2544114.2544121","https://dl.acm.org/doi/10.1145/2544114.2544121","When the goal of an auditory display is to provide inference or intuition to a listener, it is important for researchers and sound designers to gauge users' comprehension of the display to determine if they are, in fact, receiving the correct message. This paper discusses an approach to measuring listener comprehension in sonifications that contain multiple concurrently presented data series. We draw from situation awareness research that has developed measures of comprehension within environments or scenarios, based on our view that an auditory scene is similar to a virtual or mental representation of the listener's environment.","2013-09-18","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","1–6","","","","","","","AM '13","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/MC2WVWAC/Schuett and Walker - 2013 - Measuring comprehension in sonification tasks that.pdf","","","sonification; auditory displays; comprehension; multiple data series; situation awareness","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z396E5AT","conferencePaper","2014","Schuett, Jonathan H.; Winton, Riley J.; Batterman, Jared M.; Walker, Bruce N.","Auditory weather reports: demonstrating listener comprehension of five concurrent variables","Proceedings of the 9th Audio Mostly: A Conference on Interaction With Sound","978-1-4503-3032-9","","10.1145/2636879.2636898","https://dl.acm.org/doi/10.1145/2636879.2636898","Displaying multiple variables or data sets within a single sonification has been identified as a challenge for the field of auditory display research. We discuss our recent study that evaluates the usability of a sonification that contains multiple variables presented in a way that encouraged perception across multiple auditory streams. We measured listener comprehension of weather sonifications that include the variables of temperature, humidity, wind speed, wind direction, and cloud cover. Listeners could accurately identify trends in five concurrent variables presented together in a single sonification. This demonstrates that it is indeed possible to include multiple variables together within an auditory stream and thus a greater number of variables within a sonification.","2014-10-01","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","1–7","","","","","","Auditory weather reports","AM '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/M93477RD/Schuett et al. - 2014 - Auditory weather reports demonstrating listener c.pdf","","","sonification; auditory displays; comprehension; auditory scene analysis; multiple streams; stream segregation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VPNQ8SZ9","conferencePaper","2008","Coleman, Graeme W.; Macaulay, Catriona; Newell, Alan F.","Sonic mapping: towards engaging the user in the design of sound for computerized artifacts","Proceedings of the 5th Nordic conference on Human-computer interaction: building bridges","978-1-59593-704-9","","10.1145/1463160.1463170","https://dl.acm.org/doi/10.1145/1463160.1463170","This paper argues for new approaches to the design of sound for contemporary interactive technologies. We begin by presenting what we feel to be the key challenges as yet unaddressed by conventional auditory display research. Subsequently, we propose a user-centered, acoustic ecology-informed, design method that we feel can be built upon to inform the design of sound for contemporary interactive technologies, thus tackling some of the challenges introduced. Our approach consists of three stages: firstly, encouraging designers and users to experience the original auditory environment, identifying the key sounds within that environment, and then summarizing this information into an 'earwitness account' that can be used as a prelude for informing the design of sonically enhanced technologies that may be used within similar environments. By trialing this method with undergraduate interactive media design students, we identify the methodological challenges involved in attempting to engage people, who are not necessarily 'sound professionals', with their existing auditory environments. We highlight the opportunities that arise and pitfalls that should be avoided when attempting to introduce such approaches within real-world design studies.","2008-10-20","2023-07-06 05:53:57","2023-07-06 05:53:57","2023-07-05","83–92","","","","","","Sonic mapping","NordiCHI '08","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/H3D49EZI/Coleman et al. - 2008 - Sonic mapping towards engaging the user in the de.pdf","","","acoustic ecology; soundscapes; auditory environments; auditory interfaces; non-speech sound; user-centered design methods","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"78V7QPBS","conferencePaper","2008","Dodiya, Janki; Alexandrov, Vassil N.","Use of auditory cues for wayfinding assistance in virtual environment: music aids route decision","Proceedings of the 2008 ACM symposium on Virtual reality software and technology","978-1-59593-951-7","","10.1145/1450579.1450615","https://dl.acm.org/doi/10.1145/1450579.1450615","This paper addresses the crucial problem of wayfinding assistance in the Virtual Environments (VEs). A number of navigation aids such as maps, agents, trails and acoustic landmarks are available to support the user for navigation in VEs, however it is evident that most of the aids are visually dominated. This work-in-progress describes a sound based approach that intends to assist the task of 'route decision' during navigation in a VE using music. Furthermore, with use of musical sounds it aims to reduce the cognitive load associated with other visually as well as physically dominated tasks. To achieve these goals, the approach exploits the benefits provided by music to ease and enhance the task of wayfinding, whilst making the user experience in the VE smooth and enjoyable.","2008-10-27","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","171–174","","","","","","Use of auditory cues for wayfinding assistance in virtual environment","VRST '08","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/IEMTL2R7/Dodiya and Alexandrov - 2008 - Use of auditory cues for wayfinding assistance in .pdf","","","virtual environments; auditory navigation; sound and music perception; wayfinding aids","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JGN4U6IY","conferencePaper","2018","Smith, Brian A.; Nayar, Shree K.","The RAD: Making Racing Games Equivalently Accessible to People Who Are Blind","Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems","978-1-4503-5620-6","","10.1145/3173574.3174090","https://dl.acm.org/doi/10.1145/3173574.3174090","We introduce the racing auditory display (RAD), an audio-based user interface that allows players who are blind to play the same types of racing games that sighted players can play with an efficiency and sense of control that are similar to what sighted players have. The RAD works with a standard pair of headphones and comprises two novel sonification techniques: the sound slider for understanding a car's speed and trajectory on a racetrack and the turn indicator system for alerting players of the direction, sharpness, length, and timing of upcoming turns. In a user study with 15 participants (3 blind; the rest blindfolded and analyzed separately), we found that players preferred the RAD's interface over that of Mach 1, a popular blind-accessible racing game. We also found that the RAD allows an avid gamer who is blind to race as well on a complex racetrack as casual sighted players can, without a significant difference between lap times or driving paths.","2018-04-21","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","1–12","","","","","","The RAD","CHI '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/L9LZ4YCW/Smith and Nayar - 2018 - The RAD Making Racing Games Equivalently Accessib.pdf","","","sonification; accessibility; audio games; accessible games","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PQDDBL9C","conferencePaper","2011","Hug, Daniel; Misdariis, Nicolas","Towards a conceptual framework to integrate designerly and scientific sound design methods","Proceedings of the 6th Audio Mostly Conference: A Conference on Interaction with Sound","978-1-4503-1081-9","","10.1145/2095667.2095671","https://dl.acm.org/doi/10.1145/2095667.2095671","Sound design for interactive products is rapidly evolving to become a relevant topic in industry. Scientific research from the domains of Auditory Display (AD) and Sonic Interaction Design (SID) can play a central role in this development, but in order to make its way to market oriented applications, several issues still need to be addressed. Building on the sound design process employed at the Sound Perception and Design (SPD) team at Ircam, and the information gathered from interviews with professional sound designers, this paper focuses on revealing typical issues encountered in the design process of both science and design oriented communities, in particular the development of a valid and revisable, yet innovative, design hypothesis. A second aim is to improve the communication between sound and interaction designers. In order to address these challenges, a conceptual framework, which has been developed using both scientific and designerly methods, was presented and evaluated using expert reviews.","2011-09-07","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","23–30","","","","","","","AM '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/RNNGZGNE/Hug and Misdariis - 2011 - Towards a conceptual framework to integrate design.pdf","","","sonic interaction design; sound design; interactive commodities","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UBPFZT66","conferencePaper","2014","Cruz, Pablo","A parameter mapping sonification for price differences in market research studies","Proceedings of the 7th Euro American Conference on Telematics and Information Systems","978-1-4503-2435-9","","10.1145/2590651.2590777","https://dl.acm.org/doi/10.1145/2590651.2590777","Differences in prices registered in market research studies are common. Visualization of the price differences is difficult to develop and understand as several attributes are considered by the analysts. An alternative to visualization of the price differences is sonification, a kind of auditory display, in which these attributes and relations are translated into sound. In this paper we present a parameter mapping sonification for differences of prices in market research studies. As a proof of concept, we show results from an implementation of the sonification which creates four samples, one for each category of differences defined in this work. Also we describe its use and its benefits in a real market research environment.","2014-04-02","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","1–6","","","","","","","EATIS '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/E8SGU99L/Cruz - 2014 - A parameter mapping sonification for price differe.pdf","","","sonification; auditory displays; numerical sound synthesis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XC49FE7M","conferencePaper","2008","Song, Hong Jun; Beilharz, Kirsty","Aesthetic and auditory enhancements for multi-stream information sonification","Proceedings of the 3rd international conference on Digital Interactive Media in Entertainment and Arts","978-1-60558-248-1","","10.1145/1413634.1413678","https://dl.acm.org/doi/10.1145/1413634.1413678","Sonification is an emerging modality of information representation, the auditory equivalent of visualization employing non-speech sound to display attributes of form, pattern, recurrence and trends in abstract data. Like data-art or visual and auditory art-forms driven by data content directly mapped to their rendering, sonification shares the goal of aesthetic representation (auditory graphing) in a way to better and more accessibly convey the message to broader consumer audiences. Often, the simple re-contextualization of dense abstract data in an auditory graph (or sonification) is sufficient to highlight long-term trends, to hear regularities (patterns) and anomalies in periodicity of time-series data and to assimilate very subtle and fine transformations. Sonification is also optimal for certain working or ambient situations that are visually rich or visually saturated, when we seek to command topical and peripheral attention with relevant cues. Auditory display is also an alternative to visualization for people with visual impairments. Exploring the premise that sonification should be both aesthetic and informative, i.e. listenable, attractive and engaging, this paper summarises the findings of 3 experiments conducted to determine ways to better represent and access dense information mapped on to more than one concurrent stream of information. Specifically, we show evidence that spatialization of informative events coinciding in time can be more clearly distinguished and that timbre (or tone colour / tone quality) characteristics can serve to further reinforce spatial and stream separation. These findings combine to develop comprehensible methods for representing complex data-sets. We consider human cognition, auditory perception and audio reproduction technologies that each influence the ability to display information sonically.","2008-09-10","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","224–231","","","","","","","DIMEA '08","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/ESPKTSLY/Song and Beilharz - 2008 - Aesthetic and auditory enhancements for multi-stre.pdf","","","auditory stream segregation; concurrent auditory graphing; information sonification; spatialization; timbre","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AS3LXJQ6","conferencePaper","2022","Xin, Xin; Wang, Yiji; Xiang, Guo; Yang, Wenmin; Liu, Wei","Effectiveness of Multimodal Display in Navigation Situation","The Ninth International Symposium of Chinese CHI","978-1-4503-8695-1","","10.1145/3490355.3490361","https://dl.acm.org/doi/10.1145/3490355.3490361","With the development of technology, the interactive experience in the car has become more abundant, drivers have to face a large amount of information. In the navigation situation, drivers need to receive navigation information to make correct driving behavior, but this may increase drivers’ workload. The current display includes visual display, auditory display, and haptic display, but they have limitations. In order to solve the above problems and provide more suggestions for driving safety, this research explored the effectiveness of multimodal display and its merits than unimodal display in the navigation situation, dependent variables are driving behavior performance and subjective mental workload, eye tracking behavior. We adopted interview to explore current navigation situations and classified lane changing and turning have high workload than straight driving. The simulated driving experiment conducted in the later stage of research, it is 2 × 5 mixed experiment, the between-subjects factors are navigation situations (high load, low load), and the within-subjects’ factors are information display methods (visual, auditory, haptic, multimodal, control). The experiment recruited 18 participants and randomly divided them into two groups to experience each information display in turn. It is found that the multimodal display is good than visual modality under high load situations, and the lateral speed control of the driver is more stable under the multimodal condition. Although the mental workload of drivers under multimodal conditions did not show a significant difference from other conditions, the scores were still lower than other conditions. The multimodal display has the potential to ensure driving safety, but it need further research to discuss.","2022-02-07","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","50–62","","","","","","","Chinese CHI 2021","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/SUBRF6XL/Xin et al. - 2022 - Effectiveness of Multimodal Display in Navigation .pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CR252YT2","conferencePaper","2015","Seibert, Gabriela; Hug, Daniel; Cslovjecsek, Markus","Towards an Enactive Swimming Sonification: Exploring Multisensory Design and Musical Interpretation","Proceedings of the Audio Mostly 2015 on Interaction With Sound","978-1-4503-3896-7","","10.1145/2814895.2814902","https://dl.acm.org/doi/10.1145/2814895.2814902","In this paper we present a design method that integrates the exploration of visual representations and musical expertise in the process of creating a swimming sonification, and initial results of the method's application in an explorative study. Our focus lies on the creation of a sonic representation that facilitates the affective, intuitive reproduction of the crawl swim movement. The method integrates artistic creativity and a systematic design process. By combining the linguistic-conceptual, visual and auditory representation of the (imagined) movement, we aim to advance the expressive quality of the sonic representation as well as the design method in a crossmodal, holistic way. Finally we report on a qualitative evaluation of the potential of this approach to support the affective, intuitive re-enactment of the swimming movement.","2015-10-07","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","1–8","","","","","","Towards an Enactive Swimming Sonification","AM '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/Y9W4D7YG/Seibert et al. - 2015 - Towards an Enactive Swimming Sonification Explori.pdf","","","Enactive Design; Movement Sonification; Multisensory Design; Musical Improvisation; Sonic Representation; Swimming Sport Training; Visual Musical Score","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ADCC3EJB","conferencePaper","2018","Godbout, Andrew; Popa, Iulius A. T.; Boyd, Jeffrey E.","Emotional Musification","Proceedings of the Audio Mostly 2018 on Sound in Immersion and Emotion","978-1-4503-6609-0","","10.1145/3243274.3243303","https://dl.acm.org/doi/10.1145/3243274.3243303","We present a method for emotional musification that utilizes the musical game MUSE. We take advantage of the strong links between music and emotion to represent emotions as music. While we provide a prototype for measuring emotion using facial expression and physiological signals our sonification is not dependent on this. Rather we identify states within MUSE that elicit certain emotions and map those onto the arousal and valence spatial representation of emotion. In this way our efforts are compatible with emotion detection methods which can be mapped to arousal and valence. Because MUSE is based on states and state transitions we gain the ability to transition seamlessly from one state to another as new emotions are detected thus avoiding abrupt changes between music types.","2018-09-12","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","1–6","","","","","","","AM'18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/9PG8GUGR/Godbout et al. - 2018 - Emotional Musification.pdf","","","Sonification; Emotion; Process Music","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SR4NP7HL","conferencePaper","2014","Marentakis, Georgios; Liepins, Rudolfs","Evaluation of hear-through sound localization","Proceedings of the SIGCHI Conference on Human Factors in Computing Systems","978-1-4503-2473-1","","10.1145/2556288.2557168","https://dl.acm.org/doi/10.1145/2556288.2557168","Listening and interacting with audio commonly relies on using earphones which limit the ability of users to perceive their auditory environment. Earphone sets that integrate miniature microphones on their exterior can, however, be used to hear-through the auditory environment. We present an evaluation study in which sound localization when wearing such a hear-through system is compared to normal earphones, open headphones and unblocked ears. Although localization performance is improved compared to open headphones, we find that it is compromised in comparison to listening without earphones because confusions of sound direction increase and localization judgment distributions are more dispersed and show a weaker correlation to the test directions. The implications of the results to human computer interaction and possible improvements to hear-through system design are discussed.","2014-04-26","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","267–270","","","","","","","CHI '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/M96J4JTY/Marentakis and Liepins - 2014 - Evaluation of hear-through sound localization.pdf","","","auditory augmented reality; hear-through systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U4E92LTK","conferencePaper","2017","Sterkenburg, Jason; Landry, Steven; Jeon, Myounghoon","Eyes-free In-vehicle Gesture Controls: Auditory-only Displays Reduced Visual Distraction and Workload","Proceedings of the 9th International Conference on Automotive User Interfaces and Interactive Vehicular Applications Adjunct","978-1-4503-5151-5","","10.1145/3131726.3131747","https://dl.acm.org/doi/10.1145/3131726.3131747","Visual distractions increase crash risk while driving. Our research focuses on creating and evaluating an air gesture control system that is less visually demanding than current infotainment systems. We completed a within-subjects experiment with 24 participants, each of whom completed a simulated drive while using six different prototypes, in turn. The primary research questions were the influence of combinations of visual and auditory displays (visual, visual/auditory, auditory) and control orientation (vertical vs horizontal). We recorded lane departures, eye glance behavior, secondary task performance, and driver workload. Results demonstrated that for lane departures all prototypes performed comparably, with the auditory-only showing a strong tendency of improvements. A deeper look illustrated a tradeoff between eyes-on-road time and secondary task completion time for the auditory-only display -- the safest but slowest among the six prototypes. The auditory-only also reduced overall workload. Control orientation showed only small subjective effect in favor of vertical controls.","2017-09-24","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","195–200","","","","","","Eyes-free In-vehicle Gesture Controls","AutomotiveUI '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/5JULRMTP/Sterkenburg et al. - 2017 - Eyes-free In-vehicle Gesture Controls Auditory-on.pdf","","","Auditory displays; driving simulation; compatibility; in-air gesture controls","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IW973V4R","conferencePaper","2021","Enge, Kajetan; Rind, Alexander; Iber, Michael; Höldrich, Robert; Aigner, Wolfgang","It’s about Time: Adopting Theoretical Constructs from Visualization for Sonification","Proceedings of the 16th International Audio Mostly Conference","978-1-4503-8569-5","","10.1145/3478384.3478415","https://dl.acm.org/doi/10.1145/3478384.3478415","Both sonification and visualization convey information about data by effectively using our human perceptual system, but their ways to transform the data could not be more different. The sonification community has demanded a holistic perspective on data representation, including audio-visual analysis, several times during the past 30 years. A design theory of audio-visual analysis could be a first step in this direction. An indispensable foundation for this undertaking is a terminology that describes the combined design space. To build a bridge between the domains, we adopt two of the established theoretical constructs from visualization theory for the field of sonification. The two constructs are the spatial substrate and the visual mark. In our model, we choose time to be the temporal substrate of sonification. Auditory marks are then positioned in time, such as visual marks are positioned in space. The proposed definitions allow discussing visualization and sonification designs as well as multi-modal designs based on a common terminology. While the identified terminology can support audio-visual analytics research, it also provides a new perspective on sonification theory itself.","2021-10-15","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","64–71","","","","","","It’s about Time","AM '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/RKRPRZ98/Enge et al. - 2021 - It’s about Time Adopting Theoretical Constructs f.pdf","","","Audio-Visual Data Analysis; Sonification Theory; Visualization Theory","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7EZG3BPN","conferencePaper","2019","Cherng, Fu-Yin; Lee, Yi-Chen; King, Jung-Tai; Lin, Wen-Chieh","Measuring the Influences of Musical Parameters on Cognitive and Behavioral Responses to Audio Notifications Using EEG and Large-scale Online Studies","Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems","978-1-4503-5970-2","","10.1145/3290605.3300639","https://dl.acm.org/doi/10.1145/3290605.3300639","Prior studies have evaluated various designs for audio notifications. However, calls for more in-depth research on how such notifications work, especially at the level of users' cognitive states, have gone unanswered; and studies evaluating audio notifications with large numbers of participants in multiple environments have been rare. This study conducted an electroencephalography study (N=20) and an online study (N=967) to enhance understandings of how three musical parameters - melody (simple, complex), pitch (high, low), and tempo (fast, slow) - influenced users' cognition and behaviors. There are eight different notifications with different combinations of these parameters. The online study analyzed the effects of user-specific and environmental information on users' behaviors while they listened to these notifications. The results revealed that tempo and pitch have the main effect on the speed and strength (accuracy) of users' cognition and behaviors. The users' characteristics and environments influenced the effects of these musical parameters.","2019-05-02","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","1–12","","","","","","","CHI '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/ALYKXNA5/Cherng et al. - 2019 - Measuring the Influences of Musical Parameters on .pdf","","","audio notifications; brain-computer interface; neuroergonomics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5ZIIUEIZ","conferencePaper","2014","Frisson, Christian; Dupont, Stéphane; Yvart, Willy; Riche, Nicolas; Siebert, Xavier; Dutoit, Thierry","AudioMetro: directing search for sound designers through content-based cues","Proceedings of the 9th Audio Mostly: A Conference on Interaction With Sound","978-1-4503-3032-9","","10.1145/2636879.2636880","https://dl.acm.org/doi/10.1145/2636879.2636880","Sound designers source sounds in massive collections, heavily tagged by themselves and sound librarians. For each query, once successive keywords attained a limit to filter down the results, hundreds of sounds are left to be reviewed. AudioMetro combines a new content-based information visualization technique with instant audio feedback to facilitate this part of their workflow. We show through user evaluations by known-item search in collections of textural sounds that a default grid layout ordered by filename unexpectedly outperforms content-based similarity layouts resulting from a recent dimension reduction technique (Student-t Stochastic Neighbor Embedding), even when complemented with content-based glyphs that emphasize local neighborhoods and cue perceptual features. We propose a solution borrowed from image browsing: a proximity grid, whose density we optimize for nearest neighborhood preservation among the closest cells. Not only does it remove overlap but we show through a subsequent user evaluation that it also helps to direct the search. We based our experiments on an open dataset (the OLPC sound library) for replicability.","2014-10-01","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","1–8","","","","","","AudioMetro","AM '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/NS9QNWS4/Frisson et al. - 2014 - AudioMetro directing search for sound designers t.pdf","","","music information retrieval; content-based similarity; known-item search; media browsers; sound effects; visual variables","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7RHBLTES","conferencePaper","2020","Hug, Daniel","How do you sound design? an exploratory investigation of sound design process visualizations","Proceedings of the 15th International Audio Mostly Conference","978-1-4503-7563-4","","10.1145/3411109.3411144","https://dl.acm.org/doi/10.1145/3411109.3411144","Sound design is increasingly diversifying into many areas beyond its traditional domains in film, television, radio or theatre. This leads to sound designers being confronted with a multitude of design and development processes. The related methodologies have an impact on how problems are framed and what is considered an ideal path to achieve their solutions. From this a need for an educated discourse in sound design education and professional practice arises. This article investigates the creative process from the perspective of an emerging generation of sound designers. The first part of the paper outlines concepts and models of the design process in various fields of practice. The second part is devoted to an interpretive comparative analysis of sound design process visualizations created by sound design students with a professional background. Apart from gaining a better understanding of the creative process of the sound designers, the goal of this work is to contribute to a better integration of the sound design craft into contemporary design process methodologies, ultimately leading to an empowerment of the sound designer in complex, dynamic and interdisciplinary project settings.","2020-09-16","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","114–121","","","","","","How do you sound design?","AM '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/ZM7ZVB97/Hug - 2020 - How do you sound design an exploratory investigat.pdf","","","sound design; methodology; design process; sound design education","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BV2MXFNI","conferencePaper","2011","Floros, Andreas; Tatlas, Nicolas-Alexander; Potirakis, Stylianos","Sonic perceptual crossings: a tic-tac-toe audio game","Proceedings of the 6th Audio Mostly Conference: A Conference on Interaction with Sound","978-1-4503-1081-9","","10.1145/2095667.2095680","https://dl.acm.org/doi/10.1145/2095667.2095680","The development of audio-only computer games imposes a number of challenges for the sound designer, as well as for the human machine interface design approach. Modern sonification methods can be used for effective data and game-environment or conditions representation through sound, including earcons and auditory icons. In this work we take advantage of earcons fundamental characteristics, such as spatialization usually employed for concurrent/parallel reproduction, in order to implement a tic-tac-toe audio game prototype. The proposed sonic design is transparently integrated with a novel user control/interaction mechanism that can be easily implemented in state-of-the-art mobile devices incorporating movement sensors (i.e. accelerometers and gyroscope). The overall prototype design efficiency is assessed in terms of the employed sonification accuracy, while the playability achieved through the integration of the sonic design and the employed auditory user interface is assessed in real game-play conditions.","2011-09-07","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","88–94","","","","","","Sonic perceptual crossings","AM '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/8IH2C69D/Floros et al. - 2011 - Sonic perceptual crossings a tic-tac-toe audio ga.pdf","","","sonic interaction design; audio games; earcons; eye-free interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SGUBE3HN","conferencePaper","2015","Caramiaux, Baptiste; Altavilla, Alessandro; Pobiner, Scott G.; Tanaka, Atau","Form Follows Sound: Designing Interactions from Sonic Memories","Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems","978-1-4503-3145-6","","10.1145/2702123.2702515","https://dl.acm.org/doi/10.1145/2702123.2702515","Sonic interaction is the continuous relationship between user actions and sound, mediated by some technology. Because interaction with sound may be task oriented or experience-based it is important to understand the nature of action-sound relationships in order to design rich sonic interactions. We propose a participatory approach to sonic interaction design that first considers the affordances of sounds in order to imagine embodied interaction, and based on this, generates interaction models for interaction designers wishing to work with sound. We describe a series of workshops, called Form Follows Sound, where participants ideate imagined sonic interactions, and then realize working interactive sound prototypes. We introduce the Sonic Incident technique, as a way to recall memorable sound experiences. We identified three interaction models for sonic interaction design: conducting; manipulating; substituting. These three interaction models offer interaction designers and developers a framework on which they can build richer sonic interactions.","2015-04-18","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","3943–3952","","","","","","Form Follows Sound","CHI '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/2GMMC8QT/Caramiaux et al. - 2015 - Form Follows Sound Designing Interactions from So.pdf","","","sonic interaction design; sound; gesture; interaction design; methodology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"78GHGWJC","conferencePaper","2007","Foale, Cameron; Vamplew, Peter","Portal-based sound propagation for first-person computer games","Proceedings of the 4th Australasian conference on Interactive entertainment","978-1-921166-87-7","","","","First-person computer games are a popular modern video game genre. A new method is proposed, the Directional Propagation Cache, that takes advantage of the very common portal spatial subdivision method to accelerate environmental acoustics simulation for first-person games, by caching sound propagation information between portals.","2007-12-03","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","1–8","","","","","","","IE '07","","","","RMIT University","Melbourne, AUS","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/S6WMGT9A/Foale and Vamplew - 2007 - Portal-based sound propagation for first-person co.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KJDMXHNS","conferencePaper","2021","Rönnberg, Niklas","Sonification for Conveying Data and Emotion","Proceedings of the 16th International Audio Mostly Conference","978-1-4503-8569-5","","10.1145/3478384.3478387","https://dl.acm.org/doi/10.1145/3478384.3478387","In the present study a sonification of running data was evaluated. The aim of the sonification was to both convey information about the data and convey a specific emotion. The sonification was evaluated in three parts, firstly as an auditory graph, secondly together with additional text information, and thirdly together with an animated visualization, with a total of 150 responses. The results suggest that the sonification could convey an emotion similar to that intended, but at the cost of less good representation of the data. The addition of visual information supported understanding of the sonification, and the auditory representation of data. The results thus suggest that it is possible to design sonification that is perceived as both interesting and fun, and convey an emotional impression, but that there may be a trade off between musical experience and clarity in sonification.","2021-10-15","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","56–63","","","","","","","AM '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/LERZX5WP/Rönnberg - 2021 - Sonification for Conveying Data and Emotion.pdf","","","sonification; model of affect; user evaluation; visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G5R5HDRY","conferencePaper","2015","Erkut, Cumhur; Serafin, Stefania; Hoby, Michael; Sårde, Jonniy","Product Sound Design: Form, Function, and Experience","Proceedings of the Audio Mostly 2015 on Interaction With Sound","978-1-4503-3896-7","","10.1145/2814895.2814920","https://dl.acm.org/doi/10.1145/2814895.2814920","Current interactive products, services, and environments are appraised by their sensory attributes, in addition to their form and function. Sound is an important factor in these multisensory product appraisals. Integrating this sound opportunity into the design and development of interactive products, which are fit for real-world, yet constitute a strong brand identity, remains a challenge. We address this challenge by applying the research know-how of an academic institution and business practices of a sound agency SME within the core R&D and production process of the third industrial partner. Our approach has clear application scenarios in, e.g., extended wireless headsets, car audio appliances, and portable entertainment devices. We describe the prototypes developed during the project life span, and the activities and outcomes of a half-day workshop designed to disseminate the project results.","2015-10-07","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","1–6","","","","","","Product Sound Design","AM '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/G29BV5DA/Erkut et al. - 2015 - Product Sound Design Form, Function, and Experien.pdf","","","Auditory Feedback; Pedagogy; Sonic Interaction Design","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KTCMLCZN","conferencePaper","2016","Grani, Francesco; Nordahl, Rolf; Serafin, Stefania","Multimodal interactions, virtual reality and 360 movies: applications using Wavefield synthesis","Proceedings of the Audio Mostly 2016","978-1-4503-4822-5","","10.1145/2986416.2986430","https://dl.acm.org/doi/10.1145/2986416.2986430","We present a report covering our preliminary research on the use of wavefield synthesis WFS in a multimodal context. Traditionally, WFS has been used as a way to faithfully reproduce auditory experiences. To our knowledge, little research has tried to understand how to gesturally control WFS. Moreover, there are no applications combining WFS and virtual reality video productions. In this paper, we are interested in exploring the applications of WFS in the context of gestural control and 360 video production. We present three projects performed by students at Aalborg University Copenhagen that explore these directions.","2016-10-04","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","20–27","","","","","","Multimodal interactions, virtual reality and 360 movies","AM '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/TQSW6TJ9/Grani et al. - 2016 - Multimodal interactions, virtual reality and 360 m.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q93HDXHS","conferencePaper","2009","Taylor, Micah T.; Chandak, Anish; Antani, Lakulish; Manocha, Dinesh","RESound: interactive sound rendering for dynamic virtual environments","Proceedings of the 17th ACM international conference on Multimedia","978-1-60558-608-3","","10.1145/1631272.1631311","https://dl.acm.org/doi/10.1145/1631272.1631311","We present an interactive algorithm and system (RESound) for sound propagation and rendering in virtual environments and media applications. RESound uses geometric propagation techniques for fast computation of propagation paths from a source to a listener and takes into account specular reflections, diffuse reflections, and edge diffraction. In order to perform fast path computation, we use a unified ray-based representation to efficiently trace discrete rays as well as volumetric ray-frusta. RESound further improves sound quality by using statistical reverberation estimation techniques. We also present an interactive audio rendering algorithm to generate spatialized audio signals. The overall approach can render sound in dynamic scenes allowing source, listener, and obstacle motion. Moreover, our algorithm is relatively easy to parallelize on multi-core systems. We demonstrate its performance on complex game-like and architectural environments.","2009-10-19","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","271–280","","","","","","RESound","MM '09","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/NY77UAF5/Taylor et al. - 2009 - RESound interactive sound rendering for dynamic v.pdf","","","sound; acoustics; raytracing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7EBPVS2M","conferencePaper","2012","Delle Monache, Stefano; Rocchesso, Davide; Qi, Jie; Buechley, Leah; De Götzen, Amalia; Cestaro, Dario","Paper mechanisms for sonic interaction","Proceedings of the Sixth International Conference on Tangible, Embedded and Embodied Interaction","978-1-4503-1174-8","","10.1145/2148131.2148146","https://dl.acm.org/doi/10.1145/2148131.2148146","Introducing continuous sonic interaction in augmented pop-up books enhances the expressive and performative qualities of movables, making the whole narrative experience more engaging and personal. The SaMPL Spring School on Sounding Popables explored the specific topic of paper-driven sonic narratives. Working groups produced several sketches of sonic interactions with movables. The most significant sketches of sounding popables are presented and analyzed.","2012-02-19","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","61–68","","","","","","","TEI '12","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/A6B599KJ/Delle Monache et al. - 2012 - Paper mechanisms for sonic interaction.pdf","","","sonic interaction design; pop-up books","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NZZE3KND","conferencePaper","2016","Weber, Maximilian; Kuhn, Marco","KONTRAKTION: Sonification of Metagestures with electromyographic Signals","Proceedings of the Audio Mostly 2016","978-1-4503-4822-5","","10.1145/2986416.2986421","https://dl.acm.org/doi/10.1145/2986416.2986421","'Kontraktion' is an embodied musical interface using biosignals to create an immersive sonic performance setup. It explores the energetic coupling between digital synthesis and musical expression by reducing the interface to an embodied instrument and therefore tightening the connection between intention and sound. By using the setup as a biofeedback system the user explores his own subconscious gestures with a heightened sensitivity. Even subtle, usually unaware neural impulses are brought to conscious awareness by sensing muscle contractions with an armband and projecting them outward into space with sound in realtime. The users gestural expressions are embodied in sound and allow for an expressive energetic coupling between the users body and a virtual agent. Utilizing the newly adopted awareness of his body the user can take control of the sound and perform with it using the metagestures of his body as an embodied interface. The body itself is transformed into a musical instrument, controlled by neurological impulses and sonified by a virtual interpreter.","2016-10-04","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","132–138","","","","","","KONTRAKTION","AM '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/WZEC6RTH/Weber and Kuhn - 2016 - KONTRAKTION Sonification of Metagestures with ele.pdf","","","sonification; biofeedback; embodiment; emg; gesture; musical interface; surround sound","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FC2HCC5Q","conferencePaper","2011","Bikaki, Athina; Floros, Andreas","An RSS-feed auditory aggregator using earcons","Proceedings of the 6th Audio Mostly Conference: A Conference on Interaction with Sound","978-1-4503-1081-9","","10.1145/2095667.2095681","https://dl.acm.org/doi/10.1145/2095667.2095681","In this work we present a data sonification framework based on parallel/concurrent sonic earcons' representations for monitoring in real-time information related to stock market. The information under consideration is conveyed through the well-known Really Simple Syndication (RSS) feed Internet mechanism and includes both text and numeric values, converted to speech and earcons using existing speech synthesis techniques and sonic design guidelines. Due to the considered application characteristics, particular emphasis is provided on information representation concurrency, mainly achieved using sound source spatialization techniques and different timbre characteristics. Spatial positioning of sound sources is performed through typical binaural processing and reproduction. A number of systematic, subjective assessments performed have shown that the overall perceptual efficiency and sonic representation accuracy fulfills the overall application requirements, provided that the users are appropriately trained prior to using the proposed RSS-feed auditory aggregator.","2011-09-07","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","95–100","","","","","","","AM '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/EXEVDCG7/Bikaki and Floros - 2011 - An RSS-feed auditory aggregator using earcons.pdf","","","auditory displays; earcons; RSS-feed sonification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6BT93W2W","conferencePaper","2008","Ďurikovič, Dominik; Ďurikovič, Roman","Quality metrics for WEB page content representation in audio space","Proceedings of the 24th Spring Conference on Computer Graphics","978-1-60558-957-2","","10.1145/1921264.1921295","https://dl.acm.org/doi/10.1145/1921264.1921295","Having well-defined measures of web page content representation can significantly improve design, development, testing and validating of audio interfaces. First metric is connected with data changes perception by reading users. Changes in the web page that are not important for the reader comparing to the previous version are called small changes on the web page. Changes with higher importance value for reader are called huge changes. Ability to catch relevant changes in source data document by audio space representation is important measurable attribute for users reading these data. This attribute is called web change perception for web pages. First, we describe evaluation of the web change perception and next we are measuring sound perception of these representations using linear regression and calculation by Mathematica system.","2008-04-21","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","149–154","","","","","","","SCCG '08","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/LDUVBMZ4/Ďurikovič and Ďurikovič - 2008 - Quality metrics for WEB page content representatio.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YKLWPCHK","conferencePaper","2007","Stahl, Christoph","The roaring navigator: a group guide for the zoo with shared auditory landmark display","Proceedings of the 9th international conference on Human computer interaction with mobile devices and services","978-1-59593-862-6","","10.1145/1377999.1378042","https://dl.acm.org/doi/10.1145/1377999.1378042","In this paper, we introduce a shared auditory landmark display which conveys spatial survey knowledge and navigational aid to multiple users. Our guide is situated in a zoo environment, so we use recordings of animal voices to indicate the location of the animal enclosures. Spatial audio manipulates the volume and stereo balance of the sound clips, so that the listener can identify their distance and direction. The system also proactively presents audio clips with detailed information about each animal. To avoid the typical effect of social isolation through audio guides, we use shared audio so that the same sounds will be presented to each user at the same time. We have conducted an initial user study of paired visitors in the zoo to evaluate the usability of the system with positive results. The participants reported that the system is easy to use and has a stimulating influence on the communication between the visitors. As a further result, the study indicates that 'lightweight' navigational aid can be sufficient for wayfinding tasks in certain environments, which provides only the linear distance and direction of the destination.","2007-09-09","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","383–386","","","","","","The roaring navigator","MobileHCI '07","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/CXBDIYY9/Stahl - 2007 - The roaring navigator a group guide for the zoo w.pdf","","","spatial audio; audio guide; auditory landmark display; electronic guidebooks; pedestrian navigation; shared audio","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"54AZNEI6","conferencePaper","2009","Zheng, Changxi; James, Doug L.","Harmonic fluids","ACM SIGGRAPH 2009 papers","978-1-60558-726-4","","10.1145/1576246.1531343","https://dl.acm.org/doi/10.1145/1576246.1531343","Fluid sounds, such as splashing and pouring, are ubiquitous and familiar but we lack physically based algorithms to synthesize them in computer animation or interactive virtual environments. We propose a practical method for automatic procedural synthesis of synchronized harmonic bubble-based sounds from 3D fluid animations. To avoid audio-rate time-stepping of compressible fluids, we acoustically augment existing incompressible fluid solvers with particle-based models for bubble creation, vibration, advection, and radiation. Sound radiation from harmonic fluid vibrations is modeled using a time-varying linear superposition of bubble oscillators. We weight each oscillator by its bubble-to-ear acoustic transfer function, which is modeled as a discrete Green's function of the Helmholtz equation. To solve potentially millions of 3D Helmholtz problems, we propose a fast dual-domain multipole boundary-integral solver, with cost linear in the complexity of the fluid domain's boundary. Enhancements are proposed for robust evaluation, noise elimination, acceleration, and parallelization. Examples are provided for water drops, pouring, babbling, and splashing phenomena, often with thousands of acoustic bubbles, and hundreds of thousands of transfer function solves.","2009-07-27","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","1–12","","","","","","","SIGGRAPH '09","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/MVHSCR6E/Zheng and James - 2009 - Harmonic fluids.pdf","","","sound synthesis; acoustic bubbles; acoustic transfer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EI3AJENB","conferencePaper","2016","Leichsenring, Christian; Yang, Jiajun; Hammerschmidt, Jan; Hermann, Thomas","Challenges for smart environments in bathroom contexts","Proceedings of the 1st Workshop on Embodied Interaction with Smart Environments","978-1-4503-4555-2","","10.1145/3008028.3008033","https://dl.acm.org/doi/10.1145/3008028.3008033","Smart homes have been mostly treated as homogeneous environments where each room is distinguished by the activities performed there but not by any fundamentally different basic parameters for systems to operate in. We argue that at least for bathroom environments, things like the extensive presence of liquid water and humidity and special privacy considerations challenge these assumptions. We discuss typical and unique challenges for ubiquitous computing interfaces in bathroom environments and we look at how actual and conceptual systems confront these challenges. We review bathroom systems in the literature and present two systems of our own to exemplify the unique challenges to smart environments the bathroom provides, one of which is presented here for the first time.","2016-11-16","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","1–7","","","","","","","EISE '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/66F7F3HR/Leichsenring et al. - 2016 - Challenges for smart environments in bathroom cont.pdf","","","sonification; ambient intelligence; smart environments; smart home; soundscape; tangible interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IPREXH5A","conferencePaper","2022","Senan, Toros; Hengeveld, Bart; Eggen, Berry","Sounding Obstacles for Social Distance Sonification","Proceedings of the 17th International Audio Mostly Conference","978-1-4503-9701-8","","10.1145/3561212.3561239","https://dl.acm.org/doi/10.1145/3561212.3561239","This article reports the results of an experiment (N = 10) that employs continuous auditory feedback to influence participants’ routing choices while walking between two points by sonifying their interactions with invisible obstacles. A relative distance parameter, proximity, is defined and mapped simultaneously to perceived loudness and amplitude modulation frequencies of sine tones. The proximity parameter is divided into three sections: slow modulation, border zone, and fast modulation. The slow and fast modulation sections generate a monotonic relationship between proximity values and the resulting psychoacoustic parameters: fluctuation strength and roughness. A social distance sonification case study in a laboratory experiment evaluated the effectiveness of the generated hearing sensations and explored participants’ experiences through a semi-structured interview. The quantitative results show that the non-spatial, psychoacoustically-inspired sonification mappings successfully influenced participants’ routing choices during the experiental task of walking. On the other hand, the semi-structured interview revealed that participants ascribed a pleasantness/annoyance attribute to presented sounds, which was not intended.","2022-10-10","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","187–194","","","","","","","AM '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/TY39UMMG/Senan et al. - 2022 - Sounding Obstacles for Social Distance Sonificatio.pdf","","","Sonification; Psychoacoustics; Guidance technologies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YLWPBVF4","conferencePaper","2018","Metatla, Oussama; Bryan-Kinns, Nick; Stockman, Tony","“I Hear You”: Understanding Awareness Information Exchange in an Audio-only Workspace","Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems","978-1-4503-5620-6","","10.1145/3173574.3174120","https://dl.acm.org/doi/10.1145/3173574.3174120","Graphical displays are a typical means for conveying awareness information in groupware systems to help users track joint activities, but are not ideal when vision is constrained. Understanding how people maintain awareness through non-visual means is crucial for designing effective alternatives for supporting awareness in such situations. We present a lab study simulating an extreme scenario where 32 pairs of participants use an audio-only tool to edit shared audio menus. Our aim is to characterise collaboration in this audio-only space in order to identify whether and how, by itself, audio can mediate collaboration. Our findings show that the means for audio delivery and choice of working styles in this space influence types and patterns of awareness information exchange. We thus highlight the need to accommodate different working styles when designing audio support for awareness, and extend previous research by identifying types of awareness information to convey in response to group work dynamics.","2018-04-21","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","1–13","","","","","","“I Hear You”","CHI '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/7SG8JSKC/Metatla et al. - 2018 - “I Hear You” Understanding Awareness Information .pdf","","","collaboration; audio-only interaction; workspace awareness","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"644AUB9L","conferencePaper","2011","Huang, Chung-Ching; Bardzell, Jeffrey; Terrell, Jennifer","Can your pet rabbit read your email? a critical analysis of the Nabaztag rabbit","Proceedings of the 2011 Conference on Designing Pleasurable Products and Interfaces","978-1-4503-1280-6","","10.1145/2347504.2347532","https://dl.acm.org/doi/10.1145/2347504.2347532","The Nabaztag rabbit is an ambient digital device with customized functions. It was advertised as an ambient display, using strong product images suggesting that it is a pet alternative. However, after early interest, the popularity of this product did not last long. In this paper, we demonstrate interaction criticism as an approach to design research, exploring and proposing reasons for the product's decline. Specifically, we argue that the rabbit is difficult to connect with emotionally and explore several reasons this might be true. Our approach is phenomenological and hermeneutic in nature: we engaged in product usage for over twelve months, and practice a theoretically informed interpretive analysis. Using a combination of critical theories and affect research from robotics, we argue the Nabaztag product identity is confusing, which might be related to the manufactures' multiple intentions, and the gap between ideal and real users. We continue with an account of two genres of functions in the Nabaztag, revealing how they polarize of interpretation; moments when Nabaztag acted in unexpected ways; and the increased, rather than decreased, difficulty in interpreting Nabaztag the longer we used it. Interpretively understanding Nabaztag's experiential failures helps cultivate relevant design sensitivities and even implications for future designs.","2011-06-22","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","1–8","","","","","","Can your pet rabbit read your email?","DPPI '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/P5NNI6SQ/Huang et al. - 2011 - Can your pet rabbit read your email a critical an.pdf","","","HCI; HRI; ambient information display; interaction criticism; Nabaztag","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6RAFT7WB","conferencePaper","2021","Hermann, Thomas; Reinsch, Dennis","sc3nb: a Python-SuperCollider Interface for Auditory Data Science","Proceedings of the 16th International Audio Mostly Conference","978-1-4503-8569-5","","10.1145/3478384.3478401","https://dl.acm.org/doi/10.1145/3478384.3478401","This paper introduces sc3nb, a Python package for audio coding and interactive control of the SuperCollider programming environment. sc3nb supports Jupyter notebooks, enables flexible means for sound and music computing such as sound synthesis and analysis and is particularly tailored for sonification. We present the main concepts and interfaces and illustrate how to use sc3nb at hand of selected code examples for basic sonification approaches, such as audification and parameter-mapping sonification. Finally, we introduce TimedQueues which enable coordinated audiovisual displays, e.g. to synchronize matplotlib data and sc3nb-based sound rendition. sc3nb enables interactive sound applications right in the center of the pandas/numpy/scipy data science ecosystem. The open source package is hosted at GitHub and available via the Python Package Index PyPI.","2021-10-15","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","208–215","","","","","","sc3nb","AM '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/G68EJ34Q/Hermann and Reinsch - 2021 - sc3nb a Python-SuperCollider Interface for Audito.pdf","","","sonification; audio coding; auditory data science; interactive programming; Python","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2CLHMG6M","conferencePaper","2022","Kantan, Prithvi Ravi; Dahl, Sofia; Spaich, Erika G.","Sound-Guided 2-D Navigation: Effects of Information Concurrency and Coordinate System","Nordic Human-Computer Interaction Conference","978-1-4503-9699-8","","10.1145/3546155.3546688","https://dl.acm.org/doi/10.1145/3546155.3546688","Auditory guidance conveying positional information through concurrent variations in properties of synthesized sound has previously been investigated. Auditory guidance may be more effective if multidimensional tasks are divided into unidimensional tasks where the user sequentially tackles each dimension and sound property. User performance may also depend on the coordinate system used for providing guidance. We compared concurrent and sequential guidance presentations in Cartesian and polar coordinate systems in a computer-based 2-D target-finding experiment with 15 participants. Sequential guidance was superior regarding completion time and number of interruptions with less cognitive burden than concurrent guidance. Participants were slower with the polar coordinate system than the Cartesian. These findings can contribute to the development of more efficacious guidance systems.","2022-10-08","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","1–11","","","","","","Sound-Guided 2-D Navigation","NordiCHI '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/M4QYKAFP/Kantan et al. - 2022 - Sound-Guided 2-D Navigation Effects of Informatio.pdf","","","sonification; auditory guidance; concurrency; navigation; perceptual test","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"24L3X6VE","conferencePaper","2011","Houri, Naoyuki; Arita, Hiroyuki; Sakaguchi, Yutaka","Audiolizing body movement: its concept and application to motor skill learning","Proceedings of the 2nd Augmented Human International Conference","978-1-4503-0426-9","","10.1145/1959826.1959839","https://dl.acm.org/doi/10.1145/1959826.1959839","We propose a concept of ""audiolization of body movement,"" which transforms the posture/movement of the human body or human-controlled-tools into acoustic signals and feeds them back to the users in a real-time manner. It aims at helping people being aware of their body/tool states, and resultantly assisting their motor skill learning. The present paper describes features of the concepts and introduces some demonstrative applications.","2011-03-13","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","1–4","","","","","","Audiolizing body movement","AH '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/P9L46LIG/Houri et al. - 2011 - Audiolizing body movement its concept and applica.pdf","","","body movement; body awareness; audiolization; motor skill learning; sensori-motor integration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LRLNP8VY","conferencePaper","2016","Metatla, Oussama; Correia, Nuno N.; Martin, Fiore; Bryan-Kinns, Nick; Stockman, Tony","Tap the ShapeTones: Exploring the Effects of Crossmodal Congruence in an Audio-Visual Interface","Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems","978-1-4503-3362-7","","10.1145/2858036.2858456","https://dl.acm.org/doi/10.1145/2858036.2858456","There is growing interest in the application of crossmodal perception to interface design. However, most research has focused on task performance measures and often ignored user experience and engagement. We present an examination of crossmodal congruence in terms of performance and engagement in the context of a memory task of audio, visual, and audio-visual stimuli. Participants in a first study showed improved performance when using a visual congruent mapping that was cancelled by the addition of audio to the baseline conditions, and a subjective preference for the audio-visual stimulus that was not reflected in the objective data. Based on these findings, we designed an audio-visual memory game to examine the effects of crossmodal congruence on user experience and engagement. Results showed higher engagement levels with congruent displays with some reported preference for potential challenge and enjoyment that an incongruent display may support, particularly for increased task complexity.","2016-05-07","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","1055–1066","","","","","","Tap the ShapeTones","CHI '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/UBZHHAMU/Metatla et al. - 2016 - Tap the ShapeTones Exploring the Effects of Cross.pdf","","","games; user experience; audio-visual display; crossmodal congruence; spatial mappings; user engagement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FUZ265D5","conferencePaper","2009","Jeon, Myounghoon; Park, Junho; Heo, Ubeom; Yun, Jongmin","Enhanced turning point displays facilitate drivers' interaction with navigation devices","Proceedings of the 1st International Conference on Automotive User Interfaces and Interactive Vehicular Applications","978-1-60558-571-0","","10.1145/1620509.1620536","https://dl.acm.org/doi/10.1145/1620509.1620536","Recently, the use of in-vehicle navigation devices, such as PNDs (Personal or Portable Navigation Devices) has become pervasive, and the device functions have been rapidly expanded and updated. Unfortunately, drivers often have considerable difficulty using these complex technologies. To improve and optimize PND user interfaces, the present study suggested several display improvements for the turning point, which is one of the critical usability issues. Advanced Turn-By-Turn Display and Spatial Turning Sound were suggested to facilitate the preparation of the next turns. Leading Tones for Turning was also presented to help drivers tune the timing of their turns. We evaluated these new concepts with domain experts in three countries, and improved the details of the functions. We are currently implementing those features and looking forward to demonstrating new displays on the real product in our presentation at the Automotive User Interface conference.","2009-09-21","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","145–148","","","","","","","AutomotiveUI '09","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/MYQXTNAF/Jeon et al. - 2009 - Enhanced turning point displays facilitate drivers.pdf","","","advanced turn-by-turn display; AUI; GUI; IVTs; leading tones for turning; PND; spatial turning sound","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2NVKHXMH","conferencePaper","2022","Joo, Woohun","Graphic-to-Sound Sonification for Visual and Auditory Communication Design","Proceedings of the 17th International Audio Mostly Conference","978-1-4503-9701-8","","10.1145/3561212.3561214","https://dl.acm.org/doi/10.1145/3561212.3561214","I designed two sonification platforms designed for visual/auditory communication design studies and audiovisual art. The purpose of this study was to examine whether test participants can associate visuals and sound without any prior training and sonification approaches in this paper can be utilized as an interactive musical expression. The platform for the communication design study was developed first and the artistic audiovisual platform with the same sonification methodology followed next. In this paper, I introduce the (former) sonification platform designed for the image-to-sound association studies, their sonification methodologies, and present the study results. The object-oriented sonification method that I newly developed describes each shape sonically. The five image-sound association studies were conducted to see whether people can successfully associate sounds and fundamental shapes (i.e., a circle, a triangle, a square, lines, curves, and other custom shapes). Regardless of age and educational background, the correct answer rate was high.","2022-10-10","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","1–6","","","","","","","AM '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/FIRH35IY/Joo - 2022 - Graphic-to-Sound Sonification for Visual and Audit.pdf","","","Sonification; Auditory Icon; Auditory Symbol; Graphic Sonification; Image-Sound Sonification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8UECVSQ8","conferencePaper","2018","Smith, Taliesin L.; Greenberg, Jesse; Reid, Sam; Moore, Emily B.","Parallel DOM Architecture for Accessible Interactive Simulations","Proceedings of the 15th International Web for All Conference","978-1-4503-5651-0","","10.1145/3192714.3192817","https://dl.acm.org/doi/10.1145/3192714.3192817","Interactive simulations are used in classrooms around the world to support student learning. Creating accessible interactive simulations is a complex challenge that pushes the boundaries of current accessibility approaches and standards. In this work, we present a new approach to addressing accessibility needs within complex interactives. Within a custom scene graph that utilizes a model-view-controller architectural pattern, we utilize a parallel document object model (PDOM) to create interactive simulations (PhET Interactive Simulations) accessible to students through alternative input devices and descriptions accessed with screen reader software. In this paper, we describe our accessibility goals, challenges, and approach to creating robust accessible interactive simulations, and provide examples from an accessible simulation we have developed and possibilities for future extensions.","2018-04-23","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","1–8","","","","","","","W4A '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/39IR7DDQ/Smith et al. - 2018 - Parallel DOM Architecture for Accessible Interacti.pdf","","","accessibility; visual impairments; alternative input; Interactive simulations; software architectures","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"88G2PAGG","conferencePaper","2022","Zhang, Lotus; Shao, Jingyao; Liu, Augustina Ao; Jiang, Lucy; Stangl, Abigale; Fourney, Adam; Morris, Meredith Ringel; Findlater, Leah","Exploring Interactive Sound Design for Auditory Websites","Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems","978-1-4503-9157-3","","10.1145/3491102.3517695","https://dl.acm.org/doi/10.1145/3491102.3517695","Auditory interfaces increasingly support access to website content, through recent advances in voice interaction. Typically, however, these interfaces provide only limited audio styling, collapsing rich visual design into a static audio output style with a single synthesized voice. To explore the potential for more aesthetic and intuitive sound design for websites, we prompted 14 professional sound designers to create auditory website mockups and interviewed them about their designs and rationale. Our findings reveal their prioritized design considerations (aesthetics and emotion, user engagement, audio clarity, information dynamics, and interactivity), specific sound design ideas to support each consideration (e.g., replacing spoken labels with short, memorable audio expressions), and challenges with applying sound design practices to auditory websites. These findings provide promising direction for how to support designers in creating richer auditory website experiences.","2022-04-29","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","1–16","","","","","","","CHI '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/EGTXGJW5/Zhang et al. - 2022 - Exploring Interactive Sound Design for Auditory We.pdf","","","audio display; interaction design; voice interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WCFSFJGP","conferencePaper","2011","Stefik, Andreas M.; Hundhausen, Christopher; Smith, Derrick","On the design of an educational infrastructure for the blind and visually impaired in computer science","Proceedings of the 42nd ACM technical symposium on Computer science education","978-1-4503-0500-6","","10.1145/1953163.1953323","https://dl.acm.org/doi/10.1145/1953163.1953323","The blind and visually impaired community is significantly underrepresented in computer science. Students who wish to enter the discipline must overcome significant technological and educational barriers to succeed. In an attempt to help this population, we are engaged in a three-year research project to build an educational infrastructure for blind and visually impaired middle and high school students. Our primary research goal is to begin forging a multi-sensory educational infrastructure for the blind across the United States. We present here two preliminary results from this research: 1) a new auditory programming environment called Sodbeans, a programming language called Hop, and a multi-sensory (sound and touch) curriculum, and 2) an empirical study of our first summer workshop with the blind students. Results show that students reported a significant increase in programming self-efficacy after participating in our camp.","2011-03-09","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","571–576","","","","","","","SIGCSE '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/BZKUW5JB/Stefik et al. - 2011 - On the design of an educational infrastructure for.pdf","","","accessibility; assistive technology; visual impairments; auditory debugging","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C4SAEMQR","conferencePaper","2012","Jeon, Myounghoon; Riener, Andreas; Lee, Ju-Hwan; Schuett, Jonathan; Walker, Bruce N.","Cross-cultural differences in the use of in-vehicle technologies and vehicle area network services: Austria, USA, and South Korea","Proceedings of the 4th International Conference on Automotive User Interfaces and Interactive Vehicular Applications","978-1-4503-1751-1","","10.1145/2390256.2390283","https://dl.acm.org/doi/10.1145/2390256.2390283","Vehicle area network (VAN) communications and related services are getting more pervasive [1]. However, even though user-centered design has been emphasized, VAN services have often been developed through a technology-driven approach. This paper presents cross-cultural survey results on VAN services in three different countries: Austria, USA, and South Korea. The current research compared the state-of-the-art of drivers' current in-vehicle technology use and investigated their needs and wants for plausible new services in the near future. Further, we validated our next generation in-vehicle interface concepts stemming from our previous participatory design process [2]. Results showed clear differences between Austrians vs. Americans and Koreans. Even though Koreans and Americans in our survey were older than Austrians, they seemed more open-minded to VAN services (e.g., social networks in car, V2V services, in-vehicle agent, etc) in general and rated them more positively. Through these cross-cultural needs analyses of end users, designers and practitioners are expected to gain insights into developing a standardized service across cultures as well as culturally tuned in-vehicle interfaces. Moreover, we hope that this initial international collaboration can serve as a good test bed for future research and hope to expand our consortium with more colleagues in the AutomotiveUI community for further cross-cultural studies.","2012-10-17","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","163–170","","","","","","Cross-cultural differences in the use of in-vehicle technologies and vehicle area network services","AutomotiveUI '12","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/43JSL4GF/Jeon et al. - 2012 - Cross-cultural differences in the use of in-vehicl.pdf","","","cross-cultural differences; in-vehicle agents; next generation in-vehicle interfaces; social network services; VAN (vehicle area network)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JZHWSJ2A","conferencePaper","2018","Ferguson, Jamie; Williamson, John; Brewster, Stephen","Evaluating mapping designs for conveying data through tactons","Proceedings of the 10th Nordic Conference on Human-Computer Interaction","978-1-4503-6437-9","","10.1145/3240167.3240175","https://dl.acm.org/doi/10.1145/3240167.3240175","Tactons are structured vibrotactile messages which can be used to transmit information solely through the cutaneous sense. These are particularly useful in situations where visual or auditory displays are unavailable or inappropriate. Most data:vibration mappings do not consider the user's perceptions of the mappings being used, which can lead to confusion and Tactons which are difficult to interpret. To explore this issue, we conducted a magnitude estimation experiment to map how a number of vibrotactile parameters such as duration and frequency relate to the perceived magnitude of data variables that may be used in a real-world context such as error and danger. Results from this study show that when tempo and duration are used to convey data, they are perceived in the same polarity, regardless of the type of data being conveyed. This study provides polarity and scaling values which may be directly utilised by Tacton designers when creating new sets of vibrotactile messages.","2018-09-29","2023-07-06 05:56:29","2023-07-06 05:56:29","2023-07-05","215–223","","","","","","","NordiCHI '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/L75RUGUY/Ferguson et al. - 2018 - Evaluating mapping designs for conveying data thro.pdf","","","vibrotactile; non-visual; analogy; mental model; tactons","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TNGI6M3J","conferencePaper","2010","Vazquez Alvarez, Yolanda; Brewster, Stephen A.","Designing spatial audio interfaces to support multiple audio streams","Proceedings of the 12th international conference on Human computer interaction with mobile devices and services","978-1-60558-835-3","","10.1145/1851600.1851642","https://dl.acm.org/doi/10.1145/1851600.1851642","Auditory interfaces offer a solution to the problem of effective eyes-free mobile interactions. However, a problem with audio, as opposed to visual displays, is dealing with multiple simultaneous outputs. Any audio interface needs to consider: 1) simultaneous versus sequential presentation of multiple audio streams, 2) 3D audio techniques to place sounds in different spatial locations versus a single point of presentation, 3) dynamic movement versus fixed locations of audio sources. We present an experiment using a divided-attention task where a continuous podcast and an audio menu compete for attention. A sequential presentation baseline assessed the impact of cognitive load, and as expected, dividing attention had a significant effect on overall performance. However, spatial audio still increased the users' ability to attend to two streams, while dynamic movement of streams led to higher perceived workload. These results will provide guidelines for designers when building eyes-free auditory interfaces for mobile applications.","2010-09-07","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","253–256","","","","","","","MobileHCI '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/HLX5VCXX/Vazquez Alvarez and Brewster - 2010 - Designing spatial audio interfaces to support mult.pdf","","","spatial audio; auditory interfaces; divided-attention task; mobile systems; multiple audio streams","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4BVTVGPA","conferencePaper","2017","Çamcı, Anil; Lee, Kristine; Roberts, Cody J.; Forbes, Angus G.","INVISO: A Cross-platform User Interface for Creating Virtual Sonic Environments","Proceedings of the 30th Annual ACM Symposium on User Interface Software and Technology","978-1-4503-4981-9","","10.1145/3126594.3126644","https://dl.acm.org/doi/10.1145/3126594.3126644","The predominant interaction paradigm of current audio spatialization tools, which are primarily geared towards expert users, imposes a design process in which users are characterized as stationary, limiting the application domain of these tools. Navigable 3D sonic virtual realities, on the other hand, can support many applications ranging from soundscape prototyping to spatial data representation. Although modern game engines provide a limited set of audio features to create such sonic environments, the interaction methods are inherited from the graphical design features of such systems, and are not specific to the auditory modality. To address such limitations, we introduce INVISO, a novel web-based user interface for designing and experiencing rich and dynamic sonic virtual realities. Our interface enables both novice and expert users to construct complex immersive sonic environments with 3D dynamic sound components. INVISO is platform-independent and facilitates a variety of mixed reality applications, such as those where users can simultaneously experience and manipulate a virtual sonic environment. In this paper, we detail the interface design considerations for our audio-specific VR tool. To evaluate the usability of INVISO, we conduct two user studies: The first demonstrates that our visual interface effectively facilitates the generation of creative audio environments; the second demonstrates that both expert and non-expert users are able to use our software to accurately recreate complex 3D audio scenes.","2017-10-20","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","507–518","","","","","","INVISO","UIST '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/SV9M6QMA/Çamcı et al. - 2017 - INVISO A Cross-platform User Interface for Creati.pdf","","","virtual reality; 3D audio; browser-based interface; design environment; virtual sonic environments","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U5GD9G2Q","conferencePaper","2013","Bakker, Saskia; van den Hoven, Elise; Eggen, Berry","FireFlies: physical peripheral interaction design for the everyday routine of primary school teachers","Proceedings of the 7th International Conference on Tangible, Embedded and Embodied Interaction","978-1-4503-1898-3","","10.1145/2460625.2460634","https://dl.acm.org/doi/10.1145/2460625.2460634","This paper presents a research-through-design study into interactive systems for a primary school setting to support teachers' everyday tasks. We developed an open-ended interactive system called FireFlies, which is intended to be interacted with in the periphery of the teacher's attention and thereby become an integral part of everyday routines. FireFlies uses light-objects and audio as a (background) information display. Furthermore, teachers can manipulate the light and audio through physical interaction. A working prototype of FireFlies was deployed in four different classrooms for six weeks. Qualitative results reveal that all teachers found a relevant way of working with FireFlies, which they applied every day of the evaluation. After the study had ended and the systems were removed from the schools, the teachers kept reaching for the devices and mentioned they missed FireFlies, which shows that it had become part of their everyday routine.","2013-02-10","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","57–64","","","","","","FireFlies","TEI '13","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/G4GDRZFJ/Bakker et al. - 2013 - FireFlies physical peripheral interaction design .pdf","","","design; audio; calm technology; everyday routine; peripheral interaction; physical interaction; user exploration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UJMBGEXD","conferencePaper","2023","Guarese, Renan; Zambetta, Fabio; van Schyndel, Ron","Evaluating micro-guidance sonification methods in manual tasks for Blind and Visually Impaired people","Proceedings of the 34th Australian Conference on Human-Computer Interaction","9798400700248","","10.1145/3572921.3572929","https://dl.acm.org/doi/10.1145/3572921.3572929","This paper presents a user evaluation of seven sonification methods in two-dimensional (2D) manual micro-guidance tasks, which can be used as building blocks for spatialized audio in Mixed and Virtual Reality to model next-generation guidance aids for the Blind and Visually Impaired (BVI). The methods were tested in comparable interactive sonifications of 2D positions in a series of hand-navigation assessments with BVI and blindfolded sighted users, to validate the different approaches in environments without any visual feedback. Results highlighted that alternation and spatiality can be useful resources in sonified guidance, and that users accustomed to faster-than-regular audio speed replay tend to have more precise performances, while musical literacy only had a performance effect on methods highly dependent on aural skills. Ultimately, this work corroborates the notion that sonification may help BVI users perform better in day-to-day manual micro-guidance tasks such as retrieving items from a pantry, handling kitchen appliances, and properly discarding trash.","2023-04-06","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","260–271","","","","","","","OzCHI '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/NHTKAIDV/Guarese et al. - 2023 - Evaluating micro-guidance sonification methods in .pdf","","","assistive technologies; blind and visually impaired guidance; micro-guidance; mixed reality accessibility","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HBSJIIIE","conferencePaper","2010","Monache, Stefano Delle; Polotti, Pietro; Rocchesso, Davide","A toolkit for explorations in sonic interaction design","Proceedings of the 5th Audio Mostly Conference: A Conference on Interaction with Sound","978-1-4503-0046-9","","10.1145/1859799.1859800","https://dl.acm.org/doi/10.1145/1859799.1859800","Physics-based sound synthesis represents a promising paradigm for the design of a veridical and effective continuous feedback in augmented everyday contexts. In this paper, we introduce the Sound Design Toolkit (SDT), a software package available as a complete front-end application, providing a palette of virtual lutheries and foley pits, that can be exploited in sonic interaction design research and education. In particular, the package includes polyphonic features and connectivity to multiple external devices and sensors in order to facilitate the embedding of sonic attributes in interactive artifacts. The present release represents an initial version towards an effective and usable tool for sonic interaction designers.","2010-09-15","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","1–7","","","","","","","AM '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/BCWL74IR/Monache et al. - 2010 - A toolkit for explorations in sonic interaction de.pdf","","","sonic interaction design; user interfaces; physics-based sound synthesis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YSD5YJGW","conferencePaper","2011","Ramos, Daniel; Folmer, Eelke","Supplemental sonification of a bingo game","Proceedings of the 6th International Conference on Foundations of Digital Games","978-1-4503-0804-5","","10.1145/2159365.2159388","https://dl.acm.org/doi/10.1145/2159365.2159388","Visual cues are typically used in video games to indicate to the player what input to provide and when. Cues represented in multiple modalities that are presented simultaneously can be detected at lower thresholds, faster and more accurately than when presented separately in each modality. This characteristic has not been explored in playing video games to reduce errors. This paper explores the use of supplemental audio feedback to reduce errors in playing Bingo, a game which is typically played in crowded and noisy environments by a demographic, which -due to their age- are more likely to suffer from sensory impairments such as low vision or hearing impairments. A user study explored three different types of sonification (pitch, timbre, and audio icons) versus using no sonification and found that supplemental sonification using timbre or audio icons significantly reduces player's errors.","2011-06-29","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","168–173","","","","","","","FDG '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/QXTTACVY/Ramos and Folmer - 2011 - Supplemental sonification of a bingo game.pdf","","","sonification; games; multimodal feedback","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WFRN8IUW","conferencePaper","2018","Glatz, Christiane; Krupenia, Stas S.; Bülthoff, Heinrich H.; Chuang, Lewis L.","Use the Right Sound for the Right Job: Verbal Commands and Auditory Icons for a Task-Management System Favor Different Information Processes in the Brain","Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems","978-1-4503-5620-6","","10.1145/3173574.3174046","https://dl.acm.org/doi/10.1145/3173574.3174046","Design recommendations for notifications are typically based on user performance and subjective feedback. In comparison, there has been surprisingly little research on how designed notifications might be processed by the brain for the information they convey. The current study uses EEG/ERP methods to evaluate auditory notifications that were designed to cue long-distance truck drivers for task-management and driving conditions, particularly for automated driving scenarios. Two experiments separately evaluated naive students and professional truck drivers for their behavioral and brain responses to auditory notifications, which were either auditory icons or verbal commands. Our EEG/ERP results suggest that verbal commands were more readily recognized by the brain as relevant targets, but that auditory icons were more likely to update contextual working memory. Both classes of notifications did not differ on behavioral measures. This suggests that auditory icons ought to be employed for communicating contextual information and verbal commands, for urgent requests.","2018-04-21","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","1–13","","","","","","Use the Right Sound for the Right Job","CHI '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/Z8B3W95S/Glatz et al. - 2018 - Use the Right Sound for the Right Job Verbal Comm.pdf","","","auditory displays; autonomous vehicles; electroencephalography; in-vehicle interfaces; notifications","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HPIVM5HV","conferencePaper","2012","Fagerlönn, Johan; Lindberg, Stefan; Sirkka, Anna","Graded auditory warnings during in-vehicle use: using sound to guide drivers without additional noise","Proceedings of the 4th International Conference on Automotive User Interfaces and Interactive Vehicular Applications","978-1-4503-1751-1","","10.1145/2390256.2390269","https://dl.acm.org/doi/10.1145/2390256.2390269","Auditory signals have proven useful to guide and inform drivers in dangerous situations. Sounds can become annoying, however, thereby negatively affecting consumer acceptance of an interface or system. Auditory warnings are typically salient sounds such as sudden beeps or repetitive tones. But adding sound to the environment is not necessarily the only way to aurally alert people to a change in the environment. The present study explored the usefulness of three alternative strategies to notify drivers in early stages of a threatening situation using sound: 1. panning the radio sound from the driver's position (equal sound level in both ears) to one side; 2. reducing the sound level of the radio; and 3. a mild auditory warning signal (i.e., an added sound). The participants responded to the early warnings in a simple reaction task while performing a simulated driving task. After each condition, the drivers completed a questionnaire concerning their opinions of the early warnings. Interestingly, the results show that manipulating the sound of the radio can be a useful way to notify drivers. Panning the sound of the radio may be especially effective and tolerable. Potential benefits and issues with the investigated warning strategies are discussed.","2012-10-17","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","85–91","","","","","","Graded auditory warnings during in-vehicle use","AutomotiveUI '12","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/QDUSJEKG/Fagerlönn et al. - 2012 - Graded auditory warnings during in-vehicle use us.pdf","","","notification systems; alerts; auditory warnings; driver acceptance; graded warnings; traffic safety","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ISMZVIDJ","conferencePaper","1971","Smith, David Canfield; Newey, Malcolm C.; Colby, Kenneth Mark","Automated therapy for nonspeaking autistic children","Proceedings of the May 16-18, 1972, spring joint computer conference","978-1-4503-7909-0","","10.1145/1478873.1479020","https://dl.acm.org/doi/10.1145/1478873.1479020","Earlier publications described our computer method for stimulating language development in nonspeaking children, sketched several case histories (Colby 1968), and gave statistical evidence that our high rate of success (71 percent) was due to our treatment method (Colby and Smith 1970). This paper presents some proposals for making the method more widely available.","1971-11-16","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","1101–1106","","","","","","","AFIPS '72 (Spring)","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/I9KHBTWH/Smith et al. - 1971 - Automated therapy for nonspeaking autistic childre.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2SNXWJ39","conferencePaper","2010","Alvarez, Ignacio; Martin, Aqueasha; Dunbar, Jerone; Taiber, Joachim; Wilson, Dale-Marie; Gilbert, Juan E.","Voice interfaced vehicle user help","Proceedings of the 2nd International Conference on Automotive User Interfaces and Interactive Vehicular Applications","978-1-4503-0437-5","","10.1145/1969773.1969782","https://dl.acm.org/doi/10.1145/1969773.1969782","Manuals were designed to provide support and information about the usage and maintenance of the vehicle. In many cases user's manuals are the driver's only guidance. However, lack of clarity and efficiency of manuals lead to user dissatisfaction. In vehicles this problem is even more crucial given that driving a motor vehicle is, for many people, the most complex and potentially dangerous task they will perform during their lifetime. In this paper we present a voice interfaced driver manual that can potentially fix the deficiencies of its alternatives. In addition we aim to provide a case for the integration of such technology in a vehicle to reduce driver distraction, increase driver satisfaction, and manual usability, while also benefiting Original Equipment Manufacturers (OEMs) in lowering costs and reducing the documentation process.","2010-11-11","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","42–49","","","","","","","AutomotiveUI '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/JV8L36FH/Alvarez et al. - 2010 - Voice interfaced vehicle user help.pdf","","","answers first; ITECH; vehicle user help; voice-interfaced manual","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V6H45XU3","conferencePaper","2015","Beattie, David; Baillie, Lynne; Halvey, Martin","A comparison of artificial driving sounds for automated vehicles","Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing","978-1-4503-3574-4","","10.1145/2750858.2807519","https://dl.acm.org/doi/10.1145/2750858.2807519","As automated vehicles currently do not provide sufficient feedback relating to the primary driving task, drivers have no assurance that an automated vehicle has understood and can cope with upcoming traffic situations [16]. To address this we conducted two user evaluations to investigate auditory displays in automated vehicles using different types of sound cues related to the primary driving sounds: acceleration, deceleration/braking, gear changing and indicating. Our first study compared earcons, speech and auditory icons with existing vehicle sounds. Our findings suggested that earcons were an effective alternative to existing vehicle sounds for presenting information related to the primary driving task. Based on these findings a second study was conducted to further investigate earcons modulated by different sonic parameters to present primary driving sounds. We discovered that earcons containing naturally mapped sonic parameters such as pitch and timbre were as effective as existing sounds in a simulated automated vehicle.","2015-09-07","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","451–462","","","","","","","UbiComp '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/MAYRJPBV/Beattie et al. - 2015 - A comparison of artificial driving sounds for auto.pdf","","","auditory displays; speech; auditory icons; earcons; automated vehicles; driving simulator","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E6SMYFKD","conferencePaper","2010","McCullagh, P. J.; Ware, M. P.; Lightbody, G.","Brain Computer Interfaces for inclusion","Proceedings of the 1st Augmented Human International Conference","978-1-60558-825-4","","10.1145/1785455.1785461","https://dl.acm.org/doi/10.1145/1785455.1785461","In this paper, we describe an intelligent graphical user interface (IGUI) and a User Application Interface (UAI) tailored to Brain Computer Interface (BCI) interaction, designed for people with severe communication needs. The IGUI has three components; a two way interface for communication with BCI2000 concerning user events and event handling; an interface to user applications concerning the passing of user commands and associated device identifiers, and the receiving of notification of device status; and an interface to an extensible mark-up language (xml) file containing menu content definitions. The interface has achieved control of domotic applications. The architecture however permits control of more complex 'smart' environments and could be extended further for entertainment by interacting with media devices. Using components of the electroencephalogram (EEG) to mediate expression is also technically possible, but is much more speculative, and without proven efficacy. The IGUI-BCI approach described could potentially find wider use in the augmentation of the general population, to provide alternative computer interaction, an additional control channel and experimental leisure activities.","2010-04-02","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","1–8","","","","","","","AH '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/PTT26EYM/McCullagh et al. - 2010 - Brain Computer Interfaces for inclusion.pdf","","","user interface; brain computer interfaces; domotic control; entertainment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2C2FMEY8","conferencePaper","2016","Yu, Bin; Bongers, Nienke; van Asseldonk, Alissa; Hu, Jun; Funk, Mathias; Feijs, Loe","LivingSurface: Biofeedback through Shape-changing Display","Proceedings of the TEI '16: Tenth International Conference on Tangible, Embedded, and Embodied Interaction","978-1-4503-3582-9","","10.1145/2839462.2839469","https://dl.acm.org/doi/10.1145/2839462.2839469","In this paper we describe the concept, design and implementation of LivingSurface, an interactive wall-like surface as a shape-changing display of biofeedback. The surface changes its shape responding to an individual's physiological data, reflecting the internal bodily processes. The surface design basically consists of two layers: the pattern layer (front layer) and the actuating layer (back layer). The first is a complex paper-based structure with repetitive incisions created by laser cutting. The actuating layer serves as a medium transforming the force from servomotors, vibration motors or fans into an action on the pattern layer. The cutout patterns are stimulated to vibrate, swing, bulge, or rotate which is used to display physiological information in dynamic physical form. This work has been exhibited on Milan Design Week 2015; we collected and analyzed the feedback from the visitors during the exhibition and discuss the possibilities of the proposed surfaces as a shape-changing interface of biofeedback or an ambient display of information.","2016-02-14","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","168–175","","","","","","LivingSurface","TEI '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/YEZHBN93/Yu et al. - 2016 - LivingSurface Biofeedback through Shape-changing .pdf","","","Biofeedback; interactive object; information visualization; physical display; shape-changing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2L522Z5F","conferencePaper","2010","Jo, Hyun; Martens, William L.; Park, Youngjin; Kim, Sunmin","Confirming the perception of virtual source elevation effects created using 5.1 channel surround sound playback","Proceedings of the 9th ACM SIGGRAPH Conference on Virtual-Reality Continuum and its Applications in Industry","978-1-4503-0459-7","","10.1145/1900179.1900200","https://dl.acm.org/doi/10.1145/1900179.1900200","Employing an array of nine speakers, five of which were at the listener's ear level, and four of which were elevated well above the listener's ear level, an experimental investigation of virtual sound source elevation was completed in each of three reproduction environments. The primary question of interest was that regarding whether the elevation of virtual sound sources could be modulated in a simple fashion using only the five ear-level speakers that form a conventional 5.1 channel surround-sound speaker layout [ITU-R. BS. 775-1. 1994]. It was found that the creation of elevated virtual sources was possible using the two surround-channel speakers or using all five ear-level speakers, and the resulting elevated virtual source imagery was compared with the source imagery associated with sound reproduced via speakers that were actually well elevated above the listener's ear level. Besides the extremely dry listening conditions of the anechoic chamber, tests were completed in a reverberation chamber, and in a moderately dry audio surround production studio, typical of the controlled acoustics featured in many critical listening spaces. The fact that similar results were observed in each of three listening environments supports the conclusion that the observed results are not idiosyncratic to any particular environment, such as the anechoic chamber, but results will likely generalize across many environments.","2010-12-12","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","103–110","","","","","","","VRCAI '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/9HL8PP5X/Jo et al. - 2010 - Confirming the perception of virtual source elevat.pdf","","","5.1 channel surround sound; elevation perception; sound localization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VHZGRKEU","conferencePaper","2010","Murphy, Emma; Bates, Enda; Fitzpatrick, Dónal","Designing auditory cues to enhance spoken mathematics for visually impaired users","Proceedings of the 12th international ACM SIGACCESS conference on Computers and accessibility","978-1-60558-881-0","","10.1145/1878803.1878819","https://dl.acm.org/doi/10.1145/1878803.1878819","Visual mathematic notation provides a succinct and unambiguous description of the structure of mathematical formulae in a manner that is difficult to replicate through the linear channels of synthesized speech and Braille. It is proposed that the use of auditory cues can enhance accessibility to mathematical material and reduce common ambiguities encountered through spoken mathematics. However, the use of additional complex hierarchies of non-speech sounds to represent the structure and scope of equations may be cognitively demanding to process. This can detract from the users' understanding of the mathematical content. In this paper, a new system is presented, which uses a mixture of non-speech auditory cues, modified speech (spearcons) and binaural spatialization to disambiguate the structure of mathematical formulae. A design study, involving an online survey with 56 users, was undertaken to evaluate an existing set of auditory cues and to brainstorm alternative ideas and solutions from users before implementing modified designs and conducting a separate controlled evaluation. It is proposed that by involving a wide number of users in the creative design process, intuitive auditory cues will be implemented with the potential to enhance spoken mathematics for visually impaired users.","2010-10-25","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","75–82","","","","","","","ASSETS '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/UE8FTQK7/Murphy et al. - 2010 - Designing auditory cues to enhance spoken mathemat.pdf","","","accessibility; spearcons; non-speech sound; visually impaired users; design methods for user interfaces; mathematics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F3AYR97Q","conferencePaper","2007","Hoggan, Eve; Brewster, Stephen","Designing audio and tactile crossmodal icons for mobile devices","Proceedings of the 9th international conference on Multimodal interfaces","978-1-59593-817-6","","10.1145/1322192.1322222","https://dl.acm.org/doi/10.1145/1322192.1322222","This paper reports an experiment into the design of crossmodal icons which can provide an alternative form of output for mobile devices using audio and tactile modalities to communicate information. A complete set of crossmodal icons was created by encoding three dimensions of information in three crossmodal auditory/tactile parameters. Earcons were used for the audio and Tactons for the tactile crossmodal icons. The experiment investigated absolute identification of audio and tactile crossmodal icons when a user is trained in one modality and tested in the other (and given no training in the other modality) to see if knowledge could be transferred between modalities. We also compared performance when users were static and mobile to see any effects that mobility might have on recognition of the cues. The results showed that if participants were trained in sound with Earcons and then tested with the same messages presented via Tactons they could recognize 85% of messages when stationary and 76% when mobile. When trained with Tactons and tested with Earcons participants could accurately recognize 76.5% of messages when stationary and 71% of messages when mobile. These results suggest that participants can recognize and understand a message in a different modality very effectively. These results will aid designers of mobile displays in creating effective crossmodal cues which require minimal training for users and can provide alternative presentation modalities through which information may be presented if the context requires.","2007-11-12","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","162–169","","","","","","","ICMI '07","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/4SZQX6JH/Hoggan and Brewster - 2007 - Designing audio and tactile crossmodal icons for m.pdf","","","multimodal interaction; earcons; crossmodal interaction; mobile interaction; tactons (tactile icons)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"85D6SJVA","conferencePaper","2016","Mirnig, Alexander G.; Perterer, Nicole; Meschtscherjakov, Alexander; Krischkowsky, Alina; Neureiter, Katja; Laminger, Arno; Tscheligi, Manfred","Enhancing Telephone Communication in the Vehicle Through Audio from the Headrest: A Comparison Study","Proceedings of the 8th International Conference on Automotive User Interfaces and Interactive Vehicular Applications","978-1-4503-4533-0","","10.1145/3003715.3005415","https://dl.acm.org/doi/10.1145/3003715.3005415","The distraction potential of communication systems in the automotive context necessitates hands-free and attention undemanding systems. Today's hands-free car kits are of increasingly high quality, since bad audio quality can negatively impact the overall communication quality. Most solutions use built-in speakers for output and a microphone near the driver (e.g. on the ceiling). Thereby, audio quality can suffer e.g. from the long distance between the speaker and the listener. In a recent study, we compared perceived voice quality and social presence of a prototype with speakers installed in the headrest of a vehicle, to a high-end on-board audio system in a communication situation between a person sitting in the driver's seat and a person outside the vehicle. We found that Personal Audio received generally better results while also introducing its own set of issues, e.g., causing spatial disorientation in communication situations, in which other individuals are present in the car.","2016-10-24","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","59–66","","","","","","Enhancing Telephone Communication in the Vehicle Through Audio from the Headrest","Automotive'UI 16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/BSLMPS7V/Mirnig et al. - 2016 - Enhancing Telephone Communication in the Vehicle T.pdf","","","user study; social presence; Headrest speaker; in-car audio; perceived quality of experience","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DG3WP897","conferencePaper","2012","Grimshaw, Mark; Garner, Tom","The use of sound to represent data and concepts as a means to engender creative thought: some thoughts on implementation and a research agenda","Proceedings of the 7th Audio Mostly Conference: A Conference on Interaction with Sound","978-1-4503-1569-2","","10.1145/2371456.2371458","https://dl.acm.org/doi/10.1145/2371456.2371458","This paper poses the question: How can sound be used to function analogously to the function of the images in a graph in order to create the conditions for creative thought and insight to occur and thus to facilitate the synthesis of new knowledge? It uses this to develop further questions and a research agenda. In particular, it is concerned with the use of sonification of the non-audio data and concepts represented in a diagram or graph and the techniques that might be used to foster a creative research environment using sound. The ultimate goal of the research agenda is to go beyond sonification and to use sound pro-actively in a Virtual Research Environment in order to create the conditions for creative thinking and insight to occur with the hope that this may then lead to the synthesis of new knowledge.","2012-09-26","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","9–15","","","","","","The use of sound to represent data and concepts as a means to engender creative thought","AM '12","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/4BK2ASJ6/Grimshaw and Garner - 2012 - The use of sound to represent data and concepts as.pdf","","","emotion; sound; cognition; creativity; knowledge synthesis; meaning; virtual research environment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E3KQUGBR","conferencePaper","2021","Iber, Michael; Dumphart, Bernhard; de Jesus Oliveira, Victor-Adriel; Ferstl, Stefan; M. Reis, Joschua; Slijepčević, Djordje; Heller, Mario; Raberger, Anna-Maria; Horsak, Brian","Mind the Steps: Towards Auditory Feedback in Tele-Rehabilitation Based on Automated Gait Classification","Proceedings of the 16th International Audio Mostly Conference","978-1-4503-8569-5","","10.1145/3478384.3478398","https://dl.acm.org/doi/10.1145/3478384.3478398","We describe a proof-of-concept for the implementation of a mobile auditory biofeedback system based on automated classification of functional gait disorders. The classification is embedded in a sensor-instrumented insole and is based on ground reaction forces (GRFs). GRF data have been successfully used for the classification of gait patterns into clinically relevant classes and are frequently used in clinical practice to quantitatively describe human motion. A feed-forward neural network that was implemented on the firmware of the insole is used to estimate the GRFs using pressure and accelerator data. Compared to GRF measurements obtained from force plates, the estimated GRFs performed highly accurately. To distinguish between normal physiological gait and gait disorders, we trained and evaluated a support vector machine with labeled data from a publicly accessible database. The automated gait classification was sonified for auditory feedback. The high potential of the implemented auditory feedback for preventive and supportive applications in physical therapy, such as supervised therapy settings and tele-rehabilitation, was highlighted by a semi-structured interview with two experts.","2021-10-15","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","139–146","","","","","","Mind the Steps","AM '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/NMWUIJPS/Iber et al. - 2021 - Mind the Steps Towards Auditory Feedback in Tele-.pdf","","","Auditory Feedback; Rehabilitation; Automated Gait Classification; Biomechanics; Physical Therapy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LTDEX2VF","conferencePaper","2012","McGregor, Iain; Turner, Phil","Soundscapes and repertory grids: comparing listeners' and a designer's experiences","Proceedings of the 30th European Conference on Cognitive Ergonomics","978-1-4503-1786-3","","10.1145/2448136.2448164","https://dl.acm.org/doi/10.1145/2448136.2448164","This paper reports on establishing whether listeners have the same listening experience as the person who designed the sound. Surprisingly, there is little or no evidence as to whether what is designed to be heard is what is actually heard. The study reported here is a qualitative study into these two experiences. Research approach -- A repertory grid technique was adopted using listener and designer generated constructs. One designer and 20 listeners rated 25 elements within a surround sound recording created by a soundscape generative system. The listeners' modal response was compared to the designer's. Findings/Design -- The results suggest that it is perfectly feasible to compare designers and listeners experiences and to establish points of agreement and disagreement. Research limitations/Implications -- Only UK-based university students and staff participated in the study, which limited generalisation of the findings. Originality/Value -- Demonstrates an ontology of sound based on user experience rather than designer's whim. This approach is based upon long-term experiences and our conceptualisation of sound Take away message -- Comparing listeners' experiences could allow designers to be confident with their sound designs.","2012-08-28","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","131–137","","","","","","Soundscapes and repertory grids","ECCE '12","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/SXSQNCXC/McGregor and Turner - 2012 - Soundscapes and repertory grids comparing listene.pdf","","","soundscape; designers; listeners; listening; repertory grid","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H26VVPCF","conferencePaper","2018","Grahn, Hilkka; Kujala, Tuomo","Visual Distraction Effects between In-Vehicle Tasks with a Smartphone and a Motorcycle Helmet-Mounted Head-Up Display","Proceedings of the 22nd International Academic Mindtrek Conference","978-1-4503-6589-5","","10.1145/3275116.3275134","https://dl.acm.org/doi/10.1145/3275116.3275134","Besides motorists, also motorcyclists need safer user interfaces to interact with useful applications on the road. In this paper, distraction effects of in-vehicle tasks conducted with a head-up display (HUD) for motorcyclists were compared to smartphone tasks with 24 participants in a driving simulator. Compared to the smartphone tasks, the head-up display tasks decreased the percentage of inappropriately long glances by 45 percent. The head-up display tasks were also experienced as less demanding than the smartphone tasks. Additionally, the use of head-up display for navigation did not lead to gaze concentration effects compared to baseline driving. The head-up display is concluded to be a safer option for the tested tasks for motorcyclists than a smartphone. Based on earlier research, we assume that the use of peripheral vision allowed drivers to better maintain situational awareness during the head-up display tasks compared to the head-down smartphone tasks. In addition, the easy-to-learn haptic design of the head-up display handlebar controller could be used without vision.","2018-10-10","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","153–162","","","","","","","Mindtrek '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/SNZ698ED/Grahn and Kujala - 2018 - Visual Distraction Effects between In-Vehicle Task.pdf","","","head-down display; head-up display; Driver distraction; head-mounted display; occlusion distance; visual demand; visual occlusion","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IVFD6PUS","conferencePaper","2015","Gerino, Andrea; Picinali, Lorenzo; Bernareggi, Cristian; Alabastro, Nicolò; Mascetti, Sergio","Towards Large Scale Evaluation of Novel Sonification Techniques for Non Visual Shape Exploration","Proceedings of the 17th International ACM SIGACCESS Conference on Computers & Accessibility","978-1-4503-3400-6","","10.1145/2700648.2809848","https://dl.acm.org/doi/10.1145/2700648.2809848","There are several situations in which a person with visual impairment or blindness needs to extract information from an image. Examples include everyday activities, like reading a map, as well as educational activities, like exercises to develop visuospatial skills. In this contribution we propose a set of 6 sonification techniques to recognize simple shapes on touchscreen devices. The effectiveness of these sonification techniques is evaluated though Invisible Puzzle, a mobile application that makes it possible to conduct non-supervised evaluation sessions. Invisible Puzzle adopts a gamification approach and is a preliminary step in the development of a complete game that will make it possible to conduct a large scale evaluation with hundreds or thousands of blind users. With Invisible Puzzle we conducted 131 tests with sighted subjects and 18 tests with subjects with blindness. All subjects involved in the process successfully completed the evaluation session, with high engagement, hence showing the effectiveness of the evaluation procedure. Results give interesting insights on the differences among the sonification techniques and, most importantly, show that, after a short training, subjects are able to identify many different shapes.","2015-10-26","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","13–21","","","","","","","ASSETS '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/H6I6XXF4/Gerino et al. - 2015 - Towards Large Scale Evaluation of Novel Sonificati.pdf","","","sonification; accessibility; gamification; image recognition; remote evaluation; touch-screen devices; visual impairment or blindness","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"29H2GRXS","conferencePaper","2019","Urbanek, Michael; Güldenpfennig, Florian","Celebrating 20 Years of Computer-based Audio Gaming","Proceedings of the 14th International Audio Mostly Conference: A Journey in Sound","978-1-4503-7297-8","","10.1145/3356590.3356605","https://dl.acm.org/doi/10.1145/3356590.3356605","We look back on two decades of academic research on audio games. During this time, a substantial amount of research has explored many facets of this special genre of computer games. However, despite many publications, there is a lack of review papers, which help delineate this growing research field. For this reason, we take one step back and investigate 20 years of audio game research by synthesizing a literature review adopting grounded theory methods. The resulting research map provides an overview of efforts into audio games with a special focus on how to design for audio games. We observed three important trends or tensions in audio game research. Firstly, audio games research depended heavily on technological advancements during the last two decades. Secondly, most studies about audio games were conducted with novices to audio games in lab situations, that is, based on artificial situations and not on real gamers and their genuine experience. Thirdly, the audio game design process per se has been greatly neglected in the literature so far. We conclude the paper by discussing design or research implications.","2019-09-18","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","90–97","","","","","","","AM'19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/QRKUBTHV/Urbanek and Güldenpfennig - 2019 - Celebrating 20 Years of Computer-based Audio Gamin.pdf","","","Review; Audio Games; Game Design; Grounded TheoryMethods","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GPA2YIRS","conferencePaper","2013","Langlotz, Tobias; Regenbrecht, Holger; Zollmann, Stefanie; Schmalstieg, Dieter","Audio stickies: visually-guided spatial audio annotations on a mobile augmented reality platform","Proceedings of the 25th Australian Computer-Human Interaction Conference: Augmentation, Application, Innovation, Collaboration","978-1-4503-2525-7","","10.1145/2541016.2541022","https://dl.acm.org/doi/10.1145/2541016.2541022","This paper describes spatially aligned user-generated audio annotations and the integration with visual augmentations into a single mobile AR system. Details of our prototype system are presented, along with an explorative usability study and technical evaluation of the design. Mobile Augmented Reality applications allow for visual augmentations as well as tagging and annotation of the surrounding environment. Texts and graphics are currently the media of choice for these applications with GPS coordinates used to determine spatial location. Our research demonstrates that the use of visually guided audio annotations that are positioned and orientated in augmented outdoor space successfully provides for additional, novel, and enhanced mobile user experience.","2013-11-25","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","545–554","","","","","","Audio stickies","OzCHI '13","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/CBKKSQTZ/Langlotz et al. - 2013 - Audio stickies visually-guided spatial audio anno.pdf","","","augmented reality; spatial audio; mobile phone","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3DXDT7YG","conferencePaper","2014","Heller, Florian; Krämer, Aaron; Borchers, Jan","Simplifying orientation measurement for mobile audio augmented reality applications","Proceedings of the SIGCHI Conference on Human Factors in Computing Systems","978-1-4503-2473-1","","10.1145/2556288.2557021","https://dl.acm.org/doi/10.1145/2556288.2557021","Audio augmented reality systems overlay the physical world with a virtual audio space. Today's smartphones provide enough processing power to create the impression of virtual sound sources being located in the real world. To achieve this, information about the user's location and orientation is necessary which requires additional hardware. In a real-world installation, however, we observed that instead of turning their head to localize sounds, users tend to turn their entire body. Therefore, we suggest to simply measure orientation of the user's body - or even just the mobile device she is holding - to generate the spatial audio. To verify this approach, we present two studies: Our first study in examines the user's head, body, and mobile device orientation when moving through an audio augmented reality system in a lab setting. Our second study analyzes the user experience in a real-world installation when using head, body, or device orientation to control the audio spatialization. We found that when navigating close to sound sources head tracking is necessary, but that it can potentially be replaced by device tracking in larger or more explorative usage scenarios. These findings help reduce the technical complexity of mobile audio augmented reality systems (MAARS), and enable their wider dissemination as mobile software-only apps.","2014-04-26","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","615–624","","","","","","","CHI '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/DWUVPEGU/Heller et al. - 2014 - Simplifying orientation measurement for mobile aud.pdf","","","spatial audio; mobile devices; orientation; audio augmented reality; binaural rendering; presence","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5SMPI9MS","conferencePaper","2011","Karuei, Idin; MacLean, Karon E.; Foley-Fisher, Zoltan; MacKenzie, Russell; Koch, Sebastian; El-Zohairy, Mohamed","Detecting vibrations across the body in mobile contexts","Proceedings of the SIGCHI Conference on Human Factors in Computing Systems","978-1-4503-0228-9","","10.1145/1978942.1979426","https://dl.acm.org/doi/10.1145/1978942.1979426","In this paper we explore the potential and limitations of vibrotactile displays in practical wearable applications, by comparing users' detection rate and response time to stimuli applied across the body in varied conditions. We examined which body locations are more sensitive to vibrations and more affected by movement; whether visual workload, expectation of location, or gender impact performance; and if users have subjective preferences to any of these conditions. In two experiments we compared these factors using five vibration intensities on up to 13 body locations. Our contributions are comparisons of tactile detection performance under conditions typifying mobile use, an experiment design that supports further investigation in vibrotactile communication, and guidelines for optimal display location given intended use.","2011-05-07","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","3267–3276","","","","","","","CHI '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/I5VW7H7C/Karuei et al. - 2011 - Detecting vibrations across the body in mobile con.pdf","","","mobile applications; vibrotactile display; wearable haptics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GXVP5TK4","conferencePaper","2012","Bakker, Saskia; van den Hoven, Elise; Eggen, Berry; Overbeeke, Kees","Exploring peripheral interaction design for primary school teachers","Proceedings of the Sixth International Conference on Tangible, Embedded and Embodied Interaction","978-1-4503-1174-8","","10.1145/2148131.2148184","https://dl.acm.org/doi/10.1145/2148131.2148184","This paper explores the concept of peripheral interactions; interactions with technology that take place in the background or periphery of the attention. We present two designs for a classroom setting. CawClock makes selected time frames audible in order to provide teachers with awareness of time. NoteLet is designed to support the teacher in observing children's behavior, by enabling him or her to take pictures of the classroom through straightforward interactions on a bracelet. A qualitative, two-week exploration of both systems in a classroom revealed that the soundscapes of CawClock indeed shifted to the periphery of the attention and supported the teacher's time awareness. The actions with NoteLet did not shift to the periphery. However, the tangible aspects of NoteLet seemed to facilitate the interaction to be quick and simple, which may indicate that it could shift to the periphery with more practice. Tangible interaction therefore seems a promising interaction style for this purpose.","2012-02-19","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","245–252","","","","","","","TEI '12","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/4I4VTHFA/Bakker et al. - 2012 - Exploring peripheral interaction design for primar.pdf","","","design; tangible interaction; audio; attention; calm technology; peripheral interaction; awareness; periphery","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NQWCLTMQ","conferencePaper","2018","Shim, Youngbo Aram; Lee, Jaeyeon; Lee, Geehyuk","Exploring Multimodal Watch-back Tactile Display using Wind and Vibration","Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems","978-1-4503-5620-6","","10.1145/3173574.3173706","https://dl.acm.org/doi/10.1145/3173574.3173706","A tactile display on the back of a smartwatch is an attractive output option; however, its channel capacity is limited owing to the small contact area. In order to expand the channel capacity, we considered using two perceptually distinct types of stimuli, wind and vibration, together on the same skin area. The result is a multimodal tactile display that combines wind and vibration to create ""colored"" tactile sensations on the wrist. As a first step toward this goal, we conducted in this study four user experiments with a wind-vibration tactile display to examine different ways of combining wind and vibration: Individual, Sequential, and Simultaneous. The results revealed the sequential combination of wind and vibration to exhibit the highest potential, with an information transfer capacity of 3.29 bits. In particular, the transition of tactile modality was perceived at an accuracy of 98.52%. The current results confirm the feasibility and potential of a multimodal tactile display combining wind and vibration.","2018-04-19","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","1–12","","","","","","","CHI '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/DENQVVS9/Shim et al. - 2018 - Exploring Multimodal Watch-back Tactile Display us.pdf","","","vibrotactile display; airflow display; multimodal tactile display; watch-back tactile display; wearable tactile display","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NV292NSF","conferencePaper","2010","Costanza, Enrico; Panchard, Jacques; Zufferey, Guillaume; Nembrini, Julien; Freudiger, Julien; Huang, Jeffrey; Hubaux, Jean-Pierre","SensorTune: a mobile auditory interface for DIY wireless sensor networks","Proceedings of the SIGCHI Conference on Human Factors in Computing Systems","978-1-60558-929-9","","10.1145/1753326.1753675","https://dl.acm.org/doi/10.1145/1753326.1753675","Wireless Sensor Networks (WSNs) allow the monitoring of activity or environmental conditions over a large area, from homes to industrial plants, from agriculture fields to forests and glaciers. They can support a variety of applications, from assisted living to natural disaster prevention. WSNs can, however, be challenging to setup and maintain, reducing the potential for real-world adoption. To address this limitation, this paper introduces SensorTune, a novel mobile interface to support non-expert users in iteratively setting up a WSN. SensorTune uses non-speech audio to present to its users information regarding the connectivity of the network they are setting up, allowing them to decide how to extend it. To simplify the interpretation of the data presented, the system adopts the metaphor of tuning a consumer analog radio, a very common and well known operation. A user study was conducted in which 20 subjects setup real multi-hop networks inside a large building using a limited number of wireless nodes. Subjects repeated the task with SensorTune and with a comparable mobile GUI interface. Experimental results show a statistically significant difference in the task completion time and a clear preference of users for the auditory interface.","2010-04-10","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","2317–2326","","","","","","SensorTune","CHI '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/QU33W5L3/Costanza et al. - 2010 - SensorTune a mobile auditory interface for DIY wi.pdf","","","sonification; wireless sensor network; user study; mobile hci; network deployment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CE9BLLN3","conferencePaper","2016","Russell, Spencer; Dublon, Gershon; Paradiso, Joseph A.","HearThere: Networked Sensory Prosthetics Through Auditory Augmented Reality","Proceedings of the 7th Augmented Human International Conference 2016","978-1-4503-3680-2","","10.1145/2875194.2875247","https://dl.acm.org/doi/10.1145/2875194.2875247","In this paper we present a vision for scalable indoor and outdoor auditory augmented reality (AAR), as well as HearThere, a wearable device and infrastructure demonstrating the feasibility of that vision. HearThere preserves the spatial alignment between virtual audio sources and the user's environment, using head tracking and bone conduction headphones to achieve seamless mixing of real and virtual sounds. To scale between indoor, urban, and natural environments, our system supports multi-scale location tracking, using fine-grained (20-cm) Ultra-WideBand (UWB) radio tracking when in range of our infrastructure anchors and mobile GPS otherwise. In our tests, users were able to navigate through an AAR scene and pinpoint audio source locations down to 1m. We found that bone conduction is a viable technology for producing realistic spatial sound, and show that users' audio localization ability is considerably better in UWB coverage zones than with GPS alone. HearThere is a major step towards realizing our vision of networked sensory prosthetics, in which sensor networks serve as collective sensory extensions into the world around us. In our vision, AAR would be used to mix spatialized data sonification with distributed, livestreaming microphones. In this concept, HearThere promises a more expansive perceptual world, or umwelt, where sensor data becomes immediately attributable to extrinsic phenomena, externalized in the wearer's perception. We are motivated by two goals: first, to remedy a fractured state of attention caused by existing mobile and wearable technologies; and second, to bring the distant or often invisible processes underpinning a complex natural environment more directly into human consciousness.","2016-02-25","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","1–8","","","","","","HearThere","AH '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/I6TPE24V/Russell et al. - 2016 - HearThere Networked Sensory Prosthetics Through A.pdf","","","sonification; auditory augmented reality; bone conduction; sensory augmentation; UWB","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WC7KYNJZ","conferencePaper","2022","Johansen, Stine S.; van Berkel, Niels; Fritsch, Jonas","Characterising Soundscape Research in Human-Computer Interaction","Designing Interactive Systems Conference","978-1-4503-9358-4","","10.1145/3532106.3533458","https://dl.acm.org/doi/10.1145/3532106.3533458","‘Soundscapes’ are an increasingly active topic in Human-Computer Interaction (HCI) and interaction design. From mapping acoustic environments through sound recordings to designing compositions as interventions, soundscapes appear as a recurring theme across a wide body of HCI research. Based on this growing interest, now is the time to explore the types of studies in which soundscapes provide a valuable lens to HCI research. In this paper, we review papers from conferences sponsored or co-sponsored by the ACM Special Interest Group on Computer-Human Interaction in which the term ’soundscape’ occurs. We analyse a total of 235 papers to understand the role of soundscapes as a research focus and identify untapped opportunities for soundscape research within HCI. We identify two common soundscape conceptualisations: (1) Acoustic environments and (2) Compositions, and describe what characterises studies into each concept and the hybrid forms that also occur. On the basis of this, we carve out a foundation for future soundscape research in HCI as a methodological anchor to form a common ground and support this growing research interest. Finally, we offer five recommendations for further research into soundscapes within HCI.","2022-06-13","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","1394–1417","","","","","","","DIS '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/HTN6Q97K/Johansen et al. - 2022 - Characterising Soundscape Research in Human-Comput.pdf","","","Soundscape; audio; literature review; sounds; theory","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VR9N3H6H","conferencePaper","2009","Crossan, Andrew; McGill, Mark; Brewster, Stephen; Murray-Smith, Roderick","Head tilting for interaction in mobile contexts","Proceedings of the 11th International Conference on Human-Computer Interaction with Mobile Devices and Services","978-1-60558-281-8","","10.1145/1613858.1613866","https://dl.acm.org/doi/10.1145/1613858.1613866","Developing interfaces for mobile situations requires that devices are useable on the move. Here, we explore head tilting as an input technique to allow a user to interact with a mobile device 'hands free'. A Fitts' Law style evaluation is described where a user acquires targets, moving the cursor by head tilt. We explore d position and velocity control cursor mechanisms in both static and mobile situations to see which provided the best level of performance. Results show that participants could successfully acquire targets using head tilting. Position control was shown to be si gnificantly faster and more accurate in a static context, but exhi bited significantly poorer accuracy and longer target acquisition times when the user was on the move. We further demonstrate how analysis of user's gait shows consistent targeting biases at different stages in the gait cycle.","2009-09-15","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","1–10","","","","","","","MobileHCI '09","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/U66YX5DP/Crossan et al. - 2009 - Head tilting for interaction in mobile contexts.pdf","","","mobile; accelerometer; Fitts' law; hands-free interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TUKJDEAB","conferencePaper","2019","Lee, Yi-Chen; Cherng, Fu-Yin; King, Jung-Tai; Lin, Wen-Chieh","To Repeat or Not to Repeat? Redesigning Repeating Auditory Alarms Based on EEG Analysis","Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems","978-1-4503-5970-2","","10.1145/3290605.3300743","https://dl.acm.org/doi/10.1145/3290605.3300743","Auditory alarms that repeatedly interrupt users until they react are common, especially in the context of alarms. However, when an alarm repeats, our brains habituate to it and perceive it less and less, with reductions in both perception and attention-shifting: a phenomenon known as the repetition-suppression effect (RS). To retain users' perception and attention, this paper proposes and tests the use of pitch- and intensity-modulated alarms. Its experimental findings suggest that the proposed modulated alarms can reduce RS, albeit in different patterns, depending on whether pitch or intensity is the focus of the modulation. Specifically, pitch-modulated alarms were found to reduce RS more when the number of repetitions was small, while intensity-modulated alarms reduced it more as the number of repetitions increased. Based on these results, we make several recommendations for the design of improved repeating alarms, based on which modulation approach should be adopted in various situations.","2019-05-02","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","1–10","","","","","","To Repeat or Not to Repeat?","CHI '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/MU4N6JWH/Lee et al. - 2019 - To Repeat or Not to Repeat Redesigning Repeating .pdf","","","brain-computer interface; neuroergonomics; auditory alarms","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ECCYLASS","conferencePaper","2009","Garzonis, Stavros; Jones, Simon; Jay, Tim; O'Neill, Eamonn","Auditory icon and earcon mobile service notifications: intuitiveness, learnability, memorability and preference","Proceedings of the SIGCHI Conference on Human Factors in Computing Systems","978-1-60558-246-7","","10.1145/1518701.1518932","https://dl.acm.org/doi/10.1145/1518701.1518932","With an ever increasing number of mobile services, meaningful audio notifications could effectively inform users of the incoming services while minimising undesired and intrusive interruptions. Therefore, careful design of mobile service notification is needed. In this paper we evaluate two types of audio (auditory icons and earcons) as mobile service notifications, by comparing them on 4 measures: intuitiveness, learnability, memorability and user preference. A 4-stage longitudinal evaluation involving two lab experiments, a field study and a web-based experiment indicated that auditory icons performed significantly better in all measures. Implications for mobile audio notification design are presented.","2009-04-04","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","1513–1522","","","","","","Auditory icon and earcon mobile service notifications","CHI '09","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/9TJKN2M7/Garzonis et al. - 2009 - Auditory icon and earcon mobile service notificati.pdf","","","auditory icons; earcons; mobile audio notifications; intuitiveness; learnability; memorability; mobile services","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TYC25ZC5","conferencePaper","2021","Quinton, Michael; McGregor, Iain; Benyon, David","Sonification of Planetary Orbits in Asteroid Belts","Proceedings of the 16th International Audio Mostly Conference","978-1-4503-8569-5","","10.1145/3478384.3478390","https://dl.acm.org/doi/10.1145/3478384.3478390","This study investigates the design and evaluation of a sonification designed to detect any planets orbiting within an asteroid belt of an exosolar system. The interface was designed for an astronomer who studies this phenomenon. User centered design methods were applied to create an accurate sonification of the data that could allow the astronomer to perceive possible planetary movements within an asteroid belt. The sonification was developed over three stages: A requirements gathering exercise inquiring about the data that the astronomer uses in her work. A design and development stage based on the findings of the requirements gathering and the third stage, an evaluation of the sonification design. The sonification effectively allowed the astronomer to immediately detect a planet orbiting within an asteroid belt. Multiple parameter mappings provide richer auditory stimuli that are more semantical to the user. The use of more familiar, natural sounding sound design led to a clearer comprehension of the dataset. The use of spatial mapping and movement allowed for immediate identification and understanding of the planet's course through the asteroid belt.","2021-10-15","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","72–80","","","","","","","AM '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/2MDKT23T/Quinton et al. - 2021 - Sonification of Planetary Orbits in Asteroid Belts.pdf","","","Sonification; Astronomy; Exoplanet hunting; Grounded theory; Parameter mapping sonification; User centered design","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FR5NHFK8","conferencePaper","2021","Jung, Jingun; Son, Sunmin; Lee, Sangyoon; Kim, Yeonsu; Lee, Geehyuk","ThroughHand: 2D Tactile Interaction to Simultaneously Recognize and Touch Multiple Objects","Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems","978-1-4503-8096-6","","10.1145/3411764.3445530","https://dl.acm.org/doi/10.1145/3411764.3445530","Users with visual impairments find it difficult to enjoy real-time 2D interactive applications on the touchscreen. Touchscreen applications such as sports games often require simultaneous recognition of and interaction with multiple moving targets through vision. To mitigate this issue, we propose ThroughHand, a novel tactile interaction that enables users with visual impairments to interact with multiple dynamic objects in real time. We designed the ThroughHand interaction to utilize the potential of the human tactile sense that spatially registers both sides of the hand with respect to each other. ThroughHand allows interaction with multiple objects by enabling users to perceive the objects using the palm while providing a touch input space on the back of the same hand. A user study verified that ThroughHand enables users to locate stimuli on the palm with a margin of error of approximately 13 mm and effectively provides a real-time 2D interaction experience for users with visual impairments.","2021-05-07","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","1–13","","","","","","ThroughHand","CHI '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/9PQ4TDMK/Jung et al. - 2021 - ThroughHand 2D Tactile Interaction to Simultaneou.pdf","","","Games; Haptics; Accessibility; Real-time interaction; Shape-changing display; Visual impairments","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9F879HMM","conferencePaper","2019","Rogers, Katja; Funke, Jana; Frommel, Julian; Stamm, Sven; Weber, Michael","Exploring Interaction Fidelity in Virtual Reality: Object Manipulation and Whole-Body Movements","Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems","978-1-4503-5970-2","","10.1145/3290605.3300644","https://dl.acm.org/doi/10.1145/3290605.3300644","High degrees of interaction fidelity (IF) in virtual reality (VR) are said to improve user experience and immersion, but there is also evidence of low IF providing comparable experiences. VR games are now increasingly prevalent, yet we still do not fully understand the trade-off between realism and abstraction in this context. We conducted a lab study comparing high and low IF for object manipulation tasks in a VR game. In a second study, we investigated players' experiences of IF for whole-body movements in a VR game that allowed players to crawl underneath virtual boulders and ""dangle'' along monkey bars. Our findings show that high IF is preferred for object manipulation, but for whole-body movements, moderate IF can suffice, as there is a trade-off with usability and social factors. We provide guidelines for the development of VR games based on our results.","2019-05-02","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","1–14","","","","","","Exploring Interaction Fidelity in Virtual Reality","CHI '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/ADB9ADAR/Rogers et al. - 2019 - Exploring Interaction Fidelity in Virtual Reality.pdf","","","virtual reality; games; interaction fidelity; player experience; virtual objects; whole body interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y6SZXAN8","conferencePaper","2019","Wedoff, Ryan; Ball, Lindsay; Wang, Amelia; Khoo, Yi Xuan; Lieberman, Lauren; Rector, Kyle","Virtual Showdown: An Accessible Virtual Reality Game with Scaffolds for Youth with Visual Impairments","Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems","978-1-4503-5970-2","","10.1145/3290605.3300371","https://dl.acm.org/doi/10.1145/3290605.3300371","Virtual Reality (VR) is a growing source of entertainment, but people who are visually impaired have not been effectively included. Audio cues are motivated as a complement to visuals, making experiences more immersive, but are not a primary cue. To address this, we implemented a VR game called Virtual Showdown. We based Virtual Showdown on an accessible real-world game called Showdown, where people use their hearing to locate and hit a ball against an opponent. Further, we developed Verbal and Verbal/Vibration Scaffolds to teach people how to play Virtual Showdown. We assessed the acceptability of Virtual Showdown and compared our scaffolds in an empirical study with 34 youth who are visually impaired. Thirty-three participants wanted to play Virtual Showdown again, and we learned that participants scored higher with the Verbal Scaffold or if they had prior Showdown experience. Our empirical findings inform the design of future accessible VR experiences.","2019-05-02","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","1–15","","","","","","Virtual Showdown","CHI '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/XLARJ9I3/Wedoff et al. - 2019 - Virtual Showdown An Accessible Virtual Reality Ga.pdf","","","blind; virtual reality; low vision; spatial audio; haptics; youth","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ACLBAYUL","conferencePaper","2021","Gonçalves, David; Rodrigues, André; Richardson, Mike L.; de Sousa, Alexandra A.; Proulx, Michael J.; Guerreiro, Tiago","Exploring Asymmetric Roles in Mixed-Ability Gaming","Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems","978-1-4503-8096-6","","10.1145/3411764.3445494","https://dl.acm.org/doi/10.1145/3411764.3445494","The landscape of digital games is segregated by player ability. For example, sighted players have a multitude of highly visual games at their disposal, while blind players may choose from a variety of audio games. Attempts at improving cross-ability access to any of those are often limited in the experience they provide, or disregard multiplayer experiences. We explore ability-based asymmetric roles as a design approach to create engaging and challenging mixed-ability play. Our team designed and developed two collaborative testbed games exploring asymmetric interdependent roles. In a remote study with 13 mixed-visual-ability pairs we assessed how roles affected perceptions of engagement, competence, and autonomy, using a mixed-methods approach. The games provided an engaging and challenging experience, in which differences in visual ability were not limiting. Our results underline how experiences unequal by design can give rise to an equitable joint experience.","2021-05-07","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","1–14","","","","","","","CHI '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/P7R8BQC5/Gonçalves et al. - 2021 - Exploring Asymmetric Roles in Mixed-Ability Gaming.pdf","","","visual impairment; inclusion; game accessibility; mixed-ability; social gaming","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8EFV4SU2","conferencePaper","2020","Gonçalves, David; Rodrigues, André; Guerreiro, Tiago","Playing With Others: Depicting Multiplayer Gaming Experiences of People With Visual Impairments","Proceedings of the 22nd International ACM SIGACCESS Conference on Computers and Accessibility","978-1-4503-7103-2","","10.1145/3373625.3418304","https://dl.acm.org/doi/10.1145/3373625.3418304","Games bring people together in immersive and challenging interactions. In this paper, we share multiplayer gaming experiences of people with visual impairments collected from interviews with 10 adults and 10 minors, and 140 responses to an online survey. We include the perspectives of 17 sighted people who play with someone who has a visual impairment, collected in a second online survey. Our focus is on group play, particularly on the problems and opportunities that arise from mixed-visual-ability scenarios. These show that people with visual impairments are playing diverse games, but face limitations in playing with others who have different visual abilities. What stands out is the lack of intersection in gaming opportunities, and consequently, in habits and interests of people with different visual abilities. We highlight barriers associated with these experiences beyond inaccessibility issues and discuss implications and opportunities for the design of mixed-ability gaming.","2020-10-29","2023-07-06 05:58:37","2023-07-06 05:58:37","2023-07-05","1–12","","","","","","Playing With Others","ASSETS '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/3JUA4GLK/Gonçalves et al. - 2020 - Playing With Others Depicting Multiplayer Gaming .pdf","","","visual impairment; inclusion; game accessibility; mixed-ability; social gaming","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4QGGUGTJ","conferencePaper","2010","Dingler, Tilman; Brewster, Stephen","AudioFeeds: a mobile auditory application for monitoring online activities","Proceedings of the 18th ACM international conference on Multimedia","978-1-60558-933-6","","10.1145/1873951.1874151","https://dl.acm.org/doi/10.1145/1873951.1874151","User participation has transformed the way news travel the globe. With the rise of the 'Web 2.0' phenomenon users have been empowered with the means of creating and distributing informational items, which we call social feeds. Platforms like Twitter and Facebook provide a variety of tools to facilitate real-time communication among people. But social sites are not limited to personal chat; they also provide an effective means for organizing large groups of people in response to catastrophic disasters. Monitoring these feeds can provide time-critical information, but can easily lead to information overload due to the large amount of data being shared. In this paper we introduce a mobile auditory display application called AudioFeeds that allows users to maintain an overview of activities in different social feeds. AudioFeeds runs on a mobile device and enables users to get an overview of their social networks and spot peaks in activity by sonifying social feeds and creating a spatialised soundscape around the user's head. We conducted a user study looking into different aspects of activity monitoring. Results show that our application provides an effective way for monitoring overall activity levels and allows users to identify activity peaks with 86.1% accuracy even when mobile.","2010-10-25","2023-07-06 06:06:10","2023-07-06 06:06:10","2023-07-05","1067–1070","","","","","","AudioFeeds","MM '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/LK8JQICW/Dingler and Brewster - 2010 - AudioFeeds a mobile auditory application for moni.pdf","","","auditory display; social media; mobile application","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KCWSL7QU","conferencePaper","2017","Kreković, G.; Vican, I.","Towards a Parallel Computing Framework for Direct Sonification of Multivariate Chronological Data","Proceedings of the 12th International Audio Mostly Conference on Augmented and Participatory Sound and Music Experiences","978-1-4503-5373-1","","10.1145/3123514.3123551","https://dl.acm.org/doi/10.1145/3123514.3123551","This paper presents a generic and scalable framework for direct sonification of large multivariate data sets with an explicit time dimension. As digitalization and the process of data collection gathers momentum in many fields of human activity, such large data sets with many dimensions of different data types are common. The specificity of our framework is uniformness of the synthesis technique on different temporal scales achieved by using direct sonification of particular data rows in corresponding sound grains. This way, both distinctiveness of individual data rows and patterns on the higher scale should become perceivable in the synthesized audio content. In order to attain scalability, the implementation relies on parallel computing.","2017-08-23","2023-07-06 06:06:10","2023-07-06 06:06:10","2023-07-05","1–4","","","","","","","AM '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/AVGHL2IC/Kreković and Vican - 2017 - Towards a Parallel Computing Framework for Direct .pdf","","","sonification; auditory display; sound synthesis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZR8LDHIW","conferencePaper","2010","Henthorne, Cody; Tilevich, Eli","Sonifying performance data to facilitate tuning of complex systems: performance tuning: music to my ears","Proceedings of the ACM international conference companion on Object oriented programming systems languages and applications companion","978-1-4503-0240-1","","10.1145/1869542.1869548","https://dl.acm.org/doi/10.1145/1869542.1869548","In the modern computing landscape, the challenge of tuning software systems is exacerbated by the necessity to accommodate multiple divergent execution environments and stakeholders. Achieving optimal performance requires a different configuration for every combination of hardware setups and business requirements. In addition, the state of the art in system tuning can involve complex statistical models, which require deep expertise not commonly possessed by the average software developer. This paper presents a novel approach to tuning complex software systems by leveraging sound to convey performance information during execution. We conducted a scientific survey to determine which sound characteristics (e.g., loudness, panning, pitch, tempo, etc.) are most accurate to express information to the average programmer. As determined by the survey, the characteristics that scored the highest across all the participants were used to create a proof-of-concept demonstration. The demonstration showed that a programmer who is not an expert in either software tuning or enterprise computing can configure the parameters of a real world enterprise application server, so that its resulting performance surpasses that exhibited under the standard configuration. Our results indicate that sound-based tuning approaches can provide valuable solutions to the challenges of configuring complex computer systems.","2010-10-17","2023-07-06 06:06:10","2023-07-06 06:06:10","2023-07-05","35–42","","","","","","Sonifying performance data to facilitate tuning of complex systems","OOPSLA '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/KT82JAB5/Henthorne and Tilevich - 2010 - Sonifying performance data to facilitate tuning of.pdf","","","sonification; empirical studies; enterprise application servers; J2EE; performance tuning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AGUQSTBH","conferencePaper","2020","Groß-Vogt, Katharina","The drinking reminder: prototype of a smart jar","Proceedings of the 15th International Audio Mostly Conference","978-1-4503-7563-4","","10.1145/3411109.3411130","https://dl.acm.org/doi/10.1145/3411109.3411130","The drinking reminder is a smart jar that reminds and motivates its user to drink a certain amount of water over time. The prototype is based on Arduino soft- and hardware and has been used as an exploration platform for sonic interaction design. The presented implementation follows a peripheral approach, using bird sounds.","2020-09-16","2023-07-06 06:06:10","2023-07-06 06:06:10","2023-07-05","257–260","","","","","","The drinking reminder","AM '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/3GKF7MUN/Groß-Vogt - 2020 - The drinking reminder prototype of a smart jar.pdf","","","sonification; sonic interaction design; augmented reality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q9BPKTUB","conferencePaper","2020","Donato, Balandino Di; Dewey, Christopher; Michailidis, Tychonas","Human-Sound Interaction: Towards a Human-Centred Sonic Interaction Design approach","Proceedings of the 7th International Conference on Movement and Computing","978-1-4503-7505-4","","10.1145/3401956.3404233","https://dl.acm.org/doi/10.1145/3401956.3404233","In this paper, we explore human-centered interaction design aspects that determine the realisation and appreciation of musical works (installations, composition and performance), interfaces for sound design and musical expression, augmented instruments, sonic aspects of virtual environments and interactive audiovisual performances. In this first work, with the human at the centre of the design, we started sketching modes of interaction with sound that could result direct, engaging, natural and embodied in a collaborative, interactive, inclusive and diverse music environment. We define this as Human-Sound Interaction (HSI). To facilitate the exploration of HSIs, we prototyped SoundSculpt, a cross-modal audio, holographic projection and mid-air haptic feedback system. During an informal half-day workshop, we observed that HSIs through SoundSculpt have the potential to foster new ways of interaction with sound and to make them accessible to diverse musicians, sound artists and audience.","2020-07-15","2023-07-06 06:06:10","2023-07-06 06:06:10","2023-07-05","1–4","","","","","","Human-Sound Interaction","MOCO '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/ET5W9JV5/Donato et al. - 2020 - Human-Sound Interaction Towards a Human-Centred S.pdf","","","sound affordances; holographic projection; Human-Centere Interaction Design; Human-Sound Interaction; mid-air haptic feedback","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E2BAYD5C","conferencePaper","2022","Temor, Lucas; Husain, Zainab; Coppin, Peter","A cross-modal UX design pedagogy for industrial design","Proceedings of the 17th International Audio Mostly Conference","978-1-4503-9701-8","","10.1145/3561212.3561241","https://dl.acm.org/doi/10.1145/3561212.3561241","Everyday experience is multi-sensory, and user experience (UX) design aims to extend this to interactions with products, services, and designed worlds. However, tools and pedagogies for UX are overwhelmingly visual, whereas human-rights-based accessibility legislation mandates the inclusion of diverse peoples, including blind and partially sighted individuals. Coupling auditory and haptic UX techniques from human-computer interaction with industrial design’s (ID) cross-modal tradition of prototyping physical products fostered our novel cross-modal UX course for second-year ID undergraduates. Affordance-based theories of perception-action and Gestalt principles of perceptual organization were used to inform design in auditory, tactile, and visual sensory modalities situated in a novel pedagogical framework. Each week theoretical models were presented alongside hands-on workshops using the BBC micro:bit, developing computational literacy through cross-modal physical prototyping. Student projects demonstrate an understanding of theory and practice and include auditory and tactile interfaces.","2022-10-10","2023-07-06 06:06:10","2023-07-06 06:06:10","2023-07-05","195–198","","","","","","","AM '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/46CWAF7N/Temor et al. - 2022 - A cross-modal UX design pedagogy for industrial de.pdf","","","user experience; cross-sensory; design education; industrial design","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KIHKN7QM","conferencePaper","2016","Katan, Simon","Using Interactive Machine Learning to Sonify Visually Impaired Dancers' Movement","Proceedings of the 3rd International Symposium on Movement and Computing","978-1-4503-4307-7","","10.1145/2948910.2948960","https://dl.acm.org/doi/10.1145/2948910.2948960","This preliminary research investigates the application of Interactive Machine Learning (IML) to sonify the movements of visually impaired dancers. Using custom wearable devices with localized sound, our observations demonstrate how sonification enables the communication of time-based information about movements such as phrase length and periodicity, and nuanced information such as magnitudes and accelerations. The work raises a number challenges regarding the application of IML to this domain. In particular we identify a need for ensuring even rates of change in regression models when performing sonification and a need for consideration of how to convey machine learning approaches to end users.","2016-07-05","2023-07-06 06:06:10","2023-07-06 06:06:10","2023-07-05","1–4","","","","","","","MOCO '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","ACM Digital Library","","","","/Users/minsik/Zotero/storage/TIK836MZ/Katan - 2016 - Using Interactive Machine Learning to Sonify Visua.pdf","","","Sonification; Dance; Accessible Interfaces; Interactive Machine Learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""