"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"XG82I44D","journalArticle","2022","Foley, Liam; Schlesinger, Joseph; Schutz, Michael","More detectable, less annoying: Temporal variation in amplitude envelope and spectral content improves auditory interface efficacy","The Journal of the Acoustical Society of America","","0001-4966","10.1121/10.0010447","https://doi.org/10.1121/10.0010447","Auditory interfaces, such as auditory alarms, are useful tools for human computer interaction. Unfortunately, poor detectability and annoyance inhibit the efficacy of many interface sounds. Here, it is shown in two ways how moving beyond the traditional simplistic temporal structures of normative interface sounds can significantly improve auditory interface efficacy. First, participants rated tones with percussive amplitude envelopes as significantly less annoying than tones with flat amplitude envelopes. Crucially, this annoyance reduction did not come with a detection cost as percussive tones were detected more often than flat tones—particularly, at relatively low listening levels. Second, it was found that reductions in the duration of a tone's harmonics significantly lowered its annoyance without a commensurate reduction in detection. Together, these findings help inform our theoretical understanding of detection and annoyance of sound. In addition, they offer promising original design considerations for auditory interfaces.","2022-05-12","2023-07-10 06:14:09","2023-07-10 06:14:09","2023-07-10 06:14:09","3189-3196","","5","151","","The Journal of the Acoustical Society of America","More detectable, less annoying","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/7HKF836U/Foley et al. - 2022 - More detectable, less annoying Temporal variation.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2QP3QKBS","journalArticle","2017","Paté, Arthur; Boschi, Lapo; Dubois, Danièle; Le Carrou, Jean-Loïc; Holtzman, Benjamin","Auditory display of seismic data: On the use of experts' categorizations and verbal descriptions as heuristics for geoscience","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.4978441","https://doi.org/10.1121/1.4978441","Auditory display can complement visual representations in order to better interpret scientific data. A previous article showed that the free categorization of “audified seismic signals” operated by listeners can be explained by various geophysical parameters. The present article confirms this result and shows that cognitive representations of listeners can be used as heuristics for the characterization of seismic signals. Free sorting tests are conducted with audified seismic signals, with the earthquake/seismometer relative location, playback audification speed, and earthquake magnitude as controlled variables. The analysis is built on partitions (categories) and verbal comments (categorization criteria). Participants from different backgrounds (acousticians or geoscientists) are contrasted in order to investigate the role of the participants' expertise. Sounds resulting from different earthquake/station distances or azimuths, crustal structure and topography along the path of the seismic wave, earthquake magnitude, are found to (a) be sorted into different categories, (b) elicit different verbal descriptions mainly focused on the perceived number of events, frequency content, and background noise level. Building on these perceptual results, acoustic descriptors are computed and geophysical interpretations are proposed in order to match the verbal descriptions. Another result is the robustness of the categories with respect to the audification speed factor.","2017-03-27","2023-07-10 06:14:16","2023-07-10 06:14:16","2023-07-10 06:14:15","2143-2162","","3","141","","The Journal of the Acoustical Society of America","Auditory display of seismic data","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/KDCGEV2D/Paté et al. - 2017 - Auditory display of seismic data On the use of ex.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SYXCPQGX","journalArticle","2007","Cavaco, Sofia; Lewicki, Michael S.","Statistical modeling of intrinsic structures in impacts sounds","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.2729368","https://doi.org/10.1121/1.2729368","This paper presents a statistical data-driven method for learning intrinsic structures of impact sounds. The method applies principal and independent component analysis to learn low-dimensional representations that model the distribution of both the time-varying spectral and amplitude structure. As a result, the method is able to decompose sounds into a small number of underlying features that characterize acoustic properties such as ringing, resonance, sustain, decay, and onsets. The method is highly flexible and makes no a priori assumptions about the physics, acoustics, or dynamics of the objects. In addition, by modeling the underlying distribution, the method can capture the natural variability of ensembles of related impact sounds.","2007-06-01","2023-07-10 06:14:22","2023-07-10 06:14:22","2023-07-10 06:14:22","3558-3568","","6","121","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/L5R4EUUS/Cavaco and Lewicki - 2007 - Statistical modeling of intrinsic structures in im.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XC7CNJXR","journalArticle","2001","Krishnan, Sridhar; Rangayyan, Rangaraj M.; Bell, G. Douglas; Frank, Cyril B.","Auditory display of knee-joint vibration signals","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.1413995","https://doi.org/10.1121/1.1413995","Sounds generated due to rubbing of knee-joint surfaces may lead to a potential tool for noninvasive assessment of articular cartilage degeneration. In the work reported in the present paper, an attempt is made to perform computer-assisted auscultation of knee joints by auditory display (AD) of vibration signals (also known as vibroarthrographic or VAG signals) emitted during active movement of the leg. Two types of AD methods are considered: audification and sonification. In audification, the VAG signals are scaled in time and frequency using a time-frequency distribution to facilitate aural analysis. In sonification, the instantaneous mean frequency and envelope of the VAG signals are derived and used to synthesize sounds that are expected to facilitate more accurate diagnosis than the original signals by improving their aural quality. Auditory classification experiments were performed by two orthopedic surgeons with 37 VAG signals including 19 normal and 18 abnormal cases. Sensitivity values (correct detection of abnormality) of 31%, 44%, and 83%, and overall classification accuracies of 53%, 40%, and 57% were obtained with the direct playback, audification, and sonification methods, respectively. The corresponding d′ scores were estimated to be 1.10, −0.36, and 0.55. The high sensitivity of the sonification method indicates that the technique could lead to improved detection of knee-joint abnormalities; however, additional work is required to improve its specificity and achieve better overall performance.","2001-12-01","2023-07-10 06:14:29","2023-07-10 06:14:29","2023-07-10 06:14:29","3292-3304","","6","110","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/C4EBPB97/Krishnan et al. - 2001 - Auditory display of knee-joint vibration signals.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JVYXJYAU","journalArticle","2000","Jin, Craig; Schenkel, Markus; Carlile, Simon","Neural system identification model of human sound localization","The Journal of the Acoustical Society of America","","0001-4966","10.1121/1.1288411","https://doi.org/10.1121/1.1288411","This paper examines the role of biological constraints in the human auditory localization process. A psychophysical and neural system modeling approach was undertaken in which performance comparisons between competing models and a human subject explore the relevant biologically plausible “realism constraints.” The directional acoustical cues, upon which sound localization is based, were derived from the human subject’s head-related transfer functions (HRTFs). Sound stimuli were generated by convolving bandpass noise with the HRTFs and were presented to both the subject and the model. The input stimuli to the model were processed using the Auditory Image Model of cochlear processing. The cochlear data were then analyzed by a time-delay neural network which integrated temporal and spectral information to determine the spatial location of the sound source. The combined cochlear model and neural network provided a system model of the sound localization process. Aspects of humanlike localization performance were qualitatively achieved for broadband and bandpass stimuli when the model architecture incorporated frequency division (i.e., the progressive integration of information across the different frequency channels) and was trained using variable bandwidth and center-frequency sounds. Results indicate that both issues are relevant to human sound localization performance.","2000-09-01","2023-07-10 06:14:54","2023-07-10 06:14:54","2023-07-10 06:14:54","1215-1235","","3","108","","The Journal of the Acoustical Society of America","","","","","","","","","","","","","Silverchair","","","","/Users/minsik/Zotero/storage/FYDP78DY/Jin et al. - 2000 - Neural system identification model of human sound .pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""